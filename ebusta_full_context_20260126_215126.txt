=== EBusta Full Project Context: Mon Jan 26 09:51:26 PM MSK 2026 ===

--- SECTION: GIT DIFF (LAST 1 HOUR) ---
diff --git a/Makefile b/Makefile
index 0e0d13d..d2c2d21 100644
--- a/Makefile
+++ b/Makefile
@@ -1,21 +1,36 @@
 # EBusta Project Makefile
-LISP_DIR=./lisp-converter
-TESTS_DIR=./tests
+LISP_DIR=$(shell pwd)/lisp-converter
+GRPC_DIR=$(shell pwd)/grpc
+TESTS_DIR=$(shell pwd)/tests
 
-.PHONY: run-dsl-server test-dsl test-compliance update-docs
+.PHONY: run-dsl-server debug-dsl-server test-dsl test-compliance build-bin clean
 
+# Стандартный тихий запуск
 run-dsl-server:
-	bash $(LISP_DIR)/run_dsl_server.sh
+	./dsl-converter
+
+# Запуск с логами запросов
+debug-dsl-server:
+	./dsl-converter --verbose
+
+build-bin:
+	sbcl --noinform \
+		--eval '(push (truename "$(GRPC_DIR)/") asdf:*central-registry*)' \
+		--eval '(push (truename "$(LISP_DIR)/") asdf:*central-registry*)' \
+		--eval '(ql:quickload :ebusta-search :silent t)' \
+		--load "$(LISP_DIR)/dsl-service.lisp" \
+		--eval '(ebusta-service:build-binary)' \
+		--quit
 
 test-dsl:
 	$(LISP_DIR)/grpcurl -plaintext \
 		-import-path $(LISP_DIR) \
 		-proto $(LISP_DIR)/search.proto \
-		-d '{"raw_query": "(:and (:field \"title\" \"Lisp\") (:field \"author\" \"Serge\"))"}' \
+		-d '{"raw_query": "author:\"Стивен Кинг\" AND title:Куджо"}' \
 		localhost:50052 ebusta.library.v1.MessageConverter/Convert
 
 test-compliance:
 	bash $(TESTS_DIR)/test_compliance.sh
 
-update-docs:
-	bash $(LISP_DIR)/update_api_docs.sh
+clean:
+	rm -f dsl-converter
diff --git a/ebusta_context_20260125_233811.txt b/ebusta_context_20260125_233811.txt
deleted file mode 100644
index c43fad2..0000000
--- a/ebusta_context_20260125_233811.txt
+++ /dev/null
@@ -1,11665 +0,0 @@
-=== EBusta Project Context: Sun Jan 25 11:38:11 PM MSK 2026 ===
-
---- SECTION: GIT DIFF (LAST 1 HOUR) ---
-diff --git a/ebusta_context.txt b/ebusta_context.txt
-deleted file mode 100644
-index 257ba29..0000000
---- a/ebusta_context.txt
-+++ /dev/null
-@@ -1,5744 +0,0 @@
--=== EBusta Project Context: Sun Jan 25 03:46:48 AM MSK 2026 ===
--
----- SECTION: GIT DIFF (LAST 1 HOUR) ---
----- END SECTION: GIT DIFF ---
--
----- START_FILE: ./internal/parser/parser_test.go ---
--package parser
--
--import (
--	"ebusta/api/proto/v1"
--	"testing"
--)
--
--func TestParser(t *testing.T) {
--	tests := []struct {
--		name     string
--		input    string
--		validate func(*testing.T, *libraryv1.SearchQuery)
--	}{
--		{
--			name:  "Simple Any Search",
--			input: "Unix",
--			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
--				f := q.GetFilter()
--				if f == nil || f.Field != "any" || f.Value != "Unix" {
--					t.Errorf("Expected any:Unix, got %+v", f)
--				}
--			},
--		},
--		{
--			name:  "Field Search",
--			input: "author:Кинг",
--			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
--				f := q.GetFilter()
--				if f == nil || f.Field != "author" || f.Value != "Кинг" {
--					t.Errorf("Expected author:Кинг, got %+v", f)
--				}
--			},
--		},
--		{
--			name:  "Logical AND",
--			input: "author:Кинг AND title:Оно",
--			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
--				l := q.GetLogical()
--				if l == nil || l.Op != libraryv1.LogicalOp_AND || len(l.Nodes) != 2 {
--					t.Errorf("Expected AND with 2 nodes, got %+v", l)
--				}
--			},
--		},
--		{
--			name:  "Negation NOT",
--			input: "NOT title:Куджо",
--			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
--				n := q.GetNegation()
--				if n == nil {
--					t.Fatalf("Expected negation node, got nil")
--				}
--				f := n.Node.GetFilter()
--				if f.Field != "title" || f.Value != "Куджо" {
--					t.Errorf("Expected NOT title:Куджо, got %s:%s", f.Field, f.Value)
--				}
--			},
--		},
--		{
--			name:  "Regex Detection",
--			input: "title:/^Unix.*/",
--			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
--				f := q.GetFilter()
--				if f.Operator != libraryv1.Operator_OP_REGEX {
--					t.Errorf("Expected REGEX operator, got %v", f.Operator)
--				}
--			},
--		},
--	}
--
--	for _, tt := range tests {
--		t.Run(tt.name, func(t *testing.T) {
--			p := NewParser(tt.input)
--			query := p.Parse()
--			tt.validate(t, query)
--		})
--	}
--}
--
----- END_FILE: ./internal/parser/parser_test.go ---
--
----- START_FILE: ./internal/parser/lexer.go ---
--package parser
--
--import (
--	"strings"
--)
--
--// ==========================================
--// LEXER DEFINITIONS
--// ==========================================
--
--type TokenType int
--
--const (
--	TOKEN_EOF TokenType = iota
--	TOKEN_ERROR
--	TOKEN_IDENT     // author, title, Кинг
--	TOKEN_STRING    // "Стивен Кинг"
--	TOKEN_COLON     // :
--	TOKEN_AND       // AND
--	TOKEN_OR        // OR
--	TOKEN_NOT       // NOT, -
--	TOKEN_LPAREN    // (
--	TOKEN_RPAREN    // )
--	TOKEN_EQUALS    // =
--	TOKEN_CONTAINS  // ~
--)
--
--type Token struct {
--	Type  TokenType
--	Value string
--	Pos   int
--}
--
--type Lexer struct {
--	input  string
--	pos    int
--	start  int
--	width  int
--	tokens []Token
--}
--
--// newLexer создает лексер (используется в parser.go)
--func newLexer(input string) *Lexer {
--	return &Lexer{input: input}
--}
--
--// NextToken возвращает следующий токен (используется в parser.go)
--func (l *Lexer) NextToken() Token {
--	l.skipWhitespace()
--	if l.pos >= len(l.input) {
--		return Token{Type: TOKEN_EOF}
--	}
--
--	ch := l.input[l.pos]
--
--	switch {
--	case isLetter(ch):
--		return l.scanIdentifier()
--	case ch == '"':
--		return l.scanString()
--	case ch == ':':
--		l.pos++
--		return Token{Type: TOKEN_COLON, Value: ":"}
--	case ch == '(':
--		l.pos++
--		return Token{Type: TOKEN_LPAREN, Value: "("}
--	case ch == ')':
--		l.pos++
--		return Token{Type: TOKEN_RPAREN, Value: ")"}
--	case ch == '-': // Минус как NOT
--		l.pos++
--		return Token{Type: TOKEN_NOT, Value: "-"}
--	case ch == '=':
--		l.pos++
--		return Token{Type: TOKEN_EQUALS, Value: "="}
--	case ch == '~':
--		l.pos++
--		return Token{Type: TOKEN_CONTAINS, Value: "~"}
--	}
--
--	return Token{Type: TOKEN_ERROR, Value: string(ch)}
--}
--
--func (l *Lexer) skipWhitespace() {
--	for l.pos < len(l.input) && (l.input[l.pos] == ' ' || l.input[l.pos] == '\t') {
--		l.pos++
--	}
--}
--
--func (l *Lexer) scanIdentifier() Token {
--	start := l.pos
--	for l.pos < len(l.input) && isLetter(l.input[l.pos]) {
--		l.pos++
--	}
--	lit := l.input[start:l.pos]
--	
--	switch strings.ToUpper(lit) {
--	case "AND":
--		return Token{Type: TOKEN_AND, Value: lit}
--	case "OR":
--		return Token{Type: TOKEN_OR, Value: lit}
--	case "NOT":
--		return Token{Type: TOKEN_NOT, Value: lit}
--	}
--	return Token{Type: TOKEN_IDENT, Value: lit}
--}
--
--func (l *Lexer) scanString() Token {
--	l.pos++ // skip opening quote
--	start := l.pos
--	for l.pos < len(l.input) && l.input[l.pos] != '"' {
--		l.pos++
--	}
--	lit := l.input[start:l.pos]
--	if l.pos < len(l.input) {
--		l.pos++ // skip closing quote
--	}
--	return Token{Type: TOKEN_STRING, Value: lit}
--}
--
--func isLetter(ch byte) bool {
--	return (ch >= 'a' && ch <= 'z') || (ch >= 'A' && ch <= 'Z') || (ch >= '0' && ch <= '9') || ch > 127 || ch == '_' || ch == '.'
--}
--
----- END_FILE: ./internal/parser/lexer.go ---
--
----- START_FILE: ./internal/parser/parser.go ---
--package parser
--
--import (
--	"fmt"
--	"ebusta/api/proto/v1"
--)
--
--// ==========================================
--// PUBLIC API
--// ==========================================
--
--// Parse - точка входа. Создает лексер и парсер.
--func Parse(input string) *libraryv1.SearchQuery {
--	l := newLexer(input)
--	p := newParser(l)
--	return p.parseSearchQuery()
--}
--
--// ==========================================
--// PARSER LOGIC
--// ==========================================
--
--type Parser struct {
--	l       *Lexer
--	curTok  Token
--	peekTok Token
--}
--
--func newParser(l *Lexer) *Parser {
--	p := &Parser{l: l}
--	p.nextToken()
--	p.nextToken()
--	return p
--}
--
--func (p *Parser) nextToken() {
--	p.curTok = p.peekTok
--	p.peekTok = p.l.NextToken()
--}
--
--// Expression -> Term { OR Term }
--func (p *Parser) parseSearchQuery() *libraryv1.SearchQuery {
--	if p.curTok.Type == TOKEN_EOF {
--		return nil
--	}
--	return p.parseExpression()
--}
--
--func (p *Parser) parseExpression() *libraryv1.SearchQuery {
--	left := p.parseTerm()
--
--	for p.curTok.Type == TOKEN_OR {
--		p.nextToken() // eat OR
--		right := p.parseTerm()
--		left = &libraryv1.SearchQuery{
--			Node: &libraryv1.SearchQuery_Logical{
--				Logical: &libraryv1.LogicalNode{
--					Op:    libraryv1.LogicalOp_OR,
--					Nodes: []*libraryv1.SearchQuery{left, right},
--				},
--			},
--		}
--	}
--	return left
--}
--
--// Term -> Factor { AND Factor }
--func (p *Parser) parseTerm() *libraryv1.SearchQuery {
--	left := p.parseFactor()
--
--	for p.curTok.Type == TOKEN_AND {
--		p.nextToken() // eat AND
--		right := p.parseFactor()
--		left = &libraryv1.SearchQuery{
--			Node: &libraryv1.SearchQuery_Logical{
--				Logical: &libraryv1.LogicalNode{
--					Op:    libraryv1.LogicalOp_AND,
--					Nodes: []*libraryv1.SearchQuery{left, right},
--				},
--			},
--		}
--	}
--	return left
--}
--
--// Factor -> ( Expr ) | NOT Factor | Filter
--func (p *Parser) parseFactor() *libraryv1.SearchQuery {
--	switch p.curTok.Type {
--	case TOKEN_LPAREN:
--		p.nextToken() // eat (
--		exp := p.parseExpression()
--		if p.curTok.Type != TOKEN_RPAREN {
--			fmt.Println("Error: expected )") 
--		}
--		p.nextToken() // eat )
--		return exp
--
--	case TOKEN_NOT:
--		p.nextToken() // eat NOT
--		right := p.parseFactor()
--		return &libraryv1.SearchQuery{
--			Node: &libraryv1.SearchQuery_Negation{
--				Negation: &libraryv1.NotNode{
--					Node: right,
--				},
--			},
--		}
--	
--	default:
--		return p.parseFilter()
--	}
--}
--
--// Filter -> IDENT [OP] VALUE
--func (p *Parser) parseFilter() *libraryv1.SearchQuery {
--	if p.curTok.Type == TOKEN_IDENT && (p.peekTok.Type == TOKEN_COLON || p.peekTok.Type == TOKEN_EQUALS || p.peekTok.Type == TOKEN_CONTAINS) {
--		field := p.curTok.Value
--		p.nextToken() // eat field
--		
--		var op libraryv1.Operator
--		switch p.curTok.Type {
--		case TOKEN_COLON:    op = libraryv1.Operator_OP_CONTAINS
--		case TOKEN_EQUALS:   op = libraryv1.Operator_OP_EQUALS
--		case TOKEN_CONTAINS: op = libraryv1.Operator_OP_CONTAINS
--		}
--		
--		p.nextToken() // eat op
--		
--		value := p.curTok.Value
--		p.nextToken() // eat value
--
--		return &libraryv1.SearchQuery{
--			Node: &libraryv1.SearchQuery_Filter{
--				Filter: &libraryv1.FilterNode{
--					Field:    field,
--					Value:    value,
--					Operator: op,
--				},
--			},
--		}
--	}
--
--	// Implicit "any" search
--	val := p.curTok.Value
--	p.nextToken()
--	
--	return &libraryv1.SearchQuery{
--		Node: &libraryv1.SearchQuery_Filter{
--			Filter: &libraryv1.FilterNode{
--				Field:    "any",
--				Value:    val,
--				Operator: libraryv1.Operator_OP_CONTAINS,
--			},
--		},
--	}
--}
--
----- END_FILE: ./internal/parser/parser.go ---
--
----- START_FILE: ./internal/logger/logger.go ---
--package logger
--
--import (
--	"context"
--	"time"
--	"github.com/sirupsen/logrus"
--)
--
--type ctxKey string
--const RequestIDKey ctxKey = "requestId"
--
--func init() {
--	logrus.SetFormatter(&logrus.TextFormatter{
--		FullTimestamp:   true,
--		TimestampFormat: "15:04:05",
--		ForceColors:     true,
--		DisableColors:   false,
--	})
--}
--
--func For(ctx context.Context) *logrus.Entry {
--	id, ok := ctx.Value(RequestIDKey).(string)
--	if !ok {
--		return logrus.NewEntry(logrus.StandardLogger())
--	}
--	return logrus.WithField("request_id", id)
--}
--
--func ContextWithID(ctx context.Context, id string) context.Context {
--	return context.WithValue(ctx, RequestIDKey, id)
--}
--
--func Track(ctx context.Context, msg string) func() {
--	start := time.Now()
--	return func() {
--		dur := time.Since(start)
--		entry := For(ctx).WithField("duration", dur.String())
--		
--		if dur > 500*time.Millisecond {
--			entry.Warnf("%s completed (SLOW)", msg)
--		} else {
--			entry.Infof("%s completed", msg)
--		}
--	}
--}
--
----- END_FILE: ./internal/logger/logger.go ---
--
----- START_FILE: ./internal/metrics/metrics.go ---
--package metrics
--
--import (
--	"github.com/prometheus/client_golang/prometheus"
--	"github.com/prometheus/client_golang/prometheus/promauto"
--)
--
--var (
--	HttpRequestsTotal = promauto.NewCounterVec(prometheus.CounterOpts{
--		Name: "ebusta_gateway_requests_total",
--		Help: "Total number of HTTP requests to gateway",
--	}, []string{"method", "path", "status"})
--
--	HttpRequestDuration = promauto.NewHistogramVec(prometheus.HistogramOpts{
--		Name:    "ebusta_gateway_request_duration_seconds",
--		Help:    "Duration of HTTP requests in seconds",
--		Buckets: prometheus.DefBuckets,
--	}, []string{"path"})
--)
--
----- END_FILE: ./internal/metrics/metrics.go ---
--
----- START_FILE: ./internal/storage/datamanager/config/config.go ---
--package config
--
--import (
--	"time"
--	"github.com/kelseyhightower/envconfig"
--)
--
--type Config struct {
--	BindAddr    string        `env:"BIND_ADDR" default:":8082"`
--	OSScheme    string        `env:"OS_SCHEME" default:"http"`
--	OSHost      string        `env:"OS_HOST" default:"mercury"`
--	OSPort      string        `env:"OS_PORT" default:"9200"`
--	OSIndex     string        `env:"OS_INDEX" default:"ebusta"`
--	ESUser      string        `env:"ES_USER"`
--	ESPass      string        `env:"ES_PASS"`
--	HTTPTimeout time.Duration `env:"HTTP_TIMEOUT" default:"5s"`
--	LogJSON     bool          `env:"LOG_JSON" default:"false"`
--	LogLevel    string        `env:"LOG_LEVEL" default:"INFO"`
--	LogPath     string        `env:"LOG_PATH"` // Default is empty, logs to stdout
--}
--
--func (c *Config) Validate() error {
--	if c.BindAddr == "" {
--		return ErrInvalid("bind address is required")
--	}
--	if c.OSHost == "" || c.OSPort == "" || c.OSIndex == "" {
--		return ErrInvalid("OS_HOST/OS_PORT/OS_INDEX are required")
--	}
--	return nil
--}
--
--type invalidErr string
--func (e invalidErr) Error() string { return string(e) }
--func ErrInvalid(msg string) error { return invalidErr(msg) }
--
--func Load() (Config, error) {
--	var cfg Config
--	if err := envconfig.Process("", &cfg); err != nil {
--		return cfg, err
--	}
--	return cfg, cfg.Validate()
--}
--
----- END_FILE: ./internal/storage/datamanager/config/config.go ---
--
----- START_FILE: ./internal/storage/datamanager/delivery/grpc.go ---
--package delivery
--
--import (
--	"context"
--	"ebusta/api/proto/v1"
--	"ebusta/internal/logger"
--)
--
--type DataManagerServer struct {
--	libraryv1.UnimplementedLibraryServiceServer
--}
--
--// ИСПРАВЛЕНИЕ: Метод должен называться SearchBooks, чтобы соответствовать интерфейсу
--func (s *DataManagerServer) SearchBooks(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
--	// Если логгер еще не настроен, используем простой принт или заглушку
--	if logger.For(ctx) != nil {
--		defer logger.Track(ctx, "Storage: DB Search Operation")()
--	}
--
--	// Моковые данные для теста
--	books := []*libraryv1.Book{
--		{
--			Id:      "101",
--			Title:   "The Art of Unix Programming",
--			Authors: []string{"Eric S. Raymond"},
--		},
--	}
--
--	return &libraryv1.SearchResponse{
--		Books: books,
--		Total: int32(len(books)),
--	}, nil
--}
--
--func (s *DataManagerServer) GetAuthors(ctx context.Context, req *libraryv1.ListRequest) (*libraryv1.ListResponse, error) {
--	return &libraryv1.ListResponse{Items: []string{"King", "Tolkien"}}, nil
--}
--
----- END_FILE: ./internal/storage/datamanager/delivery/grpc.go ---
--
----- START_FILE: ./internal/storage/datamanager/delivery/handlers.go ---
--package delivery
--
--import (
--	"ebusta/api/proto/v1"
--	"encoding/json"
--	"log"
--)
--
--func MapOSResponseToGrpc(body []byte) ([]*libraryv1.Book, int32) {
--	// Total выносим в interface{}, так как OS может вернуть и число, и объект
--	var raw struct {
--		Hits struct {
--			Total interface{} `json:"total"`
--			Hits  []struct {
--				ID     string `json:"_id"`
--				Source struct {
--					Title   string   `json:"title"`
--					Authors []string `json:"authors"`
--				} `json:"_source"`
--			} `json:"hits"`
--		} `json:"hits"`
--	}
--
--	if err := json.Unmarshal(body, &raw); err != nil {
--		log.Printf("❌ DataManager Parsing Error: %v", err)
--		return nil, 0
--	}
--
--	var totalValue int32
--	// Гибкое извлечение Total (поддержка объекта и числа)
--	switch v := raw.Hits.Total.(type) {
--	case float64:
--		totalValue = int32(v)
--	case map[string]interface{}:
--		if val, ok := v["value"].(float64); ok {
--			totalValue = int32(val)
--		}
--	}
--
--	var books []*libraryv1.Book
--	for _, h := range raw.Hits.Hits {
--		// Защита от пустых авторов
--		authors := h.Source.Authors
--		if authors == nil {
--			authors = []string{"Unknown"}
--		}
--		
--		books = append(books, &libraryv1.Book{
--			Id:      h.ID,
--			Title:   h.Source.Title,
--			Authors: authors,
--		})
--	}
--
--	// Если хиты есть, а total 0 (бывает при определенных настройках OS)
--	if totalValue == 0 && len(books) > 0 {
--		totalValue = int32(len(books))
--	}
--
--	return books, totalValue
--}
--
----- END_FILE: ./internal/storage/datamanager/delivery/handlers.go ---
--
----- START_FILE: ./internal/storage/datamanager/shaping/shaping.go ---
--package shaping
--
--import (
--	"encoding/json"
--	"fmt"
--)
--
--// --- Search shaping ---
--type searchHit struct {
--	Source struct {
--		Title   string   `json:"title"`
--		Authors []string `json:"authors"`
--		FileInfo struct {
--			Container string `json:"container"`
--			Filename  string `json:"filename"`
--		} `json:"fileInfo"`
--	} `json:"_source"`
--}
--type searchResp struct {
--	Hits struct {
--		Total struct{ Value int `json:"value"` } `json:"total"`
--		Hits  []searchHit `json:"hits"`
--	} `json:"hits"`
--}
--
--// ShapeSearch flattens OpenSearch hits into a smaller payload.
--func ShapeSearch(data []byte, from, size int) ([]byte, error) {
--	var r searchResp
--	if err := json.Unmarshal(data, &r); err != nil {
--		return nil, fmt.Errorf("decode hits: %w", err)
--	}
--	type item struct {
--		Title    string   `json:"title"`
--		Authors  []string `json:"authors"`
--		Download string   `json:"download,omitempty"`
--	}
--	out := struct {
--		Total    int    `json:"total"`
--		From     int    `json:"from"`
--		Size     int    `json:"size"`
--		NextFrom int    `json:"next_from"`
--		Items    []item `json:"items"`
--	}{
--		Total:    r.Hits.Total.Value,
--		From:     from,
--		Size:     size,
--		NextFrom: from + size,
--		Items:    make([]item, 0, len(r.Hits.Hits)), // ensure [] not null
--	}
--	for _, h := range r.Hits.Hits {
--		dl := ""
--		if h.Source.FileInfo.Container != "" && h.Source.FileInfo.Filename != "" {
--			dl = h.Source.FileInfo.Container + "/" + h.Source.FileInfo.Filename
--		}
--		out.Items = append(out.Items, item{
--			Title:    h.Source.Title,
--			Authors:  h.Source.Authors,
--			Download: dl,
--		})
--	}
--	return json.MarshalIndent(out, "", "  ")
--}
--
--// --- Composite/aggregation shaping (best-effort generic) ---
--type composite struct {
--	AfterKey any `json:"after_key"`
--	Buckets  any `json:"buckets"`
--}
--type aggResp struct {
--	Aggregations map[string]composite `json:"aggregations"`
--}
--
--func ShapeComposite(data []byte) ([]byte, error) {
--	var r aggResp
--	if err := json.Unmarshal(data, &r); err != nil {
--		return nil, fmt.Errorf("decode aggregations: %w", err)
--	}
--	if len(r.Aggregations) == 0 {
--		// pass-through
--		return data, nil
--	}
--	// pick first aggregation
--	for name, c := range r.Aggregations {
--		out := map[string]any{
--			"name":       name,
--			"buckets":    c.Buckets,
--			"after_key":  c.AfterKey,
--		}
--		return json.MarshalIndent(out, "", "  ")
--	}
--	return data, nil
--}
--
----- END_FILE: ./internal/storage/datamanager/shaping/shaping.go ---
--
----- START_FILE: ./internal/storage/datamanager/shaping/shaping_test.go ---
--package shaping
--
--import "testing"
--
--func TestShapeSearch(t *testing.T) {
--	jsonIn := []byte(`{"hits":{"total":{"value":2},"hits":[{"_source":{"title":"A","authors":["X"],"fileInfo":{"container":"c","filename":"a.fb2"}}},{"_source":{"title":"B","authors":["Y"],"fileInfo":{"container":"d","filename":"b.fb2"}}}]}}`)
--	out, err := ShapeSearch(jsonIn, 0, 10)
--	if err != nil { t.Fatalf("unexpected error: %v", err) }
--	mustContain(t, string(out), `"total": 2`)
--	mustContain(t, string(out), `"items": [`)
--	mustContain(t, string(out), `"download": "c/a.fb2"`)
--}
--
--func mustContain(t *testing.T, s, sub string) {
--	t.Helper()
--	if !contains(s, sub) { t.Fatalf("expected substring %q in %s", sub, s) }
--}
--
--func contains(s, sub string) bool { return len(s) >= len(sub) && (s == sub || (len(sub) > 0 && (stringIndex(s, sub) >= 0))) }
--func stringIndex(s, sub string) int {
--	for i := 0; i+len(sub) <= len(s); i++ {
--		if s[i:i+len(sub)] == sub { return i }
--	}
--	return -1
--}
--
----- END_FILE: ./internal/storage/datamanager/shaping/shaping_test.go ---
--
----- START_FILE: ./internal/storage/datamanager/proxy/proxy.go ---
--package proxy
--
--import (
--	"bytes"
--	"context"
--	"encoding/base64"
--	"encoding/json"
--	"fmt"
--	"io"
--	"net/http"
--	"sync"
--	"time"
--
--	"github.com/sirupsen/logrus"
--
--	"ebusta/internal/storage/datamanager/config"
--)
--
--type Proxy struct {
--	cfg     config.Config
--	client  *http.Client
--	logger  *logrus.Logger
--	baseURL string
--	once    sync.Once
--}
--
--func New(cfg config.Config, logger *logrus.Logger) *Proxy {
--	return &Proxy{
--		cfg:    cfg,
--		logger: logger,
--		client: newHTTPClient(cfg),
--	}
--}
--
--func newHTTPClient(cfg config.Config) *http.Client {
--	t := &http.Transport{
--		MaxIdleConns:        100,
--		IdleConnTimeout:     90 * time.Second,
--		DisableCompression:  false,
--		ForceAttemptHTTP2:   true,
--	}
--	return &http.Client{Transport: t, Timeout: cfg.HTTPTimeout}
--}
--
--func (p *Proxy) BaseURL() string {
--	p.once.Do(func() {
--		p.baseURL = fmt.Sprintf("%s://%s:%s/%s/_search/template", p.cfg.OSScheme, p.cfg.OSHost, p.cfg.OSPort, p.cfg.OSIndex)
--	})
--	return p.baseURL
--}
--
--// Structured error envelope
--type ErrorEnvelope struct {
--	Error ErrorBody `json:"error"`
--}
--type ErrorBody struct {
--	Code    string      `json:"code"`
--	Message string      `json:"message"`
--	Details interface{} `json:"details,omitempty"`
--}
--
--func WriteError(w http.ResponseWriter, status int, code, message string, details interface{}) {
--	w.Header().Set("Content-Type", "application/json")
--	w.WriteHeader(status)
--	_ = json.NewEncoder(w).Encode(ErrorEnvelope{
--		Error: ErrorBody{Code: code, Message: message, Details: details},
--	})
--}
--
--// DoTemplate executes a stored template by id with params.
--func (p *Proxy) DoTemplate(ctx context.Context, id string, params map[string]any) ([]byte, int, error) {
--	body := map[string]any{
--		"id":     id,
--		"params": params,
--	}
--	
--	// This now only logs if LOG_LEVEL=DEBUG
--	if p.logger.IsLevelEnabled(logrus.DebugLevel) {
--		p.logger.WithFields(logrus.Fields{
--			"template": id,
--			"params":   params,
--		}).Debug("os.request") // Changed from Info to Debug
--	}
--	
--	buf, err := json.Marshal(body)
--	if err != nil {
--		return nil, 0, fmt.Errorf("marshal body: %w", err)
--	}
--
--	req, err := http.NewRequestWithContext(ctx, http.MethodPost, p.BaseURL(), bytes.NewReader(buf))
--	if err != nil {
--		return nil, 0, fmt.Errorf("failed to create request: %w", err)
--	}
--	req.Header.Set("Content-Type", "application/json")
--	if p.cfg.ESUser != "" || p.cfg.ESPass != "" {
--		req.SetBasicAuth(p.cfg.ESUser, p.cfg.ESPass)
--	}
--
--	res, err := p.client.Do(req)
--	if err != nil {
--		return nil, 0, fmt.Errorf("upstream do: %w", err)
--	}
--	defer res.Body.Close()
--
--	data, _ := io.ReadAll(res.Body)
--	
--	// This now only logs if LOG_LEVEL=DEBUG
--	if p.logger.IsLevelEnabled(logrus.DebugLevel) {
--		p.logger.WithFields(logrus.Fields{
--			"template": id,
--			"status": res.StatusCode,
--			"response_body": string(data),
--		}).Debug("os.response")
--	}
--	
--	return data, res.StatusCode, nil
--}
--
--// DecodeAfter supports raw JSON or base64(JSON).
--func DecodeAfter(s string) (any, error) {
--	if s == "" {
--		return nil, nil
--	}
--	// try raw JSON first
--	var v any
--	if json.Unmarshal([]byte(s), &v) == nil {
--		return v, nil
--	}
--	// try base64
--	b, err := base64.StdEncoding.DecodeString(s)
--	if err != nil {
--		return nil, fmt.Errorf("invalid after (not json or base64): %w", err)
--	}
--	if err := json.Unmarshal(b, &v); err != nil {
--		return nil, fmt.Errorf("invalid after (bad json): %w", err)
--	}
--	return v, nil
--}
--
----- END_FILE: ./internal/storage/datamanager/proxy/proxy.go ---
--
----- START_FILE: ./internal/middleware/logging.go ---
--package middleware
--
--import (
--	"net/http"
--	"time"
--
--	"github.com/sirupsen/logrus"
--)
--
--// RequestLogger logs incoming requests at the INFO level.
--func RequestLogger(log *logrus.Logger) func(http.Handler) http.Handler {
--	return func(next http.Handler) http.Handler {
--		return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
--			start := time.Now()
--			
--			// Serve the request
--			next.ServeHTTP(w, r)
--			
--			// Log the request
--			log.WithFields(logrus.Fields{
--				"method": r.Method,
--				"path":   r.URL.Path,
--//				"query":  r.URL.RawQuery,
--				"query":  r.URL.Query(),
--				"remote": r.RemoteAddr,
--				"agent":  r.UserAgent(),
--				"took":   time.Since(start),
--			}).Info("http.request")
--		})
--	}
--}
--
----- END_FILE: ./internal/middleware/logging.go ---
--
----- START_FILE: ./internal/middleware/middleware.go ---
--package middleware
--
--import (
--	"net/http"
--	"strings"
--)
--
--// CORS allows basic CORS for browser apps.
--func CORS(next http.Handler) http.Handler {
--	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
--		w.Header().Set("Access-Control-Allow-Origin", "*")
--		w.Header().Set("Access-Control-Allow-Methods", "GET,POST,OPTIONS")
--		w.Header().Set("Access-Control-Allow-Headers", "Content-Type,Authorization")
--		if strings.ToUpper(r.Method) == "OPTIONS" {
--			w.WriteHeader(http.StatusNoContent)
--			return
--		}
--		next.ServeHTTP(w, r)
--	})
--}
--
----- END_FILE: ./internal/middleware/middleware.go ---
--
----- START_FILE: ./ebusta.yaml ---
--datamanager:
--  opensearch_url: "http://192.168.1.179:9200"
--  index_name: "flibusta_merged_index"
--  debug: true
--
--orchestrator:
--  storage_addr: "localhost:50051"
--  processor_addr: "localhost:50053"
--
--web:
--  port: 8080
--
----- END_FILE: ./ebusta.yaml ---
--
----- START_FILE: ./api/proto/v1/auth.proto ---
--syntax = "proto3";
--
--package libraryv1;
--
--option go_package = "ebusta/api/proto/v1;libraryv1";
--
--service AuthService {
--  // Проверка доступа пользователя
--  rpc CheckAccess (AccessRequest) returns (AccessResponse);
--}
--
--message AccessRequest {
--  string user_id = 1;      // ID (например, Telegram UID или ник в BBS)
--  string platform = 2;     // Источник (web, telegram, cli, bbs)
--  string trace_id = 3;     // Для сквозного логирования
--}
--
--message AccessResponse {
--  bool allowed = 1;        // Разрешен ли вход
--  string reason = 2;       // Причина отказа
--  string user_role = 3;    // Роль пользователя (admin, family, guest)
--}
--
----- END_FILE: ./api/proto/v1/auth.proto ---
--
----- START_FILE: ./api/proto/v1/library_grpc.pb.go ---
--// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
--// versions:
--// - protoc-gen-go-grpc v1.6.0
--// - protoc             v3.21.12
--// source: api/proto/v1/library.proto
--
--package libraryv1
--
--import (
--	context "context"
--	grpc "google.golang.org/grpc"
--	codes "google.golang.org/grpc/codes"
--	status "google.golang.org/grpc/status"
--)
--
--// This is a compile-time assertion to ensure that this generated file
--// is compatible with the grpc package it is being compiled against.
--// Requires gRPC-Go v1.64.0 or later.
--const _ = grpc.SupportPackageIsVersion9
--
--const (
--	OrchestratorService_Search_FullMethodName = "/libraryv1.OrchestratorService/Search"
--)
--
--// OrchestratorServiceClient is the client API for OrchestratorService service.
--//
--// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
--type OrchestratorServiceClient interface {
--	Search(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
--}
--
--type orchestratorServiceClient struct {
--	cc grpc.ClientConnInterface
--}
--
--func NewOrchestratorServiceClient(cc grpc.ClientConnInterface) OrchestratorServiceClient {
--	return &orchestratorServiceClient{cc}
--}
--
--func (c *orchestratorServiceClient) Search(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
--	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
--	out := new(SearchResponse)
--	err := c.cc.Invoke(ctx, OrchestratorService_Search_FullMethodName, in, out, cOpts...)
--	if err != nil {
--		return nil, err
--	}
--	return out, nil
--}
--
--// OrchestratorServiceServer is the server API for OrchestratorService service.
--// All implementations must embed UnimplementedOrchestratorServiceServer
--// for forward compatibility.
--type OrchestratorServiceServer interface {
--	Search(context.Context, *SearchRequest) (*SearchResponse, error)
--	mustEmbedUnimplementedOrchestratorServiceServer()
--}
--
--// UnimplementedOrchestratorServiceServer must be embedded to have
--// forward compatible implementations.
--//
--// NOTE: this should be embedded by value instead of pointer to avoid a nil
--// pointer dereference when methods are called.
--type UnimplementedOrchestratorServiceServer struct{}
--
--func (UnimplementedOrchestratorServiceServer) Search(context.Context, *SearchRequest) (*SearchResponse, error) {
--	return nil, status.Error(codes.Unimplemented, "method Search not implemented")
--}
--func (UnimplementedOrchestratorServiceServer) mustEmbedUnimplementedOrchestratorServiceServer() {}
--func (UnimplementedOrchestratorServiceServer) testEmbeddedByValue()                             {}
--
--// UnsafeOrchestratorServiceServer may be embedded to opt out of forward compatibility for this service.
--// Use of this interface is not recommended, as added methods to OrchestratorServiceServer will
--// result in compilation errors.
--type UnsafeOrchestratorServiceServer interface {
--	mustEmbedUnimplementedOrchestratorServiceServer()
--}
--
--func RegisterOrchestratorServiceServer(s grpc.ServiceRegistrar, srv OrchestratorServiceServer) {
--	// If the following call panics, it indicates UnimplementedOrchestratorServiceServer was
--	// embedded by pointer and is nil.  This will cause panics if an
--	// unimplemented method is ever invoked, so we test this at initialization
--	// time to prevent it from happening at runtime later due to I/O.
--	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
--		t.testEmbeddedByValue()
--	}
--	s.RegisterService(&OrchestratorService_ServiceDesc, srv)
--}
--
--func _OrchestratorService_Search_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
--	in := new(SearchRequest)
--	if err := dec(in); err != nil {
--		return nil, err
--	}
--	if interceptor == nil {
--		return srv.(OrchestratorServiceServer).Search(ctx, in)
--	}
--	info := &grpc.UnaryServerInfo{
--		Server:     srv,
--		FullMethod: OrchestratorService_Search_FullMethodName,
--	}
--	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
--		return srv.(OrchestratorServiceServer).Search(ctx, req.(*SearchRequest))
--	}
--	return interceptor(ctx, in, info, handler)
--}
--
--// OrchestratorService_ServiceDesc is the grpc.ServiceDesc for OrchestratorService service.
--// It's only intended for direct use with grpc.RegisterService,
--// and not to be introspected or modified (even as a copy)
--var OrchestratorService_ServiceDesc = grpc.ServiceDesc{
--	ServiceName: "libraryv1.OrchestratorService",
--	HandlerType: (*OrchestratorServiceServer)(nil),
--	Methods: []grpc.MethodDesc{
--		{
--			MethodName: "Search",
--			Handler:    _OrchestratorService_Search_Handler,
--		},
--	},
--	Streams:  []grpc.StreamDesc{},
--	Metadata: "api/proto/v1/library.proto",
--}
--
--const (
--	ProcessorService_Process_FullMethodName = "/libraryv1.ProcessorService/Process"
--)
--
--// ProcessorServiceClient is the client API for ProcessorService service.
--//
--// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
--type ProcessorServiceClient interface {
--	Process(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
--}
--
--type processorServiceClient struct {
--	cc grpc.ClientConnInterface
--}
--
--func NewProcessorServiceClient(cc grpc.ClientConnInterface) ProcessorServiceClient {
--	return &processorServiceClient{cc}
--}
--
--func (c *processorServiceClient) Process(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
--	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
--	out := new(SearchResponse)
--	err := c.cc.Invoke(ctx, ProcessorService_Process_FullMethodName, in, out, cOpts...)
--	if err != nil {
--		return nil, err
--	}
--	return out, nil
--}
--
--// ProcessorServiceServer is the server API for ProcessorService service.
--// All implementations must embed UnimplementedProcessorServiceServer
--// for forward compatibility.
--type ProcessorServiceServer interface {
--	Process(context.Context, *SearchRequest) (*SearchResponse, error)
--	mustEmbedUnimplementedProcessorServiceServer()
--}
--
--// UnimplementedProcessorServiceServer must be embedded to have
--// forward compatible implementations.
--//
--// NOTE: this should be embedded by value instead of pointer to avoid a nil
--// pointer dereference when methods are called.
--type UnimplementedProcessorServiceServer struct{}
--
--func (UnimplementedProcessorServiceServer) Process(context.Context, *SearchRequest) (*SearchResponse, error) {
--	return nil, status.Error(codes.Unimplemented, "method Process not implemented")
--}
--func (UnimplementedProcessorServiceServer) mustEmbedUnimplementedProcessorServiceServer() {}
--func (UnimplementedProcessorServiceServer) testEmbeddedByValue()                          {}
--
--// UnsafeProcessorServiceServer may be embedded to opt out of forward compatibility for this service.
--// Use of this interface is not recommended, as added methods to ProcessorServiceServer will
--// result in compilation errors.
--type UnsafeProcessorServiceServer interface {
--	mustEmbedUnimplementedProcessorServiceServer()
--}
--
--func RegisterProcessorServiceServer(s grpc.ServiceRegistrar, srv ProcessorServiceServer) {
--	// If the following call panics, it indicates UnimplementedProcessorServiceServer was
--	// embedded by pointer and is nil.  This will cause panics if an
--	// unimplemented method is ever invoked, so we test this at initialization
--	// time to prevent it from happening at runtime later due to I/O.
--	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
--		t.testEmbeddedByValue()
--	}
--	s.RegisterService(&ProcessorService_ServiceDesc, srv)
--}
--
--func _ProcessorService_Process_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
--	in := new(SearchRequest)
--	if err := dec(in); err != nil {
--		return nil, err
--	}
--	if interceptor == nil {
--		return srv.(ProcessorServiceServer).Process(ctx, in)
--	}
--	info := &grpc.UnaryServerInfo{
--		Server:     srv,
--		FullMethod: ProcessorService_Process_FullMethodName,
--	}
--	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
--		return srv.(ProcessorServiceServer).Process(ctx, req.(*SearchRequest))
--	}
--	return interceptor(ctx, in, info, handler)
--}
--
--// ProcessorService_ServiceDesc is the grpc.ServiceDesc for ProcessorService service.
--// It's only intended for direct use with grpc.RegisterService,
--// and not to be introspected or modified (even as a copy)
--var ProcessorService_ServiceDesc = grpc.ServiceDesc{
--	ServiceName: "libraryv1.ProcessorService",
--	HandlerType: (*ProcessorServiceServer)(nil),
--	Methods: []grpc.MethodDesc{
--		{
--			MethodName: "Process",
--			Handler:    _ProcessorService_Process_Handler,
--		},
--	},
--	Streams:  []grpc.StreamDesc{},
--	Metadata: "api/proto/v1/library.proto",
--}
--
--const (
--	StorageService_SearchBooks_FullMethodName = "/libraryv1.StorageService/SearchBooks"
--)
--
--// StorageServiceClient is the client API for StorageService service.
--//
--// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
--type StorageServiceClient interface {
--	SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
--}
--
--type storageServiceClient struct {
--	cc grpc.ClientConnInterface
--}
--
--func NewStorageServiceClient(cc grpc.ClientConnInterface) StorageServiceClient {
--	return &storageServiceClient{cc}
--}
--
--func (c *storageServiceClient) SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
--	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
--	out := new(SearchResponse)
--	err := c.cc.Invoke(ctx, StorageService_SearchBooks_FullMethodName, in, out, cOpts...)
--	if err != nil {
--		return nil, err
--	}
--	return out, nil
--}
--
--// StorageServiceServer is the server API for StorageService service.
--// All implementations must embed UnimplementedStorageServiceServer
--// for forward compatibility.
--type StorageServiceServer interface {
--	SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error)
--	mustEmbedUnimplementedStorageServiceServer()
--}
--
--// UnimplementedStorageServiceServer must be embedded to have
--// forward compatible implementations.
--//
--// NOTE: this should be embedded by value instead of pointer to avoid a nil
--// pointer dereference when methods are called.
--type UnimplementedStorageServiceServer struct{}
--
--func (UnimplementedStorageServiceServer) SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error) {
--	return nil, status.Error(codes.Unimplemented, "method SearchBooks not implemented")
--}
--func (UnimplementedStorageServiceServer) mustEmbedUnimplementedStorageServiceServer() {}
--func (UnimplementedStorageServiceServer) testEmbeddedByValue()                        {}
--
--// UnsafeStorageServiceServer may be embedded to opt out of forward compatibility for this service.
--// Use of this interface is not recommended, as added methods to StorageServiceServer will
--// result in compilation errors.
--type UnsafeStorageServiceServer interface {
--	mustEmbedUnimplementedStorageServiceServer()
--}
--
--func RegisterStorageServiceServer(s grpc.ServiceRegistrar, srv StorageServiceServer) {
--	// If the following call panics, it indicates UnimplementedStorageServiceServer was
--	// embedded by pointer and is nil.  This will cause panics if an
--	// unimplemented method is ever invoked, so we test this at initialization
--	// time to prevent it from happening at runtime later due to I/O.
--	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
--		t.testEmbeddedByValue()
--	}
--	s.RegisterService(&StorageService_ServiceDesc, srv)
--}
--
--func _StorageService_SearchBooks_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
--	in := new(SearchRequest)
--	if err := dec(in); err != nil {
--		return nil, err
--	}
--	if interceptor == nil {
--		return srv.(StorageServiceServer).SearchBooks(ctx, in)
--	}
--	info := &grpc.UnaryServerInfo{
--		Server:     srv,
--		FullMethod: StorageService_SearchBooks_FullMethodName,
--	}
--	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
--		return srv.(StorageServiceServer).SearchBooks(ctx, req.(*SearchRequest))
--	}
--	return interceptor(ctx, in, info, handler)
--}
--
--// StorageService_ServiceDesc is the grpc.ServiceDesc for StorageService service.
--// It's only intended for direct use with grpc.RegisterService,
--// and not to be introspected or modified (even as a copy)
--var StorageService_ServiceDesc = grpc.ServiceDesc{
--	ServiceName: "libraryv1.StorageService",
--	HandlerType: (*StorageServiceServer)(nil),
--	Methods: []grpc.MethodDesc{
--		{
--			MethodName: "SearchBooks",
--			Handler:    _StorageService_SearchBooks_Handler,
--		},
--	},
--	Streams:  []grpc.StreamDesc{},
--	Metadata: "api/proto/v1/library.proto",
--}
--
--const (
--	AuthService_CheckAccess_FullMethodName = "/libraryv1.AuthService/CheckAccess"
--)
--
--// AuthServiceClient is the client API for AuthService service.
--//
--// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
--type AuthServiceClient interface {
--	CheckAccess(ctx context.Context, in *AccessRequest, opts ...grpc.CallOption) (*AccessResponse, error)
--}
--
--type authServiceClient struct {
--	cc grpc.ClientConnInterface
--}
--
--func NewAuthServiceClient(cc grpc.ClientConnInterface) AuthServiceClient {
--	return &authServiceClient{cc}
--}
--
--func (c *authServiceClient) CheckAccess(ctx context.Context, in *AccessRequest, opts ...grpc.CallOption) (*AccessResponse, error) {
--	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
--	out := new(AccessResponse)
--	err := c.cc.Invoke(ctx, AuthService_CheckAccess_FullMethodName, in, out, cOpts...)
--	if err != nil {
--		return nil, err
--	}
--	return out, nil
--}
--
--// AuthServiceServer is the server API for AuthService service.
--// All implementations must embed UnimplementedAuthServiceServer
--// for forward compatibility.
--type AuthServiceServer interface {
--	CheckAccess(context.Context, *AccessRequest) (*AccessResponse, error)
--	mustEmbedUnimplementedAuthServiceServer()
--}
--
--// UnimplementedAuthServiceServer must be embedded to have
--// forward compatible implementations.
--//
--// NOTE: this should be embedded by value instead of pointer to avoid a nil
--// pointer dereference when methods are called.
--type UnimplementedAuthServiceServer struct{}
--
--func (UnimplementedAuthServiceServer) CheckAccess(context.Context, *AccessRequest) (*AccessResponse, error) {
--	return nil, status.Error(codes.Unimplemented, "method CheckAccess not implemented")
--}
--func (UnimplementedAuthServiceServer) mustEmbedUnimplementedAuthServiceServer() {}
--func (UnimplementedAuthServiceServer) testEmbeddedByValue()                     {}
--
--// UnsafeAuthServiceServer may be embedded to opt out of forward compatibility for this service.
--// Use of this interface is not recommended, as added methods to AuthServiceServer will
--// result in compilation errors.
--type UnsafeAuthServiceServer interface {
--	mustEmbedUnimplementedAuthServiceServer()
--}
--
--func RegisterAuthServiceServer(s grpc.ServiceRegistrar, srv AuthServiceServer) {
--	// If the following call panics, it indicates UnimplementedAuthServiceServer was
--	// embedded by pointer and is nil.  This will cause panics if an
--	// unimplemented method is ever invoked, so we test this at initialization
--	// time to prevent it from happening at runtime later due to I/O.
--	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
--		t.testEmbeddedByValue()
--	}
--	s.RegisterService(&AuthService_ServiceDesc, srv)
--}
--
--func _AuthService_CheckAccess_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
--	in := new(AccessRequest)
--	if err := dec(in); err != nil {
--		return nil, err
--	}
--	if interceptor == nil {
--		return srv.(AuthServiceServer).CheckAccess(ctx, in)
--	}
--	info := &grpc.UnaryServerInfo{
--		Server:     srv,
--		FullMethod: AuthService_CheckAccess_FullMethodName,
--	}
--	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
--		return srv.(AuthServiceServer).CheckAccess(ctx, req.(*AccessRequest))
--	}
--	return interceptor(ctx, in, info, handler)
--}
--
--// AuthService_ServiceDesc is the grpc.ServiceDesc for AuthService service.
--// It's only intended for direct use with grpc.RegisterService,
--// and not to be introspected or modified (even as a copy)
--var AuthService_ServiceDesc = grpc.ServiceDesc{
--	ServiceName: "libraryv1.AuthService",
--	HandlerType: (*AuthServiceServer)(nil),
--	Methods: []grpc.MethodDesc{
--		{
--			MethodName: "CheckAccess",
--			Handler:    _AuthService_CheckAccess_Handler,
--		},
--	},
--	Streams:  []grpc.StreamDesc{},
--	Metadata: "api/proto/v1/library.proto",
--}
--
--const (
--	MessageConverterService_Convert_FullMethodName = "/libraryv1.MessageConverterService/Convert"
--)
--
--// MessageConverterServiceClient is the client API for MessageConverterService service.
--//
--// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
--type MessageConverterServiceClient interface {
--	Convert(ctx context.Context, in *RawInput, opts ...grpc.CallOption) (*UnmarshaledMessage, error)
--}
--
--type messageConverterServiceClient struct {
--	cc grpc.ClientConnInterface
--}
--
--func NewMessageConverterServiceClient(cc grpc.ClientConnInterface) MessageConverterServiceClient {
--	return &messageConverterServiceClient{cc}
--}
--
--func (c *messageConverterServiceClient) Convert(ctx context.Context, in *RawInput, opts ...grpc.CallOption) (*UnmarshaledMessage, error) {
--	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
--	out := new(UnmarshaledMessage)
--	err := c.cc.Invoke(ctx, MessageConverterService_Convert_FullMethodName, in, out, cOpts...)
--	if err != nil {
--		return nil, err
--	}
--	return out, nil
--}
--
--// MessageConverterServiceServer is the server API for MessageConverterService service.
--// All implementations must embed UnimplementedMessageConverterServiceServer
--// for forward compatibility.
--type MessageConverterServiceServer interface {
--	Convert(context.Context, *RawInput) (*UnmarshaledMessage, error)
--	mustEmbedUnimplementedMessageConverterServiceServer()
--}
--
--// UnimplementedMessageConverterServiceServer must be embedded to have
--// forward compatible implementations.
--//
--// NOTE: this should be embedded by value instead of pointer to avoid a nil
--// pointer dereference when methods are called.
--type UnimplementedMessageConverterServiceServer struct{}
--
--func (UnimplementedMessageConverterServiceServer) Convert(context.Context, *RawInput) (*UnmarshaledMessage, error) {
--	return nil, status.Error(codes.Unimplemented, "method Convert not implemented")
--}
--func (UnimplementedMessageConverterServiceServer) mustEmbedUnimplementedMessageConverterServiceServer() {
--}
--func (UnimplementedMessageConverterServiceServer) testEmbeddedByValue() {}
--
--// UnsafeMessageConverterServiceServer may be embedded to opt out of forward compatibility for this service.
--// Use of this interface is not recommended, as added methods to MessageConverterServiceServer will
--// result in compilation errors.
--type UnsafeMessageConverterServiceServer interface {
--	mustEmbedUnimplementedMessageConverterServiceServer()
--}
--
--func RegisterMessageConverterServiceServer(s grpc.ServiceRegistrar, srv MessageConverterServiceServer) {
--	// If the following call panics, it indicates UnimplementedMessageConverterServiceServer was
--	// embedded by pointer and is nil.  This will cause panics if an
--	// unimplemented method is ever invoked, so we test this at initialization
--	// time to prevent it from happening at runtime later due to I/O.
--	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
--		t.testEmbeddedByValue()
--	}
--	s.RegisterService(&MessageConverterService_ServiceDesc, srv)
--}
--
--func _MessageConverterService_Convert_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
--	in := new(RawInput)
--	if err := dec(in); err != nil {
--		return nil, err
--	}
--	if interceptor == nil {
--		return srv.(MessageConverterServiceServer).Convert(ctx, in)
--	}
--	info := &grpc.UnaryServerInfo{
--		Server:     srv,
--		FullMethod: MessageConverterService_Convert_FullMethodName,
--	}
--	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
--		return srv.(MessageConverterServiceServer).Convert(ctx, req.(*RawInput))
--	}
--	return interceptor(ctx, in, info, handler)
--}
--
--// MessageConverterService_ServiceDesc is the grpc.ServiceDesc for MessageConverterService service.
--// It's only intended for direct use with grpc.RegisterService,
--// and not to be introspected or modified (even as a copy)
--var MessageConverterService_ServiceDesc = grpc.ServiceDesc{
--	ServiceName: "libraryv1.MessageConverterService",
--	HandlerType: (*MessageConverterServiceServer)(nil),
--	Methods: []grpc.MethodDesc{
--		{
--			MethodName: "Convert",
--			Handler:    _MessageConverterService_Convert_Handler,
--		},
--	},
--	Streams:  []grpc.StreamDesc{},
--	Metadata: "api/proto/v1/library.proto",
--}
--
--const (
--	LibraryService_SearchBooks_FullMethodName = "/libraryv1.LibraryService/SearchBooks"
--	LibraryService_GetAuthors_FullMethodName  = "/libraryv1.LibraryService/GetAuthors"
--)
--
--// LibraryServiceClient is the client API for LibraryService service.
--//
--// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
--//
--// Legacy
--type LibraryServiceClient interface {
--	SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
--	GetAuthors(ctx context.Context, in *ListRequest, opts ...grpc.CallOption) (*ListResponse, error)
--}
--
--type libraryServiceClient struct {
--	cc grpc.ClientConnInterface
--}
--
--func NewLibraryServiceClient(cc grpc.ClientConnInterface) LibraryServiceClient {
--	return &libraryServiceClient{cc}
--}
--
--func (c *libraryServiceClient) SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
--	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
--	out := new(SearchResponse)
--	err := c.cc.Invoke(ctx, LibraryService_SearchBooks_FullMethodName, in, out, cOpts...)
--	if err != nil {
--		return nil, err
--	}
--	return out, nil
--}
--
--func (c *libraryServiceClient) GetAuthors(ctx context.Context, in *ListRequest, opts ...grpc.CallOption) (*ListResponse, error) {
--	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
--	out := new(ListResponse)
--	err := c.cc.Invoke(ctx, LibraryService_GetAuthors_FullMethodName, in, out, cOpts...)
--	if err != nil {
--		return nil, err
--	}
--	return out, nil
--}
--
--// LibraryServiceServer is the server API for LibraryService service.
--// All implementations must embed UnimplementedLibraryServiceServer
--// for forward compatibility.
--//
--// Legacy
--type LibraryServiceServer interface {
--	SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error)
--	GetAuthors(context.Context, *ListRequest) (*ListResponse, error)
--	mustEmbedUnimplementedLibraryServiceServer()
--}
--
--// UnimplementedLibraryServiceServer must be embedded to have
--// forward compatible implementations.
--//
--// NOTE: this should be embedded by value instead of pointer to avoid a nil
--// pointer dereference when methods are called.
--type UnimplementedLibraryServiceServer struct{}
--
--func (UnimplementedLibraryServiceServer) SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error) {
--	return nil, status.Error(codes.Unimplemented, "method SearchBooks not implemented")
--}
--func (UnimplementedLibraryServiceServer) GetAuthors(context.Context, *ListRequest) (*ListResponse, error) {
--	return nil, status.Error(codes.Unimplemented, "method GetAuthors not implemented")
--}
--func (UnimplementedLibraryServiceServer) mustEmbedUnimplementedLibraryServiceServer() {}
--func (UnimplementedLibraryServiceServer) testEmbeddedByValue()                        {}
--
--// UnsafeLibraryServiceServer may be embedded to opt out of forward compatibility for this service.
--// Use of this interface is not recommended, as added methods to LibraryServiceServer will
--// result in compilation errors.
--type UnsafeLibraryServiceServer interface {
--	mustEmbedUnimplementedLibraryServiceServer()
--}
--
--func RegisterLibraryServiceServer(s grpc.ServiceRegistrar, srv LibraryServiceServer) {
--	// If the following call panics, it indicates UnimplementedLibraryServiceServer was
--	// embedded by pointer and is nil.  This will cause panics if an
--	// unimplemented method is ever invoked, so we test this at initialization
--	// time to prevent it from happening at runtime later due to I/O.
--	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
--		t.testEmbeddedByValue()
--	}
--	s.RegisterService(&LibraryService_ServiceDesc, srv)
--}
--
--func _LibraryService_SearchBooks_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
--	in := new(SearchRequest)
--	if err := dec(in); err != nil {
--		return nil, err
--	}
--	if interceptor == nil {
--		return srv.(LibraryServiceServer).SearchBooks(ctx, in)
--	}
--	info := &grpc.UnaryServerInfo{
--		Server:     srv,
--		FullMethod: LibraryService_SearchBooks_FullMethodName,
--	}
--	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
--		return srv.(LibraryServiceServer).SearchBooks(ctx, req.(*SearchRequest))
--	}
--	return interceptor(ctx, in, info, handler)
--}
--
--func _LibraryService_GetAuthors_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
--	in := new(ListRequest)
--	if err := dec(in); err != nil {
--		return nil, err
--	}
--	if interceptor == nil {
--		return srv.(LibraryServiceServer).GetAuthors(ctx, in)
--	}
--	info := &grpc.UnaryServerInfo{
--		Server:     srv,
--		FullMethod: LibraryService_GetAuthors_FullMethodName,
--	}
--	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
--		return srv.(LibraryServiceServer).GetAuthors(ctx, req.(*ListRequest))
--	}
--	return interceptor(ctx, in, info, handler)
--}
--
--// LibraryService_ServiceDesc is the grpc.ServiceDesc for LibraryService service.
--// It's only intended for direct use with grpc.RegisterService,
--// and not to be introspected or modified (even as a copy)
--var LibraryService_ServiceDesc = grpc.ServiceDesc{
--	ServiceName: "libraryv1.LibraryService",
--	HandlerType: (*LibraryServiceServer)(nil),
--	Methods: []grpc.MethodDesc{
--		{
--			MethodName: "SearchBooks",
--			Handler:    _LibraryService_SearchBooks_Handler,
--		},
--		{
--			MethodName: "GetAuthors",
--			Handler:    _LibraryService_GetAuthors_Handler,
--		},
--	},
--	Streams:  []grpc.StreamDesc{},
--	Metadata: "api/proto/v1/library.proto",
--}
--
----- END_FILE: ./api/proto/v1/library_grpc.pb.go ---
--
----- START_FILE: ./api/proto/v1/library.pb.go ---
--// Code generated by protoc-gen-go. DO NOT EDIT.
--// versions:
--// 	protoc-gen-go v1.36.11
--// 	protoc        v3.21.12
--// source: api/proto/v1/library.proto
--
--package libraryv1
--
--import (
--	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
--	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
--	reflect "reflect"
--	sync "sync"
--	unsafe "unsafe"
--)
--
--const (
--	// Verify that this generated code is sufficiently up-to-date.
--	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
--	// Verify that runtime/protoimpl is sufficiently up-to-date.
--	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
--)
--
--type LogicalOp int32
--
--const (
--	LogicalOp_AND LogicalOp = 0
--	LogicalOp_OR  LogicalOp = 1
--	LogicalOp_NOT LogicalOp = 2
--)
--
--// Enum value maps for LogicalOp.
--var (
--	LogicalOp_name = map[int32]string{
--		0: "AND",
--		1: "OR",
--		2: "NOT",
--	}
--	LogicalOp_value = map[string]int32{
--		"AND": 0,
--		"OR":  1,
--		"NOT": 2,
--	}
--)
--
--func (x LogicalOp) Enum() *LogicalOp {
--	p := new(LogicalOp)
--	*p = x
--	return p
--}
--
--func (x LogicalOp) String() string {
--	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
--}
--
--func (LogicalOp) Descriptor() protoreflect.EnumDescriptor {
--	return file_api_proto_v1_library_proto_enumTypes[0].Descriptor()
--}
--
--func (LogicalOp) Type() protoreflect.EnumType {
--	return &file_api_proto_v1_library_proto_enumTypes[0]
--}
--
--func (x LogicalOp) Number() protoreflect.EnumNumber {
--	return protoreflect.EnumNumber(x)
--}
--
--// Deprecated: Use LogicalOp.Descriptor instead.
--func (LogicalOp) EnumDescriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{0}
--}
--
--type Operator int32
--
--const (
--	Operator_OP_EQUALS   Operator = 0
--	Operator_OP_CONTAINS Operator = 1
--	Operator_OP_REGEX    Operator = 2
--)
--
--// Enum value maps for Operator.
--var (
--	Operator_name = map[int32]string{
--		0: "OP_EQUALS",
--		1: "OP_CONTAINS",
--		2: "OP_REGEX",
--	}
--	Operator_value = map[string]int32{
--		"OP_EQUALS":   0,
--		"OP_CONTAINS": 1,
--		"OP_REGEX":    2,
--	}
--)
--
--func (x Operator) Enum() *Operator {
--	p := new(Operator)
--	*p = x
--	return p
--}
--
--func (x Operator) String() string {
--	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
--}
--
--func (Operator) Descriptor() protoreflect.EnumDescriptor {
--	return file_api_proto_v1_library_proto_enumTypes[1].Descriptor()
--}
--
--func (Operator) Type() protoreflect.EnumType {
--	return &file_api_proto_v1_library_proto_enumTypes[1]
--}
--
--func (x Operator) Number() protoreflect.EnumNumber {
--	return protoreflect.EnumNumber(x)
--}
--
--// Deprecated: Use Operator.Descriptor instead.
--func (Operator) EnumDescriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{1}
--}
--
--type SearchRequest struct {
--	state         protoimpl.MessageState `protogen:"open.v1"`
--	Query         string                 `protobuf:"bytes,1,opt,name=query,proto3" json:"query,omitempty"`
--	TemplateId    string                 `protobuf:"bytes,2,opt,name=template_id,json=templateId,proto3" json:"template_id,omitempty"`
--	Limit         int32                  `protobuf:"varint,3,opt,name=limit,proto3" json:"limit,omitempty"`
--	Offset        int32                  `protobuf:"varint,4,opt,name=offset,proto3" json:"offset,omitempty"`
--	TraceId       string                 `protobuf:"bytes,5,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *SearchRequest) Reset() {
--	*x = SearchRequest{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[0]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *SearchRequest) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*SearchRequest) ProtoMessage() {}
--
--func (x *SearchRequest) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[0]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use SearchRequest.ProtoReflect.Descriptor instead.
--func (*SearchRequest) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{0}
--}
--
--func (x *SearchRequest) GetQuery() string {
--	if x != nil {
--		return x.Query
--	}
--	return ""
--}
--
--func (x *SearchRequest) GetTemplateId() string {
--	if x != nil {
--		return x.TemplateId
--	}
--	return ""
--}
--
--func (x *SearchRequest) GetLimit() int32 {
--	if x != nil {
--		return x.Limit
--	}
--	return 0
--}
--
--func (x *SearchRequest) GetOffset() int32 {
--	if x != nil {
--		return x.Offset
--	}
--	return 0
--}
--
--func (x *SearchRequest) GetTraceId() string {
--	if x != nil {
--		return x.TraceId
--	}
--	return ""
--}
--
--type SearchResponse struct {
--	state         protoimpl.MessageState `protogen:"open.v1"`
--	Status        string                 `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
--	Total         int32                  `protobuf:"varint,2,opt,name=total,proto3" json:"total,omitempty"`
--	Books         []*Book                `protobuf:"bytes,3,rep,name=books,proto3" json:"books,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *SearchResponse) Reset() {
--	*x = SearchResponse{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[1]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *SearchResponse) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*SearchResponse) ProtoMessage() {}
--
--func (x *SearchResponse) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[1]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use SearchResponse.ProtoReflect.Descriptor instead.
--func (*SearchResponse) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{1}
--}
--
--func (x *SearchResponse) GetStatus() string {
--	if x != nil {
--		return x.Status
--	}
--	return ""
--}
--
--func (x *SearchResponse) GetTotal() int32 {
--	if x != nil {
--		return x.Total
--	}
--	return 0
--}
--
--func (x *SearchResponse) GetBooks() []*Book {
--	if x != nil {
--		return x.Books
--	}
--	return nil
--}
--
--type Book struct {
--	state         protoimpl.MessageState `protogen:"open.v1"`
--	Id            string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
--	Title         string                 `protobuf:"bytes,2,opt,name=title,proto3" json:"title,omitempty"`
--	Authors       []string               `protobuf:"bytes,3,rep,name=authors,proto3" json:"authors,omitempty"`
--	Container     string                 `protobuf:"bytes,4,opt,name=container,proto3" json:"container,omitempty"`
--	Filename      string                 `protobuf:"bytes,5,opt,name=filename,proto3" json:"filename,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *Book) Reset() {
--	*x = Book{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[2]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *Book) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*Book) ProtoMessage() {}
--
--func (x *Book) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[2]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use Book.ProtoReflect.Descriptor instead.
--func (*Book) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{2}
--}
--
--func (x *Book) GetId() string {
--	if x != nil {
--		return x.Id
--	}
--	return ""
--}
--
--func (x *Book) GetTitle() string {
--	if x != nil {
--		return x.Title
--	}
--	return ""
--}
--
--func (x *Book) GetAuthors() []string {
--	if x != nil {
--		return x.Authors
--	}
--	return nil
--}
--
--func (x *Book) GetContainer() string {
--	if x != nil {
--		return x.Container
--	}
--	return ""
--}
--
--func (x *Book) GetFilename() string {
--	if x != nil {
--		return x.Filename
--	}
--	return ""
--}
--
--type ListRequest struct {
--	state         protoimpl.MessageState `protogen:"open.v1"`
--	Query         string                 `protobuf:"bytes,1,opt,name=query,proto3" json:"query,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *ListRequest) Reset() {
--	*x = ListRequest{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[3]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *ListRequest) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*ListRequest) ProtoMessage() {}
--
--func (x *ListRequest) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[3]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use ListRequest.ProtoReflect.Descriptor instead.
--func (*ListRequest) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{3}
--}
--
--func (x *ListRequest) GetQuery() string {
--	if x != nil {
--		return x.Query
--	}
--	return ""
--}
--
--type ListResponse struct {
--	state         protoimpl.MessageState `protogen:"open.v1"`
--	Items         []string               `protobuf:"bytes,1,rep,name=items,proto3" json:"items,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *ListResponse) Reset() {
--	*x = ListResponse{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[4]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *ListResponse) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*ListResponse) ProtoMessage() {}
--
--func (x *ListResponse) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[4]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use ListResponse.ProtoReflect.Descriptor instead.
--func (*ListResponse) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{4}
--}
--
--func (x *ListResponse) GetItems() []string {
--	if x != nil {
--		return x.Items
--	}
--	return nil
--}
--
--type AccessRequest struct {
--	state         protoimpl.MessageState `protogen:"open.v1"`
--	UserId        string                 `protobuf:"bytes,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`
--	Platform      string                 `protobuf:"bytes,2,opt,name=platform,proto3" json:"platform,omitempty"`
--	TraceId       string                 `protobuf:"bytes,3,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *AccessRequest) Reset() {
--	*x = AccessRequest{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[5]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *AccessRequest) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*AccessRequest) ProtoMessage() {}
--
--func (x *AccessRequest) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[5]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use AccessRequest.ProtoReflect.Descriptor instead.
--func (*AccessRequest) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{5}
--}
--
--func (x *AccessRequest) GetUserId() string {
--	if x != nil {
--		return x.UserId
--	}
--	return ""
--}
--
--func (x *AccessRequest) GetPlatform() string {
--	if x != nil {
--		return x.Platform
--	}
--	return ""
--}
--
--func (x *AccessRequest) GetTraceId() string {
--	if x != nil {
--		return x.TraceId
--	}
--	return ""
--}
--
--type AccessResponse struct {
--	state         protoimpl.MessageState `protogen:"open.v1"`
--	Allowed       bool                   `protobuf:"varint,1,opt,name=allowed,proto3" json:"allowed,omitempty"`
--	Reason        string                 `protobuf:"bytes,2,opt,name=reason,proto3" json:"reason,omitempty"`
--	UserRole      string                 `protobuf:"bytes,3,opt,name=user_role,json=userRole,proto3" json:"user_role,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *AccessResponse) Reset() {
--	*x = AccessResponse{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[6]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *AccessResponse) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*AccessResponse) ProtoMessage() {}
--
--func (x *AccessResponse) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[6]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use AccessResponse.ProtoReflect.Descriptor instead.
--func (*AccessResponse) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{6}
--}
--
--func (x *AccessResponse) GetAllowed() bool {
--	if x != nil {
--		return x.Allowed
--	}
--	return false
--}
--
--func (x *AccessResponse) GetReason() string {
--	if x != nil {
--		return x.Reason
--	}
--	return ""
--}
--
--func (x *AccessResponse) GetUserRole() string {
--	if x != nil {
--		return x.UserRole
--	}
--	return ""
--}
--
--type RawInput struct {
--	state protoimpl.MessageState `protogen:"open.v1"`
--	// Исправлено: переименовано в 'data', чтобы появился метод GetData(), который ждет message-converter
--	Data          string `protobuf:"bytes,1,opt,name=data,proto3" json:"data,omitempty"`
--	TraceId       string `protobuf:"bytes,2,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *RawInput) Reset() {
--	*x = RawInput{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[7]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *RawInput) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*RawInput) ProtoMessage() {}
--
--func (x *RawInput) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[7]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use RawInput.ProtoReflect.Descriptor instead.
--func (*RawInput) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{7}
--}
--
--func (x *RawInput) GetData() string {
--	if x != nil {
--		return x.Data
--	}
--	return ""
--}
--
--func (x *RawInput) GetTraceId() string {
--	if x != nil {
--		return x.TraceId
--	}
--	return ""
--}
--
--type MessageMeta struct {
--	state         protoimpl.MessageState `protogen:"open.v1"`
--	TraceId       string                 `protobuf:"bytes,1,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
--	CanonicalForm string                 `protobuf:"bytes,2,opt,name=canonical_form,json=canonicalForm,proto3" json:"canonical_form,omitempty"`
--	Platform      string                 `protobuf:"bytes,3,opt,name=platform,proto3" json:"platform,omitempty"`
--	UserId        string                 `protobuf:"bytes,4,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`
--	// Исправлено: добавлено поле, которое требует message-converter
--	AstPlan       string `protobuf:"bytes,5,opt,name=ast_plan,json=astPlan,proto3" json:"ast_plan,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *MessageMeta) Reset() {
--	*x = MessageMeta{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[8]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *MessageMeta) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*MessageMeta) ProtoMessage() {}
--
--func (x *MessageMeta) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[8]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use MessageMeta.ProtoReflect.Descriptor instead.
--func (*MessageMeta) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{8}
--}
--
--func (x *MessageMeta) GetTraceId() string {
--	if x != nil {
--		return x.TraceId
--	}
--	return ""
--}
--
--func (x *MessageMeta) GetCanonicalForm() string {
--	if x != nil {
--		return x.CanonicalForm
--	}
--	return ""
--}
--
--func (x *MessageMeta) GetPlatform() string {
--	if x != nil {
--		return x.Platform
--	}
--	return ""
--}
--
--func (x *MessageMeta) GetUserId() string {
--	if x != nil {
--		return x.UserId
--	}
--	return ""
--}
--
--func (x *MessageMeta) GetAstPlan() string {
--	if x != nil {
--		return x.AstPlan
--	}
--	return ""
--}
--
--type UnmarshaledMessage struct {
--	state         protoimpl.MessageState `protogen:"open.v1"`
--	Meta          *MessageMeta           `protobuf:"bytes,1,opt,name=meta,proto3" json:"meta,omitempty"`
--	Query         *SearchQuery           `protobuf:"bytes,2,opt,name=query,proto3" json:"query,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *UnmarshaledMessage) Reset() {
--	*x = UnmarshaledMessage{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[9]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *UnmarshaledMessage) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*UnmarshaledMessage) ProtoMessage() {}
--
--func (x *UnmarshaledMessage) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[9]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use UnmarshaledMessage.ProtoReflect.Descriptor instead.
--func (*UnmarshaledMessage) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{9}
--}
--
--func (x *UnmarshaledMessage) GetMeta() *MessageMeta {
--	if x != nil {
--		return x.Meta
--	}
--	return nil
--}
--
--func (x *UnmarshaledMessage) GetQuery() *SearchQuery {
--	if x != nil {
--		return x.Query
--	}
--	return nil
--}
--
--type Response struct {
--	state         protoimpl.MessageState `protogen:"open.v1"`
--	Status        string                 `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
--	Books         []*Book                `protobuf:"bytes,2,rep,name=books,proto3" json:"books,omitempty"`
--	Meta          *ResponseMeta          `protobuf:"bytes,3,opt,name=meta,proto3" json:"meta,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *Response) Reset() {
--	*x = Response{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[10]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *Response) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*Response) ProtoMessage() {}
--
--func (x *Response) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[10]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use Response.ProtoReflect.Descriptor instead.
--func (*Response) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{10}
--}
--
--func (x *Response) GetStatus() string {
--	if x != nil {
--		return x.Status
--	}
--	return ""
--}
--
--func (x *Response) GetBooks() []*Book {
--	if x != nil {
--		return x.Books
--	}
--	return nil
--}
--
--func (x *Response) GetMeta() *ResponseMeta {
--	if x != nil {
--		return x.Meta
--	}
--	return nil
--}
--
--type ResponseMeta struct {
--	state         protoimpl.MessageState `protogen:"open.v1"`
--	TraceId       string                 `protobuf:"bytes,1,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
--	CanonicalForm string                 `protobuf:"bytes,2,opt,name=canonical_form,json=canonicalForm,proto3" json:"canonical_form,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *ResponseMeta) Reset() {
--	*x = ResponseMeta{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[11]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *ResponseMeta) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*ResponseMeta) ProtoMessage() {}
--
--func (x *ResponseMeta) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[11]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use ResponseMeta.ProtoReflect.Descriptor instead.
--func (*ResponseMeta) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{11}
--}
--
--func (x *ResponseMeta) GetTraceId() string {
--	if x != nil {
--		return x.TraceId
--	}
--	return ""
--}
--
--func (x *ResponseMeta) GetCanonicalForm() string {
--	if x != nil {
--		return x.CanonicalForm
--	}
--	return ""
--}
--
--type SearchQuery struct {
--	state protoimpl.MessageState `protogen:"open.v1"`
--	// Types that are valid to be assigned to Node:
--	//
--	//	*SearchQuery_Filter
--	//	*SearchQuery_Logical
--	//	*SearchQuery_Negation
--	Node          isSearchQuery_Node `protobuf_oneof:"node"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *SearchQuery) Reset() {
--	*x = SearchQuery{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[12]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *SearchQuery) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*SearchQuery) ProtoMessage() {}
--
--func (x *SearchQuery) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[12]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use SearchQuery.ProtoReflect.Descriptor instead.
--func (*SearchQuery) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{12}
--}
--
--func (x *SearchQuery) GetNode() isSearchQuery_Node {
--	if x != nil {
--		return x.Node
--	}
--	return nil
--}
--
--func (x *SearchQuery) GetFilter() *FilterNode {
--	if x != nil {
--		if x, ok := x.Node.(*SearchQuery_Filter); ok {
--			return x.Filter
--		}
--	}
--	return nil
--}
--
--func (x *SearchQuery) GetLogical() *LogicalNode {
--	if x != nil {
--		if x, ok := x.Node.(*SearchQuery_Logical); ok {
--			return x.Logical
--		}
--	}
--	return nil
--}
--
--func (x *SearchQuery) GetNegation() *NotNode {
--	if x != nil {
--		if x, ok := x.Node.(*SearchQuery_Negation); ok {
--			return x.Negation
--		}
--	}
--	return nil
--}
--
--type isSearchQuery_Node interface {
--	isSearchQuery_Node()
--}
--
--type SearchQuery_Filter struct {
--	Filter *FilterNode `protobuf:"bytes,1,opt,name=filter,proto3,oneof"`
--}
--
--type SearchQuery_Logical struct {
--	Logical *LogicalNode `protobuf:"bytes,2,opt,name=logical,proto3,oneof"`
--}
--
--type SearchQuery_Negation struct {
--	Negation *NotNode `protobuf:"bytes,3,opt,name=negation,proto3,oneof"`
--}
--
--func (*SearchQuery_Filter) isSearchQuery_Node() {}
--
--func (*SearchQuery_Logical) isSearchQuery_Node() {}
--
--func (*SearchQuery_Negation) isSearchQuery_Node() {}
--
--type FilterNode struct {
--	state         protoimpl.MessageState `protogen:"open.v1"`
--	Field         string                 `protobuf:"bytes,1,opt,name=field,proto3" json:"field,omitempty"`
--	Value         string                 `protobuf:"bytes,2,opt,name=value,proto3" json:"value,omitempty"`
--	Operator      Operator               `protobuf:"varint,3,opt,name=operator,proto3,enum=libraryv1.Operator" json:"operator,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *FilterNode) Reset() {
--	*x = FilterNode{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[13]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *FilterNode) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*FilterNode) ProtoMessage() {}
--
--func (x *FilterNode) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[13]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use FilterNode.ProtoReflect.Descriptor instead.
--func (*FilterNode) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{13}
--}
--
--func (x *FilterNode) GetField() string {
--	if x != nil {
--		return x.Field
--	}
--	return ""
--}
--
--func (x *FilterNode) GetValue() string {
--	if x != nil {
--		return x.Value
--	}
--	return ""
--}
--
--func (x *FilterNode) GetOperator() Operator {
--	if x != nil {
--		return x.Operator
--	}
--	return Operator_OP_EQUALS
--}
--
--type LogicalNode struct {
--	state         protoimpl.MessageState `protogen:"open.v1"`
--	Op            LogicalOp              `protobuf:"varint,1,opt,name=op,proto3,enum=libraryv1.LogicalOp" json:"op,omitempty"`
--	Nodes         []*SearchQuery         `protobuf:"bytes,2,rep,name=nodes,proto3" json:"nodes,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *LogicalNode) Reset() {
--	*x = LogicalNode{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[14]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *LogicalNode) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*LogicalNode) ProtoMessage() {}
--
--func (x *LogicalNode) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[14]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use LogicalNode.ProtoReflect.Descriptor instead.
--func (*LogicalNode) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{14}
--}
--
--func (x *LogicalNode) GetOp() LogicalOp {
--	if x != nil {
--		return x.Op
--	}
--	return LogicalOp_AND
--}
--
--func (x *LogicalNode) GetNodes() []*SearchQuery {
--	if x != nil {
--		return x.Nodes
--	}
--	return nil
--}
--
--type NotNode struct {
--	state protoimpl.MessageState `protogen:"open.v1"`
--	// Важно: имя поля 'node' генерирует поле 'Node' в Go структуре, что нужно парсеру
--	Node          *SearchQuery `protobuf:"bytes,1,opt,name=node,proto3" json:"node,omitempty"`
--	unknownFields protoimpl.UnknownFields
--	sizeCache     protoimpl.SizeCache
--}
--
--func (x *NotNode) Reset() {
--	*x = NotNode{}
--	mi := &file_api_proto_v1_library_proto_msgTypes[15]
--	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--	ms.StoreMessageInfo(mi)
--}
--
--func (x *NotNode) String() string {
--	return protoimpl.X.MessageStringOf(x)
--}
--
--func (*NotNode) ProtoMessage() {}
--
--func (x *NotNode) ProtoReflect() protoreflect.Message {
--	mi := &file_api_proto_v1_library_proto_msgTypes[15]
--	if x != nil {
--		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
--		if ms.LoadMessageInfo() == nil {
--			ms.StoreMessageInfo(mi)
--		}
--		return ms
--	}
--	return mi.MessageOf(x)
--}
--
--// Deprecated: Use NotNode.ProtoReflect.Descriptor instead.
--func (*NotNode) Descriptor() ([]byte, []int) {
--	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{15}
--}
--
--func (x *NotNode) GetNode() *SearchQuery {
--	if x != nil {
--		return x.Node
--	}
--	return nil
--}
--
--var File_api_proto_v1_library_proto protoreflect.FileDescriptor
--
--const file_api_proto_v1_library_proto_rawDesc = "" +
--	"\n" +
--	"\x1aapi/proto/v1/library.proto\x12\tlibraryv1\"\x8f\x01\n" +
--	"\rSearchRequest\x12\x14\n" +
--	"\x05query\x18\x01 \x01(\tR\x05query\x12\x1f\n" +
--	"\vtemplate_id\x18\x02 \x01(\tR\n" +
--	"templateId\x12\x14\n" +
--	"\x05limit\x18\x03 \x01(\x05R\x05limit\x12\x16\n" +
--	"\x06offset\x18\x04 \x01(\x05R\x06offset\x12\x19\n" +
--	"\btrace_id\x18\x05 \x01(\tR\atraceId\"e\n" +
--	"\x0eSearchResponse\x12\x16\n" +
--	"\x06status\x18\x01 \x01(\tR\x06status\x12\x14\n" +
--	"\x05total\x18\x02 \x01(\x05R\x05total\x12%\n" +
--	"\x05books\x18\x03 \x03(\v2\x0f.libraryv1.BookR\x05books\"\x80\x01\n" +
--	"\x04Book\x12\x0e\n" +
--	"\x02id\x18\x01 \x01(\tR\x02id\x12\x14\n" +
--	"\x05title\x18\x02 \x01(\tR\x05title\x12\x18\n" +
--	"\aauthors\x18\x03 \x03(\tR\aauthors\x12\x1c\n" +
--	"\tcontainer\x18\x04 \x01(\tR\tcontainer\x12\x1a\n" +
--	"\bfilename\x18\x05 \x01(\tR\bfilename\"#\n" +
--	"\vListRequest\x12\x14\n" +
--	"\x05query\x18\x01 \x01(\tR\x05query\"$\n" +
--	"\fListResponse\x12\x14\n" +
--	"\x05items\x18\x01 \x03(\tR\x05items\"_\n" +
--	"\rAccessRequest\x12\x17\n" +
--	"\auser_id\x18\x01 \x01(\tR\x06userId\x12\x1a\n" +
--	"\bplatform\x18\x02 \x01(\tR\bplatform\x12\x19\n" +
--	"\btrace_id\x18\x03 \x01(\tR\atraceId\"_\n" +
--	"\x0eAccessResponse\x12\x18\n" +
--	"\aallowed\x18\x01 \x01(\bR\aallowed\x12\x16\n" +
--	"\x06reason\x18\x02 \x01(\tR\x06reason\x12\x1b\n" +
--	"\tuser_role\x18\x03 \x01(\tR\buserRole\"9\n" +
--	"\bRawInput\x12\x12\n" +
--	"\x04data\x18\x01 \x01(\tR\x04data\x12\x19\n" +
--	"\btrace_id\x18\x02 \x01(\tR\atraceId\"\x9f\x01\n" +
--	"\vMessageMeta\x12\x19\n" +
--	"\btrace_id\x18\x01 \x01(\tR\atraceId\x12%\n" +
--	"\x0ecanonical_form\x18\x02 \x01(\tR\rcanonicalForm\x12\x1a\n" +
--	"\bplatform\x18\x03 \x01(\tR\bplatform\x12\x17\n" +
--	"\auser_id\x18\x04 \x01(\tR\x06userId\x12\x19\n" +
--	"\bast_plan\x18\x05 \x01(\tR\aastPlan\"n\n" +
--	"\x12UnmarshaledMessage\x12*\n" +
--	"\x04meta\x18\x01 \x01(\v2\x16.libraryv1.MessageMetaR\x04meta\x12,\n" +
--	"\x05query\x18\x02 \x01(\v2\x16.libraryv1.SearchQueryR\x05query\"v\n" +
--	"\bResponse\x12\x16\n" +
--	"\x06status\x18\x01 \x01(\tR\x06status\x12%\n" +
--	"\x05books\x18\x02 \x03(\v2\x0f.libraryv1.BookR\x05books\x12+\n" +
--	"\x04meta\x18\x03 \x01(\v2\x17.libraryv1.ResponseMetaR\x04meta\"P\n" +
--	"\fResponseMeta\x12\x19\n" +
--	"\btrace_id\x18\x01 \x01(\tR\atraceId\x12%\n" +
--	"\x0ecanonical_form\x18\x02 \x01(\tR\rcanonicalForm\"\xac\x01\n" +
--	"\vSearchQuery\x12/\n" +
--	"\x06filter\x18\x01 \x01(\v2\x15.libraryv1.FilterNodeH\x00R\x06filter\x122\n" +
--	"\alogical\x18\x02 \x01(\v2\x16.libraryv1.LogicalNodeH\x00R\alogical\x120\n" +
--	"\bnegation\x18\x03 \x01(\v2\x12.libraryv1.NotNodeH\x00R\bnegationB\x06\n" +
--	"\x04node\"i\n" +
--	"\n" +
--	"FilterNode\x12\x14\n" +
--	"\x05field\x18\x01 \x01(\tR\x05field\x12\x14\n" +
--	"\x05value\x18\x02 \x01(\tR\x05value\x12/\n" +
--	"\boperator\x18\x03 \x01(\x0e2\x13.libraryv1.OperatorR\boperator\"a\n" +
--	"\vLogicalNode\x12$\n" +
--	"\x02op\x18\x01 \x01(\x0e2\x14.libraryv1.LogicalOpR\x02op\x12,\n" +
--	"\x05nodes\x18\x02 \x03(\v2\x16.libraryv1.SearchQueryR\x05nodes\"5\n" +
--	"\aNotNode\x12*\n" +
--	"\x04node\x18\x01 \x01(\v2\x16.libraryv1.SearchQueryR\x04node*%\n" +
--	"\tLogicalOp\x12\a\n" +
--	"\x03AND\x10\x00\x12\x06\n" +
--	"\x02OR\x10\x01\x12\a\n" +
--	"\x03NOT\x10\x02*8\n" +
--	"\bOperator\x12\r\n" +
--	"\tOP_EQUALS\x10\x00\x12\x0f\n" +
--	"\vOP_CONTAINS\x10\x01\x12\f\n" +
--	"\bOP_REGEX\x10\x022T\n" +
--	"\x13OrchestratorService\x12=\n" +
--	"\x06Search\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse2R\n" +
--	"\x10ProcessorService\x12>\n" +
--	"\aProcess\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse2T\n" +
--	"\x0eStorageService\x12B\n" +
--	"\vSearchBooks\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse2Q\n" +
--	"\vAuthService\x12B\n" +
--	"\vCheckAccess\x12\x18.libraryv1.AccessRequest\x1a\x19.libraryv1.AccessResponse2X\n" +
--	"\x17MessageConverterService\x12=\n" +
--	"\aConvert\x12\x13.libraryv1.RawInput\x1a\x1d.libraryv1.UnmarshaledMessage2\x93\x01\n" +
--	"\x0eLibraryService\x12B\n" +
--	"\vSearchBooks\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse\x12=\n" +
--	"\n" +
--	"GetAuthors\x12\x16.libraryv1.ListRequest\x1a\x17.libraryv1.ListResponseB\x1fZ\x1debusta/api/proto/v1;libraryv1b\x06proto3"
--
--var (
--	file_api_proto_v1_library_proto_rawDescOnce sync.Once
--	file_api_proto_v1_library_proto_rawDescData []byte
--)
--
--func file_api_proto_v1_library_proto_rawDescGZIP() []byte {
--	file_api_proto_v1_library_proto_rawDescOnce.Do(func() {
--		file_api_proto_v1_library_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_api_proto_v1_library_proto_rawDesc), len(file_api_proto_v1_library_proto_rawDesc)))
--	})
--	return file_api_proto_v1_library_proto_rawDescData
--}
--
--var file_api_proto_v1_library_proto_enumTypes = make([]protoimpl.EnumInfo, 2)
--var file_api_proto_v1_library_proto_msgTypes = make([]protoimpl.MessageInfo, 16)
--var file_api_proto_v1_library_proto_goTypes = []any{
--	(LogicalOp)(0),             // 0: libraryv1.LogicalOp
--	(Operator)(0),              // 1: libraryv1.Operator
--	(*SearchRequest)(nil),      // 2: libraryv1.SearchRequest
--	(*SearchResponse)(nil),     // 3: libraryv1.SearchResponse
--	(*Book)(nil),               // 4: libraryv1.Book
--	(*ListRequest)(nil),        // 5: libraryv1.ListRequest
--	(*ListResponse)(nil),       // 6: libraryv1.ListResponse
--	(*AccessRequest)(nil),      // 7: libraryv1.AccessRequest
--	(*AccessResponse)(nil),     // 8: libraryv1.AccessResponse
--	(*RawInput)(nil),           // 9: libraryv1.RawInput
--	(*MessageMeta)(nil),        // 10: libraryv1.MessageMeta
--	(*UnmarshaledMessage)(nil), // 11: libraryv1.UnmarshaledMessage
--	(*Response)(nil),           // 12: libraryv1.Response
--	(*ResponseMeta)(nil),       // 13: libraryv1.ResponseMeta
--	(*SearchQuery)(nil),        // 14: libraryv1.SearchQuery
--	(*FilterNode)(nil),         // 15: libraryv1.FilterNode
--	(*LogicalNode)(nil),        // 16: libraryv1.LogicalNode
--	(*NotNode)(nil),            // 17: libraryv1.NotNode
--}
--var file_api_proto_v1_library_proto_depIdxs = []int32{
--	4,  // 0: libraryv1.SearchResponse.books:type_name -> libraryv1.Book
--	10, // 1: libraryv1.UnmarshaledMessage.meta:type_name -> libraryv1.MessageMeta
--	14, // 2: libraryv1.UnmarshaledMessage.query:type_name -> libraryv1.SearchQuery
--	4,  // 3: libraryv1.Response.books:type_name -> libraryv1.Book
--	13, // 4: libraryv1.Response.meta:type_name -> libraryv1.ResponseMeta
--	15, // 5: libraryv1.SearchQuery.filter:type_name -> libraryv1.FilterNode
--	16, // 6: libraryv1.SearchQuery.logical:type_name -> libraryv1.LogicalNode
--	17, // 7: libraryv1.SearchQuery.negation:type_name -> libraryv1.NotNode
--	1,  // 8: libraryv1.FilterNode.operator:type_name -> libraryv1.Operator
--	0,  // 9: libraryv1.LogicalNode.op:type_name -> libraryv1.LogicalOp
--	14, // 10: libraryv1.LogicalNode.nodes:type_name -> libraryv1.SearchQuery
--	14, // 11: libraryv1.NotNode.node:type_name -> libraryv1.SearchQuery
--	2,  // 12: libraryv1.OrchestratorService.Search:input_type -> libraryv1.SearchRequest
--	2,  // 13: libraryv1.ProcessorService.Process:input_type -> libraryv1.SearchRequest
--	2,  // 14: libraryv1.StorageService.SearchBooks:input_type -> libraryv1.SearchRequest
--	7,  // 15: libraryv1.AuthService.CheckAccess:input_type -> libraryv1.AccessRequest
--	9,  // 16: libraryv1.MessageConverterService.Convert:input_type -> libraryv1.RawInput
--	2,  // 17: libraryv1.LibraryService.SearchBooks:input_type -> libraryv1.SearchRequest
--	5,  // 18: libraryv1.LibraryService.GetAuthors:input_type -> libraryv1.ListRequest
--	3,  // 19: libraryv1.OrchestratorService.Search:output_type -> libraryv1.SearchResponse
--	3,  // 20: libraryv1.ProcessorService.Process:output_type -> libraryv1.SearchResponse
--	3,  // 21: libraryv1.StorageService.SearchBooks:output_type -> libraryv1.SearchResponse
--	8,  // 22: libraryv1.AuthService.CheckAccess:output_type -> libraryv1.AccessResponse
--	11, // 23: libraryv1.MessageConverterService.Convert:output_type -> libraryv1.UnmarshaledMessage
--	3,  // 24: libraryv1.LibraryService.SearchBooks:output_type -> libraryv1.SearchResponse
--	6,  // 25: libraryv1.LibraryService.GetAuthors:output_type -> libraryv1.ListResponse
--	19, // [19:26] is the sub-list for method output_type
--	12, // [12:19] is the sub-list for method input_type
--	12, // [12:12] is the sub-list for extension type_name
--	12, // [12:12] is the sub-list for extension extendee
--	0,  // [0:12] is the sub-list for field type_name
--}
--
--func init() { file_api_proto_v1_library_proto_init() }
--func file_api_proto_v1_library_proto_init() {
--	if File_api_proto_v1_library_proto != nil {
--		return
--	}
--	file_api_proto_v1_library_proto_msgTypes[12].OneofWrappers = []any{
--		(*SearchQuery_Filter)(nil),
--		(*SearchQuery_Logical)(nil),
--		(*SearchQuery_Negation)(nil),
--	}
--	type x struct{}
--	out := protoimpl.TypeBuilder{
--		File: protoimpl.DescBuilder{
--			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
--			RawDescriptor: unsafe.Slice(unsafe.StringData(file_api_proto_v1_library_proto_rawDesc), len(file_api_proto_v1_library_proto_rawDesc)),
--			NumEnums:      2,
--			NumMessages:   16,
--			NumExtensions: 0,
--			NumServices:   6,
--		},
--		GoTypes:           file_api_proto_v1_library_proto_goTypes,
--		DependencyIndexes: file_api_proto_v1_library_proto_depIdxs,
--		EnumInfos:         file_api_proto_v1_library_proto_enumTypes,
--		MessageInfos:      file_api_proto_v1_library_proto_msgTypes,
--	}.Build()
--	File_api_proto_v1_library_proto = out.File
--	file_api_proto_v1_library_proto_goTypes = nil
--	file_api_proto_v1_library_proto_depIdxs = nil
--}
--
----- END_FILE: ./api/proto/v1/library.pb.go ---
--
----- START_FILE: ./api/proto/v1/library.proto ---
--syntax = "proto3";
--
--package libraryv1;
--
--option go_package = "ebusta/api/proto/v1;libraryv1";
--
--// ==========================================
--// 1. SERVICES
--// ==========================================
--
--service OrchestratorService {
--  rpc Search (SearchRequest) returns (SearchResponse);
--}
--
--service ProcessorService {
--  rpc Process (SearchRequest) returns (SearchResponse);
--}
--
--service StorageService {
--  rpc SearchBooks (SearchRequest) returns (SearchResponse);
--}
--
--service AuthService {
--  rpc CheckAccess (AccessRequest) returns (AccessResponse);
--}
--
--service MessageConverterService {
--  rpc Convert (RawInput) returns (UnmarshaledMessage);
--}
--
--// Legacy
--service LibraryService {
--  rpc SearchBooks (SearchRequest) returns (SearchResponse);
--  rpc GetAuthors (ListRequest) returns (ListResponse);
--}
--
--// ==========================================
--// 2. MESSAGES
--// ==========================================
--
--message SearchRequest {
--  string query = 1;
--  string template_id = 2;
--  int32 limit = 3;
--  int32 offset = 4;
--  string trace_id = 5;
--}
--
--message SearchResponse {
--  string status = 1;
--  int32 total = 2;
--  repeated Book books = 3;
--}
--
--message Book {
--  string id = 1;
--  string title = 2;
--  repeated string authors = 3;
--  string container = 4;
--  string filename = 5;
--}
--
--message ListRequest {
--  string query = 1;
--}
--
--message ListResponse {
--  repeated string items = 1;
--}
--
--// --- AUTH ---
--
--message AccessRequest {
--  string user_id = 1;
--  string platform = 2;
--  string trace_id = 3;
--}
--
--message AccessResponse {
--  bool allowed = 1;
--  string reason = 2;
--  string user_role = 3;
--}
--
--// ==========================================
--// 3. CONVERTER & AST (Fixed for existing code)
--// ==========================================
--
--message RawInput {
--  // Исправлено: переименовано в 'data', чтобы появился метод GetData(), который ждет message-converter
--  string data = 1; 
--  string trace_id = 2;
--}
--
--message MessageMeta {
--  string trace_id = 1;
--  string canonical_form = 2;
--  string platform = 3;
--  string user_id = 4;
--  // Исправлено: добавлено поле, которое требует message-converter
--  string ast_plan = 5; 
--}
--
--message UnmarshaledMessage {
--  MessageMeta meta = 1;
--  SearchQuery query = 2;
--}
--
--message Response {
--  string status = 1;
--  repeated Book books = 2;
--  ResponseMeta meta = 3;
--}
--
--message ResponseMeta {
--  string trace_id = 1;
--  string canonical_form = 2;
--}
--
--// --- AST NODES (Strictly for parser.go) ---
--
--enum LogicalOp {
--  AND = 0;
--  OR = 1;
--  NOT = 2;
--}
--
--enum Operator {
--  OP_EQUALS = 0;
--  OP_CONTAINS = 1;
--  OP_REGEX = 2;
--}
--
--message SearchQuery {
--  oneof node {
--    FilterNode filter = 1;
--    LogicalNode logical = 2;
--    NotNode negation = 3;
--  }
--}
--
--message FilterNode {
--  string field = 1;
--  string value = 2;
--  Operator operator = 3;
--}
--
--message LogicalNode {
--  LogicalOp op = 1;
--  repeated SearchQuery nodes = 2;
--}
--
--message NotNode {
--  // Важно: имя поля 'node' генерирует поле 'Node' в Go структуре, что нужно парсеру
--  SearchQuery node = 1; 
--}
--
----- END_FILE: ./api/proto/v1/library.proto ---
--
----- START_FILE: ./opensearch/templates/fl_authors_all.json ---
--{
--  "script": {
--    "lang": "mustache",
--    "source": "{\n  \"size\": 0,\n  \"aggs\": {\n    \"authors\": {\n      \"composite\": {\n        \"size\": {{size}},\n        \"sources\": [ { \"a\": { \"terms\": { \"field\": \"authors.kw\" } } } ]{{#after}},\n        \"after\": {{after}}{{/after}}\n      }\n    }\n  }\n}\n"
--  }
--}
--
--
----- END_FILE: ./opensearch/templates/fl_authors_all.json ---
--
----- START_FILE: ./opensearch/templates/fl_author_fuzzy.json ---
--{
--  "script": {
--    "lang": "mustache",
--    "source": {
--      "query": {
--        "match": {
--          "authors": {
--            "query": "{{author}}",
--            "operator": "and"
--          }
--        }
--      },
--      "size": "{{size}}",
--      "from": "{{from}}",
--      "_source": ["title", "authors", "fileInfo.container", "fileInfo.filename"],
--      "track_total_hits": false
--    }
--  }
--}
--
----- END_FILE: ./opensearch/templates/fl_author_fuzzy.json ---
--
----- START_FILE: ./opensearch/templates/fl_author_exact.json ---
--{
--  "script": {
--    "lang": "mustache",
--    "source": {
--      "query": { "term": { "authors.kw": "{{author}}" } },
--      "collapse": { "field": "title.kw", "inner_hits": { "name": "best", "size": 1, "sort": [{"fileInfo.size": "desc"}] } },
--      "size": "{{size}}{{^size}}20{{/size}}"
--    }
--  }
--}
--
----- END_FILE: ./opensearch/templates/fl_author_exact.json ---
--
----- START_FILE: ./opensearch/templates/fl_names_token_prefix.json ---
--{
--  "script": {
--    "lang": "mustache",
--    "source": "{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        { \"multi_match\": { \"query\": \"{{q}}\", \"type\": \"phrase_prefix\", \"fields\": [\"authors^3\",\"title^1\"] } },\n        { \"match\": { \"authors.prefix\": { \"query\": \"{{q}}\", \"boost\": 4 } } },\n        { \"match\": { \"title.prefix\":   { \"query\": \"{{q}}\", \"boost\": 2 } } }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"size\": {{size}},\n  \"from\": {{from}},\n  \"sort\": [{ \"title.kw\": { \"order\": \"asc\" } }],\n  \"track_total_hits\": false,\n  \"_source\": [\"title\",\"authors\",\"fileInfo.container\",\"fileInfo.filename\"],\n  \"highlight\": { \"fields\": { \"authors\": {}, \"title\": {} } }\n}"
--  }
--}
----- END_FILE: ./opensearch/templates/fl_names_token_prefix.json ---
--
----- START_FILE: ./opensearch/templates/fl_title_match.json ---
--{
--  "script": {
--    "lang": "mustache",
--    "source": {
--      "query": {
--        "match": {
--          "title": {
--            "query": "{{q}}",
--            "operator": "and"
--          }
--        }
--      },
--      "from": "{{from}}",
--      "size": "{{size}}"
--    }
--  }
--}
--
----- END_FILE: ./opensearch/templates/fl_title_match.json ---
--
----- START_FILE: ./opensearch/templates/fl_title_substring.json ---
--{
--  "script": {
--    "lang": "mustache",
--    "source": "{\n  \"from\": 0,\n  \"size\": {{size}},\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"*{{q}}*\",\n      \"fields\": [\"title.kw\", \"authors.kw\"],\n      \"analyze_wildcard\": true,\n      \"default_operator\": \"and\"\n    }\n  },\n  \"_source\": [\"title\", \"authors\", \"year\", \"fileInfo.container\", \"fileInfo.filename\"]\n}\n"
--  }
--}
--
--
----- END_FILE: ./opensearch/templates/fl_title_substring.json ---
--
----- START_FILE: ./opensearch/templates/fl_title_prefix.json ---
--{
--  "script": {
--    "lang": "mustache",
--    "source": "{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        { \"match\": { \"title.prefix\": { \"query\": \"{{q}}\", \"boost\": 5 } } },\n        { \"match_phrase_prefix\": { \"title\": { \"query\": \"{{q}}\", \"boost\": 2 } } },\n        { \"term\": { \"title.kw\": { \"value\": \"{{q}}\", \"boost\": 20 } } }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"size\": {{size}},\n  \"from\": {{from}},\n  \"sort\": [{ \"title.kw\": { \"order\": \"asc\" } }],\n  \"track_total_hits\": false,\n  \"_source\": [\"title\",\"authors\",\"fileInfo.container\",\"fileInfo.filename\"],\n  \"highlight\": { \"fields\": { \"title\": {} } }\n}"
--  }
--}
----- END_FILE: ./opensearch/templates/fl_title_prefix.json ---
--
----- START_FILE: ./opensearch/templates/fl_mixed_search.json ---
--{
--  "script": {
--    "lang": "mustache",
--    "source": {
--      "query": {
--        "multi_match": {
--          "query": "{{query}}",
--          "fields": ["title^3", "authors", "annotation"],
--          "type": "best_fields",
--          "fuzziness": "AUTO"
--        }
--      },
--      "collapse": {
--        "field": "title.kw",
--        "inner_hits": { "name": "best", "size": 1, "sort": [{"fileInfo.size": "desc"}] }
--      },
--      "from": "{{from}}{{^from}}0{{/from}}",
--      "size": "{{size}}{{^size}}10{{/size}}"
--    }
--  }
--}
--
----- END_FILE: ./opensearch/templates/fl_mixed_search.json ---
--
----- START_FILE: ./opensearch/templates/fl_titles_all.json ---
--{
--  "script": {
--    "lang": "mustache",
--    "source": "{\n  \"size\": 0,\n  \"aggs\": {\n    \"titles\": {\n      \"composite\": {\n        \"size\": {{size}},\n        \"sources\": [ { \"t\": { \"terms\": { \"field\": \"title.kw\" } } } ]{{#after}},\n        \"after\": {{after}}{{/after}}\n      }\n    }\n  }\n}\n"
--  }
--}
--
--
----- END_FILE: ./opensearch/templates/fl_titles_all.json ---
--
----- START_FILE: ./opensearch/flibusta_merged_index.fixed.json ---
--{
--  "settings": {
--    "index": {
--      "number_of_shards": 1,
--      "number_of_replicas": 1,
--      "refresh_interval": "1s"
--    },
--    "analysis": {
--      "filter": {
--        "ru_stop": {
--          "type": "stop",
--          "stopwords": "_russian_"
--        },
--        "ru_stemmer": {
--          "type": "stemmer",
--          "language": "russian"
--        },
--        "en_stop": {
--          "type": "stop",
--          "stopwords": "_english_"
--        },
--        "en_stemmer": {
--          "type": "stemmer",
--          "language": "english"
--        },
--        "shingle_2_3": {
--          "type": "shingle",
--          "min_shingle_size": 2,
--          "max_shingle_size": 3
--        }
--      },
--      "char_filter": {
--        "quotes": {
--          "type": "mapping",
--          "mappings": [
--            "“=>\"",
--            "”=>\"",
--            "‘=>'",
--            "’=>'"
--          ]
--        }
--      },
--      "normalizer": {
--        "lc_ascii": {
--          "type": "custom",
--          "filter": [
--            "lowercase",
--            "asciifolding"
--          ]
--        }
--      },
--      "analyzer": {
--        "mixed_text": {
--          "type": "custom",
--          "tokenizer": "standard",
--          "char_filter": [
--            "quotes"
--          ],
--          "filter": [
--            "lowercase",
--            "ru_stop",
--            "ru_stemmer",
--            "en_stop",
--            "en_stemmer"
--          ]
--        },
--        "autocomplete": {
--          "type": "custom",
--          "tokenizer": "standard",
--          "filter": [
--            "lowercase"
--          ]
--        },
--        "autocomplete_edge": {
--          "type": "custom",
--          "tokenizer": "edge_ngram_tokenizer",
--          "filter": [
--            "lowercase"
--          ]
--        },
--        "shingled": {
--          "type": "custom",
--          "tokenizer": "standard",
--          "filter": [
--            "lowercase",
--            "shingle_2_3"
--          ]
--        }
--      },
--      "tokenizer": {
--        "edge_ngram_tokenizer": {
--          "type": "edge_ngram",
--          "min_gram": 2,
--          "max_gram": 20,
--          "token_chars": [
--            "letter",
--            "digit"
--          ]
--        }
--      }
--    }
--  },
--  "mappings": {
--    "dynamic": "strict",
--    "properties": {
--      "id": {
--        "type": "keyword"
--      },
--      "docId": {
--        "type": "keyword"
--      },
--      "source": {
--        "type": "keyword"
--      },
--      "ingestedAt": {
--        "type": "date"
--      },
--      "title": {
--        "type": "text",
--        "analyzer": "mixed_text",
--        "fields": {
--          "kw": {
--            "type": "keyword",
--            "normalizer": "lc_ascii"
--          },
--          "ac": {
--            "type": "text",
--            "analyzer": "autocomplete_edge",
--            "search_analyzer": "autocomplete"
--          },
--          "sh": {
--            "type": "text",
--            "analyzer": "shingled"
--          }
--        }
--      },
--      "authors": {
--        "type": "text",
--        "analyzer": "mixed_text",
--        "fields": {
--          "kw": {
--            "type": "keyword",
--            "normalizer": "lc_ascii"
--          },
--          "ac": {
--            "type": "text",
--            "analyzer": "autocomplete_edge",
--            "search_analyzer": "autocomplete"
--          }
--        }
--      },
--      "genres": {
--        "type": "keyword",
--        "normalizer": "lc_ascii"
--      },
--      "languages": {
--        "type": "keyword",
--        "normalizer": "lc_ascii"
--      },
--      "year": {
--        "type": "integer"
--      },
--      "annotation": {
--        "type": "text",
--        "analyzer": "mixed_text"
--      },
--      "sequences": {
--        "type": "nested",
--        "properties": {
--          "name": {
--            "type": "text",
--            "analyzer": "mixed_text",
--            "fields": {
--              "kw": {
--                "type": "keyword",
--                "normalizer": "lc_ascii"
--              },
--              "ac": {
--                "type": "text",
--                "analyzer": "autocomplete_edge",
--                "search_analyzer": "autocomplete"
--              }
--            }
--          },
--          "number": {
--            "type": "float"
--          }
--        }
--      },
--      "fileInfo": {
--        "type": "object",
--        "properties": {
--          "container": {
--            "type": "keyword"
--          },
--          "filename": {
--            "type": "keyword"
--          },
--          "size": {
--            "type": "long"
--          },
--          "sha1": {
--            "type": "keyword"
--          }
--        }
--      },
--      "suggest_title": {
--        "type": "completion"
--      },
--      "suggest_author": {
--        "type": "completion"
--      }
--    }
--  }
--}
----- END_FILE: ./opensearch/flibusta_merged_index.fixed.json ---
--
----- START_FILE: ./opensearch/os-setup-config.yaml ---
--opensearch:
--  url: "http://cloud-1:9200"
--  index_name: "flibusta_merged_index"
--
--paths:
--  index_file: "./flibusta_merged_index.fixed.json"
--  templates_dir: "./templates"
--
--logging:
--  log_path: "os-setup.log"
--
----- END_FILE: ./opensearch/os-setup-config.yaml ---
--
----- START_FILE: ./cmd/datamanager/main.go ---
--package main
--
--import (
--	"bytes"
--	"context"
--	"encoding/json"
--	"fmt"
--	"io"
--	"log"
--	"net"
--	"net/http"
--	"os"
--
--	"ebusta/api/proto/v1"
--	"github.com/spf13/viper"
--	"google.golang.org/grpc"
--)
--
--type storageServer struct {
--	libraryv1.UnimplementedStorageServiceServer
--	osBaseURL string
--	indexName string
--	debug     bool
--}
--
--func (s *storageServer) SearchBooks(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
--	templateID := req.TemplateId
--	if templateID == "" {
--		templateID = "fl_mixed_search"
--	}
--	
--	var paramName string
--	switch templateID {
--	case "fl_author_exact", "fl_author_fuzzy":
--		paramName = "author"
--	case "fl_title_substring", "fl_titles_all":
--		paramName = "q"
--	default:
--		paramName = "q"
--	}
--
--	osReqBody := map[string]interface{}{
--		"id": templateID,
--		"params": map[string]interface{}{
--			paramName: req.Query,
--			"from":    0,
--			"size":    req.Limit,
--		},
--	}
--	
--	if val, ok := osReqBody["params"].(map[string]interface{})["size"].(int32); ok && val == 0 {
--		osReqBody["params"].(map[string]interface{})["size"] = 10
--	}
--
--	jsonData, _ := json.Marshal(osReqBody)
--	targetURL := fmt.Sprintf("%s/%s/_search/template", s.osBaseURL, s.indexName)
--	log.Printf("📤 [OS-REQ] URL: %s | BODY: %s", targetURL, string(jsonData))
--
--	resp, err := http.Post(targetURL, "application/json", bytes.NewBuffer(jsonData))
--	if err != nil {
--		return nil, err
--	}
--	defer resp.Body.Close()
--
--	body, _ := io.ReadAll(resp.Body)
--	
--	// ГИБКИЙ ПАРСИНГ: Total может быть числом, объектом или отсутствовать
--	var osRaw struct {
--		Hits struct {
--			Total interface{} `json:"total"`
--			Hits  []struct {
--				Source struct {
--					Title   string   `json:"title"`
--					Authors []string `json:"authors"`
--				} `json:"_source"`
--				ID string `json:"_id"`
--			} `json:"hits"`
--		} `json:"hits"`
--	}
--
--	if err := json.Unmarshal(body, &osRaw); err != nil {
--		log.Printf("❌ Storage parse error: %v", err)
--		return &libraryv1.SearchResponse{Status: "error"}, nil
--	}
--
--	var totalValue int32
--	switch v := osRaw.Hits.Total.(type) {
--	case float64:
--		totalValue = int32(v)
--	case map[string]interface{}:
--		if val, ok := v["value"].(float64); ok {
--			totalValue = int32(val)
--		}
--	}
--
--	res := &libraryv1.SearchResponse{}
--	for _, hit := range osRaw.Hits.Hits {
--		res.Books = append(res.Books, &libraryv1.Book{
--			Id:      hit.ID,
--			Title:   hit.Source.Title,
--			Authors: hit.Source.Authors,
--		})
--	}
--
--	// FALLBACK: Если хиты есть, а total 0 или не распарсился
--	if totalValue == 0 && len(res.Books) > 0 {
--		totalValue = int32(len(res.Books))
--	}
--	res.Total = totalValue
--
--	log.Printf("📥 [OS-RESP] Found: %d books", totalValue)
--	return res, nil
--}
--
--func main() {
--	viper.SetConfigName("ebusta")
--	viper.SetConfigType("yaml")
--	viper.AddConfigPath(".")
--	viper.ReadInConfig()
--
--	osBaseURL := viper.GetString("datamanager.opensearch_url")
--	indexName := viper.GetString("datamanager.index_name")
--	debug := os.Getenv("DEBUG") != ""
--
--	lis, err := net.Listen("tcp", ":50051")
--	if err != nil { log.Fatalf("failed to listen: %v", err) }
--
--	s := grpc.NewServer()
--	libraryv1.RegisterStorageServiceServer(s, &storageServer{
--		osBaseURL: osBaseURL,
--		indexName: indexName,
--		debug:     debug,
--	})
--
--	log.Println("💾 DataManager (Storage) started on :50051")
--	s.Serve(lis)
--}
--
----- END_FILE: ./cmd/datamanager/main.go ---
--
----- START_FILE: ./cmd/bulker/main.go ---
--package main
--
--import (
--	"archive/zip"
--	"bufio"
--	"bytes"
--	"crypto/sha1"
--	"encoding/hex"
--	"encoding/json"
--	"encoding/xml"
--	"flag"
--	"fmt"
--	"io"
--	"os"
--	"path/filepath"
--	"regexp"
--	"strings"
--	"sync"
--	"sync/atomic"
--	"time"
--
--	"github.com/schollz/progressbar/v3"
--	"github.com/sirupsen/logrus"
--	"golang.org/x/text/encoding/charmap"
--	"golang.org/x/text/encoding/unicode"
--	"gopkg.in/yaml.v3"
--)
--
--type Config struct {
--	OpenSearch struct {
--		IndexName string `yaml:"index_name"`
--	} `yaml:"opensearch"`
--	Paths struct {
--		WarnDir   string `yaml:"warn_dir"`
--		OutputDir string `yaml:"output_dir"`
--		SourceDir string `yaml:"source_dir"`
--	} `yaml:"paths"`
--	Processing struct {
--		Threads int `yaml:"threads"`
--	} `yaml:"processing"`
--}
--
--type docOut struct {
--	Title      string    `json:"title"`
--	Authors    []string  `json:"authors,omitempty"`
--	IngestedAt time.Time `json:"ingestedAt"`
--	FileInfo   struct {
--		Container string `json:"container"`
--		Filename  string `json:"filename"`
--		Sha1      string `json:"sha1"`
--		Size      int64  `json:"size"`
--	} `json:"fileInfo"`
--}
--
--var (
--	cfg          Config
--	log          = logrus.New()
--	outFile      *os.File
--	outMu        sync.Mutex
--	bar          *progressbar.ProgressBar
--	rescuedCount int32
--	// Флаги управления
--	flagRescan  *bool
--	flagVerbose *bool
--)
--
--func main() {
--	configPath := flag.String("config", "./config.yaml", "Path to config file")
--	container := flag.String("container", "", "Process only this specific ZIP from source_dir")
--	rescue := flag.Bool("rescue", false, "Rescue mode")
--	flagRescan = flag.Bool("rescan", false, "Force rescan all files ignoring existing output")
--	flagVerbose = flag.Bool("verbose", false, "Detailed check by hashing every file")
--	flag.Parse()
--
--	cFile, err := os.ReadFile(*configPath)
--	if err != nil {
--		fmt.Printf("Error: Cannot read config file at %s\n", *configPath)
--		os.Exit(1)
--	}
--	_ = yaml.Unmarshal(cFile, &cfg)
--
--	log.SetFormatter(&logrus.TextFormatter{FullTimestamp: true, ForceColors: true})
--	_ = os.MkdirAll(cfg.Paths.OutputDir, 0755)
--
--	if *rescue {
--		runRescueMode()
--		fmt.Printf("\n🏁 Rescue Finished. Successfully processed: %d files.\n", atomic.LoadInt32(&rescuedCount))
--	} else if *container != "" {
--		fullPath := filepath.Join(cfg.Paths.SourceDir, *container)
--		dstPath := filepath.Join(cfg.Paths.OutputDir, *container+".jsonl")
--		processSingleZip(fullPath, dstPath)
--	} else {
--		archives, _ := filepath.Glob(filepath.Join(cfg.Paths.SourceDir, "*.zip"))
--		for _, zipPath := range archives {
--			dstPath := filepath.Join(cfg.Paths.OutputDir, filepath.Base(zipPath)+".jsonl")
--			processSingleZip(zipPath, dstPath)
--		}
--	}
--}
--
--// Нормализация файла: удаление дубликатов и перезапись
--func normalizeJSONL(path string) (int, error) {
--	baseName := filepath.Base(path)
--	log.Infof("[%s] Normalization started: scanning for unique IDs...", baseName)
--
--	f, err := os.Open(path)
--	if err != nil {
--		return 0, err
--	}
--	defer f.Close()
--
--	tmpPath := path + ".tmp"
--	tmpFile, err := os.Create(tmpPath)
--	if err != nil {
--		return 0, err
--	}
--	defer tmpFile.Close()
--
--	hashes := make(map[string]bool)
--	scanner := bufio.NewScanner(f)
--	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
--	count := 0
--
--	for scanner.Scan() {
--		line1 := scanner.Text()
--		if strings.Contains(line1, `"_index"`) {
--			match := re.FindStringSubmatch(line1)
--			if len(match) > 1 {
--				id := match[1]
--				if scanner.Scan() {
--					line2 := scanner.Text()
--					if !hashes[id] {
--						hashes[id] = true
--						_, _ = tmpFile.WriteString(line1 + "\n")
--						_, _ = tmpFile.WriteString(line2 + "\n")
--						count++
--					}
--				}
--			}
--		}
--	}
--
--	log.Infof("[%s] Writing normalized file to disk (%d unique records)...", baseName, count)
--
--	f.Close()
--	tmpFile.Close()
--
--	if err := os.Rename(tmpPath, path); err != nil {
--		return 0, err
--	}
--
--	log.Infof("[%s] Normalization finished successfully.", baseName)
--	return count, nil
--}
--
--func countExistingDocs(path string) int {
--	count := 0
--	f, err := os.Open(path)
--	if err != nil { return 0 }
--	defer f.Close()
--	scanner := bufio.NewScanner(f)
--	for scanner.Scan() {
--		if strings.Contains(scanner.Text(), `"_index"`) { count++ }
--	}
--	return count
--}
--
--func loadExistingHashes(path string) map[string]bool {
--	hashes := make(map[string]bool)
--	f, err := os.Open(path)
--	if err != nil { return hashes }
--	defer f.Close()
--	scanner := bufio.NewScanner(f)
--	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
--	for scanner.Scan() {
--		line := scanner.Text()
--		if strings.Contains(line, `"_index"`) {
--			match := re.FindStringSubmatch(line)
--			if len(match) > 1 { hashes[match[1]] = true }
--		}
--	}
--	return hashes
--}
--
--func processSingleZip(zipPath, dstPath string) {
--	containerName := filepath.Base(zipPath)
--	z, err := zip.OpenReader(zipPath)
--	if err != nil {
--		log.Errorf("Failed to open zip %s: %v", zipPath, err)
--		return
--	}
--	defer z.Close()
--
--	zipFb2Count := 0
--	for _, f := range z.File {
--		if strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { zipFb2Count++ }
--	}
--
--	// 1. Быстрая проверка и интеграция нормализации
--	if !*flagRescan && !*flagVerbose {
--		jsonlDocCount := countExistingDocs(dstPath)
--		if jsonlDocCount > 0 {
--			if zipFb2Count == jsonlDocCount {
--				log.Infof("[%s] Quick check: counts match (%d). Skipping container.", containerName, zipFb2Count)
--				z.Close()
--				os.Exit(10)
--			} else {
--				log.Infof("[%s] Count mismatch (ZIP: %d, JSONL: %d). Starting normalization...", containerName, zipFb2Count, jsonlDocCount)
--				
--				newCount, err := normalizeJSONL(dstPath)
--				
--				// Новая проверка после нормализации
--				log.Infof("[%s] New check after normalization: count is %d.", containerName, newCount)
--				
--				if err == nil {
--					if newCount == zipFb2Count {
--						log.Infof("[%s] Result: Counts match! Skipping container.", containerName)
--						z.Close()
--						os.Exit(10)
--					} else {
--						log.Infof("[%s] Result: Still mismatch. Proceeding to detailed check.", containerName)
--					}
--				} else {
--					log.Errorf("[%s] Normalization failed: %v. Proceeding to detailed check.", containerName, err)
--				}
--			}
--		}
--	}
--
--	existingHashes := make(map[string]bool)
--	if !*flagRescan {
--		existingHashes = loadExistingHashes(dstPath)
--		if len(existingHashes) > 0 && *flagVerbose {
--			log.Infof("[%s] Found %d already processed documents.", containerName, len(existingHashes))
--		}
--	}
--
--	type workItem struct {
--		file *zip.File
--		raw  []byte
--		sha  string
--	}
--	var tasks []workItem
--
--	for _, f := range z.File {
--		if !strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { continue }
--		rc, err := f.Open()
--		if err != nil {
--			log.Errorf("Read error %s: %v", f.Name, err)
--			continue
--		}
--		raw, _ := io.ReadAll(rc)
--		rc.Close()
--		sum := sha1.Sum(raw)
--		sha := hex.EncodeToString(sum[:])
--		if existingHashes[sha] {
--			if *flagVerbose { log.Infof("Skipping %s (already exists in output)", f.Name) }
--			continue
--		}
--		tasks = append(tasks, workItem{file: f, raw: raw, sha: sha})
--	}
--
--	if len(tasks) == 0 {
--		log.Infof("Container %s is fully processed. Nothing new.", containerName)
--		z.Close()
--		os.Exit(10)
--	}
--
--	openOutputFile(dstPath)
--	defer outFile.Close()
--	bar = progressbar.Default(int64(len(tasks)), "🚢 "+containerName)
--	jobs := make(chan workItem)
--	var wg sync.WaitGroup
--	for i := 0; i < cfg.Processing.Threads; i++ {
--		wg.Add(1)
--		go func() {
--			defer wg.Done()
--			for item := range jobs {
--				doc, err := parseResilient(item.raw)
--				if err != nil {
--					log.Errorf("FAILED: %s | %v", item.file.Name, err)
--					saveToWarn(item.file.Name, item.raw, err)
--				} else {
--					saveToOutputWithSha(item.file.Name, containerName, item.raw, item.sha, doc)
--				}
--				_ = bar.Add(1)
--			}
--		}()
--	}
--	for _, task := range tasks { jobs <- task }
--	close(jobs)
--	wg.Wait()
--}
--
--func runRescueMode() {
--	files, _ := filepath.Glob(filepath.Join(cfg.Paths.WarnDir, "*fb2"))
--	if len(files) == 0 { return }
--	dstPath := filepath.Join(cfg.Paths.OutputDir, "rescued_items.jsonl")
--	openOutputFile(dstPath)
--	defer outFile.Close()
--	bar = progressbar.Default(int64(len(files)), "🩹 Rescuing")
--	jobs := make(chan string)
--	var wg sync.WaitGroup
--	for i := 0; i < cfg.Processing.Threads; i++ {
--		wg.Add(1)
--		go func() {
--			defer wg.Done()
--			for path := range jobs {
--				data, err := os.ReadFile(path)
--				if err != nil || len(data) == 0 {
--					_ = os.Remove(path)
--					_ = os.Remove(path + ".log")
--					_ = bar.Add(1)
--					continue
--				}
--				doc, err := parseResilient(data)
--				if err == nil {
--					if saveToOutput(filepath.Base(path), "rescued", data, doc) {
--						_ = os.Remove(path)
--						_ = os.Remove(path + ".log")
--						atomic.AddInt32(&rescuedCount, 1)
--					}
--				} else { log.Errorf("FAILED: %s | %v", filepath.Base(path), err) }
--				_ = bar.Add(1)
--			}
--		}()
--	}
--	for _, f := range files { jobs <- f }
--	close(jobs)
--	wg.Wait()
--}
--
--func parseResilient(data []byte) (*docOut, error) {
--	if len(data) == 0 { return nil, fmt.Errorf("empty file") }
--	utf8Data := convertToUTF8(data)
--	doc, err := parseFB2(utf8Data)
--	if err == nil { return doc, nil }
--	return parseWithRegex(utf8Data)
--}
--
--func convertToUTF8(data []byte) []byte {
--	if len(data) < 2 { return data }
--	if (data[0] == 0xFF && data[1] == 0xFE) || (data[0] == 0xFE && data[1] == 0xFF) {
--		dec := unicode.UTF16(unicode.LittleEndian, unicode.UseBOM).NewDecoder()
--		out, _ := dec.Bytes(data)
--		return out
--	}
--	if len(data) > 10 && data[1] == 0 && data[3] == 0 {
--		dec := unicode.UTF16(unicode.LittleEndian, unicode.IgnoreBOM).NewDecoder()
--		out, _ := dec.Bytes(data)
--		return out
--	}
--	header := string(data[:min(len(data), 500)])
--	if strings.Contains(strings.ToLower(header), "windows-1251") {
--		out, _ := charmap.Windows1251.NewDecoder().Bytes(data)
--		return out
--	}
--	return bytes.ToValidUTF8(data, []byte(" "))
--}
--
--func parseWithRegex(data []byte) (*docOut, error) {
--	doc := &docOut{}
--	reTitle := regexp.MustCompile(`(?is)<book-title[^>]*>(.*?)</book-title>`)
--	if m := reTitle.FindSubmatch(data); len(m) > 1 { doc.Title = strings.TrimSpace(string(m[1])) }
--	reAuthor := regexp.MustCompile(`(?is)<author[^>]*>(.*?)</author>`)
--	reFirst := regexp.MustCompile(`(?is)<first-name[^>]*>(.*?)</first-name>`)
--	reLast := regexp.MustCompile(`(?is)<last-name[^>]*>(.*?)</last-name>`)
--	authors := reAuthor.FindAllSubmatch(data, -1)
--	for _, a := range authors {
--		fn, ln := reFirst.FindSubmatch(a[1]), reLast.FindSubmatch(a[1])
--		name := ""
--		if len(fn) > 1 { name += string(fn[1]) + " " }
--		if len(ln) > 1 { name += string(ln[1]) }
--		if name = strings.TrimSpace(name); name != "" { doc.Authors = append(doc.Authors, name) }
--	}
--	if doc.Title == "" { return nil, fmt.Errorf("regex failed") }
--	return doc, nil
--}
--
--func openOutputFile(path string) {
--	var err error
--	outFile, err = os.OpenFile(path, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
--	if err != nil { log.Fatal(err) }
--}
--
--func saveToOutput(filename, container string, raw []byte, doc *docOut) bool {
--	sum := sha1.Sum(raw)
--	sha := hex.EncodeToString(sum[:])
--	return saveToOutputWithSha(filename, container, raw, sha, doc)
--}
--
--func saveToOutputWithSha(filename, container string, raw []byte, sha string, doc *docOut) bool {
--	doc.FileInfo.Container, doc.FileInfo.Filename, doc.FileInfo.Sha1, doc.FileInfo.Size = container, filename, sha, int64(len(raw))
--	doc.IngestedAt = time.Now()
--	action, _ := json.Marshal(map[string]map[string]any{"index": {"_index": cfg.OpenSearch.IndexName, "_id": sha}})
--	data, _ := json.Marshal(doc)
--	outMu.Lock()
--	defer outMu.Unlock()
--	_, _ = outFile.Write(append(action, '\n'))
--	_, _ = outFile.Write(append(data, '\n'))
--	return true
--}
--
--func saveToWarn(filename string, data []byte, err error) {
--	_ = os.WriteFile(filepath.Join(cfg.Paths.WarnDir, filename), data, 0644)
--	_ = os.WriteFile(filepath.Join(cfg.Paths.WarnDir, filename+".log"), []byte(err.Error()), 0644)
--}
--
--func parseFB2(data []byte) (*docOut, error) {
--	d := xml.NewDecoder(bytes.NewReader(data))
--	d.CharsetReader = func(charset string, input io.Reader) (io.Reader, error) { return input, nil }
--	d.Strict = false
--	var doc docOut
--	var inTitle bool
--	for {
--		t, err := d.Token()
--		if err != nil || t == nil { break }
--		switch se := t.(type) {
--		case xml.StartElement:
--			if se.Name.Local == "title-info" { inTitle = true }
--			if se.Name.Local == "book-title" && inTitle { _ = d.DecodeElement(&doc.Title, &se) }
--			if se.Name.Local == "author" && inTitle {
--				var a struct { First string `xml:"first-name"`; Last string `xml:"last-name"` }
--				_ = d.DecodeElement(&a, &se)
--				if n := strings.TrimSpace(a.First + " " + a.Last); n != "" { doc.Authors = append(doc.Authors, n) }
--			}
--		case xml.EndElement:
--			if se.Name.Local == "title-info" { inTitle = false }
--		}
--	}
--	if doc.Title == "" { return nil, fmt.Errorf("xml: no title") }
--	return &doc, nil
--}
--
--func min(a, b int) int { if a < b { return a }; return b }
--
----- END_FILE: ./cmd/bulker/main.go ---
--
----- START_FILE: ./cmd/processor/main.go ---
--package main
--
--import (
--	"context"
--	"log"
--	"net"
--	"strings"
--
--	"ebusta/api/proto/v1"
--	"google.golang.org/grpc"
--)
--
--type processorServer struct {
--	libraryv1.UnimplementedProcessorServiceServer
--	storage libraryv1.StorageServiceClient
--}
--
--func (s *processorServer) Process(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
--	fullQuery := req.Query
--	qLower := strings.ToLower(fullQuery)
--	log.Printf("🧠 Processor: Handling '%s'", fullQuery)
--
--	// 1. Сложные запросы (AND/OR)
--	if strings.Contains(qLower, " and ") || strings.Contains(qLower, " or ") {
--		cleanQuery := fullQuery
--		for _, prefix := range []string{"author:", "title:", "Author:", "Title:"} {
--			cleanQuery = strings.ReplaceAll(cleanQuery, prefix, "")
--		}
--		log.Printf("🧠 Processor: Complex query cleaned: '%s'", cleanQuery)
--		return s.storage.SearchBooks(ctx, &libraryv1.SearchRequest{
--			Query:      strings.TrimSpace(cleanQuery),
--			TemplateId: "fl_mixed_search",
--			Limit:      req.Limit,
--			TraceId:    req.TraceId,
--		})
--	}
--
--	// 2. Обработка префикса title: (Каскадный поиск)
--	if strings.HasPrefix(qLower, "title:") {
--		cleanTitle := strings.TrimSpace(strings.TrimPrefix(fullQuery, "title:"))
--		
--		// Попытка 1: Строгий substring
--		subReq := &libraryv1.SearchRequest{
--			Query:      cleanTitle,
--			TemplateId: "fl_title_substring",
--			Limit:      req.Limit,
--			TraceId:    req.TraceId,
--		}
--		resp, err := s.storage.SearchBooks(ctx, subReq)
--		
--		if err == nil && resp.Total > 0 {
--			return resp, nil
--		}
--
--		// Попытка 2: Умный Match (анализатор разберется с регистром)
--		log.Printf("⚠️ Substring search found 0, switching to fl_title_match for: %s", cleanTitle)
--		subReq.TemplateId = "fl_title_match"
--		return s.storage.SearchBooks(ctx, subReq)
--	}
--
--	// 3. Обработка префикса author: (уже настроена)
--	if strings.HasPrefix(qLower, "author:") {
--		cleanAuthor := strings.TrimSpace(strings.TrimPrefix(fullQuery, "author:"))
--		subReq := &libraryv1.SearchRequest{
--			Query:      cleanAuthor,
--			TemplateId: "fl_author_exact",
--			Limit:      req.Limit,
--			TraceId:    req.TraceId,
--		}
--		resp, err := s.storage.SearchBooks(ctx, subReq)
--		if err == nil && resp.Total > 0 {
--			return resp, nil
--		}
--		log.Printf("⚠️ Switching to fuzzy for: %s", cleanAuthor)
--		subReq.TemplateId = "fl_author_fuzzy"
--		return s.storage.SearchBooks(ctx, subReq)
--	}
--
--	return s.storage.SearchBooks(ctx, req)
--}
--
--func main() {
--	lis, err := net.Listen("tcp", ":50053")
--	if err != nil { log.Fatal(err) }
--	conn, err := grpc.Dial("localhost:50051", grpc.WithInsecure())
--	if err != nil { log.Fatal(err) }
--	defer conn.Close()
--	s := grpc.NewServer()
--	libraryv1.RegisterProcessorServiceServer(s, &processorServer{storage: libraryv1.NewStorageServiceClient(conn)})
--	log.Println("🧠 Ebusta Processor started on :50053")
--	s.Serve(lis)
--}
--
----- END_FILE: ./cmd/processor/main.go ---
--
----- START_FILE: ./cmd/cli/main.go ---
--package main
--
--import (
--	"context"
--	"fmt"
--	"log"
--	"os"
--	"path/filepath"
--	"strings"
--	"time"
--
--	"ebusta/api/proto/v1"
--	"github.com/peterh/liner"
--	"google.golang.org/grpc"
--	"google.golang.org/grpc/credentials/insecure"
--)
--
--var (
--	debugMode   bool
--	historyPath = filepath.Join(os.TempDir(), ".ebusta_history")
--)
--
--func main() {
--	if os.Getenv("DEBUG") != "" {
--		debugMode = true
--		log.Println("🐞 DEBUG MODE: ENABLED")
--	}
--
--	conn, err := grpc.Dial("localhost:50054", grpc.WithTransportCredentials(insecure.NewCredentials()))
--	if err != nil {
--		log.Fatalf("❌ Failed to connect to Orchestrator: %v", err)
--	}
--	defer conn.Close()
--
--	client := libraryv1.NewOrchestratorServiceClient(conn)
--
--	if len(os.Args) > 1 {
--		query := strings.Join(os.Args[1:], " ")
--		runSearch(client, query)
--	} else {
--		runInteractiveLoop(client)
--	}
--}
--
--func runInteractiveLoop(client libraryv1.OrchestratorServiceClient) {
--	line := liner.NewLiner()
--	defer line.Close()
--
--	line.SetCtrlCAborts(true)
--
--	// Загружаем историю из файла, если он есть
--	if f, err := os.Open(historyPath); err == nil {
--		line.ReadHistory(f)
--		f.Close()
--	}
--
--	fmt.Println("🚀 Ebusta CLI Interactive Mode (with History Support)")
--	fmt.Println("Use UP/DOWN arrows for history. Type 'exit' to stop.")
--	fmt.Println("---------------------------------")
--
--	for {
--		if text, err := line.Prompt("ebusta> "); err == nil {
--			text = strings.TrimSpace(text)
--			if text == "" {
--				continue
--			}
--			if text == "exit" || text == "quit" {
--				fmt.Println("Bye!")
--				break
--			}
--
--			// Добавляем в историю и сохраняем
--			line.AppendHistory(text)
--			runSearch(client, text)
--
--			// Сохраняем историю после каждого успешного ввода
--			if f, err := os.Create(historyPath); err == nil {
--				line.WriteHistory(f)
--				f.Close()
--			}
--		} else if err == liner.ErrPromptAborted {
--			fmt.Println("Aborted")
--			break
--		} else {
--			log.Print("Error reading line: ", err)
--			break
--		}
--	}
--}
--
--func runSearch(client libraryv1.OrchestratorServiceClient, query string) {
--	if debugMode {
--		log.Printf("📡 Sending query: '%s'", query)
--	}
--
--	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
--	defer cancel()
--
--	resp, err := client.Search(ctx, &libraryv1.SearchRequest{
--		Query:   query,
--		TraceId: "cli-user",
--	})
--
--	if err != nil {
--		log.Printf("❌ Error: %v", err)
--		return
--	}
--
--	if resp.Total == 0 && len(resp.Books) == 0 {
--		fmt.Println("No results found.")
--		return
--	}
--
--	fmt.Printf("%-40s | %-40s | %s\n", "ID", "Title", "Authors")
--	fmt.Println(strings.Repeat("-", 100))
--
--	for _, b := range resp.Books {
--		fmt.Printf("%-40s | %-40s | %s\n", 
--			b.Id, 
--			truncate(b.Title, 38), 
--			truncate(strings.Join(b.Authors, ", "), 30),
--		)
--	}
--}
--
--func truncate(s string, max int) string {
--	runes := []rune(s)
--	if len(runes) > max {
--		return string(runes[:max]) + "..."
--	}
--	return s
--}
--
----- END_FILE: ./cmd/cli/main.go ---
--
----- START_FILE: ./cmd/client/main.go ---
--package main
--
--import (
--	"context"
--	"log"
--	"time"
--
--	"ebusta/api/proto/v1" // Убедись, что модуль называется так же, как в go.mod
--	"google.golang.org/grpc"
--	"google.golang.org/grpc/credentials/insecure"
--)
--
--func main() {
--	// Подключаемся к серверу Data-Manager
--	conn, err := grpc.Dial("localhost:50051", grpc.WithTransportCredentials(insecure.NewCredentials()))
--	if err != nil {
--		log.Fatalf("did not connect: %v", err)
--	}
--	defer conn.Close()
--
--	c := libraryv1.NewLibraryServiceClient(conn)
--
--	ctx, cancel := context.WithTimeout(context.Background(), time.Second)
--	defer cancel()
--
--	log.Println("--- Ebusta gRPC Client: Sending Search Request ---")
--	
--	// ИСПРАВЛЕНИЕ 1: Метод называется SearchBooks
--	r, err := c.SearchBooks(ctx, &libraryv1.SearchRequest{
--		Query: "Flibusta rules",
--		Limit: 5,
--	})
--	if err != nil {
--		log.Fatalf("could not search: %v", err)
--	}
--
--	// ИСПРАВЛЕНИЕ 2: Используем GetTotal() вместо GetTotalFound()
--	log.Printf("Response from server: Found %d books", r.GetTotal())
--	
--	for _, book := range r.GetBooks() {
--		log.Printf("-> Book: [%s] %s (Authors: %v)", book.GetId(), book.GetTitle(), book.GetAuthors())
--	}
--}
--
----- END_FILE: ./cmd/client/main.go ---
--
----- START_FILE: ./cmd/web-adapter/main.go ---
--package main
--
--import (
--	"context"
--	"fmt"
--	"log"
--	"net/http"
--	"os"
--	"strings"
--	"time"
--
--	"ebusta/api/proto/v1"
--	"google.golang.org/grpc"
--	"google.golang.org/grpc/credentials/insecure"
--)
--
--func main() {
--	// 1. Подключение к Orchestrator (порт 50054)
--	orchHost := os.Getenv("ORCHESTRATOR_HOST")
--	if orchHost == "" {
--		orchHost = "localhost:50054"
--	}
--
--	conn, err := grpc.Dial(orchHost, grpc.WithTransportCredentials(insecure.NewCredentials()))
--	if err != nil {
--		log.Fatalf("did not connect: %v", err)
--	}
--	defer conn.Close()
--
--	// ИСПРАВЛЕНИЕ 1: Правильное имя клиента (OrchestratorServiceClient)
--	client := libraryv1.NewOrchestratorServiceClient(conn)
--
--	http.HandleFunc("/input", func(w http.ResponseWriter, r *http.Request) {
--		query := r.URL.Query().Get("msg")
--		if query == "" {
--			query = r.URL.Query().Get("q")
--		}
--		
--		if query == "" {
--			http.Error(w, "Please provide 'msg' parameter", http.StatusBadRequest)
--			return
--		}
--
--		log.Printf("🌍 Web Adapter received: %s", query)
--
--		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
--		defer cancel()
--
--		// ИСПРАВЛЕНИЕ 2: Используем SearchRequest и метод Search
--		resp, err := client.Search(ctx, &libraryv1.SearchRequest{
--			Query: query,
--		})
--
--		if err != nil {
--			http.Error(w, fmt.Sprintf("Error calling Orchestrator: %v", err), http.StatusInternalServerError)
--			return
--		}
--
--		// Форматируем простой текстовый ответ
--		w.Header().Set("Content-Type", "text/plain; charset=utf-8")
--		
--		if len(resp.Books) == 0 {
--			fmt.Fprintf(w, "No books found for: %s\n", query)
--			return
--		}
--
--		fmt.Fprintf(w, "Found %d books:\n", len(resp.Books))
--		fmt.Fprintln(w, strings.Repeat("-", 40))
--		for _, b := range resp.Books {
--			authors := strings.Join(b.Authors, ", ")
--			fmt.Fprintf(w, "[%s] %s — %s\n", b.Id, b.Title, authors)
--		}
--	})
--
--	port := os.Getenv("PORT")
--	if port == "" {
--		port = "8080"
--	}
--
--	log.Printf("🌍 Web Adapter started on :%s", port)
--	if err := http.ListenAndServe(":"+port, nil); err != nil {
--		log.Fatalf("failed to serve: %v", err)
--	}
--}
--
----- END_FILE: ./cmd/web-adapter/main.go ---
--
----- START_FILE: ./cmd/auth-manager/whitelist.yaml ---
--users:
--  - id: "serge_dev_cli"
--    platform: "cli"
--    role: "admin"
--  - id: "12345678"
--    platform: "telegram"
--    role: "family"
--
----- END_FILE: ./cmd/auth-manager/whitelist.yaml ---
--
----- START_FILE: ./cmd/auth-manager/main.go ---
--package main
--
--import (
--	"context"
--	"log"
--	"net"
--	"os"
--
--	"ebusta/api/proto/v1"
--	"google.golang.org/grpc"
--	"gopkg.in/yaml.v3"
--)
--
--type UserEntry struct {
--	ID       string `yaml:"id"`
--	Platform string `yaml:"platform"`
--	Role     string `yaml:"role"`
--}
--
--type Whitelist struct {
--	Users []UserEntry `yaml:"users"`
--}
--
--type authServer struct {
--	libraryv1.UnimplementedAuthServiceServer
--	whitelist Whitelist
--}
--
--func (s *authServer) CheckAccess(ctx context.Context, req *libraryv1.AccessRequest) (*libraryv1.AccessResponse, error) {
--	log.Printf("[%s] Auth check: user=%s platform=%s", req.TraceId, req.UserId, req.Platform)
--
--	for _, u := range s.whitelist.Users {
--		if u.ID == req.UserId && u.Platform == req.Platform {
--			return &libraryv1.AccessResponse{
--				Allowed:  true,
--				UserRole: u.Role,
--			}, nil
--		}
--	}
--
--	return &libraryv1.AccessResponse{
--		Allowed: false,
--		Reason:  "Access denied: user not in whitelist for this platform",
--	}, nil
--}
--
--func main() {
--	data, err := os.ReadFile("cmd/auth-manager/whitelist.yaml")
--	if err != nil {
--		log.Fatalf("Failed to read whitelist: %v", err)
--	}
--
--	var wl Whitelist
--	if err := yaml.Unmarshal(data, &wl); err != nil {
--		log.Fatalf("Failed to parse whitelist: %v", err)
--	}
--
--	lis, err := net.Listen("tcp", ":50055")
--	if err != nil {
--		log.Fatalf("failed to listen: %v", err)
--	}
--
--	s := grpc.NewServer()
--	libraryv1.RegisterAuthServiceServer(s, &authServer{whitelist: wl})
--
--	log.Println("🛡  Auth-Manager started on :50055")
--	if err := s.Serve(lis); err != nil {
--		log.Fatalf("failed to serve: %v", err)
--	}
--}
--
----- END_FILE: ./cmd/auth-manager/main.go ---
--
----- START_FILE: ./cmd/orchestrator/main.go ---
--package main
--
--import (
--	"context"
--	"log"
--	"net"
--
--	"ebusta/api/proto/v1"
--	"google.golang.org/grpc"
--	"google.golang.org/grpc/credentials/insecure"
--)
--
--type orchestratorServer struct {
--	libraryv1.UnimplementedOrchestratorServiceServer
--	processorClient libraryv1.ProcessorServiceClient
--}
--
--func (s *orchestratorServer) Search(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
--	log.Printf("🎼 Orchestrator received: %s", req.Query)
--	return s.processorClient.Process(ctx, req)
--}
--
--func main() {
--	// Orchestrator -> Processor
--	conn, err := grpc.Dial("localhost:50053", grpc.WithTransportCredentials(insecure.NewCredentials()))
--	if err != nil {
--		log.Fatalf("failed to connect to processor: %v", err)
--	}
--
--	lis, err := net.Listen("tcp", ":50054")
--	if err != nil {
--		log.Fatalf("failed to listen: %v", err)
--	}
--
--	s := grpc.NewServer()
--	libraryv1.RegisterOrchestratorServiceServer(s, &orchestratorServer{
--		processorClient: libraryv1.NewProcessorServiceClient(conn),
--	})
--
--	log.Println("🎼 Orchestrator started on :50054")
--	s.Serve(lis)
--}
--
----- END_FILE: ./cmd/orchestrator/main.go ---
--
----- START_FILE: ./cmd/message-converter/main.go ---
--package main
--
--import (
--	"context"
--	"fmt"
--	"log"
--	"net"
--
--	"ebusta/api/proto/v1"
--	"ebusta/internal/parser"
--	"google.golang.org/grpc"
--)
--
--type server struct {
--	libraryv1.UnimplementedMessageConverterServiceServer
--}
--
--func (s *server) Convert(ctx context.Context, req *libraryv1.RawInput) (*libraryv1.UnmarshaledMessage, error) {
--	log.Printf("🔄 Converter parsing: %s", req.Data)
--
--	// Теперь эта функция существует в internal/parser/parser.go
--	queryAst := parser.Parse(req.Data)
--
--	return &libraryv1.UnmarshaledMessage{
--		Meta: &libraryv1.MessageMeta{
--			TraceId:       req.TraceId,
--			CanonicalForm: req.Data,
--			// Преобразуем структуру AST в строку для логов/отладки
--			AstPlan:       fmt.Sprintf("%v", queryAst),
--		},
--		Query: queryAst,
--	}, nil
--}
--
--func main() {
--	lis, err := net.Listen("tcp", ":50052")
--	if err != nil {
--		log.Fatalf("failed to listen: %v", err)
--	}
--
--	s := grpc.NewServer()
--	libraryv1.RegisterMessageConverterServiceServer(s, &server{})
--
--	log.Println("🔄 MessageConverter started on :50052")
--	if err := s.Serve(lis); err != nil {
--		log.Fatalf("failed to serve: %v", err)
--	}
--}
--
----- END_FILE: ./cmd/message-converter/main.go ---
--
----- START_FILE: ./backlog-parser.md ---
--Цель: Перевод Processor на полную поддержку Ebusta Search DSL v1.1 через обход дерева SearchQuery.
--+3
--
--1. Рефакторинг контракта взаимодействия
--Изменить логику обработки в cmd/processor/main.go , чтобы сервис извлекал поле query типа SearchQuery из входящего сообщения UnmarshaledMessage.
--+4
--
--Обеспечить передачу структурированного объекта SearchQuery от Message-Converter к Processor через gRPC.
--+3
--
--2. Реализация компонента AST Walker
--Разработать рекурсивную функцию обхода дерева SearchQuery в internal/processor.
--+2
--
--Реализовать обработку узла LogicalNode для поддержки операторов AND и OR.
--+1
--
--Реализовать обработку узла NotNode для поддержки инверсии запросов (negation).
--+1
--
--3. Маппинг узлов на шаблоны OpenSearch
--Заменить проверку strings.HasPrefix(queryLower, "author:") на извлечение FilterNode с полем field: "author".
--+1
--
--Привязать FilterNode  к существующим шаблонам данных:
--
--
--field: "author" -> fl_author_exact / fl_author_fuzzy.
--
--
--field: "title" -> fl_title_substring / fl_title_prefix.
--
--
--field: "any" -> fl_mixed_search.
--+1
--
--Интегрировать поддержку Operator:
--+1
--
--
--OP_REGEX -> трансляция в регулярные выражения OpenSearch.
--
--
--OP_EQUALS -> точное совпадение.
--+1
--
--4. Координация логических условий
--Реализовать трансляцию LogicalNode в структуру bool query (must, should, must_not) для OpenSearch.
--+3
--
--Обеспечить соблюдение приоритетов операторов: NOT > AND > OR.
--
--5. Тестирование и верификация
--Добавить интеграционные тесты в tests/smoke_full.sh для проверки цепочки: DSL-строка -> Message-Converter (AST) -> Processor (Walker) -> Data-Manager.
--+2
--
--Верифицировать поле meta.canonical_form в ответе для подтверждения корректности разобранного дерева.
--+1
--
--Аудит готовности:
--
--
--Переменные: Поля LogicalOp, Operator и SearchQuery уже объявлены в api/proto/v1/library.proto.
--+1
--
--
--Функции: Парсер parser.Parse(req.Data) уже интегрирован в cmd/message-converter/main.go.
--
--
--Инфраструктура: Шаблоны OpenSearch (fl_mixed_search, fl_author_exact и др.) готовы к приему структурированных параметров.
--
----- END_FILE: ./backlog-parser.md ---
--
----- START_FILE: ./books.json ---
--[
--  {"id": "1", "title": "Оно", "authors": ["Стивен Кинг"]},
--  {"id": "2", "title": "Сияние", "authors": ["Стивен Кинг"]},
--  {"id": "3", "title": "The Hobbit", "authors": ["J.R.R. Tolkien"]}
--]
--
----- END_FILE: ./books.json ---
--
----- START_FILE: ./go.mod ---
--module ebusta
--
--go 1.24.0
--
--toolchain go1.24.11
--
--require (
--	github.com/kelseyhightower/envconfig v1.4.0
--	github.com/peterh/liner v1.2.2
--	github.com/prometheus/client_golang v1.23.2
--	github.com/schollz/progressbar/v3 v3.19.0
--	github.com/sirupsen/logrus v1.9.3
--	github.com/spf13/viper v1.21.0
--	golang.org/x/text v0.31.0
--	google.golang.org/grpc v1.78.0
--	google.golang.org/protobuf v1.36.10
--	gopkg.in/yaml.v3 v3.0.1
--)
--
--require (
--	github.com/beorn7/perks v1.0.1 // indirect
--	github.com/cespare/xxhash/v2 v2.3.0 // indirect
--	github.com/fsnotify/fsnotify v1.9.0 // indirect
--	github.com/go-viper/mapstructure/v2 v2.4.0 // indirect
--	github.com/mattn/go-runewidth v0.0.16 // indirect
--	github.com/mitchellh/colorstring v0.0.0-20190213212951-d06e56a500db // indirect
--	github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect
--	github.com/pelletier/go-toml/v2 v2.2.4 // indirect
--	github.com/prometheus/client_model v0.6.2 // indirect
--	github.com/prometheus/common v0.66.1 // indirect
--	github.com/prometheus/procfs v0.16.1 // indirect
--	github.com/rivo/uniseg v0.4.7 // indirect
--	github.com/sagikazarmark/locafero v0.11.0 // indirect
--	github.com/sourcegraph/conc v0.3.1-0.20240121214520-5f936abd7ae8 // indirect
--	github.com/spf13/afero v1.15.0 // indirect
--	github.com/spf13/cast v1.10.0 // indirect
--	github.com/spf13/pflag v1.0.10 // indirect
--	github.com/subosito/gotenv v1.6.0 // indirect
--	go.yaml.in/yaml/v2 v2.4.2 // indirect
--	go.yaml.in/yaml/v3 v3.0.4 // indirect
--	golang.org/x/net v0.47.0 // indirect
--	golang.org/x/sys v0.38.0 // indirect
--	golang.org/x/term v0.37.0 // indirect
--	google.golang.org/genproto/googleapis/rpc v0.0.0-20251029180050-ab9386a59fda // indirect
--)
--
----- END_FILE: ./go.mod ---
--
----- START_FILE: ./Makefile ---
--BIN_DIR=bin
--PROTO_DIR=api/proto/v1
--
--.PHONY: build run stop clean smoke-test smoke proto tidy
--
--# Главная цель: сначала генерация proto, потом сборка
--build: proto
--	@mkdir -p $(BIN_DIR)
--	@# Создаем скрипт для логирования (вывод в консоль + файл)
--	@printf "#!/bin/bash\ntee -a \$$1" > $(BIN_DIR)/tee.sh && chmod +x $(BIN_DIR)/tee.sh
--	
--	@echo "📦 Tidy root dependencies..."
--	@go mod tidy
--
--	@echo "🏗️  Building Core Services..."
--	@go build -o $(BIN_DIR)/datamanager ./cmd/datamanager
--	@go build -o $(BIN_DIR)/auth-manager ./cmd/auth-manager
--	@go build -o $(BIN_DIR)/message-converter ./cmd/message-converter
--	@go build -o $(BIN_DIR)/processor ./cmd/processor
--	@go build -o $(BIN_DIR)/orchestrator ./cmd/orchestrator
--	@go build -o $(BIN_DIR)/web-adapter ./cmd/web-adapter
--	@go build -o $(BIN_DIR)/ebusta-cli ./cmd/cli
--	@go build -o $(BIN_DIR)/client ./cmd/client
--
--	@echo "🏗️  Building F2Bulker (Nested Module)..."
--	@cd f2bulker && go mod tidy && go build -o ../$(BIN_DIR)/f2bulker ./cmd/bulker
--
--# Генерация gRPC кода
--proto:
--	@echo "🧬 Generating gRPC code..."
--	@protoc --proto_path=. \
--		--go_out=. --go_opt=paths=source_relative \
--		--go-grpc_out=. --go-grpc_opt=paths=source_relative \
--		$(PROTO_DIR)/library.proto
--
--# Запуск инфраструктуры
--run: stop build
--	@echo "🚀 Starting services..."
--	@./$(BIN_DIR)/datamanager 2>&1 | ./$(BIN_DIR)/tee.sh datamanager.log &
--	@./$(BIN_DIR)/auth-manager 2>&1 | ./$(BIN_DIR)/tee.sh auth-manager.log &
--	@./$(BIN_DIR)/message-converter 2>&1 | ./$(BIN_DIR)/tee.sh message-converter.log &
--	@./$(BIN_DIR)/processor 2>&1 | ./$(BIN_DIR)/tee.sh processor.log &
--	@./$(BIN_DIR)/orchestrator 2>&1 | ./$(BIN_DIR)/tee.sh orchestrator.log &
--	@./$(BIN_DIR)/web-adapter 2>&1 | ./$(BIN_DIR)/tee.sh web-adapter.log &
--	@echo "✅ All systems go! Logs are being written to *.log"
--	@sleep 2
--
--# Остановка (игнорируем ошибки если процесс не найден)
--stop:
--	@echo "🛑 Stopping services..."
--	@-pkill -f $(BIN_DIR)/datamanager > /dev/null 2>&1 || true
--	@-pkill -f $(BIN_DIR)/auth-manager > /dev/null 2>&1 || true
--	@-pkill -f $(BIN_DIR)/message-converter > /dev/null 2>&1 || true
--	@-pkill -f $(BIN_DIR)/processor > /dev/null 2>&1 || true
--	@-pkill -f $(BIN_DIR)/orchestrator > /dev/null 2>&1 || true
--	@-pkill -f $(BIN_DIR)/web-adapter > /dev/null 2>&1 || true
--
--# Быстрый тест CLI
--smoke-test:
--	@echo "🧪 Running CLI Smoke Check..."
--	@./$(BIN_DIR)/ebusta-cli "author:Кинг" | grep -q "Plan" && echo "  ✅ CLI OK" || (echo "  ❌ CLI Failed"; exit 1)
--
--# Запуск скриптовых тестов
--smoke:
--	@echo "🧪 Running Integration Smoke Tests..."
--	@for test in tests/smoke_*.sh; do \
--		echo -n "Running $$test... "; \
--		bash $$test; \
--	done
--
--# Очистка
--clean: stop
--	@echo "🧹 Cleaning up..."
--	rm -rf $(BIN_DIR) *.log
--	# Удаляем сгенерированные pb.go файлы, чтобы гарантировать чистую пересборку
--	find . -name "*.pb.go" -delete
--
----- END_FILE: ./Makefile ---
--
----- START_FILE: ./f2bulker/config.yaml ---
--opensearch:
--  index_name: "flibusta_merged_index"
--  url: "http://192.168.1.179:9200"
--
--paths:
--  warn_dir: "./data/warn"
--  output_dir: "./data/out"
--  source_dir: "/mnt/fb2/fb2.Flibusta.Net"
--
--processing:
--  threads: 4
--
--logging:
--  log_path: "f2bulker.log"
--
--metrics:
--  pushgateway_url: "http://localhost:9091"
--
--# Пауза в секундах между архивами, чтобы сервер остыл
--sleep_between_zips: 600 
--
--
--uploading:
--  log_path: "uploader.log"
--  sleep_between_uploads: 30
--
----- END_FILE: ./f2bulker/config.yaml ---
--
----- START_FILE: ./f2bulker/cmd/bulker/main.go ---
--package main
--
--import (
--	"archive/zip"
--	"bufio"
--	"bytes"
--	"crypto/sha1"
--	"encoding/hex"
--	"encoding/json"
--	"encoding/xml"
--	"flag"
--	"fmt"
--	"io"
--	"os"
--	"path/filepath"
--	"regexp"
--	"strings"
--	"sync"
--	"sync/atomic"
--	"time"
--
--	"github.com/schollz/progressbar/v3"
--	"github.com/sirupsen/logrus"
--	"golang.org/x/text/encoding/charmap"
--	"golang.org/x/text/encoding/unicode"
--	"gopkg.in/yaml.v3"
--)
--
--type Config struct {
--	OpenSearch struct {
--		IndexName string `yaml:"index_name"`
--	} `yaml:"opensearch"`
--	Paths struct {
--		WarnDir   string `yaml:"warn_dir"`
--		OutputDir string `yaml:"output_dir"`
--		SourceDir string `yaml:"source_dir"`
--	} `yaml:"paths"`
--	Processing struct {
--		Threads int `yaml:"threads"`
--	} `yaml:"processing"`
--}
--
--type docOut struct {
--	Title      string    `json:"title"`
--	Authors    []string  `json:"authors,omitempty"`
--	IngestedAt time.Time `json:"ingestedAt"`
--	FileInfo   struct {
--		Container string `json:"container"`
--		Filename  string `json:"filename"`
--		Sha1      string `json:"sha1"`
--		Size      int64  `json:"size"`
--	} `json:"fileInfo"`
--}
--
--var (
--	cfg           Config
--	log           = logrus.New()
--	outFile       *os.File
--	outMu         sync.Mutex
--	bar           *progressbar.ProgressBar
--	rescuedCount  int32
--	flagRescan    *bool
--	flagVerbose   *bool
--	flagSuperFast *bool
--)
--
--func main() {
--	configPath := flag.String("config", "./config.yaml", "Path to config file")
--	container := flag.String("container", "", "Process specific ZIP")
--	rescue := flag.Bool("rescue", false, "Rescue mode")
--	flagRescan = flag.Bool("rescan", false, "Force rescan all")
--	flagVerbose = flag.Bool("verbose", false, "Detailed check")
--	flagSuperFast = flag.Bool("fast", false, "Ultra-fast skip if output exists")
--	flag.Parse()
--
--	cFile, err := os.ReadFile(*configPath)
--	if err != nil {
--		fmt.Printf("Error reading config: %v\n", err)
--		os.Exit(1)
--	}
--	if err := yaml.Unmarshal(cFile, &cfg); err != nil {
--		fmt.Printf("Error parsing YAML: %v\n", err)
--		os.Exit(1)
--	}
--
--	log.SetFormatter(&logrus.TextFormatter{FullTimestamp: true, ForceColors: true})
--	_ = os.MkdirAll(cfg.Paths.OutputDir, 0755)
--
--	if *rescue {
--		runRescueMode()
--	} else if *container != "" {
--		processSingleZip(filepath.Join(cfg.Paths.SourceDir, *container), filepath.Join(cfg.Paths.OutputDir, *container+".jsonl"))
--	} else {
--		archives, _ := filepath.Glob(filepath.Join(cfg.Paths.SourceDir, "*.zip"))
--		for _, zipPath := range archives {
--			processSingleZip(zipPath, filepath.Join(cfg.Paths.OutputDir, filepath.Base(zipPath)+".jsonl"))
--		}
--	}
--}
--
--func normalizeJSONL(path string) (int, error) {
--	f, err := os.Open(path)
--	if err != nil { return 0, err }
--	defer f.Close()
--	tmpPath := path + ".tmp"
--	tmpFile, err := os.Create(tmpPath)
--	if err != nil { return 0, err }
--	defer tmpFile.Close()
--
--	hashes := make(map[string]bool)
--	scanner := bufio.NewScanner(f)
--	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
--	count := 0
--	for scanner.Scan() {
--		line1 := scanner.Text()
--		if strings.Contains(line1, `"_index"`) {
--			match := re.FindStringSubmatch(line1)
--			if len(match) > 1 {
--				id := match[1]
--				if scanner.Scan() {
--					line2 := scanner.Text()
--					if !hashes[id] {
--						hashes[id] = true
--						_, _ = tmpFile.WriteString(line1 + "\n")
--						_, _ = tmpFile.WriteString(line2 + "\n")
--						count++
--					}
--				}
--			}
--		}
--	}
--	_ = os.Rename(tmpPath, path)
--	return count, nil
--}
--
--func countExistingDocs(path string) int {
--	count := 0
--	f, err := os.Open(path)
--	if err != nil { return 0 }
--	defer f.Close()
--	scanner := bufio.NewScanner(f)
--	for scanner.Scan() {
--		if strings.Contains(scanner.Text(), `"_index"`) { count++ }
--	}
--	return count
--}
--
--func loadExistingHashes(path string) map[string]bool {
--	hashes := make(map[string]bool)
--	f, err := os.Open(path)
--	if err != nil { return hashes }
--	defer f.Close()
--	scanner := bufio.NewScanner(f)
--	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
--	for scanner.Scan() {
--		line := scanner.Text()
--		if strings.Contains(line, `"_index"`) {
--			match := re.FindStringSubmatch(line)
--			if len(match) > 1 { hashes[match[1]] = true }
--		}
--	}
--	return hashes
--}
--
--func processSingleZip(zipPath, dstPath string) {
--	containerName := filepath.Base(zipPath)
--	if *flagSuperFast && !*flagRescan {
--		if info, err := os.Stat(dstPath); err == nil && info.Size() > 0 {
--			log.Infof("[%s] Fast-skip: exists.", containerName)
--			os.Exit(10)
--		}
--	}
--
--	z, err := zip.OpenReader(zipPath)
--	if err != nil { return }
--	defer z.Close()
--
--	fb2Count := 0
--	for _, f := range z.File {
--		if strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { fb2Count++ }
--	}
--
--	if !*flagRescan && !*flagVerbose {
--		if jsonlCount := countExistingDocs(dstPath); jsonlCount > 0 {
--			if fb2Count == jsonlCount {
--				os.Exit(10)
--			} else {
--				newCount, _ := normalizeJSONL(dstPath)
--				if newCount == fb2Count { os.Exit(10) }
--			}
--		}
--	}
--
--	existingHashes := make(map[string]bool)
--	if !*flagRescan { existingHashes = loadExistingHashes(dstPath) }
--
--	type workItem struct {
--		file *zip.File
--		raw  []byte
--		sha  string
--	}
--	var tasks []workItem
--
--	for _, f := range z.File {
--		if !strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { continue }
--		
--		if len(existingHashes) == 0 && !*flagRescan && !*flagVerbose {
--			tasks = append(tasks, workItem{file: f})
--			continue
--		}
--
--		rc, err := f.Open()
--		if err != nil { continue }
--		data, _ := io.ReadAll(rc)
--		rc.Close()
--		sum := sha1.Sum(data)
--		sha := hex.EncodeToString(sum[:])
--		if !existingHashes[sha] {
--			tasks = append(tasks, workItem{file: f, raw: data, sha: sha})
--		}
--	}
--
--	if len(tasks) == 0 { os.Exit(10) }
--
--	openOutputFile(dstPath)
--	defer outFile.Close()
--	bar = progressbar.Default(int64(len(tasks)), "🚢 "+containerName)
--	jobs := make(chan workItem)
--	var wg sync.WaitGroup
--	for i := 0; i < cfg.Processing.Threads; i++ {
--		wg.Add(1)
--		go func() {
--			defer wg.Done()
--			for item := range jobs {
--				if item.raw == nil {
--					rc, err := item.file.Open()
--					if err == nil {
--						item.raw, _ = io.ReadAll(rc)
--						rc.Close()
--						sum := sha1.Sum(item.raw)
--						item.sha = hex.EncodeToString(sum[:])
--					}
--				}
--				if item.raw != nil {
--					if doc, err := parseResilient(item.raw); err == nil {
--						saveToOutputWithSha(item.file.Name, containerName, item.raw, item.sha, doc)
--					}
--				}
--				_ = bar.Add(1)
--			}
--		}()
--	}
--	for _, t := range tasks { jobs <- t }
--	close(jobs)
--	wg.Wait()
--}
--
--func runRescueMode() {
--	files, _ := filepath.Glob(filepath.Join(cfg.Paths.WarnDir, "*fb2"))
--	if len(files) == 0 { return }
--	dstPath := filepath.Join(cfg.Paths.OutputDir, "rescued_items.jsonl")
--	openOutputFile(dstPath)
--	defer outFile.Close()
--	jobs := make(chan string)
--	var wg sync.WaitGroup
--	for i := 0; i < cfg.Processing.Threads; i++ {
--		wg.Add(1)
--		go func() {
--			defer wg.Done()
--			for path := range jobs {
--				data, err := os.ReadFile(path)
--				if err != nil { continue }
--				if doc, err := parseResilient(data); err == nil {
--					if saveToOutput(filepath.Base(path), "rescued", data, doc) {
--						_ = os.Remove(path)
--						atomic.AddInt32(&rescuedCount, 1)
--					}
--				}
--			}
--		}()
--	}
--	for _, f := range files { jobs <- f }
--	close(jobs)
--	wg.Wait()
--}
--
--func parseResilient(data []byte) (*docOut, error) {
--	utf8Data := convertToUTF8(data)
--	if doc, err := parseFB2(utf8Data); err == nil { return doc, nil }
--	return parseWithRegex(utf8Data)
--}
--
--func convertToUTF8(data []byte) []byte {
--	if len(data) < 2 { return data }
--	if (data[0] == 0xFF && data[1] == 0xFE) || (data[0] == 0xFE && data[1] == 0xFF) {
--		dec := unicode.UTF16(unicode.LittleEndian, unicode.UseBOM).NewDecoder()
--		out, _ := dec.Bytes(data)
--		return out
--	}
--	header := string(data[:min(len(data), 500)])
--	if strings.Contains(strings.ToLower(header), "windows-1251") {
--		out, _ := charmap.Windows1251.NewDecoder().Bytes(data)
--		return out
--	}
--	return bytes.ToValidUTF8(data, []byte(" "))
--}
--
--func parseWithRegex(data []byte) (*docOut, error) {
--	doc := &docOut{}
--	reTitle := regexp.MustCompile(`(?is)<book-title[^>]*>(.*?)</book-title>`)
--	if m := reTitle.FindSubmatch(data); len(m) > 1 { doc.Title = string(m[1]) }
--	if doc.Title == "" { return nil, fmt.Errorf("regex failed") }
--	return doc, nil
--}
--
--func openOutputFile(path string) {
--	var err error
--	outFile, err = os.OpenFile(path, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
--	if err != nil {
--		log.Fatalf("Critical: failed to open output file: %v", err)
--	}
--}
--
--func saveToOutput(filename, container string, raw []byte, doc *docOut) bool {
--	sum := sha1.Sum(raw)
--	sha := hex.EncodeToString(sum[:])
--	return saveToOutputWithSha(filename, container, raw, sha, doc)
--}
--
--func saveToOutputWithSha(filename, container string, raw []byte, sha string, doc *docOut) bool {
--	doc.FileInfo.Container, doc.FileInfo.Filename, doc.FileInfo.Sha1, doc.FileInfo.Size = container, filename, sha, int64(len(raw))
--	doc.IngestedAt = time.Now()
--	action, _ := json.Marshal(map[string]map[string]any{"index": {"_index": cfg.OpenSearch.IndexName, "_id": sha}})
--	data, _ := json.Marshal(doc)
--	outMu.Lock()
--	defer outMu.Unlock()
--	_, _ = outFile.Write(append(action, '\n'))
--	_, _ = outFile.Write(append(data, '\n'))
--	return true
--}
--
--func parseFB2(data []byte) (*docOut, error) {
--	var doc docOut
--	d := xml.NewDecoder(bytes.NewReader(data))
--	for {
--		t, _ := d.Token()
--		if t == nil { break }
--		if se, ok := t.(xml.StartElement); ok && se.Name.Local == "book-title" {
--			_ = d.DecodeElement(&doc.Title, &se)
--		}
--	}
--	if doc.Title == "" { return nil, fmt.Errorf("no title") }
--	return &doc, nil
--}
--
--func min(a, b int) int { if a < b { return a }; return b }
--
----- END_FILE: ./f2bulker/cmd/bulker/main.go ---
--
----- START_FILE: ./f2bulker/go.mod ---
--module f2bulker
--
--go 1.24.11
--
--require (
--	github.com/schollz/progressbar/v3 v3.19.0
--	github.com/sirupsen/logrus v1.9.3
--	golang.org/x/text v0.32.0
--	gopkg.in/yaml.v3 v3.0.1
--)
--
--require (
--	github.com/kr/pretty v0.3.1 // indirect
--	github.com/mitchellh/colorstring v0.0.0-20190213212951-d06e56a500db // indirect
--	github.com/rivo/uniseg v0.4.7 // indirect
--	github.com/rogpeppe/go-internal v1.10.0 // indirect
--	github.com/stretchr/testify v1.11.1 // indirect
--	golang.org/x/sys v0.35.0 // indirect
--	golang.org/x/term v0.28.0 // indirect
--	gopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c // indirect
--)
--
----- END_FILE: ./f2bulker/go.mod ---
--
----- START_FILE: ./f2bulker/Makefile ---
--BINARY_NAME=f2bulker
--INSTALL_DIR=/opt/f2bulker
--BIN_PATH=$(INSTALL_DIR)/$(BINARY_NAME)
--LOCAL_BIN=./bin/$(BINARY_NAME)
--IS_ROOT = $(shell id -u)
--
--.PHONY: build install clean check-root
--
--build:
--	go mod tidy
--	mkdir -p bin
--	go build -o $(LOCAL_BIN) ./cmd/bulker/main.go
--
--check-root:
--ifneq ($(IS_ROOT), 0)
--	@echo "Error: Run 'sudo make install'"
--	@exit 1
--endif
--
--install: check-root
--	@if [ ! -f $(LOCAL_BIN) ]; then echo "Run 'make build' first"; exit 1; fi
--	mkdir -p $(INSTALL_DIR)
--	mkdir -p $(INSTALL_DIR)/data/src $(INSTALL_DIR)/data/out $(INSTALL_DIR)/data/warn
--	cp $(LOCAL_BIN) $(INSTALL_DIR)/
--	cp ./config.yaml $(INSTALL_DIR)/
--	cp ./scripts/scan_zips.sh $(INSTALL_DIR)/
--	chmod +x $(BIN_PATH)
--	chmod +x $(INSTALL_DIR)/scan_zips.sh
--	@echo "Installed to $(INSTALL_DIR)"
--	@echo "Link: sudo ln -sf $(BIN_PATH) /usr/local/bin/$(BINARY_NAME)"
--
--clean:
--	rm -rf bin
--
----- END_FILE: ./f2bulker/Makefile ---
--
----- START_FILE: ./f2bulker/README.md ---
--# f2bulker: Высокопроизводительный индексатор FB2 в OpenSearch
--
--## 1. Спецификация требований (ISO 29148)
--
--Данный раздел формализует требования к системе, обеспечивая их проверяемость и соответствие техническим целям проекта.
--
--### 1.1 Функциональные требования (Functional Requirements)
--* **FR-1: Извлечение из ZIP.** Система должна открывать ZIP-архивы и извлекать файлы формата `.fb2`.
--* **FR-2: Парсинг метаданных.** Программа должна извлекать название книги и список авторов из структуры FB2.
--* **FR-3: Отказоустойчивость.** При ошибках XML-парсинга система должна применять поиск через регулярные выражения.
--* **FR-4: Формат Bulk API.** Вывод должен формироваться в формате JSONL, пригодном для Bulk API OpenSearch, включая строку метаданных индекса и строку документа.
--* **FR-5: Дедупликация.** Система должна рассчитывать SHA1-хеш каждого файла и пропускать уже обработанные объекты на основе анализа выходного файла.
--* **FR-6: Режим Fast-skip.** При установленном флаге `-fast` система должна мгновенно пропускать контейнер, если соответствующий ему `.jsonl` файл существует и не пуст.
--* **FR-7: Управление через CLI.** Программа должна поддерживать флаги `-config`, `-container`, `-rescan`, `-verbose`, `-fast`.
--* **FR-8: Интеграция со скриптами.** Программа должна возвращать код завершения `10` при пропуске обработанного контейнера для корректной работы внешних планировщиков.
--
--### 1.2 Нефункциональные требования (Performance & Quality)
--* **PR-1: Параллелизм.** Обработка должна распределяться между потоками (горутинами) согласно параметру `Threads` в конфигурации.
--* **PR-2: Оптимизация Discovery.** Для новых контейнеров этап подготовки задач не должен включать чтение содержимого файлов в основном потоке.
--* **PR-3: Эффективность памяти.** Содержимое файлов должно очищаться из RAM сразу после записи в выходной файл.
--* **PR-4: Поддержка кодировок.** Система должна корректно обрабатывать UTF-8, UTF-16 и Windows-1251.
--
-----
--
--## 2. Документ технической реализации
--
--### 2.1 Архитектура системы
--Программа построена на модели **Concurrent Worker Pool** (Пул параллельных воркеров).
--
--
--
--#### Компоненты потока управления:
--1.  **Главный поток (Producer):** Сканирует архивы и формирует очередь задач.
--2.  **Канал задач (`jobs`):** Буферизированный канал для передачи структур `workItem`.
--3.  **Воркеры (Consumers):** Набор из N горутин, выполняющих параллельное чтение, хеширование и парсинг.
--4.  **Синхронизатор:** `sync.WaitGroup` для контроля завершения всех процессов перед выходом.
--
--### 2.2 Пошаговая передача управления
--1.  **`main` → `processSingleZip`:** Инициализация параметров конкретного контейнера.
--2.  **Проверка Fast-skip:** Если флаг `-fast` активен, управление через `os.Stat` проверяет наличие файла. При успехе — немедленный выход через `os.Exit(10)`.
--3.  **Discovery (Оптимизированный):** * Если база хешей пуста (новый контейнер), основной поток лишь заполняет список `tasks` ссылками на `zip.File`, минуя вызовы `f.Open` и `io.ReadAll`.
--    * Это устраняет "зависание" программы перед появлением прогресс-бара.
--4.  **Развертывание воркеров:** Основной поток передает задачи в канал. Управление внутри воркера реализует **Lazy Loading**: если данные файла отсутствуют (`item.raw == nil`), воркер сам инициирует чтение и расчет SHA1 параллельно с другими воркерами.
--5.  **Завершение:** После закрытия канала воркеры завершают работу, и управление возвращается в `main` для перехода к следующему ZIP-архиву.
--
--### 2.3 Жизненный цикл переменных
--* **`item.raw` ([]byte):** Данные файла. Память выделяется либо в Discovery, либо в воркере. Ссылка на массив байтов обнуляется сразу после вызова `saveToOutputWithSha`, что позволяет Garbage Collector (GC) освобождать память итеративно.
--* **`existingHashes` (map):** Карта хешей. Загружается один раз в начале обработки ZIP для дедупликации. При ее отсутствии активируется режим ускоренного Discovery.
--* **`err`:** Все переменные ошибок проходят аудит; при критических сбоях (например, невозможность открыть файл вывода) программа завершается через `log.Fatalf`.
--
--### 2.4 Матрица состояний (Аудит логики `-fast`)
--
--| Режим `-fast` | Состояние контейнера | Логика | Результат |
--| :--- | :--- | :--- | :--- |
--| **Установлен** | **Обработан** | `os.Stat` находит файл | Мгновенный выход `Exit(10)`. |
--| **Установлен** | **Не обработан** | `os.Stat` возвращает ошибку | Быстрый Discovery -> Параллельное хеширование. |
--| **Не установлен** | **Обработан** | Сравнение счетчиков файлов | Выход `Exit(10)`, если количество совпадает. |
--| **Не установлен** | **Не обработан** | База хешей пуста | Быстрый Discovery -> Параллельное хеширование. |
--
-----
--
--## 3. Инструкции по эксплуатации
--
--### Сборка
--```bash
--make build
--
----- END_FILE: ./f2bulker/README.md ---
--
----- START_FILE: ./f2bulker/backlog.md ---
--# Ebusta Project Backlog
--
--## Ingesting (f2bulker)
--- [ ] **Issue #1**: Ошибка парсинга UTF-16 (BOM ÿþ). Файл `547782.fb2` падает с `XML syntax error: invalid UTF-8`. Необходимо доработать `charsetReader` для корректной десериализации UTF-16 Little Endian. [cite: 440-442]
--- [ ] **Feature**: Поддержка группировки в DSL (скобки). [cite: 141]
--
--## System
--- [ ] **Auth**: Интеграция Auth-Manager в Orchestrator. [cite: 219-220]
--- [ ] **OS**: Переход с мока `books.json` на реальные поисковые шаблоны OpenSearch. [cite: 221]
--
----- END_FILE: ./f2bulker/backlog.md ---
--
----- START_FILE: ./README.md ---
--# Ebusta 📚
--
--Микросервисная поисковая система для архивов Flibusta. Позволяет выполнять быстрый поиск по миллионам записей через OpenSearch, используя собственный DSL (Domain Specific Language).
--
--## 🏗 Архитектура системы
--
--Система состоит из нескольких независимых сервисов, взаимодействующих по gRPC:
--
--* **Web-Adapter (The Door)**: Принимает внешние HTTP-запросы и передает их в оркестратор.
--* **Orchestrator**: Координирует работу всех сервисов, управляет Trace-ID.
--* **Message-Converter**: Парсит строку запроса в AST-дерево.
--* **Processor**: Обрабатывает бизнес-логику и выбирает стратегию поиска.
--* **Datamanager**: Слой данных, работающий с OpenSearch.
--* **Auth-Manager**: Проверяет права доступа и управляет whitelist.
--* **Ebusta-CLI**: Интерактивная оболочка для работы с системой.
--
--
--
--## 🚦 Карта портов
--
--| Сервис            | Порт (gRPC) | Функции                          |
--|:------------------|:------------|:---------------------------------|
--| Datamanager       | `:50051`    | Слой данных (OpenSearch)         |
--| Message-Converter | `:50052`    | Парсер (AST)                     |
--| Processor         | `:50053`    | Логика и выбор шаблонов          |
--| Orchestrator      | `:50054`    | Координация                      |
--| Auth-Manager      | `:50055`    | Безопасность (Whitelist)         |
--| Web-Adapter       | `:8080`     | HTTP-вход (REST)                 |
--| Metrics           | `:9091`     | Prometheus метрики (Datamanager) |
--
--## 🚀 Быстрый старт
--
--### Сборка и запуск
--Требуется установленный Go 1.21+ и Protoc.
--
--```bash
--make build   # Генерация Proto и компиляция всех сервисов
--make run     # Запуск всей системы в фоновом режиме
--
--
----- END_FILE: ./README.md ---
--
----- START_FILE: ./errors.yaml ---
--# Сообщения для пользователя ("Дятла")
--user_errors:
--  invalid_command: "🥚 Слушай, дятел, я не понял твою команду. Попробуй 'get ID' или просто текст поиска."
--  empty_payload: "🥚 Дятел, ты забыл ввести текст после команды!"
--
--# Сообщения при сбоях системы ("Сорян, братан")
--system_errors:
--  converter_down: "🛠 Сорян, братан, у нас конвертер приуныл. Скоро починим."
--  processor_error: "🛠 Сорян, братан, труба забилась. Мы уже вызвали сантехников."
--  data_layer_down: "📉 Сорян, братан, библиотека закрыта на ремонт. Попробуй позже."
--  generic_error: "🧨 Сорян, братан, что-то пошло совсем не так. RequestID: %s"
--
----- END_FILE: ./errors.yaml ---
--
----- START_FILE: ./doc/requirements.md ---
--# Спецификация требований системы "Eboost-Library" (v2.1)
--
--## 1. Основание проекта (Project Foundation)
--
--### 1.1. Описание проблемы
--Владельцы больших личных коллекций электронных книг сталкиваются с проблемой "мертвого груза": книги хранятся локально, но доступ к ним извне (с телефона, в дороге, для друзей) ограничен. Существующие решения либо слишком тяжеловесны, либо привязаны к одному интерфейсу. 
--
--### 1.2. Концепция (Scope)
--Необходима система-посредник, которая абстрагирует хранилище и поиск через единый внутренний протокол, предоставляя доступ через разные каналы коммуникации (Telegram, IRC, CLI) с сохранением контекста пользователя.
--
-----
--
--## 2. Бизнес-требования (Business Requirements)
--
--| ID | Наименование | Описание |
--| :--- | :--- | :--- |
--| **BR-1** | Мультиканальность | Единая точка входа через разные интерфейсы (TG, IRC, CLI). |
--| **BR-2** | Скорость поиска | Time-to-Content не более 3 секунд. |
--| **BR-3** | Изоляция логики | Добавление новых фронтов без изменения Core-компонентов. |
--| **BR-4** | Управляемый доступ | Ограничение доступа только для доверенного круга лиц. |
--| **BR-5** | Поддержка форматов | Обработка и выдача разных расширений (EPUB, PDF, FB2). |
--| **BR-6** | Континуитет сессий | Сохранение состояния поиска и навигации (пагинации). |
--| **BR-7** | Масштабируемость | Стабильная работа при объеме базы до 1 000 000 книг. |
--| **BR-8** | Автономность | Работа с локальными файлами без внешних зависимостей. |
--
-----
--
--## 3. Требования заинтересованных сторон (Stakeholder Requirements)
--
--### 3.1. Группа: Поиск и навигация
--* **UR-1: Поиск по атрибутам.** Пользователь должен иметь возможность найти книгу по автору, названию или серии.
--    * *Трассировка:* [BR-1, BR-7, BR-2]
--* **UR-2: Просмотр результатов.** Пользователь должен иметь возможность листать страницы выдачи (пагинация) без повторного ввода запроса.
--    * *Трассировка:* [BR-6]
--* **UR-3: Уточнение формата.** При выборе книги система должна предлагать список доступных для неё форматов.
--    * *Трассировка:* [BR-5]
--
--### 3.2. Группа: Получение контента
--* **UR-4: Прямая доставка (TG).** В Telegram файл должен приходить документом (до определенного лимита размера).
--    * *Трассировка:* [BR-1, BR-8]
--* **UR-5: Ссылочная доставка (IRC/CLI).** В текстовых интерфейсах пользователь должен получать временную ссылку на скачивание.
--    * *Трассировка:* [BR-1, BR-8]
--
--### 3.3. Группа: Доступ и интерфейс
--* **UR-6: Прозрачная авторизация.** Доступ предоставляется автоматически на основе ID платформы (UID Telegram, Host IRC).
--    * *Трассировка:* [BR-4]
--* **UR-7: Унификация команд.** Командный синтаксис должен быть единообразным для всех адаптеров.
--    * *Трассировка:* [BR-1, BR-3]
--
--### 3.4. Группа: Администрирование
--* **UR-8: Управление белыми списками.** Владелец должен иметь возможность оперативно менять список разрешенных ID.
--    * *Трассировка:* [BR-4]
--
-----
--
--## 4. Глоссарий
--* **UnifiedMessage** — внутренний формат структуры данных, в который преобразуются все входящие запросы.
--* **Whitelist** — список идентификаторов пользователей, имеющих доступ к системе.
--* **OpenSearch** — основной движок полнотекстового поиска.
--
----- END_FILE: ./doc/requirements.md ---
--
----- START_FILE: ./doc/architecture-IN.md ---
--cat << 'EOF' > ebusta_arch_spec.md
--# Техническая спецификация: Архитектура Ebusta (Orchestration Model)
--
--**Дата:** 05.01.2026
--**Статус:** Утверждено
--**Модель взаимодействия:** Централизованная оркестрация (Orchestration)
--
--## 1. Обзор архитектуры
--Система строится на базе центрального компонента (**Orchestrator**), который координирует работу «тонких» адаптеров, парсера DSL и сервиса данных на удаленном хосте Mercury.
--
--### Ключевые узлы:
--1. **Adapters (The Door)**: SSH/BBS, Telegram, Web. Принимают ввод, передают его в Core, получают результат и рендерят его.
--2. **Orchestrator (Core)**: Логический центр. Управляет жизненным циклом запроса.
--3. **Parser**: Библиотека для конвертации строки в `libraryv1.SearchQuery`.
--4. **Data Manager (Mercury Proxy)**: gRPC-сервис, транслирующий запросы в OpenSearch (Docker на Mercury).
--
--## 2. Спецификация UnifiedMessage
--`UnifiedMessage` является единым транспортным контейнером внутри системы.
--
--```protobuf
--message UnifiedMessage {
--    string request_id = 1;
--    
--    // Метаданные источника для обратной маршрутизации
--    message Context {
--        string client_id = 1;
--        enum SourceType {
--            BBS = 0;
--            TELEGRAM = 1;
--            WEB = 2;
--        }
--        SourceType source = 2;
--    }
--    Context context = 2;
--
--    // Полезная нагрузка (Payload)
--    oneof content {
--        libraryv1.SearchQuery query = 3;  // Структурированный запрос
--        SearchResult result = 4;          // Результаты из OpenSearch
--        string error = 5;                 // Описание ошибки
--    }
--}
--
----- END_FILE: ./doc/architecture-IN.md ---
--
----- START_FILE: ./doc/architecture.md ---
--# Архитектура системы "Eboost-Library" (v2.0)
--
--## 1. Описание проблемы
--[cite_start]Владельцы больших личных коллекций электронных книг часто сталкиваются с проблемой "мертвого груза": книги хранятся локально, но доступ к ним извне (с телефона, в дороге, для друзей) ограничен или неудобен[cite: 1, 3]. Существующие решения либо слишком тяжеловесны, либо привязаны к одному интерфейсу. [cite_start]Необходима система, которая абстрагирует хранилище и поиск, предоставляя единый доступ через разные каналы коммуникации с сохранением контекста пользователя[cite: 3, 39].
--
--## 2. Предметная область (DDD Contexts)
--Согласно принципам Domain-Driven Design, система разделена на следующие ограниченные контексты:
--* [cite_start]**Interaction (Взаимодействие):** Трансформация специфичных протоколов (Telegram, IRC, CLI) в единый бизнес-язык системы `UnifiedMessage`[cite: 4, 14].
--* [cite_start]**Identity & Access (Доступ):** Идентификация пользователей, проверка прав по Bot Token или белым спискам[cite: 6].
--* [cite_start]**Library Core (Ядро):** Оркестрация процессов разбора команд, навигации и формирования ответов[cite: 14, 15].
--* [cite_start]**Catalog (Каталог):** Полнотекстовый поиск и управление метаданными книг в OpenSearch[cite: 19, 21].
--* [cite_start]**Delivery (Доставка):** Извлечение файлов из хранилища и предоставление ссылок или бинарных данных[cite: 25, 27].
--
--## 3. Компоненты системы
--
--### Слой адаптеров (Front-end)
--* [cite_start]**TelegramAdapter:** Реализует интерфейс бота, обрабатывает Webhook/Long Polling[cite: 4].
--* [cite_start]**IrcAdapter:** Микросервис-клиент для подключения к IRC-серверам и каналам[cite: 6, 7].
--* [cite_start]**CliAdapter:** Интерфейс командной строки (Linux CLI) для удаленного обращения к ядру[cite: 10, 11].
--* [cite_start]**Translator (New):** Компонент внутри адаптеров или перед процессором, преобразующий `RawPayload` в `UnifiedMessage`[cite: 30].
--
--### Слой управления и состояния
--* **Auth-Manager (New):** Проверяет UserID на наличие в Allow-листах или внешних провайдерах (Keycloak).
--* **Session-Manager (New):** Прокси к **Redis** для хранения состояния поиска и текущего положения пользователя в каталоге.
--* [cite_start]**Config-Manager:** Централизованный сервис для хранения лимитов, шаблонов ответов и локализации[cite: 22, 23].
--
--### Слой бизнес-логики (Core)
--* [cite_start]**Processor:** Центральный сервис, выполняющий разбор команд (/book, /author) и координирующий другие службы[cite: 14, 15, 17].
--
--### Слой данных и хранилища
--* [cite_start]**Data-Manager:** Прокси-сервис для построения запросов к **OpenSearch**[cite: 19, 21].
--* [cite_start]**Book-Fetcher:** Сервис выдачи файлов по ключу из локального или объектного хранилища[cite: 25, 26, 28].
--
--## 4. Потоки данных
--
--### Поиск книги
--1.  [cite_start]**Адаптер** (TG/IRC/CLI) принимает ввод и через **Translator** создает `UnifiedMessage`[cite: 30].
--2.  **Auth-Manager** подтверждает права пользователя.
--3.  [cite_start]**Processor** запрашивает метаданные у **Data-Manager**[cite: 31].
--4.  **Processor** сохраняет ID результатов в **Session-Manager** (Redis) для поддержки пагинации.
--5.  [cite_start]Формируется ответ и возвращается пользователю через соответствующий адаптер[cite: 32, 33].
--
--### Получение файла
--1.  [cite_start]Пользователь выбирает книгу и формат[cite: 34].
--2.  [cite_start]**Processor** запрашивает файл или ссылку у **Book-Fetcher**[cite: 35, 36].
--3.  [cite_start]**Book-Fetcher** обращается к **Book Storage** и возвращает результат[cite: 37, 38].
--
--## 5. Структура проекта (Go Layout)
--```text
--.
--├── cmd/                # Точки входа (main.go) для каждого адаптера
--├── internal/           # Приватный код приложения
--│   ├── domain/         # Чистые структуры (Book, User, UnifiedMessage)
--│   ├── processor/      # Ядро (бизнес-сценарии)
--│   ├── auth/           # Проверка прав и доступ
--│   ├── session/        # Интеграция с Redis
--│   ├── translator/     # Логика маппинга сообщений
--│   ├── storage/        # Клиенты OpenSearch (Data-Manager) и FS (Fetcher)
--│   └── config/         # Config-Manager и загрузка .env/yaml
--├── pkg/                # Публичные библиотеки
--├── api/                # Протоколы обмена (gRPC/Proto или OpenAPI)
--└── deployments/        # Docker-compose и манифесты
--
----- END_FILE: ./doc/architecture.md ---
--
----- START_FILE: ./doc/ARCHITECTURE.md ---
--# Ebusta: Система поиска и доставки контента
--
--## Архитектура системы (Pipeline)
--
--Система построена на принципах микросервисной архитектуры с использованием gRPC для межсервисного взаимодействия. Весь путь сообщения от пользователя до данных разделен на изолированные этапы.
--
--### Схема потока данных (Data Flow)
--`User Input -> Adapter -> MessageConverter -> Processor -> Data-Manager`
--
-----
--
--## Компоненты системы
--
--### 1. Adapters (Входные шлюзы)
--**Пример:** `cmd/web-adapter`
--- **Функция:** Прием сырых данных из внешних интерфейсов (HTTP, TG, IRC).
--- **Ответственность:** Только транспортный уровень. Преобразует внешние запросы в gRPC-вызов `MessageConverter.Convert`.
--
--### 2. MessageConverter (Семантический анализатор)
--**Путь:** `cmd/message-converter`
--- **Функция:** Парсинг и нормализация.
--- **Задача:** Извлекает "Намерение" (Intent) и очищенные данные (Payload).
--- **UnifiedMessage:** Объект, который гарантирует, что `Processor` получит стандартизированные данные независимо от источника.
--
--### 3. Processor (Бизнес-логика / Оркестратор)
--**Путь:** `cmd/processor`
--- **Функция:** Маршрутизация и принятие решений.
--- **Логика:**
--    - Если `Intent == "search"`, запрашивает данные у `Data-Manager`.
--    - Если `Intent == "download"`, инициирует процесс загрузки.
--
--### 4. Data-Manager (Слой данных)
--**Путь:** `cmd/data-manager`
--- **Функция:** Интерфейс к поисковому движку (OpenSearch).
--- **Задача:** Выполнение поисковых запросов и возврат списка объектов `Book`.
--
-----
--
--## Технологический стек
--- **Язык:** Go (Golang)
--- **Связь:** gRPC (Protocol Buffers v3)
--- **Логирование:** Logrus
--- **Сборка:** Makefile
--
--## Порты и адреса (Service Map)
--| Сервис            | Порт   | Протокол |
--|-------------------|--------|----------|
--| Data-Manager      | :50051 | gRPC     |
--| MessageConverter  | :50052 | gRPC     |
--| Processor         | :50053 | gRPC     |
--| Web-Adapter       | :8080  | HTTP     |
--
--## Управление проектом
--- `make run` — Запуск всего пайплайна в фоне.
--- `make stop` — Безопасная остановка всех сервисов (через fuser и pkill).
--- `make proto` — Генерация кода из .proto файлов.
--
----- END_FILE: ./doc/ARCHITECTURE.md ---
--
----- START_FILE: ./doc/DSL_REQUIREMENTS.md ---
--# Specification: Ebusta Search DSL (v1.1)
--
--## 1. Goal
--Предоставление человекочитаемого языка запросов для поиска книг, который транслируется в структурированное дерево (AST) для поискового движка Mercury.
--
--## 2. Lexical Atoms (Лексика)
--- **Action**: `get`, `find`, `list`, `read` (зарезервированы)
--- **Field Prefixes**: `title:`, `author:`, `author_id:`, `desc:`
--- **Logic Operators**: `AND`, `OR` (регистронезависимые)
--- **Unary Operators**: `NOT`
--- **Pattern**: `/regex/` (строка, обернутая в косую черту)
--- **Literal**: `"exact phrase"`, `simple_word`, `101`
--
--## 3. Функциональные требования
--
--### UR 1: Базовый поиск
--- **UR 1.1 (Default Search)**: Любой ввод без префикса (например, `Unix`) должен интерпретироваться как поиск по всем полям (`field: any`).
--- **UR 1.2 (Case Insensitivity)**: Поиск по умолчанию нечувствителен к регистру.
--
--### UR 2: Целевой поиск (Scoping)
--- **UR 2.1 (Field Limiting)**: Использование префикса `field:` ограничивает поиск конкретным мета-полем.
--- **UR 2.2 (Regex)**: Если значение обернуто в `/ /`, система должна использовать регулярные выражения (Operator: `OP_REGEX`).
--
--### UR 3: Сложная логика (Boolean)
--- **UR 3.1 (Combination)**: Поддержка операторов `AND` и `OR` для объединения условий.
--- **UR 3.2 (Negation)**: Поддержка оператора `NOT` для исключения результатов из выдачи.
--- **UR 3.3 (Precedence)**: Приоритет операторов: `NOT` > `AND` > `OR`.
--
--### UR 4: Обратная связь (Feedback)
--- **UR 4.1 (Explanation)**: Каждый ответ системы должен содержать поле `meta.canonical_form`, отображающее дерево разбора запроса для верификации пользователем.
--- **UR 4.2 (Request Tracing)**: Каждому запросу присваивается `request_id`, который пробрасывается через всю цепочку (Adapter -> Converter -> Processor -> Mercury).
--
--## 4. Примеры валидных запросов
--- `author:Кинг AND NOT title:Куджо`
--- `title:/^Unix.*/ OR desc:linux`
--- `101` (трактуется как поиск ID или любой поиск по "101")
--
----- END_FILE: ./doc/DSL_REQUIREMENTS.md ---
--
----- START_FILE: ./doc/REQUIREMENTS.md ---
--# Software Requirements Specification (SRS) - Ebusta Pipeline
--
--Данный документ определяет технические требования к каждому компоненту конвейера обработки сообщений системы Ebusta.
--
-----
--
--## 1. Web-Adapter (The Gateway)
--**Роль:** Транспортный шлюз для внешних HTTP-запросов.
--
--* **SR-1.1 (Interface):** Должен обеспечивать эндпоинт `GET /input?msg=...` для приема сырых данных.
--* **SR-1.2 (Sanity Check):** Должен возвращать `HTTP 400 Bad Request`, если параметр `msg` пуст или отсутствует.
--* **SR-1.3 (Source Identification):** Обязан при вызове следующего звена передавать метку `source: "web"`.
--* **SR-1.4 (Logic Isolation):** **Запрещено** выполнять парсинг текста, поиск подстрок или любую бизнес-логику.
--* **SR-1.5 (Error Handling):** Должен транслировать gRPC-статусы ошибок в соответствующие HTTP-коды (например, `Unavailable` -> `503 Service Unavailable`).
--
-----
--
--## 2. MessageConverter (The Semantic Brain)
--**Роль:** Семантический разбор и нормализация сообщения.
--
--* **SR-2.1 (Normalization):** Должен выполнять очистку входной строки (удаление лишних пробелов в начале/конце).
--* **SR-2.2 (Intent Recognition):** Должен определять тип намерения (`Intent`) на основе командных префиксов:
--    * `get ` или `download ` -> `intent: "download"`
--    * Остальное -> `intent: "search"`
--* **SR-2.3 (Payload Extraction):** Должен возвращать в поле `Payload` только содержательную часть, очищенную от командных префиксов.
--* **SR-2.4 (Stateless):** Должен быть полностью "без состояния" (stateless) — результат парсинга зависит только от входной строки.
--* **SR-2.5 (Robustness):** Должен корректно обрабатывать пустые строки после удаления префиксов, возвращая ошибку или дефолтный интент.
--
-----
--
--## 3. Processor (The Orchestrator)
--**Роль:** Центр принятия решений и маршрутизации.
--
--* **SR-3.1 (Routing):** Обязан выполнять маршрутизацию запроса строго на основе поля `Intent` из `UnifiedMessage`.
--* **SR-3.2 (Service Coordination):**
--    * При `search`: Вызывает `Data-Manager.Search()`.
--    * При `download`: (Будущее) Вызывает `Download-Manager`.
--* **SR-3.3 (Data Aggregation):** Должен упаковывать ответы от нижестоящих сервисов в единую структуру `ActionResponse`.
--* **SR-3.4 (Resilience):** Должен использовать механизмы `Context Timeout` (не более 5 секунд на запрос) при обращении к другим сервисам.
--* **SR-3.5 (Enrichment):** Имеет право добавлять метаданные к ответу (например, время обработки или статус выполнения).
--
-----
--
--## 4. Data-Manager (The Storage Interface)
--**Роль:** Изолированный слой доступа к данным.
--
--* **SR-4.1 (Contract Compliance):** Должен принимать только структурированные объекты `SearchRequest`.
--* **SR-4.2 (Zero Context):** **Запрещено** иметь информацию об источниках запроса (TG/Web) или командах пользователя.
--* **SR-4.3 (Data Consistency):** Должен возвращать консистентный список объектов `Book`, даже если найден только один результат.
--* **SR-4.4 (Performance):** Должен обеспечивать быстрый поиск по индексу; в случае мока — имитировать задержку сети.
--* **SR-4.5 (Safety):** Должен ограничивать максимальное количество возвращаемых записей (не более 50 за один запрос) для защиты памяти системы.
--
-----
--
--## Общие системные требования (Cross-Cutting)
--1. **Communication:** Все межсервисное взаимодействие осуществляется исключительно через gRPC.
--2. **Observability:** Каждый сервис обязан логировать факт получения запроса и результат его обработки через `logrus`.
--3. **Graceful Shutdown:** Все компоненты должны корректно завершать работу по сигналу `SIGTERM`, закрывая активные соединения.
--
--## 5. UnifiedMessage (The Internal Protocol)
--**Роль:** Единый стандарт данных внутри системы.
--
--* **SR-5.1 (Neutrality):** Объект не должен содержать специфичных для мессенджеров полей (например, `chat_id` или `irc_channel`). Вся метаинформация должна быть нормализована.
--* **SR-5.2 (Intent Categorization):** Поле `Intent` должно быть строго типизировано (строка или enum), определяющее дальнейший путь сообщения:
--    * `search` — запрос на поиск информации.
--    * `download` — запрос на получение файла.
--    * `help` — запрос системной справки.
--    * `meta` — запрос статистики или информации о сервисе.
--* **SR-5.3 (Payload Integrity):** Поле `Payload` обязано содержать только очищенные данные, готовые для передачи в поисковой движок без дополнительной обработки.
--* **SR-5.4 (Traceability):** (Будущее) Должен содержать `CorrelationID` для отслеживания пути конкретного запроса через логи всех микросервисов.
--* **SR-5.5 (Context Enrichment):** Должен включать поле `Source` (откуда пришел запрос), чтобы `Processor` мог принимать решение о лимитах (например, для Web-клиентов лимиты жестче, чем для CLI).
--
----- END_FILE: ./doc/REQUIREMENTS.md ---
--
----- START_FILE: ./doc/components.md ---
--Компонент,Роль,Описание,Входящие (In),Исходящие (Out)
--Web-Adapter,API Gateway,"Точка входа. Принимает HTTP-запросы, генерирует Trace-ID и управляет цепочкой вызовов.",HTTP :8080 (/input?msg=...),"gRPC -> Message-Converter, gRPC -> Processor"
--Message-Converter,DSL Parser,Превращает сырой текст в структурированное дерево (AST). Использует internal/parser.,gRPC :50052 (Convert),Нет
--Processor,Orchestrator,"Ядро системы. Реализует логику AST Walker: получает дерево, запрашивает данные и фильтрует их.",gRPC :50053 (HandleCommand),gRPC -> Data-Manager (GetData)
--Data-Manager,Data Provider,Хранилище. Загружает books.json и отдает сырой список книг для дальнейшей фильтрации.,gRPC :50051 (GetData),Файловая система (books.json)
--CLI,UI Client,Интерактивная консоль пользователя с поддержкой истории команд (readline).,User Input,HTTP -> Web-Adapter
--Client,Debug Tool,Утилита для прямой проверки доступности Data-Manager в обход шлюзов.,Manual Run,gRPC -> Data-Manager
--
----- END_FILE: ./doc/components.md ---
---- END SECTION: GIT DIFF ---
-
---- START_FILE: ./internal/parser/parser_test.go ---
-package parser
-
-import (
-	"ebusta/api/proto/v1"
-	"testing"
-)
-
-func TestParser(t *testing.T) {
-	tests := []struct {
-		name     string
-		input    string
-		validate func(*testing.T, *libraryv1.SearchQuery)
-	}{
-		{
-			name:  "Simple Any Search",
-			input: "Unix",
-			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
-				f := q.GetFilter()
-				if f == nil || f.Field != "any" || f.Value != "Unix" {
-					t.Errorf("Expected any:Unix, got %+v", f)
-				}
-			},
-		},
-		{
-			name:  "Field Search",
-			input: "author:Кинг",
-			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
-				f := q.GetFilter()
-				if f == nil || f.Field != "author" || f.Value != "Кинг" {
-					t.Errorf("Expected author:Кинг, got %+v", f)
-				}
-			},
-		},
-		{
-			name:  "Logical AND",
-			input: "author:Кинг AND title:Оно",
-			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
-				l := q.GetLogical()
-				if l == nil || l.Op != libraryv1.LogicalOp_AND || len(l.Nodes) != 2 {
-					t.Errorf("Expected AND with 2 nodes, got %+v", l)
-				}
-			},
-		},
-		{
-			name:  "Negation NOT",
-			input: "NOT title:Куджо",
-			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
-				n := q.GetNegation()
-				if n == nil {
-					t.Fatalf("Expected negation node, got nil")
-				}
-				f := n.Node.GetFilter()
-				if f.Field != "title" || f.Value != "Куджо" {
-					t.Errorf("Expected NOT title:Куджо, got %s:%s", f.Field, f.Value)
-				}
-			},
-		},
-		{
-			name:  "Regex Detection",
-			input: "title:/^Unix.*/",
-			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
-				f := q.GetFilter()
-				if f.Operator != libraryv1.Operator_OP_REGEX {
-					t.Errorf("Expected REGEX operator, got %v", f.Operator)
-				}
-			},
-		},
-	}
-
-	for _, tt := range tests {
-		t.Run(tt.name, func(t *testing.T) {
-			p := NewParser(tt.input)
-			query := p.Parse()
-			tt.validate(t, query)
-		})
-	}
-}
-
---- END_FILE: ./internal/parser/parser_test.go ---
-
---- START_FILE: ./internal/parser/lexer.go ---
-package parser
-
-import (
-	"strings"
-)
-
-// ==========================================
-// LEXER DEFINITIONS
-// ==========================================
-
-type TokenType int
-
-const (
-	TOKEN_EOF TokenType = iota
-	TOKEN_ERROR
-	TOKEN_IDENT     // author, title, Кинг
-	TOKEN_STRING    // "Стивен Кинг"
-	TOKEN_COLON     // :
-	TOKEN_AND       // AND
-	TOKEN_OR        // OR
-	TOKEN_NOT       // NOT, -
-	TOKEN_LPAREN    // (
-	TOKEN_RPAREN    // )
-	TOKEN_EQUALS    // =
-	TOKEN_CONTAINS  // ~
-)
-
-type Token struct {
-	Type  TokenType
-	Value string
-	Pos   int
-}
-
-type Lexer struct {
-	input  string
-	pos    int
-	start  int
-	width  int
-	tokens []Token
-}
-
-// newLexer создает лексер (используется в parser.go)
-func newLexer(input string) *Lexer {
-	return &Lexer{input: input}
-}
-
-// NextToken возвращает следующий токен (используется в parser.go)
-func (l *Lexer) NextToken() Token {
-	l.skipWhitespace()
-	if l.pos >= len(l.input) {
-		return Token{Type: TOKEN_EOF}
-	}
-
-	ch := l.input[l.pos]
-
-	switch {
-	case isLetter(ch):
-		return l.scanIdentifier()
-	case ch == '"':
-		return l.scanString()
-	case ch == ':':
-		l.pos++
-		return Token{Type: TOKEN_COLON, Value: ":"}
-	case ch == '(':
-		l.pos++
-		return Token{Type: TOKEN_LPAREN, Value: "("}
-	case ch == ')':
-		l.pos++
-		return Token{Type: TOKEN_RPAREN, Value: ")"}
-	case ch == '-': // Минус как NOT
-		l.pos++
-		return Token{Type: TOKEN_NOT, Value: "-"}
-	case ch == '=':
-		l.pos++
-		return Token{Type: TOKEN_EQUALS, Value: "="}
-	case ch == '~':
-		l.pos++
-		return Token{Type: TOKEN_CONTAINS, Value: "~"}
-	}
-
-	return Token{Type: TOKEN_ERROR, Value: string(ch)}
-}
-
-func (l *Lexer) skipWhitespace() {
-	for l.pos < len(l.input) && (l.input[l.pos] == ' ' || l.input[l.pos] == '\t') {
-		l.pos++
-	}
-}
-
-func (l *Lexer) scanIdentifier() Token {
-	start := l.pos
-	for l.pos < len(l.input) && isLetter(l.input[l.pos]) {
-		l.pos++
-	}
-	lit := l.input[start:l.pos]
-	
-	switch strings.ToUpper(lit) {
-	case "AND":
-		return Token{Type: TOKEN_AND, Value: lit}
-	case "OR":
-		return Token{Type: TOKEN_OR, Value: lit}
-	case "NOT":
-		return Token{Type: TOKEN_NOT, Value: lit}
-	}
-	return Token{Type: TOKEN_IDENT, Value: lit}
-}
-
-func (l *Lexer) scanString() Token {
-	l.pos++ // skip opening quote
-	start := l.pos
-	for l.pos < len(l.input) && l.input[l.pos] != '"' {
-		l.pos++
-	}
-	lit := l.input[start:l.pos]
-	if l.pos < len(l.input) {
-		l.pos++ // skip closing quote
-	}
-	return Token{Type: TOKEN_STRING, Value: lit}
-}
-
-func isLetter(ch byte) bool {
-	return (ch >= 'a' && ch <= 'z') || (ch >= 'A' && ch <= 'Z') || (ch >= '0' && ch <= '9') || ch > 127 || ch == '_' || ch == '.'
-}
-
---- END_FILE: ./internal/parser/lexer.go ---
-
---- START_FILE: ./internal/parser/parser.go ---
-package parser
-
-import (
-	"fmt"
-	"ebusta/api/proto/v1"
-)
-
-// ==========================================
-// PUBLIC API
-// ==========================================
-
-// Parse - точка входа. Создает лексер и парсер.
-func Parse(input string) *libraryv1.SearchQuery {
-	l := newLexer(input)
-	p := newParser(l)
-	return p.parseSearchQuery()
-}
-
-// ==========================================
-// PARSER LOGIC
-// ==========================================
-
-type Parser struct {
-	l       *Lexer
-	curTok  Token
-	peekTok Token
-}
-
-func newParser(l *Lexer) *Parser {
-	p := &Parser{l: l}
-	p.nextToken()
-	p.nextToken()
-	return p
-}
-
-func (p *Parser) nextToken() {
-	p.curTok = p.peekTok
-	p.peekTok = p.l.NextToken()
-}
-
-// Expression -> Term { OR Term }
-func (p *Parser) parseSearchQuery() *libraryv1.SearchQuery {
-	if p.curTok.Type == TOKEN_EOF {
-		return nil
-	}
-	return p.parseExpression()
-}
-
-func (p *Parser) parseExpression() *libraryv1.SearchQuery {
-	left := p.parseTerm()
-
-	for p.curTok.Type == TOKEN_OR {
-		p.nextToken() // eat OR
-		right := p.parseTerm()
-		left = &libraryv1.SearchQuery{
-			Node: &libraryv1.SearchQuery_Logical{
-				Logical: &libraryv1.LogicalNode{
-					Op:    libraryv1.LogicalOp_OR,
-					Nodes: []*libraryv1.SearchQuery{left, right},
-				},
-			},
-		}
-	}
-	return left
-}
-
-// Term -> Factor { AND Factor }
-func (p *Parser) parseTerm() *libraryv1.SearchQuery {
-	left := p.parseFactor()
-
-	for p.curTok.Type == TOKEN_AND {
-		p.nextToken() // eat AND
-		right := p.parseFactor()
-		left = &libraryv1.SearchQuery{
-			Node: &libraryv1.SearchQuery_Logical{
-				Logical: &libraryv1.LogicalNode{
-					Op:    libraryv1.LogicalOp_AND,
-					Nodes: []*libraryv1.SearchQuery{left, right},
-				},
-			},
-		}
-	}
-	return left
-}
-
-// Factor -> ( Expr ) | NOT Factor | Filter
-func (p *Parser) parseFactor() *libraryv1.SearchQuery {
-	switch p.curTok.Type {
-	case TOKEN_LPAREN:
-		p.nextToken() // eat (
-		exp := p.parseExpression()
-		if p.curTok.Type != TOKEN_RPAREN {
-			fmt.Println("Error: expected )") 
-		}
-		p.nextToken() // eat )
-		return exp
-
-	case TOKEN_NOT:
-		p.nextToken() // eat NOT
-		right := p.parseFactor()
-		return &libraryv1.SearchQuery{
-			Node: &libraryv1.SearchQuery_Negation{
-				Negation: &libraryv1.NotNode{
-					Node: right,
-				},
-			},
-		}
-	
-	default:
-		return p.parseFilter()
-	}
-}
-
-// Filter -> IDENT [OP] VALUE
-func (p *Parser) parseFilter() *libraryv1.SearchQuery {
-	if p.curTok.Type == TOKEN_IDENT && (p.peekTok.Type == TOKEN_COLON || p.peekTok.Type == TOKEN_EQUALS || p.peekTok.Type == TOKEN_CONTAINS) {
-		field := p.curTok.Value
-		p.nextToken() // eat field
-		
-		var op libraryv1.Operator
-		switch p.curTok.Type {
-		case TOKEN_COLON:    op = libraryv1.Operator_OP_CONTAINS
-		case TOKEN_EQUALS:   op = libraryv1.Operator_OP_EQUALS
-		case TOKEN_CONTAINS: op = libraryv1.Operator_OP_CONTAINS
-		}
-		
-		p.nextToken() // eat op
-		
-		value := p.curTok.Value
-		p.nextToken() // eat value
-
-		return &libraryv1.SearchQuery{
-			Node: &libraryv1.SearchQuery_Filter{
-				Filter: &libraryv1.FilterNode{
-					Field:    field,
-					Value:    value,
-					Operator: op,
-				},
-			},
-		}
-	}
-
-	// Implicit "any" search
-	val := p.curTok.Value
-	p.nextToken()
-	
-	return &libraryv1.SearchQuery{
-		Node: &libraryv1.SearchQuery_Filter{
-			Filter: &libraryv1.FilterNode{
-				Field:    "any",
-				Value:    val,
-				Operator: libraryv1.Operator_OP_CONTAINS,
-			},
-		},
-	}
-}
-
---- END_FILE: ./internal/parser/parser.go ---
-
---- START_FILE: ./internal/logger/logger.go ---
-package logger
-
-import (
-	"context"
-	"time"
-	"github.com/sirupsen/logrus"
-)
-
-type ctxKey string
-const RequestIDKey ctxKey = "requestId"
-
-func init() {
-	logrus.SetFormatter(&logrus.TextFormatter{
-		FullTimestamp:   true,
-		TimestampFormat: "15:04:05",
-		ForceColors:     true,
-		DisableColors:   false,
-	})
-}
-
-func For(ctx context.Context) *logrus.Entry {
-	id, ok := ctx.Value(RequestIDKey).(string)
-	if !ok {
-		return logrus.NewEntry(logrus.StandardLogger())
-	}
-	return logrus.WithField("request_id", id)
-}
-
-func ContextWithID(ctx context.Context, id string) context.Context {
-	return context.WithValue(ctx, RequestIDKey, id)
-}
-
-func Track(ctx context.Context, msg string) func() {
-	start := time.Now()
-	return func() {
-		dur := time.Since(start)
-		entry := For(ctx).WithField("duration", dur.String())
-		
-		if dur > 500*time.Millisecond {
-			entry.Warnf("%s completed (SLOW)", msg)
-		} else {
-			entry.Infof("%s completed", msg)
-		}
-	}
-}
-
---- END_FILE: ./internal/logger/logger.go ---
-
---- START_FILE: ./internal/metrics/metrics.go ---
-package metrics
-
-import (
-	"github.com/prometheus/client_golang/prometheus"
-	"github.com/prometheus/client_golang/prometheus/promauto"
-)
-
-var (
-	HttpRequestsTotal = promauto.NewCounterVec(prometheus.CounterOpts{
-		Name: "ebusta_gateway_requests_total",
-		Help: "Total number of HTTP requests to gateway",
-	}, []string{"method", "path", "status"})
-
-	HttpRequestDuration = promauto.NewHistogramVec(prometheus.HistogramOpts{
-		Name:    "ebusta_gateway_request_duration_seconds",
-		Help:    "Duration of HTTP requests in seconds",
-		Buckets: prometheus.DefBuckets,
-	}, []string{"path"})
-)
-
---- END_FILE: ./internal/metrics/metrics.go ---
-
---- START_FILE: ./internal/storage/datamanager/config/config.go ---
-package config
-
-import (
-	"time"
-	"github.com/kelseyhightower/envconfig"
-)
-
-type Config struct {
-	BindAddr    string        `env:"BIND_ADDR" default:":8082"`
-	OSScheme    string        `env:"OS_SCHEME" default:"http"`
-	OSHost      string        `env:"OS_HOST" default:"mercury"`
-	OSPort      string        `env:"OS_PORT" default:"9200"`
-	OSIndex     string        `env:"OS_INDEX" default:"ebusta"`
-	ESUser      string        `env:"ES_USER"`
-	ESPass      string        `env:"ES_PASS"`
-	HTTPTimeout time.Duration `env:"HTTP_TIMEOUT" default:"5s"`
-	LogJSON     bool          `env:"LOG_JSON" default:"false"`
-	LogLevel    string        `env:"LOG_LEVEL" default:"INFO"`
-	LogPath     string        `env:"LOG_PATH"` // Default is empty, logs to stdout
-}
-
-func (c *Config) Validate() error {
-	if c.BindAddr == "" {
-		return ErrInvalid("bind address is required")
-	}
-	if c.OSHost == "" || c.OSPort == "" || c.OSIndex == "" {
-		return ErrInvalid("OS_HOST/OS_PORT/OS_INDEX are required")
-	}
-	return nil
-}
-
-type invalidErr string
-func (e invalidErr) Error() string { return string(e) }
-func ErrInvalid(msg string) error { return invalidErr(msg) }
-
-func Load() (Config, error) {
-	var cfg Config
-	if err := envconfig.Process("", &cfg); err != nil {
-		return cfg, err
-	}
-	return cfg, cfg.Validate()
-}
-
---- END_FILE: ./internal/storage/datamanager/config/config.go ---
-
---- START_FILE: ./internal/storage/datamanager/delivery/grpc.go ---
-package delivery
-
-import (
-	"context"
-	"ebusta/api/proto/v1"
-	"ebusta/internal/logger"
-)
-
-type DataManagerServer struct {
-	libraryv1.UnimplementedLibraryServiceServer
-}
-
-// ИСПРАВЛЕНИЕ: Метод должен называться SearchBooks, чтобы соответствовать интерфейсу
-func (s *DataManagerServer) SearchBooks(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
-	// Если логгер еще не настроен, используем простой принт или заглушку
-	if logger.For(ctx) != nil {
-		defer logger.Track(ctx, "Storage: DB Search Operation")()
-	}
-
-	// Моковые данные для теста
-	books := []*libraryv1.Book{
-		{
-			Id:      "101",
-			Title:   "The Art of Unix Programming",
-			Authors: []string{"Eric S. Raymond"},
-		},
-	}
-
-	return &libraryv1.SearchResponse{
-		Books: books,
-		Total: int32(len(books)),
-	}, nil
-}
-
-func (s *DataManagerServer) GetAuthors(ctx context.Context, req *libraryv1.ListRequest) (*libraryv1.ListResponse, error) {
-	return &libraryv1.ListResponse{Items: []string{"King", "Tolkien"}}, nil
-}
-
---- END_FILE: ./internal/storage/datamanager/delivery/grpc.go ---
-
---- START_FILE: ./internal/storage/datamanager/delivery/handlers.go ---
-package delivery
-
-import (
-	"ebusta/api/proto/v1"
-	"encoding/json"
-	"log"
-)
-
-func MapOSResponseToGrpc(body []byte) ([]*libraryv1.Book, int32) {
-	// Total выносим в interface{}, так как OS может вернуть и число, и объект
-	var raw struct {
-		Hits struct {
-			Total interface{} `json:"total"`
-			Hits  []struct {
-				ID     string `json:"_id"`
-				Source struct {
-					Title   string   `json:"title"`
-					Authors []string `json:"authors"`
-				} `json:"_source"`
-			} `json:"hits"`
-		} `json:"hits"`
-	}
-
-	if err := json.Unmarshal(body, &raw); err != nil {
-		log.Printf("❌ DataManager Parsing Error: %v", err)
-		return nil, 0
-	}
-
-	var totalValue int32
-	// Гибкое извлечение Total (поддержка объекта и числа)
-	switch v := raw.Hits.Total.(type) {
-	case float64:
-		totalValue = int32(v)
-	case map[string]interface{}:
-		if val, ok := v["value"].(float64); ok {
-			totalValue = int32(val)
-		}
-	}
-
-	var books []*libraryv1.Book
-	for _, h := range raw.Hits.Hits {
-		// Защита от пустых авторов
-		authors := h.Source.Authors
-		if authors == nil {
-			authors = []string{"Unknown"}
-		}
-		
-		books = append(books, &libraryv1.Book{
-			Id:      h.ID,
-			Title:   h.Source.Title,
-			Authors: authors,
-		})
-	}
-
-	// Если хиты есть, а total 0 (бывает при определенных настройках OS)
-	if totalValue == 0 && len(books) > 0 {
-		totalValue = int32(len(books))
-	}
-
-	return books, totalValue
-}
-
---- END_FILE: ./internal/storage/datamanager/delivery/handlers.go ---
-
---- START_FILE: ./internal/storage/datamanager/shaping/shaping.go ---
-package shaping
-
-import (
-	"encoding/json"
-	"fmt"
-)
-
-// --- Search shaping ---
-type searchHit struct {
-	Source struct {
-		Title   string   `json:"title"`
-		Authors []string `json:"authors"`
-		FileInfo struct {
-			Container string `json:"container"`
-			Filename  string `json:"filename"`
-		} `json:"fileInfo"`
-	} `json:"_source"`
-}
-type searchResp struct {
-	Hits struct {
-		Total struct{ Value int `json:"value"` } `json:"total"`
-		Hits  []searchHit `json:"hits"`
-	} `json:"hits"`
-}
-
-// ShapeSearch flattens OpenSearch hits into a smaller payload.
-func ShapeSearch(data []byte, from, size int) ([]byte, error) {
-	var r searchResp
-	if err := json.Unmarshal(data, &r); err != nil {
-		return nil, fmt.Errorf("decode hits: %w", err)
-	}
-	type item struct {
-		Title    string   `json:"title"`
-		Authors  []string `json:"authors"`
-		Download string   `json:"download,omitempty"`
-	}
-	out := struct {
-		Total    int    `json:"total"`
-		From     int    `json:"from"`
-		Size     int    `json:"size"`
-		NextFrom int    `json:"next_from"`
-		Items    []item `json:"items"`
-	}{
-		Total:    r.Hits.Total.Value,
-		From:     from,
-		Size:     size,
-		NextFrom: from + size,
-		Items:    make([]item, 0, len(r.Hits.Hits)), // ensure [] not null
-	}
-	for _, h := range r.Hits.Hits {
-		dl := ""
-		if h.Source.FileInfo.Container != "" && h.Source.FileInfo.Filename != "" {
-			dl = h.Source.FileInfo.Container + "/" + h.Source.FileInfo.Filename
-		}
-		out.Items = append(out.Items, item{
-			Title:    h.Source.Title,
-			Authors:  h.Source.Authors,
-			Download: dl,
-		})
-	}
-	return json.MarshalIndent(out, "", "  ")
-}
-
-// --- Composite/aggregation shaping (best-effort generic) ---
-type composite struct {
-	AfterKey any `json:"after_key"`
-	Buckets  any `json:"buckets"`
-}
-type aggResp struct {
-	Aggregations map[string]composite `json:"aggregations"`
-}
-
-func ShapeComposite(data []byte) ([]byte, error) {
-	var r aggResp
-	if err := json.Unmarshal(data, &r); err != nil {
-		return nil, fmt.Errorf("decode aggregations: %w", err)
-	}
-	if len(r.Aggregations) == 0 {
-		// pass-through
-		return data, nil
-	}
-	// pick first aggregation
-	for name, c := range r.Aggregations {
-		out := map[string]any{
-			"name":       name,
-			"buckets":    c.Buckets,
-			"after_key":  c.AfterKey,
-		}
-		return json.MarshalIndent(out, "", "  ")
-	}
-	return data, nil
-}
-
---- END_FILE: ./internal/storage/datamanager/shaping/shaping.go ---
-
---- START_FILE: ./internal/storage/datamanager/shaping/shaping_test.go ---
-package shaping
-
-import "testing"
-
-func TestShapeSearch(t *testing.T) {
-	jsonIn := []byte(`{"hits":{"total":{"value":2},"hits":[{"_source":{"title":"A","authors":["X"],"fileInfo":{"container":"c","filename":"a.fb2"}}},{"_source":{"title":"B","authors":["Y"],"fileInfo":{"container":"d","filename":"b.fb2"}}}]}}`)
-	out, err := ShapeSearch(jsonIn, 0, 10)
-	if err != nil { t.Fatalf("unexpected error: %v", err) }
-	mustContain(t, string(out), `"total": 2`)
-	mustContain(t, string(out), `"items": [`)
-	mustContain(t, string(out), `"download": "c/a.fb2"`)
-}
-
-func mustContain(t *testing.T, s, sub string) {
-	t.Helper()
-	if !contains(s, sub) { t.Fatalf("expected substring %q in %s", sub, s) }
-}
-
-func contains(s, sub string) bool { return len(s) >= len(sub) && (s == sub || (len(sub) > 0 && (stringIndex(s, sub) >= 0))) }
-func stringIndex(s, sub string) int {
-	for i := 0; i+len(sub) <= len(s); i++ {
-		if s[i:i+len(sub)] == sub { return i }
-	}
-	return -1
-}
-
---- END_FILE: ./internal/storage/datamanager/shaping/shaping_test.go ---
-
---- START_FILE: ./internal/storage/datamanager/proxy/proxy.go ---
-package proxy
-
-import (
-	"bytes"
-	"context"
-	"encoding/base64"
-	"encoding/json"
-	"fmt"
-	"io"
-	"net/http"
-	"sync"
-	"time"
-
-	"github.com/sirupsen/logrus"
-
-	"ebusta/internal/storage/datamanager/config"
-)
-
-type Proxy struct {
-	cfg     config.Config
-	client  *http.Client
-	logger  *logrus.Logger
-	baseURL string
-	once    sync.Once
-}
-
-func New(cfg config.Config, logger *logrus.Logger) *Proxy {
-	return &Proxy{
-		cfg:    cfg,
-		logger: logger,
-		client: newHTTPClient(cfg),
-	}
-}
-
-func newHTTPClient(cfg config.Config) *http.Client {
-	t := &http.Transport{
-		MaxIdleConns:        100,
-		IdleConnTimeout:     90 * time.Second,
-		DisableCompression:  false,
-		ForceAttemptHTTP2:   true,
-	}
-	return &http.Client{Transport: t, Timeout: cfg.HTTPTimeout}
-}
-
-func (p *Proxy) BaseURL() string {
-	p.once.Do(func() {
-		p.baseURL = fmt.Sprintf("%s://%s:%s/%s/_search/template", p.cfg.OSScheme, p.cfg.OSHost, p.cfg.OSPort, p.cfg.OSIndex)
-	})
-	return p.baseURL
-}
-
-// Structured error envelope
-type ErrorEnvelope struct {
-	Error ErrorBody `json:"error"`
-}
-type ErrorBody struct {
-	Code    string      `json:"code"`
-	Message string      `json:"message"`
-	Details interface{} `json:"details,omitempty"`
-}
-
-func WriteError(w http.ResponseWriter, status int, code, message string, details interface{}) {
-	w.Header().Set("Content-Type", "application/json")
-	w.WriteHeader(status)
-	_ = json.NewEncoder(w).Encode(ErrorEnvelope{
-		Error: ErrorBody{Code: code, Message: message, Details: details},
-	})
-}
-
-// DoTemplate executes a stored template by id with params.
-func (p *Proxy) DoTemplate(ctx context.Context, id string, params map[string]any) ([]byte, int, error) {
-	body := map[string]any{
-		"id":     id,
-		"params": params,
-	}
-	
-	// This now only logs if LOG_LEVEL=DEBUG
-	if p.logger.IsLevelEnabled(logrus.DebugLevel) {
-		p.logger.WithFields(logrus.Fields{
-			"template": id,
-			"params":   params,
-		}).Debug("os.request") // Changed from Info to Debug
-	}
-	
-	buf, err := json.Marshal(body)
-	if err != nil {
-		return nil, 0, fmt.Errorf("marshal body: %w", err)
-	}
-
-	req, err := http.NewRequestWithContext(ctx, http.MethodPost, p.BaseURL(), bytes.NewReader(buf))
-	if err != nil {
-		return nil, 0, fmt.Errorf("failed to create request: %w", err)
-	}
-	req.Header.Set("Content-Type", "application/json")
-	if p.cfg.ESUser != "" || p.cfg.ESPass != "" {
-		req.SetBasicAuth(p.cfg.ESUser, p.cfg.ESPass)
-	}
-
-	res, err := p.client.Do(req)
-	if err != nil {
-		return nil, 0, fmt.Errorf("upstream do: %w", err)
-	}
-	defer res.Body.Close()
-
-	data, _ := io.ReadAll(res.Body)
-	
-	// This now only logs if LOG_LEVEL=DEBUG
-	if p.logger.IsLevelEnabled(logrus.DebugLevel) {
-		p.logger.WithFields(logrus.Fields{
-			"template": id,
-			"status": res.StatusCode,
-			"response_body": string(data),
-		}).Debug("os.response")
-	}
-	
-	return data, res.StatusCode, nil
-}
-
-// DecodeAfter supports raw JSON or base64(JSON).
-func DecodeAfter(s string) (any, error) {
-	if s == "" {
-		return nil, nil
-	}
-	// try raw JSON first
-	var v any
-	if json.Unmarshal([]byte(s), &v) == nil {
-		return v, nil
-	}
-	// try base64
-	b, err := base64.StdEncoding.DecodeString(s)
-	if err != nil {
-		return nil, fmt.Errorf("invalid after (not json or base64): %w", err)
-	}
-	if err := json.Unmarshal(b, &v); err != nil {
-		return nil, fmt.Errorf("invalid after (bad json): %w", err)
-	}
-	return v, nil
-}
-
---- END_FILE: ./internal/storage/datamanager/proxy/proxy.go ---
-
---- START_FILE: ./internal/middleware/logging.go ---
-package middleware
-
-import (
-	"net/http"
-	"time"
-
-	"github.com/sirupsen/logrus"
-)
-
-// RequestLogger logs incoming requests at the INFO level.
-func RequestLogger(log *logrus.Logger) func(http.Handler) http.Handler {
-	return func(next http.Handler) http.Handler {
-		return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
-			start := time.Now()
-			
-			// Serve the request
-			next.ServeHTTP(w, r)
-			
-			// Log the request
-			log.WithFields(logrus.Fields{
-				"method": r.Method,
-				"path":   r.URL.Path,
-//				"query":  r.URL.RawQuery,
-				"query":  r.URL.Query(),
-				"remote": r.RemoteAddr,
-				"agent":  r.UserAgent(),
-				"took":   time.Since(start),
-			}).Info("http.request")
-		})
-	}
-}
-
---- END_FILE: ./internal/middleware/logging.go ---
-
---- START_FILE: ./internal/middleware/middleware.go ---
-package middleware
-
-import (
-	"net/http"
-	"strings"
-)
-
-// CORS allows basic CORS for browser apps.
-func CORS(next http.Handler) http.Handler {
-	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
-		w.Header().Set("Access-Control-Allow-Origin", "*")
-		w.Header().Set("Access-Control-Allow-Methods", "GET,POST,OPTIONS")
-		w.Header().Set("Access-Control-Allow-Headers", "Content-Type,Authorization")
-		if strings.ToUpper(r.Method) == "OPTIONS" {
-			w.WriteHeader(http.StatusNoContent)
-			return
-		}
-		next.ServeHTTP(w, r)
-	})
-}
-
---- END_FILE: ./internal/middleware/middleware.go ---
-
---- START_FILE: ./ebusta.yaml ---
-datamanager:
-  opensearch_url: "http://cloud-1:9200"
-  index_name: "flibusta_merged_index"
-  debug: true
-
-orchestrator:
-  storage_addr: "localhost:50051"
-  processor_addr: "localhost:50053"
-
-web:
-  port: 8080
-
---- END_FILE: ./ebusta.yaml ---
-
---- START_FILE: ./api/proto/v1/library_simple.proto ---
-syntax = "proto2";
-
-package libraryv1;
-
-message FilterNode {
-  optional string field = 1;
-  optional string value = 2;
-  optional int32 operator = 3;
-}
-
-message LogicalNode {
-  repeated SearchQuery nodes = 1;
-}
-
-message NotNode {
-  optional SearchQuery node = 1;
-}
-
-message SearchQuery {
-  optional FilterNode filter = 1;
-  optional LogicalNode logical = 2;
-  optional NotNode negation = 3;
-}
-
---- END_FILE: ./api/proto/v1/library_simple.proto ---
-
---- START_FILE: ./api/proto/v1/auth.proto ---
-syntax = "proto3";
-
-package libraryv1;
-
-option go_package = "ebusta/api/proto/v1;libraryv1";
-
-service AuthService {
-  // Проверка доступа пользователя
-  rpc CheckAccess (AccessRequest) returns (AccessResponse);
-}
-
-message AccessRequest {
-  string user_id = 1;      // ID (например, Telegram UID или ник в BBS)
-  string platform = 2;     // Источник (web, telegram, cli, bbs)
-  string trace_id = 3;     // Для сквозного логирования
-}
-
-message AccessResponse {
-  bool allowed = 1;        // Разрешен ли вход
-  string reason = 2;       // Причина отказа
-  string user_role = 3;    // Роль пользователя (admin, family, guest)
-}
-
---- END_FILE: ./api/proto/v1/auth.proto ---
-
---- START_FILE: ./api/proto/v1/library_grpc.pb.go ---
-// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
-// versions:
-// - protoc-gen-go-grpc v1.6.0
-// - protoc             v3.21.12
-// source: api/proto/v1/library.proto
-
-package libraryv1
-
-import (
-	context "context"
-	grpc "google.golang.org/grpc"
-	codes "google.golang.org/grpc/codes"
-	status "google.golang.org/grpc/status"
-)
-
-// This is a compile-time assertion to ensure that this generated file
-// is compatible with the grpc package it is being compiled against.
-// Requires gRPC-Go v1.64.0 or later.
-const _ = grpc.SupportPackageIsVersion9
-
-const (
-	OrchestratorService_Search_FullMethodName = "/libraryv1.OrchestratorService/Search"
-)
-
-// OrchestratorServiceClient is the client API for OrchestratorService service.
-//
-// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
-type OrchestratorServiceClient interface {
-	Search(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
-}
-
-type orchestratorServiceClient struct {
-	cc grpc.ClientConnInterface
-}
-
-func NewOrchestratorServiceClient(cc grpc.ClientConnInterface) OrchestratorServiceClient {
-	return &orchestratorServiceClient{cc}
-}
-
-func (c *orchestratorServiceClient) Search(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
-	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
-	out := new(SearchResponse)
-	err := c.cc.Invoke(ctx, OrchestratorService_Search_FullMethodName, in, out, cOpts...)
-	if err != nil {
-		return nil, err
-	}
-	return out, nil
-}
-
-// OrchestratorServiceServer is the server API for OrchestratorService service.
-// All implementations must embed UnimplementedOrchestratorServiceServer
-// for forward compatibility.
-type OrchestratorServiceServer interface {
-	Search(context.Context, *SearchRequest) (*SearchResponse, error)
-	mustEmbedUnimplementedOrchestratorServiceServer()
-}
-
-// UnimplementedOrchestratorServiceServer must be embedded to have
-// forward compatible implementations.
-//
-// NOTE: this should be embedded by value instead of pointer to avoid a nil
-// pointer dereference when methods are called.
-type UnimplementedOrchestratorServiceServer struct{}
-
-func (UnimplementedOrchestratorServiceServer) Search(context.Context, *SearchRequest) (*SearchResponse, error) {
-	return nil, status.Error(codes.Unimplemented, "method Search not implemented")
-}
-func (UnimplementedOrchestratorServiceServer) mustEmbedUnimplementedOrchestratorServiceServer() {}
-func (UnimplementedOrchestratorServiceServer) testEmbeddedByValue()                             {}
-
-// UnsafeOrchestratorServiceServer may be embedded to opt out of forward compatibility for this service.
-// Use of this interface is not recommended, as added methods to OrchestratorServiceServer will
-// result in compilation errors.
-type UnsafeOrchestratorServiceServer interface {
-	mustEmbedUnimplementedOrchestratorServiceServer()
-}
-
-func RegisterOrchestratorServiceServer(s grpc.ServiceRegistrar, srv OrchestratorServiceServer) {
-	// If the following call panics, it indicates UnimplementedOrchestratorServiceServer was
-	// embedded by pointer and is nil.  This will cause panics if an
-	// unimplemented method is ever invoked, so we test this at initialization
-	// time to prevent it from happening at runtime later due to I/O.
-	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
-		t.testEmbeddedByValue()
-	}
-	s.RegisterService(&OrchestratorService_ServiceDesc, srv)
-}
-
-func _OrchestratorService_Search_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
-	in := new(SearchRequest)
-	if err := dec(in); err != nil {
-		return nil, err
-	}
-	if interceptor == nil {
-		return srv.(OrchestratorServiceServer).Search(ctx, in)
-	}
-	info := &grpc.UnaryServerInfo{
-		Server:     srv,
-		FullMethod: OrchestratorService_Search_FullMethodName,
-	}
-	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
-		return srv.(OrchestratorServiceServer).Search(ctx, req.(*SearchRequest))
-	}
-	return interceptor(ctx, in, info, handler)
-}
-
-// OrchestratorService_ServiceDesc is the grpc.ServiceDesc for OrchestratorService service.
-// It's only intended for direct use with grpc.RegisterService,
-// and not to be introspected or modified (even as a copy)
-var OrchestratorService_ServiceDesc = grpc.ServiceDesc{
-	ServiceName: "libraryv1.OrchestratorService",
-	HandlerType: (*OrchestratorServiceServer)(nil),
-	Methods: []grpc.MethodDesc{
-		{
-			MethodName: "Search",
-			Handler:    _OrchestratorService_Search_Handler,
-		},
-	},
-	Streams:  []grpc.StreamDesc{},
-	Metadata: "api/proto/v1/library.proto",
-}
-
-const (
-	ProcessorService_Process_FullMethodName = "/libraryv1.ProcessorService/Process"
-)
-
-// ProcessorServiceClient is the client API for ProcessorService service.
-//
-// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
-type ProcessorServiceClient interface {
-	Process(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
-}
-
-type processorServiceClient struct {
-	cc grpc.ClientConnInterface
-}
-
-func NewProcessorServiceClient(cc grpc.ClientConnInterface) ProcessorServiceClient {
-	return &processorServiceClient{cc}
-}
-
-func (c *processorServiceClient) Process(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
-	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
-	out := new(SearchResponse)
-	err := c.cc.Invoke(ctx, ProcessorService_Process_FullMethodName, in, out, cOpts...)
-	if err != nil {
-		return nil, err
-	}
-	return out, nil
-}
-
-// ProcessorServiceServer is the server API for ProcessorService service.
-// All implementations must embed UnimplementedProcessorServiceServer
-// for forward compatibility.
-type ProcessorServiceServer interface {
-	Process(context.Context, *SearchRequest) (*SearchResponse, error)
-	mustEmbedUnimplementedProcessorServiceServer()
-}
-
-// UnimplementedProcessorServiceServer must be embedded to have
-// forward compatible implementations.
-//
-// NOTE: this should be embedded by value instead of pointer to avoid a nil
-// pointer dereference when methods are called.
-type UnimplementedProcessorServiceServer struct{}
-
-func (UnimplementedProcessorServiceServer) Process(context.Context, *SearchRequest) (*SearchResponse, error) {
-	return nil, status.Error(codes.Unimplemented, "method Process not implemented")
-}
-func (UnimplementedProcessorServiceServer) mustEmbedUnimplementedProcessorServiceServer() {}
-func (UnimplementedProcessorServiceServer) testEmbeddedByValue()                          {}
-
-// UnsafeProcessorServiceServer may be embedded to opt out of forward compatibility for this service.
-// Use of this interface is not recommended, as added methods to ProcessorServiceServer will
-// result in compilation errors.
-type UnsafeProcessorServiceServer interface {
-	mustEmbedUnimplementedProcessorServiceServer()
-}
-
-func RegisterProcessorServiceServer(s grpc.ServiceRegistrar, srv ProcessorServiceServer) {
-	// If the following call panics, it indicates UnimplementedProcessorServiceServer was
-	// embedded by pointer and is nil.  This will cause panics if an
-	// unimplemented method is ever invoked, so we test this at initialization
-	// time to prevent it from happening at runtime later due to I/O.
-	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
-		t.testEmbeddedByValue()
-	}
-	s.RegisterService(&ProcessorService_ServiceDesc, srv)
-}
-
-func _ProcessorService_Process_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
-	in := new(SearchRequest)
-	if err := dec(in); err != nil {
-		return nil, err
-	}
-	if interceptor == nil {
-		return srv.(ProcessorServiceServer).Process(ctx, in)
-	}
-	info := &grpc.UnaryServerInfo{
-		Server:     srv,
-		FullMethod: ProcessorService_Process_FullMethodName,
-	}
-	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
-		return srv.(ProcessorServiceServer).Process(ctx, req.(*SearchRequest))
-	}
-	return interceptor(ctx, in, info, handler)
-}
-
-// ProcessorService_ServiceDesc is the grpc.ServiceDesc for ProcessorService service.
-// It's only intended for direct use with grpc.RegisterService,
-// and not to be introspected or modified (even as a copy)
-var ProcessorService_ServiceDesc = grpc.ServiceDesc{
-	ServiceName: "libraryv1.ProcessorService",
-	HandlerType: (*ProcessorServiceServer)(nil),
-	Methods: []grpc.MethodDesc{
-		{
-			MethodName: "Process",
-			Handler:    _ProcessorService_Process_Handler,
-		},
-	},
-	Streams:  []grpc.StreamDesc{},
-	Metadata: "api/proto/v1/library.proto",
-}
-
-const (
-	StorageService_SearchBooks_FullMethodName = "/libraryv1.StorageService/SearchBooks"
-)
-
-// StorageServiceClient is the client API for StorageService service.
-//
-// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
-type StorageServiceClient interface {
-	SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
-}
-
-type storageServiceClient struct {
-	cc grpc.ClientConnInterface
-}
-
-func NewStorageServiceClient(cc grpc.ClientConnInterface) StorageServiceClient {
-	return &storageServiceClient{cc}
-}
-
-func (c *storageServiceClient) SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
-	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
-	out := new(SearchResponse)
-	err := c.cc.Invoke(ctx, StorageService_SearchBooks_FullMethodName, in, out, cOpts...)
-	if err != nil {
-		return nil, err
-	}
-	return out, nil
-}
-
-// StorageServiceServer is the server API for StorageService service.
-// All implementations must embed UnimplementedStorageServiceServer
-// for forward compatibility.
-type StorageServiceServer interface {
-	SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error)
-	mustEmbedUnimplementedStorageServiceServer()
-}
-
-// UnimplementedStorageServiceServer must be embedded to have
-// forward compatible implementations.
-//
-// NOTE: this should be embedded by value instead of pointer to avoid a nil
-// pointer dereference when methods are called.
-type UnimplementedStorageServiceServer struct{}
-
-func (UnimplementedStorageServiceServer) SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error) {
-	return nil, status.Error(codes.Unimplemented, "method SearchBooks not implemented")
-}
-func (UnimplementedStorageServiceServer) mustEmbedUnimplementedStorageServiceServer() {}
-func (UnimplementedStorageServiceServer) testEmbeddedByValue()                        {}
-
-// UnsafeStorageServiceServer may be embedded to opt out of forward compatibility for this service.
-// Use of this interface is not recommended, as added methods to StorageServiceServer will
-// result in compilation errors.
-type UnsafeStorageServiceServer interface {
-	mustEmbedUnimplementedStorageServiceServer()
-}
-
-func RegisterStorageServiceServer(s grpc.ServiceRegistrar, srv StorageServiceServer) {
-	// If the following call panics, it indicates UnimplementedStorageServiceServer was
-	// embedded by pointer and is nil.  This will cause panics if an
-	// unimplemented method is ever invoked, so we test this at initialization
-	// time to prevent it from happening at runtime later due to I/O.
-	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
-		t.testEmbeddedByValue()
-	}
-	s.RegisterService(&StorageService_ServiceDesc, srv)
-}
-
-func _StorageService_SearchBooks_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
-	in := new(SearchRequest)
-	if err := dec(in); err != nil {
-		return nil, err
-	}
-	if interceptor == nil {
-		return srv.(StorageServiceServer).SearchBooks(ctx, in)
-	}
-	info := &grpc.UnaryServerInfo{
-		Server:     srv,
-		FullMethod: StorageService_SearchBooks_FullMethodName,
-	}
-	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
-		return srv.(StorageServiceServer).SearchBooks(ctx, req.(*SearchRequest))
-	}
-	return interceptor(ctx, in, info, handler)
-}
-
-// StorageService_ServiceDesc is the grpc.ServiceDesc for StorageService service.
-// It's only intended for direct use with grpc.RegisterService,
-// and not to be introspected or modified (even as a copy)
-var StorageService_ServiceDesc = grpc.ServiceDesc{
-	ServiceName: "libraryv1.StorageService",
-	HandlerType: (*StorageServiceServer)(nil),
-	Methods: []grpc.MethodDesc{
-		{
-			MethodName: "SearchBooks",
-			Handler:    _StorageService_SearchBooks_Handler,
-		},
-	},
-	Streams:  []grpc.StreamDesc{},
-	Metadata: "api/proto/v1/library.proto",
-}
-
-const (
-	AuthService_CheckAccess_FullMethodName = "/libraryv1.AuthService/CheckAccess"
-)
-
-// AuthServiceClient is the client API for AuthService service.
-//
-// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
-type AuthServiceClient interface {
-	CheckAccess(ctx context.Context, in *AccessRequest, opts ...grpc.CallOption) (*AccessResponse, error)
-}
-
-type authServiceClient struct {
-	cc grpc.ClientConnInterface
-}
-
-func NewAuthServiceClient(cc grpc.ClientConnInterface) AuthServiceClient {
-	return &authServiceClient{cc}
-}
-
-func (c *authServiceClient) CheckAccess(ctx context.Context, in *AccessRequest, opts ...grpc.CallOption) (*AccessResponse, error) {
-	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
-	out := new(AccessResponse)
-	err := c.cc.Invoke(ctx, AuthService_CheckAccess_FullMethodName, in, out, cOpts...)
-	if err != nil {
-		return nil, err
-	}
-	return out, nil
-}
-
-// AuthServiceServer is the server API for AuthService service.
-// All implementations must embed UnimplementedAuthServiceServer
-// for forward compatibility.
-type AuthServiceServer interface {
-	CheckAccess(context.Context, *AccessRequest) (*AccessResponse, error)
-	mustEmbedUnimplementedAuthServiceServer()
-}
-
-// UnimplementedAuthServiceServer must be embedded to have
-// forward compatible implementations.
-//
-// NOTE: this should be embedded by value instead of pointer to avoid a nil
-// pointer dereference when methods are called.
-type UnimplementedAuthServiceServer struct{}
-
-func (UnimplementedAuthServiceServer) CheckAccess(context.Context, *AccessRequest) (*AccessResponse, error) {
-	return nil, status.Error(codes.Unimplemented, "method CheckAccess not implemented")
-}
-func (UnimplementedAuthServiceServer) mustEmbedUnimplementedAuthServiceServer() {}
-func (UnimplementedAuthServiceServer) testEmbeddedByValue()                     {}
-
-// UnsafeAuthServiceServer may be embedded to opt out of forward compatibility for this service.
-// Use of this interface is not recommended, as added methods to AuthServiceServer will
-// result in compilation errors.
-type UnsafeAuthServiceServer interface {
-	mustEmbedUnimplementedAuthServiceServer()
-}
-
-func RegisterAuthServiceServer(s grpc.ServiceRegistrar, srv AuthServiceServer) {
-	// If the following call panics, it indicates UnimplementedAuthServiceServer was
-	// embedded by pointer and is nil.  This will cause panics if an
-	// unimplemented method is ever invoked, so we test this at initialization
-	// time to prevent it from happening at runtime later due to I/O.
-	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
-		t.testEmbeddedByValue()
-	}
-	s.RegisterService(&AuthService_ServiceDesc, srv)
-}
-
-func _AuthService_CheckAccess_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
-	in := new(AccessRequest)
-	if err := dec(in); err != nil {
-		return nil, err
-	}
-	if interceptor == nil {
-		return srv.(AuthServiceServer).CheckAccess(ctx, in)
-	}
-	info := &grpc.UnaryServerInfo{
-		Server:     srv,
-		FullMethod: AuthService_CheckAccess_FullMethodName,
-	}
-	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
-		return srv.(AuthServiceServer).CheckAccess(ctx, req.(*AccessRequest))
-	}
-	return interceptor(ctx, in, info, handler)
-}
-
-// AuthService_ServiceDesc is the grpc.ServiceDesc for AuthService service.
-// It's only intended for direct use with grpc.RegisterService,
-// and not to be introspected or modified (even as a copy)
-var AuthService_ServiceDesc = grpc.ServiceDesc{
-	ServiceName: "libraryv1.AuthService",
-	HandlerType: (*AuthServiceServer)(nil),
-	Methods: []grpc.MethodDesc{
-		{
-			MethodName: "CheckAccess",
-			Handler:    _AuthService_CheckAccess_Handler,
-		},
-	},
-	Streams:  []grpc.StreamDesc{},
-	Metadata: "api/proto/v1/library.proto",
-}
-
-const (
-	MessageConverterService_Convert_FullMethodName = "/libraryv1.MessageConverterService/Convert"
-)
-
-// MessageConverterServiceClient is the client API for MessageConverterService service.
-//
-// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
-type MessageConverterServiceClient interface {
-	Convert(ctx context.Context, in *RawInput, opts ...grpc.CallOption) (*UnmarshaledMessage, error)
-}
-
-type messageConverterServiceClient struct {
-	cc grpc.ClientConnInterface
-}
-
-func NewMessageConverterServiceClient(cc grpc.ClientConnInterface) MessageConverterServiceClient {
-	return &messageConverterServiceClient{cc}
-}
-
-func (c *messageConverterServiceClient) Convert(ctx context.Context, in *RawInput, opts ...grpc.CallOption) (*UnmarshaledMessage, error) {
-	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
-	out := new(UnmarshaledMessage)
-	err := c.cc.Invoke(ctx, MessageConverterService_Convert_FullMethodName, in, out, cOpts...)
-	if err != nil {
-		return nil, err
-	}
-	return out, nil
-}
-
-// MessageConverterServiceServer is the server API for MessageConverterService service.
-// All implementations must embed UnimplementedMessageConverterServiceServer
-// for forward compatibility.
-type MessageConverterServiceServer interface {
-	Convert(context.Context, *RawInput) (*UnmarshaledMessage, error)
-	mustEmbedUnimplementedMessageConverterServiceServer()
-}
-
-// UnimplementedMessageConverterServiceServer must be embedded to have
-// forward compatible implementations.
-//
-// NOTE: this should be embedded by value instead of pointer to avoid a nil
-// pointer dereference when methods are called.
-type UnimplementedMessageConverterServiceServer struct{}
-
-func (UnimplementedMessageConverterServiceServer) Convert(context.Context, *RawInput) (*UnmarshaledMessage, error) {
-	return nil, status.Error(codes.Unimplemented, "method Convert not implemented")
-}
-func (UnimplementedMessageConverterServiceServer) mustEmbedUnimplementedMessageConverterServiceServer() {
-}
-func (UnimplementedMessageConverterServiceServer) testEmbeddedByValue() {}
-
-// UnsafeMessageConverterServiceServer may be embedded to opt out of forward compatibility for this service.
-// Use of this interface is not recommended, as added methods to MessageConverterServiceServer will
-// result in compilation errors.
-type UnsafeMessageConverterServiceServer interface {
-	mustEmbedUnimplementedMessageConverterServiceServer()
-}
-
-func RegisterMessageConverterServiceServer(s grpc.ServiceRegistrar, srv MessageConverterServiceServer) {
-	// If the following call panics, it indicates UnimplementedMessageConverterServiceServer was
-	// embedded by pointer and is nil.  This will cause panics if an
-	// unimplemented method is ever invoked, so we test this at initialization
-	// time to prevent it from happening at runtime later due to I/O.
-	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
-		t.testEmbeddedByValue()
-	}
-	s.RegisterService(&MessageConverterService_ServiceDesc, srv)
-}
-
-func _MessageConverterService_Convert_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
-	in := new(RawInput)
-	if err := dec(in); err != nil {
-		return nil, err
-	}
-	if interceptor == nil {
-		return srv.(MessageConverterServiceServer).Convert(ctx, in)
-	}
-	info := &grpc.UnaryServerInfo{
-		Server:     srv,
-		FullMethod: MessageConverterService_Convert_FullMethodName,
-	}
-	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
-		return srv.(MessageConverterServiceServer).Convert(ctx, req.(*RawInput))
-	}
-	return interceptor(ctx, in, info, handler)
-}
-
-// MessageConverterService_ServiceDesc is the grpc.ServiceDesc for MessageConverterService service.
-// It's only intended for direct use with grpc.RegisterService,
-// and not to be introspected or modified (even as a copy)
-var MessageConverterService_ServiceDesc = grpc.ServiceDesc{
-	ServiceName: "libraryv1.MessageConverterService",
-	HandlerType: (*MessageConverterServiceServer)(nil),
-	Methods: []grpc.MethodDesc{
-		{
-			MethodName: "Convert",
-			Handler:    _MessageConverterService_Convert_Handler,
-		},
-	},
-	Streams:  []grpc.StreamDesc{},
-	Metadata: "api/proto/v1/library.proto",
-}
-
-const (
-	LibraryService_SearchBooks_FullMethodName = "/libraryv1.LibraryService/SearchBooks"
-	LibraryService_GetAuthors_FullMethodName  = "/libraryv1.LibraryService/GetAuthors"
-)
-
-// LibraryServiceClient is the client API for LibraryService service.
-//
-// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
-//
-// Legacy
-type LibraryServiceClient interface {
-	SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
-	GetAuthors(ctx context.Context, in *ListRequest, opts ...grpc.CallOption) (*ListResponse, error)
-}
-
-type libraryServiceClient struct {
-	cc grpc.ClientConnInterface
-}
-
-func NewLibraryServiceClient(cc grpc.ClientConnInterface) LibraryServiceClient {
-	return &libraryServiceClient{cc}
-}
-
-func (c *libraryServiceClient) SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
-	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
-	out := new(SearchResponse)
-	err := c.cc.Invoke(ctx, LibraryService_SearchBooks_FullMethodName, in, out, cOpts...)
-	if err != nil {
-		return nil, err
-	}
-	return out, nil
-}
-
-func (c *libraryServiceClient) GetAuthors(ctx context.Context, in *ListRequest, opts ...grpc.CallOption) (*ListResponse, error) {
-	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
-	out := new(ListResponse)
-	err := c.cc.Invoke(ctx, LibraryService_GetAuthors_FullMethodName, in, out, cOpts...)
-	if err != nil {
-		return nil, err
-	}
-	return out, nil
-}
-
-// LibraryServiceServer is the server API for LibraryService service.
-// All implementations must embed UnimplementedLibraryServiceServer
-// for forward compatibility.
-//
-// Legacy
-type LibraryServiceServer interface {
-	SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error)
-	GetAuthors(context.Context, *ListRequest) (*ListResponse, error)
-	mustEmbedUnimplementedLibraryServiceServer()
-}
-
-// UnimplementedLibraryServiceServer must be embedded to have
-// forward compatible implementations.
-//
-// NOTE: this should be embedded by value instead of pointer to avoid a nil
-// pointer dereference when methods are called.
-type UnimplementedLibraryServiceServer struct{}
-
-func (UnimplementedLibraryServiceServer) SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error) {
-	return nil, status.Error(codes.Unimplemented, "method SearchBooks not implemented")
-}
-func (UnimplementedLibraryServiceServer) GetAuthors(context.Context, *ListRequest) (*ListResponse, error) {
-	return nil, status.Error(codes.Unimplemented, "method GetAuthors not implemented")
-}
-func (UnimplementedLibraryServiceServer) mustEmbedUnimplementedLibraryServiceServer() {}
-func (UnimplementedLibraryServiceServer) testEmbeddedByValue()                        {}
-
-// UnsafeLibraryServiceServer may be embedded to opt out of forward compatibility for this service.
-// Use of this interface is not recommended, as added methods to LibraryServiceServer will
-// result in compilation errors.
-type UnsafeLibraryServiceServer interface {
-	mustEmbedUnimplementedLibraryServiceServer()
-}
-
-func RegisterLibraryServiceServer(s grpc.ServiceRegistrar, srv LibraryServiceServer) {
-	// If the following call panics, it indicates UnimplementedLibraryServiceServer was
-	// embedded by pointer and is nil.  This will cause panics if an
-	// unimplemented method is ever invoked, so we test this at initialization
-	// time to prevent it from happening at runtime later due to I/O.
-	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
-		t.testEmbeddedByValue()
-	}
-	s.RegisterService(&LibraryService_ServiceDesc, srv)
-}
-
-func _LibraryService_SearchBooks_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
-	in := new(SearchRequest)
-	if err := dec(in); err != nil {
-		return nil, err
-	}
-	if interceptor == nil {
-		return srv.(LibraryServiceServer).SearchBooks(ctx, in)
-	}
-	info := &grpc.UnaryServerInfo{
-		Server:     srv,
-		FullMethod: LibraryService_SearchBooks_FullMethodName,
-	}
-	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
-		return srv.(LibraryServiceServer).SearchBooks(ctx, req.(*SearchRequest))
-	}
-	return interceptor(ctx, in, info, handler)
-}
-
-func _LibraryService_GetAuthors_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
-	in := new(ListRequest)
-	if err := dec(in); err != nil {
-		return nil, err
-	}
-	if interceptor == nil {
-		return srv.(LibraryServiceServer).GetAuthors(ctx, in)
-	}
-	info := &grpc.UnaryServerInfo{
-		Server:     srv,
-		FullMethod: LibraryService_GetAuthors_FullMethodName,
-	}
-	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
-		return srv.(LibraryServiceServer).GetAuthors(ctx, req.(*ListRequest))
-	}
-	return interceptor(ctx, in, info, handler)
-}
-
-// LibraryService_ServiceDesc is the grpc.ServiceDesc for LibraryService service.
-// It's only intended for direct use with grpc.RegisterService,
-// and not to be introspected or modified (even as a copy)
-var LibraryService_ServiceDesc = grpc.ServiceDesc{
-	ServiceName: "libraryv1.LibraryService",
-	HandlerType: (*LibraryServiceServer)(nil),
-	Methods: []grpc.MethodDesc{
-		{
-			MethodName: "SearchBooks",
-			Handler:    _LibraryService_SearchBooks_Handler,
-		},
-		{
-			MethodName: "GetAuthors",
-			Handler:    _LibraryService_GetAuthors_Handler,
-		},
-	},
-	Streams:  []grpc.StreamDesc{},
-	Metadata: "api/proto/v1/library.proto",
-}
-
---- END_FILE: ./api/proto/v1/library_grpc.pb.go ---
-
---- START_FILE: ./api/proto/v1/lisp_library.proto ---
-syntax = "proto3";
-package libraryv1;
-
-message FilterNode {
-  string field = 1;
-  string value = 2;
-  int32 operator = 3;
-}
-
-message LogicalNode {
-  repeated SearchQuery nodes = 1;
-}
-
-message NotNode {
-  SearchQuery node = 1;
-}
-
-message SearchQuery {
-  FilterNode filter = 1;
-  LogicalNode logical = 2;
-  NotNode negation = 3;
-}
-
---- END_FILE: ./api/proto/v1/lisp_library.proto ---
-
---- START_FILE: ./api/proto/v1/library.pb.go ---
-// Code generated by protoc-gen-go. DO NOT EDIT.
-// versions:
-// 	protoc-gen-go v1.36.11
-// 	protoc        v3.21.12
-// source: api/proto/v1/library.proto
-
-package libraryv1
-
-import (
-	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
-	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
-	reflect "reflect"
-	sync "sync"
-	unsafe "unsafe"
-)
-
-const (
-	// Verify that this generated code is sufficiently up-to-date.
-	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
-	// Verify that runtime/protoimpl is sufficiently up-to-date.
-	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
-)
-
-type LogicalOp int32
-
-const (
-	LogicalOp_AND LogicalOp = 0
-	LogicalOp_OR  LogicalOp = 1
-	LogicalOp_NOT LogicalOp = 2
-)
-
-// Enum value maps for LogicalOp.
-var (
-	LogicalOp_name = map[int32]string{
-		0: "AND",
-		1: "OR",
-		2: "NOT",
-	}
-	LogicalOp_value = map[string]int32{
-		"AND": 0,
-		"OR":  1,
-		"NOT": 2,
-	}
-)
-
-func (x LogicalOp) Enum() *LogicalOp {
-	p := new(LogicalOp)
-	*p = x
-	return p
-}
-
-func (x LogicalOp) String() string {
-	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
-}
-
-func (LogicalOp) Descriptor() protoreflect.EnumDescriptor {
-	return file_api_proto_v1_library_proto_enumTypes[0].Descriptor()
-}
-
-func (LogicalOp) Type() protoreflect.EnumType {
-	return &file_api_proto_v1_library_proto_enumTypes[0]
-}
-
-func (x LogicalOp) Number() protoreflect.EnumNumber {
-	return protoreflect.EnumNumber(x)
-}
-
-// Deprecated: Use LogicalOp.Descriptor instead.
-func (LogicalOp) EnumDescriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{0}
-}
-
-type Operator int32
-
-const (
-	Operator_OP_EQUALS   Operator = 0
-	Operator_OP_CONTAINS Operator = 1
-	Operator_OP_REGEX    Operator = 2
-)
-
-// Enum value maps for Operator.
-var (
-	Operator_name = map[int32]string{
-		0: "OP_EQUALS",
-		1: "OP_CONTAINS",
-		2: "OP_REGEX",
-	}
-	Operator_value = map[string]int32{
-		"OP_EQUALS":   0,
-		"OP_CONTAINS": 1,
-		"OP_REGEX":    2,
-	}
-)
-
-func (x Operator) Enum() *Operator {
-	p := new(Operator)
-	*p = x
-	return p
-}
-
-func (x Operator) String() string {
-	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
-}
-
-func (Operator) Descriptor() protoreflect.EnumDescriptor {
-	return file_api_proto_v1_library_proto_enumTypes[1].Descriptor()
-}
-
-func (Operator) Type() protoreflect.EnumType {
-	return &file_api_proto_v1_library_proto_enumTypes[1]
-}
-
-func (x Operator) Number() protoreflect.EnumNumber {
-	return protoreflect.EnumNumber(x)
-}
-
-// Deprecated: Use Operator.Descriptor instead.
-func (Operator) EnumDescriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{1}
-}
-
-type SearchRequest struct {
-	state         protoimpl.MessageState `protogen:"open.v1"`
-	Query         string                 `protobuf:"bytes,1,opt,name=query,proto3" json:"query,omitempty"`
-	TemplateId    string                 `protobuf:"bytes,2,opt,name=template_id,json=templateId,proto3" json:"template_id,omitempty"`
-	Limit         int32                  `protobuf:"varint,3,opt,name=limit,proto3" json:"limit,omitempty"`
-	Offset        int32                  `protobuf:"varint,4,opt,name=offset,proto3" json:"offset,omitempty"`
-	TraceId       string                 `protobuf:"bytes,5,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *SearchRequest) Reset() {
-	*x = SearchRequest{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[0]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *SearchRequest) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*SearchRequest) ProtoMessage() {}
-
-func (x *SearchRequest) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[0]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use SearchRequest.ProtoReflect.Descriptor instead.
-func (*SearchRequest) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{0}
-}
-
-func (x *SearchRequest) GetQuery() string {
-	if x != nil {
-		return x.Query
-	}
-	return ""
-}
-
-func (x *SearchRequest) GetTemplateId() string {
-	if x != nil {
-		return x.TemplateId
-	}
-	return ""
-}
-
-func (x *SearchRequest) GetLimit() int32 {
-	if x != nil {
-		return x.Limit
-	}
-	return 0
-}
-
-func (x *SearchRequest) GetOffset() int32 {
-	if x != nil {
-		return x.Offset
-	}
-	return 0
-}
-
-func (x *SearchRequest) GetTraceId() string {
-	if x != nil {
-		return x.TraceId
-	}
-	return ""
-}
-
-type SearchResponse struct {
-	state         protoimpl.MessageState `protogen:"open.v1"`
-	Status        string                 `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
-	Total         int32                  `protobuf:"varint,2,opt,name=total,proto3" json:"total,omitempty"`
-	Books         []*Book                `protobuf:"bytes,3,rep,name=books,proto3" json:"books,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *SearchResponse) Reset() {
-	*x = SearchResponse{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[1]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *SearchResponse) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*SearchResponse) ProtoMessage() {}
-
-func (x *SearchResponse) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[1]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use SearchResponse.ProtoReflect.Descriptor instead.
-func (*SearchResponse) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{1}
-}
-
-func (x *SearchResponse) GetStatus() string {
-	if x != nil {
-		return x.Status
-	}
-	return ""
-}
-
-func (x *SearchResponse) GetTotal() int32 {
-	if x != nil {
-		return x.Total
-	}
-	return 0
-}
-
-func (x *SearchResponse) GetBooks() []*Book {
-	if x != nil {
-		return x.Books
-	}
-	return nil
-}
-
-type Book struct {
-	state         protoimpl.MessageState `protogen:"open.v1"`
-	Id            string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
-	Title         string                 `protobuf:"bytes,2,opt,name=title,proto3" json:"title,omitempty"`
-	Authors       []string               `protobuf:"bytes,3,rep,name=authors,proto3" json:"authors,omitempty"`
-	Container     string                 `protobuf:"bytes,4,opt,name=container,proto3" json:"container,omitempty"`
-	Filename      string                 `protobuf:"bytes,5,opt,name=filename,proto3" json:"filename,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *Book) Reset() {
-	*x = Book{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[2]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *Book) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*Book) ProtoMessage() {}
-
-func (x *Book) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[2]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use Book.ProtoReflect.Descriptor instead.
-func (*Book) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{2}
-}
-
-func (x *Book) GetId() string {
-	if x != nil {
-		return x.Id
-	}
-	return ""
-}
-
-func (x *Book) GetTitle() string {
-	if x != nil {
-		return x.Title
-	}
-	return ""
-}
-
-func (x *Book) GetAuthors() []string {
-	if x != nil {
-		return x.Authors
-	}
-	return nil
-}
-
-func (x *Book) GetContainer() string {
-	if x != nil {
-		return x.Container
-	}
-	return ""
-}
-
-func (x *Book) GetFilename() string {
-	if x != nil {
-		return x.Filename
-	}
-	return ""
-}
-
-type ListRequest struct {
-	state         protoimpl.MessageState `protogen:"open.v1"`
-	Query         string                 `protobuf:"bytes,1,opt,name=query,proto3" json:"query,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *ListRequest) Reset() {
-	*x = ListRequest{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[3]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *ListRequest) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*ListRequest) ProtoMessage() {}
-
-func (x *ListRequest) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[3]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use ListRequest.ProtoReflect.Descriptor instead.
-func (*ListRequest) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{3}
-}
-
-func (x *ListRequest) GetQuery() string {
-	if x != nil {
-		return x.Query
-	}
-	return ""
-}
-
-type ListResponse struct {
-	state         protoimpl.MessageState `protogen:"open.v1"`
-	Items         []string               `protobuf:"bytes,1,rep,name=items,proto3" json:"items,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *ListResponse) Reset() {
-	*x = ListResponse{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[4]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *ListResponse) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*ListResponse) ProtoMessage() {}
-
-func (x *ListResponse) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[4]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use ListResponse.ProtoReflect.Descriptor instead.
-func (*ListResponse) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{4}
-}
-
-func (x *ListResponse) GetItems() []string {
-	if x != nil {
-		return x.Items
-	}
-	return nil
-}
-
-type AccessRequest struct {
-	state         protoimpl.MessageState `protogen:"open.v1"`
-	UserId        string                 `protobuf:"bytes,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`
-	Platform      string                 `protobuf:"bytes,2,opt,name=platform,proto3" json:"platform,omitempty"`
-	TraceId       string                 `protobuf:"bytes,3,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *AccessRequest) Reset() {
-	*x = AccessRequest{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[5]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *AccessRequest) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*AccessRequest) ProtoMessage() {}
-
-func (x *AccessRequest) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[5]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use AccessRequest.ProtoReflect.Descriptor instead.
-func (*AccessRequest) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{5}
-}
-
-func (x *AccessRequest) GetUserId() string {
-	if x != nil {
-		return x.UserId
-	}
-	return ""
-}
-
-func (x *AccessRequest) GetPlatform() string {
-	if x != nil {
-		return x.Platform
-	}
-	return ""
-}
-
-func (x *AccessRequest) GetTraceId() string {
-	if x != nil {
-		return x.TraceId
-	}
-	return ""
-}
-
-type AccessResponse struct {
-	state         protoimpl.MessageState `protogen:"open.v1"`
-	Allowed       bool                   `protobuf:"varint,1,opt,name=allowed,proto3" json:"allowed,omitempty"`
-	Reason        string                 `protobuf:"bytes,2,opt,name=reason,proto3" json:"reason,omitempty"`
-	UserRole      string                 `protobuf:"bytes,3,opt,name=user_role,json=userRole,proto3" json:"user_role,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *AccessResponse) Reset() {
-	*x = AccessResponse{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[6]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *AccessResponse) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*AccessResponse) ProtoMessage() {}
-
-func (x *AccessResponse) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[6]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use AccessResponse.ProtoReflect.Descriptor instead.
-func (*AccessResponse) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{6}
-}
-
-func (x *AccessResponse) GetAllowed() bool {
-	if x != nil {
-		return x.Allowed
-	}
-	return false
-}
-
-func (x *AccessResponse) GetReason() string {
-	if x != nil {
-		return x.Reason
-	}
-	return ""
-}
-
-func (x *AccessResponse) GetUserRole() string {
-	if x != nil {
-		return x.UserRole
-	}
-	return ""
-}
-
-type RawInput struct {
-	state protoimpl.MessageState `protogen:"open.v1"`
-	// Исправлено: переименовано в 'data', чтобы появился метод GetData(), который ждет message-converter
-	Data          string `protobuf:"bytes,1,opt,name=data,proto3" json:"data,omitempty"`
-	TraceId       string `protobuf:"bytes,2,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *RawInput) Reset() {
-	*x = RawInput{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[7]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *RawInput) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*RawInput) ProtoMessage() {}
-
-func (x *RawInput) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[7]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use RawInput.ProtoReflect.Descriptor instead.
-func (*RawInput) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{7}
-}
-
-func (x *RawInput) GetData() string {
-	if x != nil {
-		return x.Data
-	}
-	return ""
-}
-
-func (x *RawInput) GetTraceId() string {
-	if x != nil {
-		return x.TraceId
-	}
-	return ""
-}
-
-type MessageMeta struct {
-	state         protoimpl.MessageState `protogen:"open.v1"`
-	TraceId       string                 `protobuf:"bytes,1,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
-	CanonicalForm string                 `protobuf:"bytes,2,opt,name=canonical_form,json=canonicalForm,proto3" json:"canonical_form,omitempty"`
-	Platform      string                 `protobuf:"bytes,3,opt,name=platform,proto3" json:"platform,omitempty"`
-	UserId        string                 `protobuf:"bytes,4,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`
-	// Исправлено: добавлено поле, которое требует message-converter
-	AstPlan       string `protobuf:"bytes,5,opt,name=ast_plan,json=astPlan,proto3" json:"ast_plan,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *MessageMeta) Reset() {
-	*x = MessageMeta{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[8]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *MessageMeta) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*MessageMeta) ProtoMessage() {}
-
-func (x *MessageMeta) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[8]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use MessageMeta.ProtoReflect.Descriptor instead.
-func (*MessageMeta) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{8}
-}
-
-func (x *MessageMeta) GetTraceId() string {
-	if x != nil {
-		return x.TraceId
-	}
-	return ""
-}
-
-func (x *MessageMeta) GetCanonicalForm() string {
-	if x != nil {
-		return x.CanonicalForm
-	}
-	return ""
-}
-
-func (x *MessageMeta) GetPlatform() string {
-	if x != nil {
-		return x.Platform
-	}
-	return ""
-}
-
-func (x *MessageMeta) GetUserId() string {
-	if x != nil {
-		return x.UserId
-	}
-	return ""
-}
-
-func (x *MessageMeta) GetAstPlan() string {
-	if x != nil {
-		return x.AstPlan
-	}
-	return ""
-}
-
-type UnmarshaledMessage struct {
-	state         protoimpl.MessageState `protogen:"open.v1"`
-	Meta          *MessageMeta           `protobuf:"bytes,1,opt,name=meta,proto3" json:"meta,omitempty"`
-	Query         *SearchQuery           `protobuf:"bytes,2,opt,name=query,proto3" json:"query,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *UnmarshaledMessage) Reset() {
-	*x = UnmarshaledMessage{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[9]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *UnmarshaledMessage) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*UnmarshaledMessage) ProtoMessage() {}
-
-func (x *UnmarshaledMessage) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[9]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use UnmarshaledMessage.ProtoReflect.Descriptor instead.
-func (*UnmarshaledMessage) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{9}
-}
-
-func (x *UnmarshaledMessage) GetMeta() *MessageMeta {
-	if x != nil {
-		return x.Meta
-	}
-	return nil
-}
-
-func (x *UnmarshaledMessage) GetQuery() *SearchQuery {
-	if x != nil {
-		return x.Query
-	}
-	return nil
-}
-
-type Response struct {
-	state         protoimpl.MessageState `protogen:"open.v1"`
-	Status        string                 `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
-	Books         []*Book                `protobuf:"bytes,2,rep,name=books,proto3" json:"books,omitempty"`
-	Meta          *ResponseMeta          `protobuf:"bytes,3,opt,name=meta,proto3" json:"meta,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *Response) Reset() {
-	*x = Response{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[10]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *Response) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*Response) ProtoMessage() {}
-
-func (x *Response) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[10]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use Response.ProtoReflect.Descriptor instead.
-func (*Response) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{10}
-}
-
-func (x *Response) GetStatus() string {
-	if x != nil {
-		return x.Status
-	}
-	return ""
-}
-
-func (x *Response) GetBooks() []*Book {
-	if x != nil {
-		return x.Books
-	}
-	return nil
-}
-
-func (x *Response) GetMeta() *ResponseMeta {
-	if x != nil {
-		return x.Meta
-	}
-	return nil
-}
-
-type ResponseMeta struct {
-	state         protoimpl.MessageState `protogen:"open.v1"`
-	TraceId       string                 `protobuf:"bytes,1,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
-	CanonicalForm string                 `protobuf:"bytes,2,opt,name=canonical_form,json=canonicalForm,proto3" json:"canonical_form,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *ResponseMeta) Reset() {
-	*x = ResponseMeta{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[11]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *ResponseMeta) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*ResponseMeta) ProtoMessage() {}
-
-func (x *ResponseMeta) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[11]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use ResponseMeta.ProtoReflect.Descriptor instead.
-func (*ResponseMeta) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{11}
-}
-
-func (x *ResponseMeta) GetTraceId() string {
-	if x != nil {
-		return x.TraceId
-	}
-	return ""
-}
-
-func (x *ResponseMeta) GetCanonicalForm() string {
-	if x != nil {
-		return x.CanonicalForm
-	}
-	return ""
-}
-
-type SearchQuery struct {
-	state protoimpl.MessageState `protogen:"open.v1"`
-	// Types that are valid to be assigned to Node:
-	//
-	//	*SearchQuery_Filter
-	//	*SearchQuery_Logical
-	//	*SearchQuery_Negation
-	Node          isSearchQuery_Node `protobuf_oneof:"node"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *SearchQuery) Reset() {
-	*x = SearchQuery{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[12]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *SearchQuery) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*SearchQuery) ProtoMessage() {}
-
-func (x *SearchQuery) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[12]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use SearchQuery.ProtoReflect.Descriptor instead.
-func (*SearchQuery) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{12}
-}
-
-func (x *SearchQuery) GetNode() isSearchQuery_Node {
-	if x != nil {
-		return x.Node
-	}
-	return nil
-}
-
-func (x *SearchQuery) GetFilter() *FilterNode {
-	if x != nil {
-		if x, ok := x.Node.(*SearchQuery_Filter); ok {
-			return x.Filter
-		}
-	}
-	return nil
-}
-
-func (x *SearchQuery) GetLogical() *LogicalNode {
-	if x != nil {
-		if x, ok := x.Node.(*SearchQuery_Logical); ok {
-			return x.Logical
-		}
-	}
-	return nil
-}
-
-func (x *SearchQuery) GetNegation() *NotNode {
-	if x != nil {
-		if x, ok := x.Node.(*SearchQuery_Negation); ok {
-			return x.Negation
-		}
-	}
-	return nil
-}
-
-type isSearchQuery_Node interface {
-	isSearchQuery_Node()
-}
-
-type SearchQuery_Filter struct {
-	Filter *FilterNode `protobuf:"bytes,1,opt,name=filter,proto3,oneof"`
-}
-
-type SearchQuery_Logical struct {
-	Logical *LogicalNode `protobuf:"bytes,2,opt,name=logical,proto3,oneof"`
-}
-
-type SearchQuery_Negation struct {
-	Negation *NotNode `protobuf:"bytes,3,opt,name=negation,proto3,oneof"`
-}
-
-func (*SearchQuery_Filter) isSearchQuery_Node() {}
-
-func (*SearchQuery_Logical) isSearchQuery_Node() {}
-
-func (*SearchQuery_Negation) isSearchQuery_Node() {}
-
-type FilterNode struct {
-	state         protoimpl.MessageState `protogen:"open.v1"`
-	Field         string                 `protobuf:"bytes,1,opt,name=field,proto3" json:"field,omitempty"`
-	Value         string                 `protobuf:"bytes,2,opt,name=value,proto3" json:"value,omitempty"`
-	Operator      Operator               `protobuf:"varint,3,opt,name=operator,proto3,enum=libraryv1.Operator" json:"operator,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *FilterNode) Reset() {
-	*x = FilterNode{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[13]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *FilterNode) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*FilterNode) ProtoMessage() {}
-
-func (x *FilterNode) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[13]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use FilterNode.ProtoReflect.Descriptor instead.
-func (*FilterNode) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{13}
-}
-
-func (x *FilterNode) GetField() string {
-	if x != nil {
-		return x.Field
-	}
-	return ""
-}
-
-func (x *FilterNode) GetValue() string {
-	if x != nil {
-		return x.Value
-	}
-	return ""
-}
-
-func (x *FilterNode) GetOperator() Operator {
-	if x != nil {
-		return x.Operator
-	}
-	return Operator_OP_EQUALS
-}
-
-type LogicalNode struct {
-	state         protoimpl.MessageState `protogen:"open.v1"`
-	Op            LogicalOp              `protobuf:"varint,1,opt,name=op,proto3,enum=libraryv1.LogicalOp" json:"op,omitempty"`
-	Nodes         []*SearchQuery         `protobuf:"bytes,2,rep,name=nodes,proto3" json:"nodes,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *LogicalNode) Reset() {
-	*x = LogicalNode{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[14]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *LogicalNode) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*LogicalNode) ProtoMessage() {}
-
-func (x *LogicalNode) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[14]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use LogicalNode.ProtoReflect.Descriptor instead.
-func (*LogicalNode) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{14}
-}
-
-func (x *LogicalNode) GetOp() LogicalOp {
-	if x != nil {
-		return x.Op
-	}
-	return LogicalOp_AND
-}
-
-func (x *LogicalNode) GetNodes() []*SearchQuery {
-	if x != nil {
-		return x.Nodes
-	}
-	return nil
-}
-
-type NotNode struct {
-	state protoimpl.MessageState `protogen:"open.v1"`
-	// Важно: имя поля 'node' генерирует поле 'Node' в Go структуре, что нужно парсеру
-	Node          *SearchQuery `protobuf:"bytes,1,opt,name=node,proto3" json:"node,omitempty"`
-	unknownFields protoimpl.UnknownFields
-	sizeCache     protoimpl.SizeCache
-}
-
-func (x *NotNode) Reset() {
-	*x = NotNode{}
-	mi := &file_api_proto_v1_library_proto_msgTypes[15]
-	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-	ms.StoreMessageInfo(mi)
-}
-
-func (x *NotNode) String() string {
-	return protoimpl.X.MessageStringOf(x)
-}
-
-func (*NotNode) ProtoMessage() {}
-
-func (x *NotNode) ProtoReflect() protoreflect.Message {
-	mi := &file_api_proto_v1_library_proto_msgTypes[15]
-	if x != nil {
-		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
-		if ms.LoadMessageInfo() == nil {
-			ms.StoreMessageInfo(mi)
-		}
-		return ms
-	}
-	return mi.MessageOf(x)
-}
-
-// Deprecated: Use NotNode.ProtoReflect.Descriptor instead.
-func (*NotNode) Descriptor() ([]byte, []int) {
-	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{15}
-}
-
-func (x *NotNode) GetNode() *SearchQuery {
-	if x != nil {
-		return x.Node
-	}
-	return nil
-}
-
-var File_api_proto_v1_library_proto protoreflect.FileDescriptor
-
-const file_api_proto_v1_library_proto_rawDesc = "" +
-	"\n" +
-	"\x1aapi/proto/v1/library.proto\x12\tlibraryv1\"\x8f\x01\n" +
-	"\rSearchRequest\x12\x14\n" +
-	"\x05query\x18\x01 \x01(\tR\x05query\x12\x1f\n" +
-	"\vtemplate_id\x18\x02 \x01(\tR\n" +
-	"templateId\x12\x14\n" +
-	"\x05limit\x18\x03 \x01(\x05R\x05limit\x12\x16\n" +
-	"\x06offset\x18\x04 \x01(\x05R\x06offset\x12\x19\n" +
-	"\btrace_id\x18\x05 \x01(\tR\atraceId\"e\n" +
-	"\x0eSearchResponse\x12\x16\n" +
-	"\x06status\x18\x01 \x01(\tR\x06status\x12\x14\n" +
-	"\x05total\x18\x02 \x01(\x05R\x05total\x12%\n" +
-	"\x05books\x18\x03 \x03(\v2\x0f.libraryv1.BookR\x05books\"\x80\x01\n" +
-	"\x04Book\x12\x0e\n" +
-	"\x02id\x18\x01 \x01(\tR\x02id\x12\x14\n" +
-	"\x05title\x18\x02 \x01(\tR\x05title\x12\x18\n" +
-	"\aauthors\x18\x03 \x03(\tR\aauthors\x12\x1c\n" +
-	"\tcontainer\x18\x04 \x01(\tR\tcontainer\x12\x1a\n" +
-	"\bfilename\x18\x05 \x01(\tR\bfilename\"#\n" +
-	"\vListRequest\x12\x14\n" +
-	"\x05query\x18\x01 \x01(\tR\x05query\"$\n" +
-	"\fListResponse\x12\x14\n" +
-	"\x05items\x18\x01 \x03(\tR\x05items\"_\n" +
-	"\rAccessRequest\x12\x17\n" +
-	"\auser_id\x18\x01 \x01(\tR\x06userId\x12\x1a\n" +
-	"\bplatform\x18\x02 \x01(\tR\bplatform\x12\x19\n" +
-	"\btrace_id\x18\x03 \x01(\tR\atraceId\"_\n" +
-	"\x0eAccessResponse\x12\x18\n" +
-	"\aallowed\x18\x01 \x01(\bR\aallowed\x12\x16\n" +
-	"\x06reason\x18\x02 \x01(\tR\x06reason\x12\x1b\n" +
-	"\tuser_role\x18\x03 \x01(\tR\buserRole\"9\n" +
-	"\bRawInput\x12\x12\n" +
-	"\x04data\x18\x01 \x01(\tR\x04data\x12\x19\n" +
-	"\btrace_id\x18\x02 \x01(\tR\atraceId\"\x9f\x01\n" +
-	"\vMessageMeta\x12\x19\n" +
-	"\btrace_id\x18\x01 \x01(\tR\atraceId\x12%\n" +
-	"\x0ecanonical_form\x18\x02 \x01(\tR\rcanonicalForm\x12\x1a\n" +
-	"\bplatform\x18\x03 \x01(\tR\bplatform\x12\x17\n" +
-	"\auser_id\x18\x04 \x01(\tR\x06userId\x12\x19\n" +
-	"\bast_plan\x18\x05 \x01(\tR\aastPlan\"n\n" +
-	"\x12UnmarshaledMessage\x12*\n" +
-	"\x04meta\x18\x01 \x01(\v2\x16.libraryv1.MessageMetaR\x04meta\x12,\n" +
-	"\x05query\x18\x02 \x01(\v2\x16.libraryv1.SearchQueryR\x05query\"v\n" +
-	"\bResponse\x12\x16\n" +
-	"\x06status\x18\x01 \x01(\tR\x06status\x12%\n" +
-	"\x05books\x18\x02 \x03(\v2\x0f.libraryv1.BookR\x05books\x12+\n" +
-	"\x04meta\x18\x03 \x01(\v2\x17.libraryv1.ResponseMetaR\x04meta\"P\n" +
-	"\fResponseMeta\x12\x19\n" +
-	"\btrace_id\x18\x01 \x01(\tR\atraceId\x12%\n" +
-	"\x0ecanonical_form\x18\x02 \x01(\tR\rcanonicalForm\"\xac\x01\n" +
-	"\vSearchQuery\x12/\n" +
-	"\x06filter\x18\x01 \x01(\v2\x15.libraryv1.FilterNodeH\x00R\x06filter\x122\n" +
-	"\alogical\x18\x02 \x01(\v2\x16.libraryv1.LogicalNodeH\x00R\alogical\x120\n" +
-	"\bnegation\x18\x03 \x01(\v2\x12.libraryv1.NotNodeH\x00R\bnegationB\x06\n" +
-	"\x04node\"i\n" +
-	"\n" +
-	"FilterNode\x12\x14\n" +
-	"\x05field\x18\x01 \x01(\tR\x05field\x12\x14\n" +
-	"\x05value\x18\x02 \x01(\tR\x05value\x12/\n" +
-	"\boperator\x18\x03 \x01(\x0e2\x13.libraryv1.OperatorR\boperator\"a\n" +
-	"\vLogicalNode\x12$\n" +
-	"\x02op\x18\x01 \x01(\x0e2\x14.libraryv1.LogicalOpR\x02op\x12,\n" +
-	"\x05nodes\x18\x02 \x03(\v2\x16.libraryv1.SearchQueryR\x05nodes\"5\n" +
-	"\aNotNode\x12*\n" +
-	"\x04node\x18\x01 \x01(\v2\x16.libraryv1.SearchQueryR\x04node*%\n" +
-	"\tLogicalOp\x12\a\n" +
-	"\x03AND\x10\x00\x12\x06\n" +
-	"\x02OR\x10\x01\x12\a\n" +
-	"\x03NOT\x10\x02*8\n" +
-	"\bOperator\x12\r\n" +
-	"\tOP_EQUALS\x10\x00\x12\x0f\n" +
-	"\vOP_CONTAINS\x10\x01\x12\f\n" +
-	"\bOP_REGEX\x10\x022T\n" +
-	"\x13OrchestratorService\x12=\n" +
-	"\x06Search\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse2R\n" +
-	"\x10ProcessorService\x12>\n" +
-	"\aProcess\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse2T\n" +
-	"\x0eStorageService\x12B\n" +
-	"\vSearchBooks\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse2Q\n" +
-	"\vAuthService\x12B\n" +
-	"\vCheckAccess\x12\x18.libraryv1.AccessRequest\x1a\x19.libraryv1.AccessResponse2X\n" +
-	"\x17MessageConverterService\x12=\n" +
-	"\aConvert\x12\x13.libraryv1.RawInput\x1a\x1d.libraryv1.UnmarshaledMessage2\x93\x01\n" +
-	"\x0eLibraryService\x12B\n" +
-	"\vSearchBooks\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse\x12=\n" +
-	"\n" +
-	"GetAuthors\x12\x16.libraryv1.ListRequest\x1a\x17.libraryv1.ListResponseB\x1fZ\x1debusta/api/proto/v1;libraryv1b\x06proto3"
-
-var (
-	file_api_proto_v1_library_proto_rawDescOnce sync.Once
-	file_api_proto_v1_library_proto_rawDescData []byte
-)
-
-func file_api_proto_v1_library_proto_rawDescGZIP() []byte {
-	file_api_proto_v1_library_proto_rawDescOnce.Do(func() {
-		file_api_proto_v1_library_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_api_proto_v1_library_proto_rawDesc), len(file_api_proto_v1_library_proto_rawDesc)))
-	})
-	return file_api_proto_v1_library_proto_rawDescData
-}
-
-var file_api_proto_v1_library_proto_enumTypes = make([]protoimpl.EnumInfo, 2)
-var file_api_proto_v1_library_proto_msgTypes = make([]protoimpl.MessageInfo, 16)
-var file_api_proto_v1_library_proto_goTypes = []any{
-	(LogicalOp)(0),             // 0: libraryv1.LogicalOp
-	(Operator)(0),              // 1: libraryv1.Operator
-	(*SearchRequest)(nil),      // 2: libraryv1.SearchRequest
-	(*SearchResponse)(nil),     // 3: libraryv1.SearchResponse
-	(*Book)(nil),               // 4: libraryv1.Book
-	(*ListRequest)(nil),        // 5: libraryv1.ListRequest
-	(*ListResponse)(nil),       // 6: libraryv1.ListResponse
-	(*AccessRequest)(nil),      // 7: libraryv1.AccessRequest
-	(*AccessResponse)(nil),     // 8: libraryv1.AccessResponse
-	(*RawInput)(nil),           // 9: libraryv1.RawInput
-	(*MessageMeta)(nil),        // 10: libraryv1.MessageMeta
-	(*UnmarshaledMessage)(nil), // 11: libraryv1.UnmarshaledMessage
-	(*Response)(nil),           // 12: libraryv1.Response
-	(*ResponseMeta)(nil),       // 13: libraryv1.ResponseMeta
-	(*SearchQuery)(nil),        // 14: libraryv1.SearchQuery
-	(*FilterNode)(nil),         // 15: libraryv1.FilterNode
-	(*LogicalNode)(nil),        // 16: libraryv1.LogicalNode
-	(*NotNode)(nil),            // 17: libraryv1.NotNode
-}
-var file_api_proto_v1_library_proto_depIdxs = []int32{
-	4,  // 0: libraryv1.SearchResponse.books:type_name -> libraryv1.Book
-	10, // 1: libraryv1.UnmarshaledMessage.meta:type_name -> libraryv1.MessageMeta
-	14, // 2: libraryv1.UnmarshaledMessage.query:type_name -> libraryv1.SearchQuery
-	4,  // 3: libraryv1.Response.books:type_name -> libraryv1.Book
-	13, // 4: libraryv1.Response.meta:type_name -> libraryv1.ResponseMeta
-	15, // 5: libraryv1.SearchQuery.filter:type_name -> libraryv1.FilterNode
-	16, // 6: libraryv1.SearchQuery.logical:type_name -> libraryv1.LogicalNode
-	17, // 7: libraryv1.SearchQuery.negation:type_name -> libraryv1.NotNode
-	1,  // 8: libraryv1.FilterNode.operator:type_name -> libraryv1.Operator
-	0,  // 9: libraryv1.LogicalNode.op:type_name -> libraryv1.LogicalOp
-	14, // 10: libraryv1.LogicalNode.nodes:type_name -> libraryv1.SearchQuery
-	14, // 11: libraryv1.NotNode.node:type_name -> libraryv1.SearchQuery
-	2,  // 12: libraryv1.OrchestratorService.Search:input_type -> libraryv1.SearchRequest
-	2,  // 13: libraryv1.ProcessorService.Process:input_type -> libraryv1.SearchRequest
-	2,  // 14: libraryv1.StorageService.SearchBooks:input_type -> libraryv1.SearchRequest
-	7,  // 15: libraryv1.AuthService.CheckAccess:input_type -> libraryv1.AccessRequest
-	9,  // 16: libraryv1.MessageConverterService.Convert:input_type -> libraryv1.RawInput
-	2,  // 17: libraryv1.LibraryService.SearchBooks:input_type -> libraryv1.SearchRequest
-	5,  // 18: libraryv1.LibraryService.GetAuthors:input_type -> libraryv1.ListRequest
-	3,  // 19: libraryv1.OrchestratorService.Search:output_type -> libraryv1.SearchResponse
-	3,  // 20: libraryv1.ProcessorService.Process:output_type -> libraryv1.SearchResponse
-	3,  // 21: libraryv1.StorageService.SearchBooks:output_type -> libraryv1.SearchResponse
-	8,  // 22: libraryv1.AuthService.CheckAccess:output_type -> libraryv1.AccessResponse
-	11, // 23: libraryv1.MessageConverterService.Convert:output_type -> libraryv1.UnmarshaledMessage
-	3,  // 24: libraryv1.LibraryService.SearchBooks:output_type -> libraryv1.SearchResponse
-	6,  // 25: libraryv1.LibraryService.GetAuthors:output_type -> libraryv1.ListResponse
-	19, // [19:26] is the sub-list for method output_type
-	12, // [12:19] is the sub-list for method input_type
-	12, // [12:12] is the sub-list for extension type_name
-	12, // [12:12] is the sub-list for extension extendee
-	0,  // [0:12] is the sub-list for field type_name
-}
-
-func init() { file_api_proto_v1_library_proto_init() }
-func file_api_proto_v1_library_proto_init() {
-	if File_api_proto_v1_library_proto != nil {
-		return
-	}
-	file_api_proto_v1_library_proto_msgTypes[12].OneofWrappers = []any{
-		(*SearchQuery_Filter)(nil),
-		(*SearchQuery_Logical)(nil),
-		(*SearchQuery_Negation)(nil),
-	}
-	type x struct{}
-	out := protoimpl.TypeBuilder{
-		File: protoimpl.DescBuilder{
-			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
-			RawDescriptor: unsafe.Slice(unsafe.StringData(file_api_proto_v1_library_proto_rawDesc), len(file_api_proto_v1_library_proto_rawDesc)),
-			NumEnums:      2,
-			NumMessages:   16,
-			NumExtensions: 0,
-			NumServices:   6,
-		},
-		GoTypes:           file_api_proto_v1_library_proto_goTypes,
-		DependencyIndexes: file_api_proto_v1_library_proto_depIdxs,
-		EnumInfos:         file_api_proto_v1_library_proto_enumTypes,
-		MessageInfos:      file_api_proto_v1_library_proto_msgTypes,
-	}.Build()
-	File_api_proto_v1_library_proto = out.File
-	file_api_proto_v1_library_proto_goTypes = nil
-	file_api_proto_v1_library_proto_depIdxs = nil
-}
-
---- END_FILE: ./api/proto/v1/library.pb.go ---
-
---- START_FILE: ./api/proto/v1/library.proto ---
-syntax = "proto3";
-
-package libraryv1;
-
-option go_package = "ebusta/api/proto/v1;libraryv1";
-
-// ==========================================
-// 1. SERVICES
-// ==========================================
-
-service OrchestratorService {
-  rpc Search (SearchRequest) returns (SearchResponse);
-}
-
-service ProcessorService {
-  rpc Process (SearchRequest) returns (SearchResponse);
-}
-
-service StorageService {
-  rpc SearchBooks (SearchRequest) returns (SearchResponse);
-}
-
-service AuthService {
-  rpc CheckAccess (AccessRequest) returns (AccessResponse);
-}
-
-service MessageConverterService {
-  rpc Convert (RawInput) returns (UnmarshaledMessage);
-}
-
-// Legacy
-service LibraryService {
-  rpc SearchBooks (SearchRequest) returns (SearchResponse);
-  rpc GetAuthors (ListRequest) returns (ListResponse);
-}
-
-// ==========================================
-// 2. MESSAGES
-// ==========================================
-
-message SearchRequest {
-  string query = 1;
-  string template_id = 2;
-  int32 limit = 3;
-  int32 offset = 4;
-  string trace_id = 5;
-}
-
-message SearchResponse {
-  string status = 1;
-  int32 total = 2;
-  repeated Book books = 3;
-}
-
-message Book {
-  string id = 1;
-  string title = 2;
-  repeated string authors = 3;
-  string container = 4;
-  string filename = 5;
-}
-
-message ListRequest {
-  string query = 1;
-}
-
-message ListResponse {
-  repeated string items = 1;
-}
-
-// --- AUTH ---
-
-message AccessRequest {
-  string user_id = 1;
-  string platform = 2;
-  string trace_id = 3;
-}
-
-message AccessResponse {
-  bool allowed = 1;
-  string reason = 2;
-  string user_role = 3;
-}
-
-// ==========================================
-// 3. CONVERTER & AST (Fixed for existing code)
-// ==========================================
-
-message RawInput {
-  // Исправлено: переименовано в 'data', чтобы появился метод GetData(), который ждет message-converter
-  string data = 1; 
-  string trace_id = 2;
-}
-
-message MessageMeta {
-  string trace_id = 1;
-  string canonical_form = 2;
-  string platform = 3;
-  string user_id = 4;
-  // Исправлено: добавлено поле, которое требует message-converter
-  string ast_plan = 5; 
-}
-
-message UnmarshaledMessage {
-  MessageMeta meta = 1;
-  SearchQuery query = 2;
-}
-
-message Response {
-  string status = 1;
-  repeated Book books = 2;
-  ResponseMeta meta = 3;
-}
-
-message ResponseMeta {
-  string trace_id = 1;
-  string canonical_form = 2;
-}
-
-// --- AST NODES (Strictly for parser.go) ---
-
-enum LogicalOp {
-  AND = 0;
-  OR = 1;
-  NOT = 2;
-}
-
-enum Operator {
-  OP_EQUALS = 0;
-  OP_CONTAINS = 1;
-  OP_REGEX = 2;
-}
-
-message SearchQuery {
-  oneof node {
-    FilterNode filter = 1;
-    LogicalNode logical = 2;
-    NotNode negation = 3;
-  }
-}
-
-message FilterNode {
-  string field = 1;
-  string value = 2;
-  Operator operator = 3;
-}
-
-message LogicalNode {
-  LogicalOp op = 1;
-  repeated SearchQuery nodes = 2;
-}
-
-message NotNode {
-  // Важно: имя поля 'node' генерирует поле 'Node' в Go структуре, что нужно парсеру
-  SearchQuery node = 1; 
-}
-
---- END_FILE: ./api/proto/v1/library.proto ---
-
---- START_FILE: ./opensearch/templates/fl_authors_all.json ---
-{
-  "script": {
-    "lang": "mustache",
-    "source": "{\n  \"size\": 0,\n  \"aggs\": {\n    \"authors\": {\n      \"composite\": {\n        \"size\": {{size}},\n        \"sources\": [ { \"a\": { \"terms\": { \"field\": \"authors.kw\" } } } ]{{#after}},\n        \"after\": {{after}}{{/after}}\n      }\n    }\n  }\n}\n"
-  }
-}
-
-
---- END_FILE: ./opensearch/templates/fl_authors_all.json ---
-
---- START_FILE: ./opensearch/templates/fl_author_fuzzy.json ---
-{
-  "script": {
-    "lang": "mustache",
-    "source": {
-      "query": {
-        "match": {
-          "authors": {
-            "query": "{{author}}",
-            "operator": "and"
-          }
-        }
-      },
-      "size": "{{size}}",
-      "from": "{{from}}",
-      "_source": ["title", "authors", "fileInfo.container", "fileInfo.filename"],
-      "track_total_hits": false
-    }
-  }
-}
-
---- END_FILE: ./opensearch/templates/fl_author_fuzzy.json ---
-
---- START_FILE: ./opensearch/templates/fl_author_exact.json ---
-{
-  "script": {
-    "lang": "mustache",
-    "source": {
-      "query": { "term": { "authors.kw": "{{author}}" } },
-      "collapse": { "field": "title.kw", "inner_hits": { "name": "best", "size": 1, "sort": [{"fileInfo.size": "desc"}] } },
-      "size": "{{size}}{{^size}}20{{/size}}"
-    }
-  }
-}
-
---- END_FILE: ./opensearch/templates/fl_author_exact.json ---
-
---- START_FILE: ./opensearch/templates/fl_names_token_prefix.json ---
-{
-  "script": {
-    "lang": "mustache",
-    "source": "{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        { \"multi_match\": { \"query\": \"{{query}}\", \"type\": \"phrase_prefix\", \"fields\": [\"authors^3\",\"title^1\"] } },\n        { \"match\": { \"authors.prefix\": { \"query\": \"{{query}}\", \"boost\": 4 } } },\n        { \"match\": { \"title.prefix\":   { \"query\": \"{{query}}\", \"boost\": 2 } } }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"size\": {{size}},\n  \"from\": {{from}},\n  \"sort\": [{ \"title.kw\": { \"order\": \"asc\" } }],\n  \"track_total_hits\": false,\n  \"_source\": [\"title\",\"authors\",\"fileInfo.container\",\"fileInfo.filename\"],\n  \"highlight\": { \"fields\": { \"authors\": {}, \"title\": {} } }\n}"
-  }
-}
---- END_FILE: ./opensearch/templates/fl_names_token_prefix.json ---
-
---- START_FILE: ./opensearch/templates/fl_title_match.json ---
-{
-  "script": {
-    "lang": "mustache",
-    "source": {
-      "query": {
-        "match": {
-          "title": {
-            "query": "{{query}}",
-            "operator": "and"
-          }
-        }
-      },
-      "from": "{{from}}",
-      "size": "{{size}}"
-    }
-  }
-}
-
---- END_FILE: ./opensearch/templates/fl_title_match.json ---
-
---- START_FILE: ./opensearch/templates/fl_title_substring.json ---
-{
-  "script": {
-    "lang": "mustache",
-    "source": "{\n  \"from\": 0,\n  \"size\": {{size}},\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"*{{query}}*\",\n      \"fields\": [\"title.kw\", \"authors.kw\"],\n      \"analyze_wildcard\": true,\n      \"default_operator\": \"and\"\n    }\n  },\n  \"_source\": [\"title\", \"authors\", \"year\", \"fileInfo.container\", \"fileInfo.filename\"]\n}\n"
-  }
-}
-
-
---- END_FILE: ./opensearch/templates/fl_title_substring.json ---
-
---- START_FILE: ./opensearch/templates/fl_title_prefix.json ---
-{
-  "script": {
-    "lang": "mustache",
-    "source": "{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        { \"match\": { \"title.prefix\": { \"query\": \"{{query}}\", \"boost\": 5 } } },\n        { \"match_phrase_prefix\": { \"title\": { \"query\": \"{{query}}\", \"boost\": 2 } } },\n        { \"term\": { \"title.kw\": { \"value\": \"{{query}}\", \"boost\": 20 } } }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"size\": {{size}},\n  \"from\": {{from}},\n  \"sort\": [{ \"title.kw\": { \"order\": \"asc\" } }],\n  \"track_total_hits\": false,\n  \"_source\": [\"title\",\"authors\",\"fileInfo.container\",\"fileInfo.filename\"],\n  \"highlight\": { \"fields\": { \"title\": {} } }\n}"
-  }
-}
---- END_FILE: ./opensearch/templates/fl_title_prefix.json ---
-
---- START_FILE: ./opensearch/templates/fl_mixed_search.json ---
-{
-  "script": {
-    "lang": "mustache",
-    "source": {
-      "query": {
-        "multi_match": {
-          "query": "{{query}}",
-          "fields": ["title^3", "authors", "annotation"],
-          "type": "best_fields",
-          "fuzziness": "AUTO"
-        }
-      },
-      "collapse": {
-        "field": "title.kw",
-        "inner_hits": { "name": "best", "size": 1, "sort": [{"fileInfo.size": "desc"}] }
-      },
-      "from": "{{from}}{{^from}}0{{/from}}",
-      "size": "{{size}}{{^size}}10{{/size}}"
-    }
-  }
-}
-
---- END_FILE: ./opensearch/templates/fl_mixed_search.json ---
-
---- START_FILE: ./opensearch/templates/fl_titles_all.json ---
-{
-  "script": {
-    "lang": "mustache",
-    "source": "{\n  \"size\": 0,\n  \"aggs\": {\n    \"titles\": {\n      \"composite\": {\n        \"size\": {{size}},\n        \"sources\": [ { \"t\": { \"terms\": { \"field\": \"title.kw\" } } } ]{{#after}},\n        \"after\": {{after}}{{/after}}\n      }\n    }\n  }\n}\n"
-  }
-}
-
-
---- END_FILE: ./opensearch/templates/fl_titles_all.json ---
-
---- START_FILE: ./opensearch/flibusta_merged_index.fixed.json ---
-{
-  "settings": {
-    "index": {
-      "number_of_shards": 1,
-      "number_of_replicas": 1,
-      "refresh_interval": "1s"
-    },
-    "analysis": {
-      "filter": {
-        "ru_stop": {
-          "type": "stop",
-          "stopwords": "_russian_"
-        },
-        "ru_stemmer": {
-          "type": "stemmer",
-          "language": "russian"
-        },
-        "en_stop": {
-          "type": "stop",
-          "stopwords": "_english_"
-        },
-        "en_stemmer": {
-          "type": "stemmer",
-          "language": "english"
-        },
-        "shingle_2_3": {
-          "type": "shingle",
-          "min_shingle_size": 2,
-          "max_shingle_size": 3
-        }
-      },
-      "char_filter": {
-        "quotes": {
-          "type": "mapping",
-          "mappings": [
-            "“=>\"",
-            "”=>\"",
-            "‘=>'",
-            "’=>'"
-          ]
-        }
-      },
-      "normalizer": {
-        "lc_ascii": {
-          "type": "custom",
-          "filter": [
-            "lowercase",
-            "asciifolding"
-          ]
-        }
-      },
-      "analyzer": {
-        "mixed_text": {
-          "type": "custom",
-          "tokenizer": "standard",
-          "char_filter": [
-            "quotes"
-          ],
-          "filter": [
-            "lowercase",
-            "ru_stop",
-            "ru_stemmer",
-            "en_stop",
-            "en_stemmer"
-          ]
-        },
-        "autocomplete": {
-          "type": "custom",
-          "tokenizer": "standard",
-          "filter": [
-            "lowercase"
-          ]
-        },
-        "autocomplete_edge": {
-          "type": "custom",
-          "tokenizer": "edge_ngram_tokenizer",
-          "filter": [
-            "lowercase"
-          ]
-        },
-        "shingled": {
-          "type": "custom",
-          "tokenizer": "standard",
-          "filter": [
-            "lowercase",
-            "shingle_2_3"
-          ]
-        }
-      },
-      "tokenizer": {
-        "edge_ngram_tokenizer": {
-          "type": "edge_ngram",
-          "min_gram": 2,
-          "max_gram": 20,
-          "token_chars": [
-            "letter",
-            "digit"
-          ]
-        }
-      }
-    }
-  },
-  "mappings": {
-    "dynamic": "strict",
-    "properties": {
-      "id": {
-        "type": "keyword"
-      },
-      "docId": {
-        "type": "keyword"
-      },
-      "source": {
-        "type": "keyword"
-      },
-      "ingestedAt": {
-        "type": "date"
-      },
-      "title": {
-        "type": "text",
-        "analyzer": "mixed_text",
-        "fields": {
-          "kw": {
-            "type": "keyword",
-            "normalizer": "lc_ascii"
-          },
-          "ac": {
-            "type": "text",
-            "analyzer": "autocomplete_edge",
-            "search_analyzer": "autocomplete"
-          },
-          "sh": {
-            "type": "text",
-            "analyzer": "shingled"
-          }
-        }
-      },
-      "authors": {
-        "type": "text",
-        "analyzer": "mixed_text",
-        "fields": {
-          "kw": {
-            "type": "keyword",
-            "normalizer": "lc_ascii"
-          },
-          "ac": {
-            "type": "text",
-            "analyzer": "autocomplete_edge",
-            "search_analyzer": "autocomplete"
-          }
-        }
-      },
-      "genres": {
-        "type": "keyword",
-        "normalizer": "lc_ascii"
-      },
-      "languages": {
-        "type": "keyword",
-        "normalizer": "lc_ascii"
-      },
-      "year": {
-        "type": "integer"
-      },
-      "annotation": {
-        "type": "text",
-        "analyzer": "mixed_text"
-      },
-      "sequences": {
-        "type": "nested",
-        "properties": {
-          "name": {
-            "type": "text",
-            "analyzer": "mixed_text",
-            "fields": {
-              "kw": {
-                "type": "keyword",
-                "normalizer": "lc_ascii"
-              },
-              "ac": {
-                "type": "text",
-                "analyzer": "autocomplete_edge",
-                "search_analyzer": "autocomplete"
-              }
-            }
-          },
-          "number": {
-            "type": "float"
-          }
-        }
-      },
-      "fileInfo": {
-        "type": "object",
-        "properties": {
-          "container": {
-            "type": "keyword"
-          },
-          "filename": {
-            "type": "keyword"
-          },
-          "size": {
-            "type": "long"
-          },
-          "sha1": {
-            "type": "keyword"
-          }
-        }
-      },
-      "suggest_title": {
-        "type": "completion"
-      },
-      "suggest_author": {
-        "type": "completion"
-      }
-    }
-  }
-}
---- END_FILE: ./opensearch/flibusta_merged_index.fixed.json ---
-
---- START_FILE: ./opensearch/os-setup-config.yaml ---
-opensearch:
-  url: "http://cloud-1:9200"
-  index_name: "flibusta_merged_index"
-
-paths:
-  index_file: "./flibusta_merged_index.fixed.json"
-  templates_dir: "./templates"
-
-logging:
-  log_path: "os-setup.log"
-
---- END_FILE: ./opensearch/os-setup-config.yaml ---
-
---- START_FILE: ./cmd/datamanager/main.go ---
-package main
-
-import (
-	"bytes"
-	"context"
-	"encoding/json"
-	"fmt"
-	"io"
-	"log"
-	"net"
-	"net/http"
-	"os"
-
-	"ebusta/api/proto/v1"
-	"github.com/spf13/viper"
-	"google.golang.org/grpc"
-)
-
-type storageServer struct {
-	libraryv1.UnimplementedStorageServiceServer
-	osBaseURL string
-	indexName string
-	debug     bool
-}
-
-func (s *storageServer) SearchBooks(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
-	templateID := req.TemplateId
-	if templateID == "" {
-		templateID = "fl_mixed_search"
-	}
-	
-	var paramName string
-	switch templateID {
-	case "fl_author_exact", "fl_author_fuzzy":
-		paramName = "author"
-	case "fl_title_substring", "fl_titles_all":
-		paramName = "query"
-	default:
-		paramName = "query"
-	}
-
-	osReqBody := map[string]interface{}{
-		"id": templateID,
-		"params": map[string]interface{}{
-			paramName: req.Query,
-			"from":    0,
-			"size":    req.Limit,
-		},
-	}
-	
-	if val, ok := osReqBody["params"].(map[string]interface{})["size"].(int32); ok && val == 0 {
-		osReqBody["params"].(map[string]interface{})["size"] = 10
-	}
-
-	jsonData, _ := json.Marshal(osReqBody)
-	targetURL := fmt.Sprintf("%s/%s/_search/template", s.osBaseURL, s.indexName)
-	log.Printf("📤 [OS-REQ] URL: %s | BODY: %s", targetURL, string(jsonData))
-
-	resp, err := http.Post(targetURL, "application/json", bytes.NewBuffer(jsonData))
-	if err != nil {
-		return nil, err
-	}
-	defer resp.Body.Close()
-
-	body, _ := io.ReadAll(resp.Body)
-	
-	// ГИБКИЙ ПАРСИНГ: Total может быть числом, объектом или отсутствовать
-	var osRaw struct {
-		Hits struct {
-			Total interface{} `json:"total"`
-			Hits  []struct {
-				Source struct {
-					Title   string   `json:"title"`
-					Authors []string `json:"authors"`
-				} `json:"_source"`
-				ID string `json:"_id"`
-			} `json:"hits"`
-		} `json:"hits"`
-	}
-
-	if err := json.Unmarshal(body, &osRaw); err != nil {
-		log.Printf("❌ Storage parse error: %v", err)
-		return &libraryv1.SearchResponse{Status: "error"}, nil
-	}
-
-	var totalValue int32
-	switch v := osRaw.Hits.Total.(type) {
-	case float64:
-		totalValue = int32(v)
-	case map[string]interface{}:
-		if val, ok := v["value"].(float64); ok {
-			totalValue = int32(val)
-		}
-	}
-
-	res := &libraryv1.SearchResponse{}
-	for _, hit := range osRaw.Hits.Hits {
-		res.Books = append(res.Books, &libraryv1.Book{
-			Id:      hit.ID,
-			Title:   hit.Source.Title,
-			Authors: hit.Source.Authors,
-		})
-	}
-
-	// FALLBACK: Если хиты есть, а total 0 или не распарсился
-	if totalValue == 0 && len(res.Books) > 0 {
-		totalValue = int32(len(res.Books))
-	}
-	res.Total = totalValue
-
-	log.Printf("📥 [OS-RESP] Found: %d books", totalValue)
-	return res, nil
-}
-
-func main() {
-	viper.SetConfigName("ebusta")
-	viper.SetConfigType("yaml")
-	viper.AddConfigPath(".")
-	viper.ReadInConfig()
-
-	osBaseURL := viper.GetString("datamanager.opensearch_url")
-	indexName := viper.GetString("datamanager.index_name")
-	debug := os.Getenv("DEBUG") != ""
-
-	lis, err := net.Listen("tcp", ":50051")
-	if err != nil { log.Fatalf("failed to listen: %v", err) }
-
-	s := grpc.NewServer()
-	libraryv1.RegisterStorageServiceServer(s, &storageServer{
-		osBaseURL: osBaseURL,
-		indexName: indexName,
-		debug:     debug,
-	})
-
-	log.Println("💾 DataManager (Storage) started on :50051")
-	s.Serve(lis)
-}
-
---- END_FILE: ./cmd/datamanager/main.go ---
-
---- START_FILE: ./cmd/bulker/main.go ---
-package main
-
-import (
-	"archive/zip"
-	"bufio"
-	"bytes"
-	"crypto/sha1"
-	"encoding/hex"
-	"encoding/json"
-	"encoding/xml"
-	"flag"
-	"fmt"
-	"io"
-	"os"
-	"path/filepath"
-	"regexp"
-	"strings"
-	"sync"
-	"sync/atomic"
-	"time"
-
-	"github.com/schollz/progressbar/v3"
-	"github.com/sirupsen/logrus"
-	"golang.org/x/text/encoding/charmap"
-	"golang.org/x/text/encoding/unicode"
-	"gopkg.in/yaml.v3"
-)
-
-type Config struct {
-	OpenSearch struct {
-		IndexName string `yaml:"index_name"`
-	} `yaml:"opensearch"`
-	Paths struct {
-		WarnDir   string `yaml:"warn_dir"`
-		OutputDir string `yaml:"output_dir"`
-		SourceDir string `yaml:"source_dir"`
-	} `yaml:"paths"`
-	Processing struct {
-		Threads int `yaml:"threads"`
-	} `yaml:"processing"`
-}
-
-type docOut struct {
-	Title      string    `json:"title"`
-	Authors    []string  `json:"authors,omitempty"`
-	IngestedAt time.Time `json:"ingestedAt"`
-	FileInfo   struct {
-		Container string `json:"container"`
-		Filename  string `json:"filename"`
-		Sha1      string `json:"sha1"`
-		Size      int64  `json:"size"`
-	} `json:"fileInfo"`
-}
-
-var (
-	cfg          Config
-	log          = logrus.New()
-	outFile      *os.File
-	outMu        sync.Mutex
-	bar          *progressbar.ProgressBar
-	rescuedCount int32
-	// Флаги управления
-	flagRescan  *bool
-	flagVerbose *bool
-)
-
-func main() {
-	configPath := flag.String("config", "./config.yaml", "Path to config file")
-	container := flag.String("container", "", "Process only this specific ZIP from source_dir")
-	rescue := flag.Bool("rescue", false, "Rescue mode")
-	flagRescan = flag.Bool("rescan", false, "Force rescan all files ignoring existing output")
-	flagVerbose = flag.Bool("verbose", false, "Detailed check by hashing every file")
-	flag.Parse()
-
-	cFile, err := os.ReadFile(*configPath)
-	if err != nil {
-		fmt.Printf("Error: Cannot read config file at %s\n", *configPath)
-		os.Exit(1)
-	}
-	_ = yaml.Unmarshal(cFile, &cfg)
-
-	log.SetFormatter(&logrus.TextFormatter{FullTimestamp: true, ForceColors: true})
-	_ = os.MkdirAll(cfg.Paths.OutputDir, 0755)
-
-	if *rescue {
-		runRescueMode()
-		fmt.Printf("\n🏁 Rescue Finished. Successfully processed: %d files.\n", atomic.LoadInt32(&rescuedCount))
-	} else if *container != "" {
-		fullPath := filepath.Join(cfg.Paths.SourceDir, *container)
-		dstPath := filepath.Join(cfg.Paths.OutputDir, *container+".jsonl")
-		processSingleZip(fullPath, dstPath)
-	} else {
-		archives, _ := filepath.Glob(filepath.Join(cfg.Paths.SourceDir, "*.zip"))
-		for _, zipPath := range archives {
-			dstPath := filepath.Join(cfg.Paths.OutputDir, filepath.Base(zipPath)+".jsonl")
-			processSingleZip(zipPath, dstPath)
-		}
-	}
-}
-
-// Нормализация файла: удаление дубликатов и перезапись
-func normalizeJSONL(path string) (int, error) {
-	baseName := filepath.Base(path)
-	log.Infof("[%s] Normalization started: scanning for unique IDs...", baseName)
-
-	f, err := os.Open(path)
-	if err != nil {
-		return 0, err
-	}
-	defer f.Close()
-
-	tmpPath := path + ".tmp"
-	tmpFile, err := os.Create(tmpPath)
-	if err != nil {
-		return 0, err
-	}
-	defer tmpFile.Close()
-
-	hashes := make(map[string]bool)
-	scanner := bufio.NewScanner(f)
-	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
-	count := 0
-
-	for scanner.Scan() {
-		line1 := scanner.Text()
-		if strings.Contains(line1, `"_index"`) {
-			match := re.FindStringSubmatch(line1)
-			if len(match) > 1 {
-				id := match[1]
-				if scanner.Scan() {
-					line2 := scanner.Text()
-					if !hashes[id] {
-						hashes[id] = true
-						_, _ = tmpFile.WriteString(line1 + "\n")
-						_, _ = tmpFile.WriteString(line2 + "\n")
-						count++
-					}
-				}
-			}
-		}
-	}
-
-	log.Infof("[%s] Writing normalized file to disk (%d unique records)...", baseName, count)
-
-	f.Close()
-	tmpFile.Close()
-
-	if err := os.Rename(tmpPath, path); err != nil {
-		return 0, err
-	}
-
-	log.Infof("[%s] Normalization finished successfully.", baseName)
-	return count, nil
-}
-
-func countExistingDocs(path string) int {
-	count := 0
-	f, err := os.Open(path)
-	if err != nil { return 0 }
-	defer f.Close()
-	scanner := bufio.NewScanner(f)
-	for scanner.Scan() {
-		if strings.Contains(scanner.Text(), `"_index"`) { count++ }
-	}
-	return count
-}
-
-func loadExistingHashes(path string) map[string]bool {
-	hashes := make(map[string]bool)
-	f, err := os.Open(path)
-	if err != nil { return hashes }
-	defer f.Close()
-	scanner := bufio.NewScanner(f)
-	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
-	for scanner.Scan() {
-		line := scanner.Text()
-		if strings.Contains(line, `"_index"`) {
-			match := re.FindStringSubmatch(line)
-			if len(match) > 1 { hashes[match[1]] = true }
-		}
-	}
-	return hashes
-}
-
-func processSingleZip(zipPath, dstPath string) {
-	containerName := filepath.Base(zipPath)
-	z, err := zip.OpenReader(zipPath)
-	if err != nil {
-		log.Errorf("Failed to open zip %s: %v", zipPath, err)
-		return
-	}
-	defer z.Close()
-
-	zipFb2Count := 0
-	for _, f := range z.File {
-		if strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { zipFb2Count++ }
-	}
-
-	// 1. Быстрая проверка и интеграция нормализации
-	if !*flagRescan && !*flagVerbose {
-		jsonlDocCount := countExistingDocs(dstPath)
-		if jsonlDocCount > 0 {
-			if zipFb2Count == jsonlDocCount {
-				log.Infof("[%s] Quick check: counts match (%d). Skipping container.", containerName, zipFb2Count)
-				z.Close()
-				os.Exit(10)
-			} else {
-				log.Infof("[%s] Count mismatch (ZIP: %d, JSONL: %d). Starting normalization...", containerName, zipFb2Count, jsonlDocCount)
-				
-				newCount, err := normalizeJSONL(dstPath)
-				
-				// Новая проверка после нормализации
-				log.Infof("[%s] New check after normalization: count is %d.", containerName, newCount)
-				
-				if err == nil {
-					if newCount == zipFb2Count {
-						log.Infof("[%s] Result: Counts match! Skipping container.", containerName)
-						z.Close()
-						os.Exit(10)
-					} else {
-						log.Infof("[%s] Result: Still mismatch. Proceeding to detailed check.", containerName)
-					}
-				} else {
-					log.Errorf("[%s] Normalization failed: %v. Proceeding to detailed check.", containerName, err)
-				}
-			}
-		}
-	}
-
-	existingHashes := make(map[string]bool)
-	if !*flagRescan {
-		existingHashes = loadExistingHashes(dstPath)
-		if len(existingHashes) > 0 && *flagVerbose {
-			log.Infof("[%s] Found %d already processed documents.", containerName, len(existingHashes))
-		}
-	}
-
-	type workItem struct {
-		file *zip.File
-		raw  []byte
-		sha  string
-	}
-	var tasks []workItem
-
-	for _, f := range z.File {
-		if !strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { continue }
-		rc, err := f.Open()
-		if err != nil {
-			log.Errorf("Read error %s: %v", f.Name, err)
-			continue
-		}
-		raw, _ := io.ReadAll(rc)
-		rc.Close()
-		sum := sha1.Sum(raw)
-		sha := hex.EncodeToString(sum[:])
-		if existingHashes[sha] {
-			if *flagVerbose { log.Infof("Skipping %s (already exists in output)", f.Name) }
-			continue
-		}
-		tasks = append(tasks, workItem{file: f, raw: raw, sha: sha})
-	}
-
-	if len(tasks) == 0 {
-		log.Infof("Container %s is fully processed. Nothing new.", containerName)
-		z.Close()
-		os.Exit(10)
-	}
-
-	openOutputFile(dstPath)
-	defer outFile.Close()
-	bar = progressbar.Default(int64(len(tasks)), "🚢 "+containerName)
-	jobs := make(chan workItem)
-	var wg sync.WaitGroup
-	for i := 0; i < cfg.Processing.Threads; i++ {
-		wg.Add(1)
-		go func() {
-			defer wg.Done()
-			for item := range jobs {
-				doc, err := parseResilient(item.raw)
-				if err != nil {
-					log.Errorf("FAILED: %s | %v", item.file.Name, err)
-					saveToWarn(item.file.Name, item.raw, err)
-				} else {
-					saveToOutputWithSha(item.file.Name, containerName, item.raw, item.sha, doc)
-				}
-				_ = bar.Add(1)
-			}
-		}()
-	}
-	for _, task := range tasks { jobs <- task }
-	close(jobs)
-	wg.Wait()
-}
-
-func runRescueMode() {
-	files, _ := filepath.Glob(filepath.Join(cfg.Paths.WarnDir, "*fb2"))
-	if len(files) == 0 { return }
-	dstPath := filepath.Join(cfg.Paths.OutputDir, "rescued_items.jsonl")
-	openOutputFile(dstPath)
-	defer outFile.Close()
-	bar = progressbar.Default(int64(len(files)), "🩹 Rescuing")
-	jobs := make(chan string)
-	var wg sync.WaitGroup
-	for i := 0; i < cfg.Processing.Threads; i++ {
-		wg.Add(1)
-		go func() {
-			defer wg.Done()
-			for path := range jobs {
-				data, err := os.ReadFile(path)
-				if err != nil || len(data) == 0 {
-					_ = os.Remove(path)
-					_ = os.Remove(path + ".log")
-					_ = bar.Add(1)
-					continue
-				}
-				doc, err := parseResilient(data)
-				if err == nil {
-					if saveToOutput(filepath.Base(path), "rescued", data, doc) {
-						_ = os.Remove(path)
-						_ = os.Remove(path + ".log")
-						atomic.AddInt32(&rescuedCount, 1)
-					}
-				} else { log.Errorf("FAILED: %s | %v", filepath.Base(path), err) }
-				_ = bar.Add(1)
-			}
-		}()
-	}
-	for _, f := range files { jobs <- f }
-	close(jobs)
-	wg.Wait()
-}
-
-func parseResilient(data []byte) (*docOut, error) {
-	if len(data) == 0 { return nil, fmt.Errorf("empty file") }
-	utf8Data := convertToUTF8(data)
-	doc, err := parseFB2(utf8Data)
-	if err == nil { return doc, nil }
-	return parseWithRegex(utf8Data)
-}
-
-func convertToUTF8(data []byte) []byte {
-	if len(data) < 2 { return data }
-	if (data[0] == 0xFF && data[1] == 0xFE) || (data[0] == 0xFE && data[1] == 0xFF) {
-		dec := unicode.UTF16(unicode.LittleEndian, unicode.UseBOM).NewDecoder()
-		out, _ := dec.Bytes(data)
-		return out
-	}
-	if len(data) > 10 && data[1] == 0 && data[3] == 0 {
-		dec := unicode.UTF16(unicode.LittleEndian, unicode.IgnoreBOM).NewDecoder()
-		out, _ := dec.Bytes(data)
-		return out
-	}
-	header := string(data[:min(len(data), 500)])
-	if strings.Contains(strings.ToLower(header), "windows-1251") {
-		out, _ := charmap.Windows1251.NewDecoder().Bytes(data)
-		return out
-	}
-	return bytes.ToValidUTF8(data, []byte(" "))
-}
-
-func parseWithRegex(data []byte) (*docOut, error) {
-	doc := &docOut{}
-	reTitle := regexp.MustCompile(`(?is)<book-title[^>]*>(.*?)</book-title>`)
-	if m := reTitle.FindSubmatch(data); len(m) > 1 { doc.Title = strings.TrimSpace(string(m[1])) }
-	reAuthor := regexp.MustCompile(`(?is)<author[^>]*>(.*?)</author>`)
-	reFirst := regexp.MustCompile(`(?is)<first-name[^>]*>(.*?)</first-name>`)
-	reLast := regexp.MustCompile(`(?is)<last-name[^>]*>(.*?)</last-name>`)
-	authors := reAuthor.FindAllSubmatch(data, -1)
-	for _, a := range authors {
-		fn, ln := reFirst.FindSubmatch(a[1]), reLast.FindSubmatch(a[1])
-		name := ""
-		if len(fn) > 1 { name += string(fn[1]) + " " }
-		if len(ln) > 1 { name += string(ln[1]) }
-		if name = strings.TrimSpace(name); name != "" { doc.Authors = append(doc.Authors, name) }
-	}
-	if doc.Title == "" { return nil, fmt.Errorf("regex failed") }
-	return doc, nil
-}
-
-func openOutputFile(path string) {
-	var err error
-	outFile, err = os.OpenFile(path, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
-	if err != nil { log.Fatal(err) }
-}
-
-func saveToOutput(filename, container string, raw []byte, doc *docOut) bool {
-	sum := sha1.Sum(raw)
-	sha := hex.EncodeToString(sum[:])
-	return saveToOutputWithSha(filename, container, raw, sha, doc)
-}
-
-func saveToOutputWithSha(filename, container string, raw []byte, sha string, doc *docOut) bool {
-	doc.FileInfo.Container, doc.FileInfo.Filename, doc.FileInfo.Sha1, doc.FileInfo.Size = container, filename, sha, int64(len(raw))
-	doc.IngestedAt = time.Now()
-	action, _ := json.Marshal(map[string]map[string]any{"index": {"_index": cfg.OpenSearch.IndexName, "_id": sha}})
-	data, _ := json.Marshal(doc)
-	outMu.Lock()
-	defer outMu.Unlock()
-	_, _ = outFile.Write(append(action, '\n'))
-	_, _ = outFile.Write(append(data, '\n'))
-	return true
-}
-
-func saveToWarn(filename string, data []byte, err error) {
-	_ = os.WriteFile(filepath.Join(cfg.Paths.WarnDir, filename), data, 0644)
-	_ = os.WriteFile(filepath.Join(cfg.Paths.WarnDir, filename+".log"), []byte(err.Error()), 0644)
-}
-
-func parseFB2(data []byte) (*docOut, error) {
-	d := xml.NewDecoder(bytes.NewReader(data))
-	d.CharsetReader = func(charset string, input io.Reader) (io.Reader, error) { return input, nil }
-	d.Strict = false
-	var doc docOut
-	var inTitle bool
-	for {
-		t, err := d.Token()
-		if err != nil || t == nil { break }
-		switch se := t.(type) {
-		case xml.StartElement:
-			if se.Name.Local == "title-info" { inTitle = true }
-			if se.Name.Local == "book-title" && inTitle { _ = d.DecodeElement(&doc.Title, &se) }
-			if se.Name.Local == "author" && inTitle {
-				var a struct { First string `xml:"first-name"`; Last string `xml:"last-name"` }
-				_ = d.DecodeElement(&a, &se)
-				if n := strings.TrimSpace(a.First + " " + a.Last); n != "" { doc.Authors = append(doc.Authors, n) }
-			}
-		case xml.EndElement:
-			if se.Name.Local == "title-info" { inTitle = false }
-		}
-	}
-	if doc.Title == "" { return nil, fmt.Errorf("xml: no title") }
-	return &doc, nil
-}
-
-func min(a, b int) int { if a < b { return a }; return b }
-
---- END_FILE: ./cmd/bulker/main.go ---
-
---- START_FILE: ./cmd/processor/main.go ---
-package main
-
-import (
-	"context"
-	"log"
-	"net"
-	"strings"
-
-	"ebusta/api/proto/v1"
-	"google.golang.org/grpc"
-)
-
-type processorServer struct {
-	libraryv1.UnimplementedProcessorServiceServer
-	storage libraryv1.StorageServiceClient
-}
-
-func (s *processorServer) Process(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
-	fullQuery := req.Query
-	qLower := strings.ToLower(fullQuery)
-	log.Printf("🧠 Processor: Handling '%s'", fullQuery)
-
-	// 1. Сложные запросы (AND/OR)
-	if strings.Contains(qLower, " and ") || strings.Contains(qLower, " or ") {
-		cleanQuery := fullQuery
-		for _, prefix := range []string{"author:", "title:", "Author:", "Title:"} {
-			cleanQuery = strings.ReplaceAll(cleanQuery, prefix, "")
-		}
-		log.Printf("🧠 Processor: Complex query cleaned: '%s'", cleanQuery)
-		return s.storage.SearchBooks(ctx, &libraryv1.SearchRequest{
-			Query:      strings.TrimSpace(cleanQuery),
-			TemplateId: "fl_mixed_search",
-			Limit:      req.Limit,
-			TraceId:    req.TraceId,
-		})
-	}
-
-	// 2. Обработка префикса title: (Каскадный поиск)
-	if strings.HasPrefix(qLower, "title:") {
-		cleanTitle := strings.TrimSpace(strings.TrimPrefix(fullQuery, "title:"))
-		
-		// Попытка 1: Строгий substring
-		subReq := &libraryv1.SearchRequest{
-			Query:      cleanTitle,
-			TemplateId: "fl_title_substring",
-			Limit:      req.Limit,
-			TraceId:    req.TraceId,
-		}
-		resp, err := s.storage.SearchBooks(ctx, subReq)
-		
-		if err == nil && resp.Total > 0 {
-			return resp, nil
-		}
-
-		// Попытка 2: Умный Match (анализатор разберется с регистром)
-		log.Printf("⚠️ Substring search found 0, switching to fl_title_match for: %s", cleanTitle)
-		subReq.TemplateId = "fl_title_match"
-		return s.storage.SearchBooks(ctx, subReq)
-	}
-
-	// 3. Обработка префикса author: (уже настроена)
-	if strings.HasPrefix(qLower, "author:") {
-		cleanAuthor := strings.TrimSpace(strings.TrimPrefix(fullQuery, "author:"))
-		subReq := &libraryv1.SearchRequest{
-			Query:      cleanAuthor,
-			TemplateId: "fl_author_exact",
-			Limit:      req.Limit,
-			TraceId:    req.TraceId,
-		}
-		resp, err := s.storage.SearchBooks(ctx, subReq)
-		if err == nil && resp.Total > 0 {
-			return resp, nil
-		}
-		log.Printf("⚠️ Switching to fuzzy for: %s", cleanAuthor)
-		subReq.TemplateId = "fl_author_fuzzy"
-		return s.storage.SearchBooks(ctx, subReq)
-	}
-
-	return s.storage.SearchBooks(ctx, req)
-}
-
-func main() {
-	lis, err := net.Listen("tcp", ":50053")
-	if err != nil { log.Fatal(err) }
-	conn, err := grpc.Dial("localhost:50051", grpc.WithInsecure())
-	if err != nil { log.Fatal(err) }
-	defer conn.Close()
-	s := grpc.NewServer()
-	libraryv1.RegisterProcessorServiceServer(s, &processorServer{storage: libraryv1.NewStorageServiceClient(conn)})
-	log.Println("🧠 Ebusta Processor started on :50053")
-	s.Serve(lis)
-}
-
---- END_FILE: ./cmd/processor/main.go ---
-
---- START_FILE: ./cmd/cli/main.go ---
-package main
-
-import (
-	"context"
-	"fmt"
-	"log"
-	"os"
-	"path/filepath"
-	"strings"
-	"time"
-
-	"ebusta/api/proto/v1"
-	"github.com/peterh/liner"
-	"google.golang.org/grpc"
-	"google.golang.org/grpc/credentials/insecure"
-)
-
-var (
-	debugMode   bool
-	historyPath = filepath.Join(os.TempDir(), ".ebusta_history")
-)
-
-func main() {
-	if os.Getenv("DEBUG") != "" {
-		debugMode = true
-		log.Println("🐞 DEBUG MODE: ENABLED")
-	}
-
-	conn, err := grpc.Dial("localhost:50054", grpc.WithTransportCredentials(insecure.NewCredentials()))
-	if err != nil {
-		log.Fatalf("❌ Failed to connect to Orchestrator: %v", err)
-	}
-	defer conn.Close()
-
-	client := libraryv1.NewOrchestratorServiceClient(conn)
-
-	if len(os.Args) > 1 {
-		query := strings.Join(os.Args[1:], " ")
-		runSearch(client, query)
-	} else {
-		runInteractiveLoop(client)
-	}
-}
-
-func runInteractiveLoop(client libraryv1.OrchestratorServiceClient) {
-	line := liner.NewLiner()
-	defer line.Close()
-
-	line.SetCtrlCAborts(true)
-
-	// Загружаем историю из файла, если он есть
-	if f, err := os.Open(historyPath); err == nil {
-		line.ReadHistory(f)
-		f.Close()
-	}
-
-	fmt.Println("🚀 Ebusta CLI Interactive Mode (with History Support)")
-	fmt.Println("Use UP/DOWN arrows for history. Type 'exit' to stop.")
-	fmt.Println("---------------------------------")
-
-	for {
-		if text, err := line.Prompt("ebusta> "); err == nil {
-			text = strings.TrimSpace(text)
-			if text == "" {
-				continue
-			}
-			if text == "exit" || text == "quit" {
-				fmt.Println("Bye!")
-				break
-			}
-
-			// Добавляем в историю и сохраняем
-			line.AppendHistory(text)
-			runSearch(client, text)
-
-			// Сохраняем историю после каждого успешного ввода
-			if f, err := os.Create(historyPath); err == nil {
-				line.WriteHistory(f)
-				f.Close()
-			}
-		} else if err == liner.ErrPromptAborted {
-			fmt.Println("Aborted")
-			break
-		} else {
-			log.Print("Error reading line: ", err)
-			break
-		}
-	}
-}
-
-func runSearch(client libraryv1.OrchestratorServiceClient, query string) {
-	if debugMode {
-		log.Printf("📡 Sending query: '%s'", query)
-	}
-
-	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
-	defer cancel()
-
-	resp, err := client.Search(ctx, &libraryv1.SearchRequest{
-		Query:   query,
-		TraceId: "cli-user",
-	})
-
-	if err != nil {
-		log.Printf("❌ Error: %v", err)
-		return
-	}
-
-	if resp.Total == 0 && len(resp.Books) == 0 {
-		fmt.Println("No results found.")
-		return
-	}
-
-	fmt.Printf("%-40s | %-40s | %s\n", "ID", "Title", "Authors")
-	fmt.Println(strings.Repeat("-", 100))
-
-	for _, b := range resp.Books {
-		fmt.Printf("%-40s | %-40s | %s\n", 
-			b.Id, 
-			truncate(b.Title, 38), 
-			truncate(strings.Join(b.Authors, ", "), 30),
-		)
-	}
-}
-
-func truncate(s string, max int) string {
-	runes := []rune(s)
-	if len(runes) > max {
-		return string(runes[:max]) + "..."
-	}
-	return s
-}
-
---- END_FILE: ./cmd/cli/main.go ---
-
---- START_FILE: ./cmd/client/main.go ---
-package main
-
-import (
-	"context"
-	"log"
-	"time"
-
-	"ebusta/api/proto/v1" // Убедись, что модуль называется так же, как в go.mod
-	"google.golang.org/grpc"
-	"google.golang.org/grpc/credentials/insecure"
-)
-
-func main() {
-	// Подключаемся к серверу Data-Manager
-	conn, err := grpc.Dial("localhost:50051", grpc.WithTransportCredentials(insecure.NewCredentials()))
-	if err != nil {
-		log.Fatalf("did not connect: %v", err)
-	}
-	defer conn.Close()
-
-	c := libraryv1.NewLibraryServiceClient(conn)
-
-	ctx, cancel := context.WithTimeout(context.Background(), time.Second)
-	defer cancel()
-
-	log.Println("--- Ebusta gRPC Client: Sending Search Request ---")
-	
-	// ИСПРАВЛЕНИЕ 1: Метод называется SearchBooks
-	r, err := c.SearchBooks(ctx, &libraryv1.SearchRequest{
-		Query: "Flibusta rules",
-		Limit: 5,
-	})
-	if err != nil {
-		log.Fatalf("could not search: %v", err)
-	}
-
-	// ИСПРАВЛЕНИЕ 2: Используем GetTotal() вместо GetTotalFound()
-	log.Printf("Response from server: Found %d books", r.GetTotal())
-	
-	for _, book := range r.GetBooks() {
-		log.Printf("-> Book: [%s] %s (Authors: %v)", book.GetId(), book.GetTitle(), book.GetAuthors())
-	}
-}
-
---- END_FILE: ./cmd/client/main.go ---
-
---- START_FILE: ./cmd/web-adapter/main.go ---
-package main
-
-import (
-	"context"
-	"fmt"
-	"log"
-	"net/http"
-	"os"
-	"strings"
-	"time"
-
-	"ebusta/api/proto/v1"
-	"google.golang.org/grpc"
-	"google.golang.org/grpc/credentials/insecure"
-)
-
-func main() {
-	// 1. Подключение к Orchestrator (порт 50054)
-	orchHost := os.Getenv("ORCHESTRATOR_HOST")
-	if orchHost == "" {
-		orchHost = "localhost:50054"
-	}
-
-	conn, err := grpc.Dial(orchHost, grpc.WithTransportCredentials(insecure.NewCredentials()))
-	if err != nil {
-		log.Fatalf("did not connect: %v", err)
-	}
-	defer conn.Close()
-
-	// ИСПРАВЛЕНИЕ 1: Правильное имя клиента (OrchestratorServiceClient)
-	client := libraryv1.NewOrchestratorServiceClient(conn)
-
-	http.HandleFunc("/input", func(w http.ResponseWriter, r *http.Request) {
-		query := r.URL.Query().Get("msg")
-		if query == "" {
-			query = r.URL.Query().Get("q")
-		}
-		
-		if query == "" {
-			http.Error(w, "Please provide 'msg' parameter", http.StatusBadRequest)
-			return
-		}
-
-		log.Printf("🌍 Web Adapter received: %s", query)
-
-		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
-		defer cancel()
-
-		// ИСПРАВЛЕНИЕ 2: Используем SearchRequest и метод Search
-		resp, err := client.Search(ctx, &libraryv1.SearchRequest{
-			Query: query,
-		})
-
-		if err != nil {
-			http.Error(w, fmt.Sprintf("Error calling Orchestrator: %v", err), http.StatusInternalServerError)
-			return
-		}
-
-		// Форматируем простой текстовый ответ
-		w.Header().Set("Content-Type", "text/plain; charset=utf-8")
-		
-		if len(resp.Books) == 0 {
-			fmt.Fprintf(w, "No books found for: %s\n", query)
-			return
-		}
-
-		fmt.Fprintf(w, "Found %d books:\n", len(resp.Books))
-		fmt.Fprintln(w, strings.Repeat("-", 40))
-		for _, b := range resp.Books {
-			authors := strings.Join(b.Authors, ", ")
-			fmt.Fprintf(w, "[%s] %s — %s\n", b.Id, b.Title, authors)
-		}
-	})
-
-	port := os.Getenv("PORT")
-	if port == "" {
-		port = "8080"
-	}
-
-	log.Printf("🌍 Web Adapter started on :%s", port)
-	if err := http.ListenAndServe(":"+port, nil); err != nil {
-		log.Fatalf("failed to serve: %v", err)
-	}
-}
-
---- END_FILE: ./cmd/web-adapter/main.go ---
-
---- START_FILE: ./cmd/auth-manager/whitelist.yaml ---
-users:
-  - id: "serge_dev_cli"
-    platform: "cli"
-    role: "admin"
-  - id: "12345678"
-    platform: "telegram"
-    role: "family"
-
---- END_FILE: ./cmd/auth-manager/whitelist.yaml ---
-
---- START_FILE: ./cmd/auth-manager/main.go ---
-package main
-
-import (
-	"context"
-	"log"
-	"net"
-	"os"
-
-	"ebusta/api/proto/v1"
-	"google.golang.org/grpc"
-	"gopkg.in/yaml.v3"
-)
-
-type UserEntry struct {
-	ID       string `yaml:"id"`
-	Platform string `yaml:"platform"`
-	Role     string `yaml:"role"`
-}
-
-type Whitelist struct {
-	Users []UserEntry `yaml:"users"`
-}
-
-type authServer struct {
-	libraryv1.UnimplementedAuthServiceServer
-	whitelist Whitelist
-}
-
-func (s *authServer) CheckAccess(ctx context.Context, req *libraryv1.AccessRequest) (*libraryv1.AccessResponse, error) {
-	log.Printf("[%s] Auth check: user=%s platform=%s", req.TraceId, req.UserId, req.Platform)
-
-	for _, u := range s.whitelist.Users {
-		if u.ID == req.UserId && u.Platform == req.Platform {
-			return &libraryv1.AccessResponse{
-				Allowed:  true,
-				UserRole: u.Role,
-			}, nil
-		}
-	}
-
-	return &libraryv1.AccessResponse{
-		Allowed: false,
-		Reason:  "Access denied: user not in whitelist for this platform",
-	}, nil
-}
-
-func main() {
-	data, err := os.ReadFile("cmd/auth-manager/whitelist.yaml")
-	if err != nil {
-		log.Fatalf("Failed to read whitelist: %v", err)
-	}
-
-	var wl Whitelist
-	if err := yaml.Unmarshal(data, &wl); err != nil {
-		log.Fatalf("Failed to parse whitelist: %v", err)
-	}
-
-	lis, err := net.Listen("tcp", ":50055")
-	if err != nil {
-		log.Fatalf("failed to listen: %v", err)
-	}
-
-	s := grpc.NewServer()
-	libraryv1.RegisterAuthServiceServer(s, &authServer{whitelist: wl})
-
-	log.Println("🛡  Auth-Manager started on :50055")
-	if err := s.Serve(lis); err != nil {
-		log.Fatalf("failed to serve: %v", err)
-	}
-}
-
---- END_FILE: ./cmd/auth-manager/main.go ---
-
---- START_FILE: ./cmd/orchestrator/main.go ---
-package main
-
-import (
-	"context"
-	"log"
-	"net"
-
-	"ebusta/api/proto/v1"
-	"google.golang.org/grpc"
-	"google.golang.org/grpc/credentials/insecure"
-)
-
-type orchestratorServer struct {
-	libraryv1.UnimplementedOrchestratorServiceServer
-	processorClient libraryv1.ProcessorServiceClient
-}
-
-func (s *orchestratorServer) Search(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
-	log.Printf("🎼 Orchestrator received: %s", req.Query)
-	return s.processorClient.Process(ctx, req)
-}
-
-func main() {
-	// Orchestrator -> Processor
-	conn, err := grpc.Dial("localhost:50053", grpc.WithTransportCredentials(insecure.NewCredentials()))
-	if err != nil {
-		log.Fatalf("failed to connect to processor: %v", err)
-	}
-
-	lis, err := net.Listen("tcp", ":50054")
-	if err != nil {
-		log.Fatalf("failed to listen: %v", err)
-	}
-
-	s := grpc.NewServer()
-	libraryv1.RegisterOrchestratorServiceServer(s, &orchestratorServer{
-		processorClient: libraryv1.NewProcessorServiceClient(conn),
-	})
-
-	log.Println("🎼 Orchestrator started on :50054")
-	s.Serve(lis)
-}
-
---- END_FILE: ./cmd/orchestrator/main.go ---
-
---- START_FILE: ./cmd/message-converter/main.go ---
-package main
-
-import (
-	"context"
-	"fmt"
-	"log"
-	"net"
-
-	"ebusta/api/proto/v1"
-	"ebusta/internal/parser"
-	"google.golang.org/grpc"
-)
-
-type server struct {
-	libraryv1.UnimplementedMessageConverterServiceServer
-}
-
-func (s *server) Convert(ctx context.Context, req *libraryv1.RawInput) (*libraryv1.UnmarshaledMessage, error) {
-	log.Printf("🔄 Converter parsing: %s", req.Data)
-
-	// Теперь эта функция существует в internal/parser/parser.go
-	queryAst := parser.Parse(req.Data)
-
-	return &libraryv1.UnmarshaledMessage{
-		Meta: &libraryv1.MessageMeta{
-			TraceId:       req.TraceId,
-			CanonicalForm: req.Data,
-			// Преобразуем структуру AST в строку для логов/отладки
-			AstPlan:       fmt.Sprintf("%v", queryAst),
-		},
-		Query: queryAst,
-	}, nil
-}
-
-func main() {
-	lis, err := net.Listen("tcp", ":50052")
-	if err != nil {
-		log.Fatalf("failed to listen: %v", err)
-	}
-
-	s := grpc.NewServer()
-	libraryv1.RegisterMessageConverterServiceServer(s, &server{})
-
-	log.Println("🔄 MessageConverter started on :50052")
-	if err := s.Serve(lis); err != nil {
-		log.Fatalf("failed to serve: %v", err)
-	}
-}
-
---- END_FILE: ./cmd/message-converter/main.go ---
-
---- START_FILE: ./backlog-parser.md ---
-Цель: Перевод Processor на полную поддержку Ebusta Search DSL v1.1 через обход дерева SearchQuery.
-+3
-
-1. Рефакторинг контракта взаимодействия
-Изменить логику обработки в cmd/processor/main.go , чтобы сервис извлекал поле query типа SearchQuery из входящего сообщения UnmarshaledMessage.
-+4
-
-Обеспечить передачу структурированного объекта SearchQuery от Message-Converter к Processor через gRPC.
-+3
-
-2. Реализация компонента AST Walker
-Разработать рекурсивную функцию обхода дерева SearchQuery в internal/processor.
-+2
-
-Реализовать обработку узла LogicalNode для поддержки операторов AND и OR.
-+1
-
-Реализовать обработку узла NotNode для поддержки инверсии запросов (negation).
-+1
-
-3. Маппинг узлов на шаблоны OpenSearch
-Заменить проверку strings.HasPrefix(queryLower, "author:") на извлечение FilterNode с полем field: "author".
-+1
-
-Привязать FilterNode  к существующим шаблонам данных:
-
-
-field: "author" -> fl_author_exact / fl_author_fuzzy.
-
-
-field: "title" -> fl_title_substring / fl_title_prefix.
-
-
-field: "any" -> fl_mixed_search.
-+1
-
-Интегрировать поддержку Operator:
-+1
-
-
-OP_REGEX -> трансляция в регулярные выражения OpenSearch.
-
-
-OP_EQUALS -> точное совпадение.
-+1
-
-4. Координация логических условий
-Реализовать трансляцию LogicalNode в структуру bool query (must, should, must_not) для OpenSearch.
-+3
-
-Обеспечить соблюдение приоритетов операторов: NOT > AND > OR.
-
-5. Тестирование и верификация
-Добавить интеграционные тесты в tests/smoke_full.sh для проверки цепочки: DSL-строка -> Message-Converter (AST) -> Processor (Walker) -> Data-Manager.
-+2
-
-Верифицировать поле meta.canonical_form в ответе для подтверждения корректности разобранного дерева.
-+1
-
-Аудит готовности:
-
-
-Переменные: Поля LogicalOp, Operator и SearchQuery уже объявлены в api/proto/v1/library.proto.
-+1
-
-
-Функции: Парсер parser.Parse(req.Data) уже интегрирован в cmd/message-converter/main.go.
-
-
-Инфраструктура: Шаблоны OpenSearch (fl_mixed_search, fl_author_exact и др.) готовы к приему структурированных параметров.
-
---- END_FILE: ./backlog-parser.md ---
-
---- START_FILE: ./books.json ---
-[
-  {"id": "1", "title": "Оно", "authors": ["Стивен Кинг"]},
-  {"id": "2", "title": "Сияние", "authors": ["Стивен Кинг"]},
-  {"id": "3", "title": "The Hobbit", "authors": ["J.R.R. Tolkien"]}
-]
-
---- END_FILE: ./books.json ---
-
---- START_FILE: ./go.mod ---
-module ebusta
-
-go 1.24.0
-
-toolchain go1.24.11
-
-require (
-	github.com/kelseyhightower/envconfig v1.4.0
-	github.com/peterh/liner v1.2.2
-	github.com/prometheus/client_golang v1.23.2
-	github.com/schollz/progressbar/v3 v3.19.0
-	github.com/sirupsen/logrus v1.9.3
-	github.com/spf13/viper v1.21.0
-	golang.org/x/text v0.31.0
-	google.golang.org/grpc v1.78.0
-	google.golang.org/protobuf v1.36.10
-	gopkg.in/yaml.v3 v3.0.1
-)
-
-require (
-	github.com/beorn7/perks v1.0.1 // indirect
-	github.com/cespare/xxhash/v2 v2.3.0 // indirect
-	github.com/fsnotify/fsnotify v1.9.0 // indirect
-	github.com/go-viper/mapstructure/v2 v2.4.0 // indirect
-	github.com/mattn/go-runewidth v0.0.16 // indirect
-	github.com/mitchellh/colorstring v0.0.0-20190213212951-d06e56a500db // indirect
-	github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect
-	github.com/pelletier/go-toml/v2 v2.2.4 // indirect
-	github.com/prometheus/client_model v0.6.2 // indirect
-	github.com/prometheus/common v0.66.1 // indirect
-	github.com/prometheus/procfs v0.16.1 // indirect
-	github.com/rivo/uniseg v0.4.7 // indirect
-	github.com/sagikazarmark/locafero v0.11.0 // indirect
-	github.com/sourcegraph/conc v0.3.1-0.20240121214520-5f936abd7ae8 // indirect
-	github.com/spf13/afero v1.15.0 // indirect
-	github.com/spf13/cast v1.10.0 // indirect
-	github.com/spf13/pflag v1.0.10 // indirect
-	github.com/subosito/gotenv v1.6.0 // indirect
-	go.yaml.in/yaml/v2 v2.4.2 // indirect
-	go.yaml.in/yaml/v3 v3.0.4 // indirect
-	golang.org/x/net v0.47.0 // indirect
-	golang.org/x/sys v0.38.0 // indirect
-	golang.org/x/term v0.37.0 // indirect
-	google.golang.org/genproto/googleapis/rpc v0.0.0-20251029180050-ab9386a59fda // indirect
-)
-
---- END_FILE: ./go.mod ---
-
---- START_FILE: ./Makefile ---
-BIN_DIR=bin
-PROTO_DIR=api/proto/v1
-
-.PHONY: build run stop clean smoke-test smoke proto tidy
-
-# Главная цель: сначала генерация proto, потом сборка
-build: proto
-	@mkdir -p $(BIN_DIR)
-	@# Создаем скрипт для логирования (вывод в консоль + файл)
-	@printf "#!/bin/bash\ntee -a \$$1" > $(BIN_DIR)/tee.sh && chmod +x $(BIN_DIR)/tee.sh
-	
-	@echo "📦 Tidy root dependencies..."
-	@go mod tidy
-
-	@echo "🏗️  Building Core Services..."
-	@go build -o $(BIN_DIR)/datamanager ./cmd/datamanager
-	@go build -o $(BIN_DIR)/auth-manager ./cmd/auth-manager
-	@go build -o $(BIN_DIR)/message-converter ./cmd/message-converter
-	@go build -o $(BIN_DIR)/processor ./cmd/processor
-	@go build -o $(BIN_DIR)/orchestrator ./cmd/orchestrator
-	@go build -o $(BIN_DIR)/web-adapter ./cmd/web-adapter
-	@go build -o $(BIN_DIR)/ebusta-cli ./cmd/cli
-	@go build -o $(BIN_DIR)/client ./cmd/client
-
-	@echo "🏗️  Building F2Bulker (Nested Module)..."
-	@cd f2bulker && go mod tidy && go build -o ../$(BIN_DIR)/f2bulker ./cmd/bulker
-
-# Генерация gRPC кода
-proto:
-	@echo "🧬 Generating gRPC code..."
-	@protoc --proto_path=. \
-		--go_out=. --go_opt=paths=source_relative \
-		--go-grpc_out=. --go-grpc_opt=paths=source_relative \
-		$(PROTO_DIR)/library.proto
-
-# Запуск инфраструктуры
-run: stop build
-	@echo "🚀 Starting services..."
-	@./$(BIN_DIR)/datamanager 2>&1 | ./$(BIN_DIR)/tee.sh datamanager.log &
-	@./$(BIN_DIR)/auth-manager 2>&1 | ./$(BIN_DIR)/tee.sh auth-manager.log &
-	@./$(BIN_DIR)/message-converter 2>&1 | ./$(BIN_DIR)/tee.sh message-converter.log &
-	@./$(BIN_DIR)/processor 2>&1 | ./$(BIN_DIR)/tee.sh processor.log &
-	@./$(BIN_DIR)/orchestrator 2>&1 | ./$(BIN_DIR)/tee.sh orchestrator.log &
-	@./$(BIN_DIR)/web-adapter 2>&1 | ./$(BIN_DIR)/tee.sh web-adapter.log &
-	@echo "✅ All systems go! Logs are being written to *.log"
-	@sleep 2
-
-# Остановка (игнорируем ошибки если процесс не найден)
-stop:
-	@echo "🛑 Stopping services..."
-	@-pkill -f $(BIN_DIR)/datamanager > /dev/null 2>&1 || true
-	@-pkill -f $(BIN_DIR)/auth-manager > /dev/null 2>&1 || true
-	@-pkill -f $(BIN_DIR)/message-converter > /dev/null 2>&1 || true
-	@-pkill -f $(BIN_DIR)/processor > /dev/null 2>&1 || true
-	@-pkill -f $(BIN_DIR)/orchestrator > /dev/null 2>&1 || true
-	@-pkill -f $(BIN_DIR)/web-adapter > /dev/null 2>&1 || true
-
-# Быстрый тест CLI
-smoke-test:
-	@echo "🧪 Running CLI Smoke Check..."
-	@./$(BIN_DIR)/ebusta-cli "author:Кинг" | grep -q "Plan" && echo "  ✅ CLI OK" || (echo "  ❌ CLI Failed"; exit 1)
-
-# Запуск скриптовых тестов
-smoke:
-	@echo "🧪 Running Integration Smoke Tests..."
-	@for test in tests/smoke_*.sh; do \
-		echo -n "Running $$test... "; \
-		bash $$test; \
-	done
-
-# Очистка
-clean: stop
-	@echo "🧹 Cleaning up..."
-	rm -rf $(BIN_DIR) *.log
-	# Удаляем сгенерированные pb.go файлы, чтобы гарантировать чистую пересборку
-	find . -name "*.pb.go" -delete
-
---- END_FILE: ./Makefile ---
-
---- START_FILE: ./EBusta_Search_Technical_Spec_v1.1.md ---
-# Техническая спецификация: Поисковая система Ebusta (v1.1)
-
-## 1. Обзор архитектуры
-[cite_start]Система Ebusta представляет собой микросервисную поисковую платформу, предназначенную для индексации и поиска по архивам электронных книг[cite: 326]. [cite_start]Взаимодействие между компонентами осуществляется через gRPC[cite: 409].
-
-### Потоковый конвейер (Pipeline)
-1.  [cite_start]**Web-Adapter**: Принимает внешние HTTP-запросы и передает их в оркестратор[cite: 328, 411].
-2.  [cite_start]**Orchestrator**: Координирует работу микросервисов и управляет идентификаторами трассировки (`Trace-ID`)[cite: 329].
-3.  [cite_start]**Message-Converter**: Преобразует сырую строку запроса в абстрактное синтаксическое дерево (AST)[cite: 329, 413].
-4.  [cite_start]**Processor**: Центральный узел бизнес-логики, выбирающий стратегию поиска на основе AST[cite: 330, 415].
-5.  [cite_start]**Data-Manager**: Выполняет функции прокси-сервиса для взаимодействия с OpenSearch[cite: 330, 417].
-6.  [cite_start]**OpenSearch**: Движок полнотекстового поиска, выполняющий запросы по индексу `flibusta_merged_index`[cite: 369].
-
-
-
----
-
-## 2. Ebusta Search DSL (v1.1)
-
-[cite_start]DSL (Domain Specific Language) предоставляет пользователю гибкий интерфейс для управления параметрами поиска[cite: 426].
-
-### 2.1 Лексические атомы и префиксы (Scopes)
-Система поддерживает следующие префиксы для уточнения области поиска:
-* [cite_start]`title:` — Поиск по названию книги[cite: 426].
-* [cite_start]`author:` — Поиск по имени автора[cite: 426].
-* [cite_start]`author_id:` — Поиск по внутреннему идентификатору автора[cite: 426].
-* [cite_start]`desc:` — Поиск по аннотации/описанию[cite: 426].
-* **`id:`** — Поиск по уникальному идентификатору документа или SHA1-хешу файла.
-* **`file:`** — Поиск по конкретному имени файла (например, `743373.fb2`).
-* **`container:`** — Поиск по имени ZIP-архива.
-
-### 2.2 Логические операторы и выражения
-* [cite_start]**Операторы**: `AND`, `OR`, `NOT` (регистронезависимые)[cite: 426].
-* [cite_start]**Приоритет**: `NOT` > `AND` > `OR`[cite: 433].
-* [cite_start]**Регулярные выражения**: Поддерживаются паттерны вида `/regex/`[cite: 426, 430].
-* [cite_start]**Точные фразы**: Поиск по фразе в кавычках: `"Мастер и Маргарита"`[cite: 426].
-
----
-
-## 3. Внутреннее представление: SearchQuery (AST)
-
-[cite_start]Структура данных `SearchQuery` реализована в формате Protocol Buffers (`library.proto`)[cite: 173].
-
-### Компоненты дерева:
-* [cite_start]**FilterNode**: Листовой узел, содержащий поля `field`, `value` и `operator` (`OP_EQUALS`, `OP_CONTAINS`, `OP_REGEX`)[cite: 175].
-* [cite_start]**LogicalNode**: Узел ветвления, объединяющий другие запросы через логические операции[cite: 176].
-* [cite_start]**NotNode**: Узел инверсии для реализации оператора `NOT`[cite: 174, 177].
-
-
-
----
-
-## 4. Интеграция с данными (OpenSearch)
-
-### 4.1 Схема индекса
-[cite_start]Индекс `flibusta_merged_index` использует строгий маппинг (`dynamic: strict`)[cite: 197].
-* [cite_start]**Текстовые поля**: Поля `title` и `authors` используют анализатор `mixed_text` для поддержки русского и английского языков[cite: 198, 200].
-* [cite_start]**Поля ключевых слов**: Подполя `.kw` используются для точного поиска и схлопывания дублей[cite: 198, 201].
-* [cite_start]**Технические метаданные**: Объект `fileInfo` хранит `container`, `filename` и `size`[cite: 205].
-
-### 4.2 Дедупликация и ранжирование
-[cite_start]Для борьбы с дубликатами используется механизм **Collapse** по полю `title.kw`[cite: 185].
-* [cite_start]В результатах поиска всегда возвращается «лучшая» версия книги (секция `inner_hits` с именем `best`), отсортированная по максимальному размеру файла (`fileInfo.size`)[cite: 185, 186].
-
----
-
-## 5. Текущая реализация и стратегия развития
-
-### 5.1 Анализ состояния (Status Quo)
-[cite_start]На текущий момент компонент **Parser** (`internal/parser`) успешно разбирает строку в AST в сервисе `Message-Converter`[cite: 244]. [cite_start]Однако сервис **Processor** все еще использует упрощенную логику разбора строк через `strings.HasPrefix`[cite: 231, 233].
-
-### 5.2 План внедрения AST Walker
-[cite_start]Целью является полный переход на рекурсивный обход дерева `SearchQuery` в процессоре[cite: 249]:
-1.  [cite_start]**Извлечение**: Перевод `cmd/processor/main.go` на работу с полем `query` из сообщения `UnmarshaledMessage`[cite: 247].
-2.  **Маппинг**: Привязка новых префиксов (`id`, `file`, `container`) к соответствующим полям индекса OpenSearch в шаблонах.
-3.  [cite_start]**Логика**: Реализация трансляции `LogicalNode` в структуру `bool query` (must, should, must_not) для OpenSearch[cite: 254].
-4.  [cite_start]**Валидация**: Обеспечение возврата `meta.canonical_form` для отображения дерева разбора пользователю[cite: 434, 467].
-
----
-*Документ актуален на: 2026-01-25*
-
---- END_FILE: ./EBusta_Search_Technical_Spec_v1.1.md ---
-
---- START_FILE: ./f2bulker/config.yaml ---
-opensearch:
-  index_name: "flibusta_merged_index"
-  url: "http://cloud-1:9200"
-
-paths:
-  warn_dir: "./data/warn"
-  output_dir: "./data/out"
-  source_dir: "/mnt/fb2/fb2.Flibusta.Net"
-
-processing:
-  threads: 4
-
-logging:
-  log_path: "f2bulker.log"
-
-metrics:
-  pushgateway_url: "http://localhost:9091"
-
-# Пауза в секундах между архивами, чтобы сервер остыл
-sleep_between_zips: 600 
-
-
-uploading:
-  log_path: "uploader.log"
-  sleep_between_uploads: 30
-
---- END_FILE: ./f2bulker/config.yaml ---
-
---- START_FILE: ./f2bulker/cmd/bulker/main.go ---
-package main
-
-import (
-	"archive/zip"
-	"bufio"
-	"bytes"
-	"crypto/sha1"
-	"encoding/hex"
-	"encoding/json"
-	"encoding/xml"
-	"flag"
-	"fmt"
-	"io"
-	"os"
-	"path/filepath"
-	"regexp"
-	"strings"
-	"sync"
-	"sync/atomic"
-	"time"
-
-	"github.com/schollz/progressbar/v3"
-	"github.com/sirupsen/logrus"
-	"golang.org/x/text/encoding/charmap"
-	"golang.org/x/text/encoding/unicode"
-	"gopkg.in/yaml.v3"
-)
-
-type Config struct {
-	OpenSearch struct {
-		IndexName string `yaml:"index_name"`
-	} `yaml:"opensearch"`
-	Paths struct {
-		WarnDir   string `yaml:"warn_dir"`
-		OutputDir string `yaml:"output_dir"`
-		SourceDir string `yaml:"source_dir"`
-	} `yaml:"paths"`
-	Processing struct {
-		Threads int `yaml:"threads"`
-	} `yaml:"processing"`
-}
-
-type docOut struct {
-	Title      string    `json:"title"`
-	Authors    []string  `json:"authors,omitempty"`
-	IngestedAt time.Time `json:"ingestedAt"`
-	FileInfo   struct {
-		Container string `json:"container"`
-		Filename  string `json:"filename"`
-		Sha1      string `json:"sha1"`
-		Size      int64  `json:"size"`
-	} `json:"fileInfo"`
-}
-
-var (
-	cfg           Config
-	log           = logrus.New()
-	outFile       *os.File
-	outMu         sync.Mutex
-	bar           *progressbar.ProgressBar
-	rescuedCount  int32
-	flagRescan    *bool
-	flagVerbose   *bool
-	flagSuperFast *bool
-)
-
-func main() {
-	configPath := flag.String("config", "./config.yaml", "Path to config file")
-	container := flag.String("container", "", "Process specific ZIP")
-	rescue := flag.Bool("rescue", false, "Rescue mode")
-	flagRescan = flag.Bool("rescan", false, "Force rescan all")
-	flagVerbose = flag.Bool("verbose", false, "Detailed check")
-	flagSuperFast = flag.Bool("fast", false, "Ultra-fast skip if output exists")
-	flag.Parse()
-
-	cFile, err := os.ReadFile(*configPath)
-	if err != nil {
-		fmt.Printf("Error reading config: %v\n", err)
-		os.Exit(1)
-	}
-	if err := yaml.Unmarshal(cFile, &cfg); err != nil {
-		fmt.Printf("Error parsing YAML: %v\n", err)
-		os.Exit(1)
-	}
-
-	log.SetFormatter(&logrus.TextFormatter{FullTimestamp: true, ForceColors: true})
-	_ = os.MkdirAll(cfg.Paths.OutputDir, 0755)
-
-	if *rescue {
-		runRescueMode()
-	} else if *container != "" {
-		processSingleZip(filepath.Join(cfg.Paths.SourceDir, *container), filepath.Join(cfg.Paths.OutputDir, *container+".jsonl"))
-	} else {
-		archives, _ := filepath.Glob(filepath.Join(cfg.Paths.SourceDir, "*.zip"))
-		for _, zipPath := range archives {
-			processSingleZip(zipPath, filepath.Join(cfg.Paths.OutputDir, filepath.Base(zipPath)+".jsonl"))
-		}
-	}
-}
-
-func normalizeJSONL(path string) (int, error) {
-	f, err := os.Open(path)
-	if err != nil { return 0, err }
-	defer f.Close()
-	tmpPath := path + ".tmp"
-	tmpFile, err := os.Create(tmpPath)
-	if err != nil { return 0, err }
-	defer tmpFile.Close()
-
-	hashes := make(map[string]bool)
-	scanner := bufio.NewScanner(f)
-	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
-	count := 0
-	for scanner.Scan() {
-		line1 := scanner.Text()
-		if strings.Contains(line1, `"_index"`) {
-			match := re.FindStringSubmatch(line1)
-			if len(match) > 1 {
-				id := match[1]
-				if scanner.Scan() {
-					line2 := scanner.Text()
-					if !hashes[id] {
-						hashes[id] = true
-						_, _ = tmpFile.WriteString(line1 + "\n")
-						_, _ = tmpFile.WriteString(line2 + "\n")
-						count++
-					}
-				}
-			}
-		}
-	}
-	_ = os.Rename(tmpPath, path)
-	return count, nil
-}
-
-func countExistingDocs(path string) int {
-	count := 0
-	f, err := os.Open(path)
-	if err != nil { return 0 }
-	defer f.Close()
-	scanner := bufio.NewScanner(f)
-	for scanner.Scan() {
-		if strings.Contains(scanner.Text(), `"_index"`) { count++ }
-	}
-	return count
-}
-
-func loadExistingHashes(path string) map[string]bool {
-	hashes := make(map[string]bool)
-	f, err := os.Open(path)
-	if err != nil { return hashes }
-	defer f.Close()
-	scanner := bufio.NewScanner(f)
-	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
-	for scanner.Scan() {
-		line := scanner.Text()
-		if strings.Contains(line, `"_index"`) {
-			match := re.FindStringSubmatch(line)
-			if len(match) > 1 { hashes[match[1]] = true }
-		}
-	}
-	return hashes
-}
-
-func processSingleZip(zipPath, dstPath string) {
-	containerName := filepath.Base(zipPath)
-	if *flagSuperFast && !*flagRescan {
-		if info, err := os.Stat(dstPath); err == nil && info.Size() > 0 {
-			log.Infof("[%s] Fast-skip: exists.", containerName)
-			os.Exit(10)
-		}
-	}
-
-	z, err := zip.OpenReader(zipPath)
-	if err != nil { return }
-	defer z.Close()
-
-	fb2Count := 0
-	for _, f := range z.File {
-		if strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { fb2Count++ }
-	}
-
-	if !*flagRescan && !*flagVerbose {
-		if jsonlCount := countExistingDocs(dstPath); jsonlCount > 0 {
-			if fb2Count == jsonlCount {
-				os.Exit(10)
-			} else {
-				newCount, _ := normalizeJSONL(dstPath)
-				if newCount == fb2Count { os.Exit(10) }
-			}
-		}
-	}
-
-	existingHashes := make(map[string]bool)
-	if !*flagRescan { existingHashes = loadExistingHashes(dstPath) }
-
-	type workItem struct {
-		file *zip.File
-		raw  []byte
-		sha  string
-	}
-	var tasks []workItem
-
-	for _, f := range z.File {
-		if !strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { continue }
-		
-		if len(existingHashes) == 0 && !*flagRescan && !*flagVerbose {
-			tasks = append(tasks, workItem{file: f})
-			continue
-		}
-
-		rc, err := f.Open()
-		if err != nil { continue }
-		data, _ := io.ReadAll(rc)
-		rc.Close()
-		sum := sha1.Sum(data)
-		sha := hex.EncodeToString(sum[:])
-		if !existingHashes[sha] {
-			tasks = append(tasks, workItem{file: f, raw: data, sha: sha})
-		}
-	}
-
-	if len(tasks) == 0 { os.Exit(10) }
-
-	openOutputFile(dstPath)
-	defer outFile.Close()
-	bar = progressbar.Default(int64(len(tasks)), "🚢 "+containerName)
-	jobs := make(chan workItem)
-	var wg sync.WaitGroup
-	for i := 0; i < cfg.Processing.Threads; i++ {
-		wg.Add(1)
-		go func() {
-			defer wg.Done()
-			for item := range jobs {
-				if item.raw == nil {
-					rc, err := item.file.Open()
-					if err == nil {
-						item.raw, _ = io.ReadAll(rc)
-						rc.Close()
-						sum := sha1.Sum(item.raw)
-						item.sha = hex.EncodeToString(sum[:])
-					}
-				}
-				if item.raw != nil {
-					if doc, err := parseResilient(item.raw); err == nil {
-						saveToOutputWithSha(item.file.Name, containerName, item.raw, item.sha, doc)
-					}
-				}
-				_ = bar.Add(1)
-			}
-		}()
-	}
-	for _, t := range tasks { jobs <- t }
-	close(jobs)
-	wg.Wait()
-}
-
-func runRescueMode() {
-	files, _ := filepath.Glob(filepath.Join(cfg.Paths.WarnDir, "*fb2"))
-	if len(files) == 0 { return }
-	dstPath := filepath.Join(cfg.Paths.OutputDir, "rescued_items.jsonl")
-	openOutputFile(dstPath)
-	defer outFile.Close()
-	jobs := make(chan string)
-	var wg sync.WaitGroup
-	for i := 0; i < cfg.Processing.Threads; i++ {
-		wg.Add(1)
-		go func() {
-			defer wg.Done()
-			for path := range jobs {
-				data, err := os.ReadFile(path)
-				if err != nil { continue }
-				if doc, err := parseResilient(data); err == nil {
-					if saveToOutput(filepath.Base(path), "rescued", data, doc) {
-						_ = os.Remove(path)
-						atomic.AddInt32(&rescuedCount, 1)
-					}
-				}
-			}
-		}()
-	}
-	for _, f := range files { jobs <- f }
-	close(jobs)
-	wg.Wait()
-}
-
-func parseResilient(data []byte) (*docOut, error) {
-	utf8Data := convertToUTF8(data)
-	if doc, err := parseFB2(utf8Data); err == nil { return doc, nil }
-	return parseWithRegex(utf8Data)
-}
-
-func convertToUTF8(data []byte) []byte {
-	if len(data) < 2 { return data }
-	if (data[0] == 0xFF && data[1] == 0xFE) || (data[0] == 0xFE && data[1] == 0xFF) {
-		dec := unicode.UTF16(unicode.LittleEndian, unicode.UseBOM).NewDecoder()
-		out, _ := dec.Bytes(data)
-		return out
-	}
-	header := string(data[:min(len(data), 500)])
-	if strings.Contains(strings.ToLower(header), "windows-1251") {
-		out, _ := charmap.Windows1251.NewDecoder().Bytes(data)
-		return out
-	}
-	return bytes.ToValidUTF8(data, []byte(" "))
-}
-
-func parseWithRegex(data []byte) (*docOut, error) {
-	doc := &docOut{}
-	reTitle := regexp.MustCompile(`(?is)<book-title[^>]*>(.*?)</book-title>`)
-	if m := reTitle.FindSubmatch(data); len(m) > 1 { doc.Title = string(m[1]) }
-	if doc.Title == "" { return nil, fmt.Errorf("regex failed") }
-	return doc, nil
-}
-
-func openOutputFile(path string) {
-	var err error
-	outFile, err = os.OpenFile(path, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
-	if err != nil {
-		log.Fatalf("Critical: failed to open output file: %v", err)
-	}
-}
-
-func saveToOutput(filename, container string, raw []byte, doc *docOut) bool {
-	sum := sha1.Sum(raw)
-	sha := hex.EncodeToString(sum[:])
-	return saveToOutputWithSha(filename, container, raw, sha, doc)
-}
-
-func saveToOutputWithSha(filename, container string, raw []byte, sha string, doc *docOut) bool {
-	doc.FileInfo.Container, doc.FileInfo.Filename, doc.FileInfo.Sha1, doc.FileInfo.Size = container, filename, sha, int64(len(raw))
-	doc.IngestedAt = time.Now()
-	action, _ := json.Marshal(map[string]map[string]any{"index": {"_index": cfg.OpenSearch.IndexName, "_id": sha}})
-	data, _ := json.Marshal(doc)
-	outMu.Lock()
-	defer outMu.Unlock()
-	_, _ = outFile.Write(append(action, '\n'))
-	_, _ = outFile.Write(append(data, '\n'))
-	return true
-}
-
-func parseFB2(data []byte) (*docOut, error) {
-	var doc docOut
-	d := xml.NewDecoder(bytes.NewReader(data))
-	for {
-		t, _ := d.Token()
-		if t == nil { break }
-		if se, ok := t.(xml.StartElement); ok && se.Name.Local == "book-title" {
-			_ = d.DecodeElement(&doc.Title, &se)
-		}
-	}
-	if doc.Title == "" { return nil, fmt.Errorf("no title") }
-	return &doc, nil
-}
-
-func min(a, b int) int { if a < b { return a }; return b }
-
---- END_FILE: ./f2bulker/cmd/bulker/main.go ---
-
---- START_FILE: ./f2bulker/go.mod ---
-module f2bulker
-
-go 1.24.11
-
-require (
-	github.com/schollz/progressbar/v3 v3.19.0
-	github.com/sirupsen/logrus v1.9.3
-	golang.org/x/text v0.32.0
-	gopkg.in/yaml.v3 v3.0.1
-)
-
-require (
-	github.com/kr/pretty v0.3.1 // indirect
-	github.com/mitchellh/colorstring v0.0.0-20190213212951-d06e56a500db // indirect
-	github.com/rivo/uniseg v0.4.7 // indirect
-	github.com/rogpeppe/go-internal v1.10.0 // indirect
-	github.com/stretchr/testify v1.11.1 // indirect
-	golang.org/x/sys v0.35.0 // indirect
-	golang.org/x/term v0.28.0 // indirect
-	gopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c // indirect
-)
-
---- END_FILE: ./f2bulker/go.mod ---
-
---- START_FILE: ./f2bulker/Makefile ---
-BINARY_NAME=f2bulker
-INSTALL_DIR=/opt/f2bulker
-BIN_PATH=$(INSTALL_DIR)/$(BINARY_NAME)
-LOCAL_BIN=./bin/$(BINARY_NAME)
-IS_ROOT = $(shell id -u)
-
-.PHONY: build install clean check-root
-
-build:
-	go mod tidy
-	mkdir -p bin
-	go build -o $(LOCAL_BIN) ./cmd/bulker/main.go
-
-check-root:
-ifneq ($(IS_ROOT), 0)
-	@echo "Error: Run 'sudo make install'"
-	@exit 1
-endif
-
-install: check-root
-	@if [ ! -f $(LOCAL_BIN) ]; then echo "Run 'make build' first"; exit 1; fi
-	mkdir -p $(INSTALL_DIR)
-	mkdir -p $(INSTALL_DIR)/data/src $(INSTALL_DIR)/data/out $(INSTALL_DIR)/data/warn
-	cp $(LOCAL_BIN) $(INSTALL_DIR)/
-	cp ./config.yaml $(INSTALL_DIR)/
-	cp ./scripts/scan_zips.sh $(INSTALL_DIR)/
-	chmod +x $(BIN_PATH)
-	chmod +x $(INSTALL_DIR)/scan_zips.sh
-	@echo "Installed to $(INSTALL_DIR)"
-	@echo "Link: sudo ln -sf $(BIN_PATH) /usr/local/bin/$(BINARY_NAME)"
-
-clean:
-	rm -rf bin
-
---- END_FILE: ./f2bulker/Makefile ---
-
---- START_FILE: ./f2bulker/README.md ---
-# f2bulker: Высокопроизводительный индексатор FB2 в OpenSearch
-
-## 1. Спецификация требований (ISO 29148)
-
-Данный раздел формализует требования к системе, обеспечивая их проверяемость и соответствие техническим целям проекта.
-
-### 1.1 Функциональные требования (Functional Requirements)
-* **FR-1: Извлечение из ZIP.** Система должна открывать ZIP-архивы и извлекать файлы формата `.fb2`.
-* **FR-2: Парсинг метаданных.** Программа должна извлекать название книги и список авторов из структуры FB2.
-* **FR-3: Отказоустойчивость.** При ошибках XML-парсинга система должна применять поиск через регулярные выражения.
-* **FR-4: Формат Bulk API.** Вывод должен формироваться в формате JSONL, пригодном для Bulk API OpenSearch, включая строку метаданных индекса и строку документа.
-* **FR-5: Дедупликация.** Система должна рассчитывать SHA1-хеш каждого файла и пропускать уже обработанные объекты на основе анализа выходного файла.
-* **FR-6: Режим Fast-skip.** При установленном флаге `-fast` система должна мгновенно пропускать контейнер, если соответствующий ему `.jsonl` файл существует и не пуст.
-* **FR-7: Управление через CLI.** Программа должна поддерживать флаги `-config`, `-container`, `-rescan`, `-verbose`, `-fast`.
-* **FR-8: Интеграция со скриптами.** Программа должна возвращать код завершения `10` при пропуске обработанного контейнера для корректной работы внешних планировщиков.
-
-### 1.2 Нефункциональные требования (Performance & Quality)
-* **PR-1: Параллелизм.** Обработка должна распределяться между потоками (горутинами) согласно параметру `Threads` в конфигурации.
-* **PR-2: Оптимизация Discovery.** Для новых контейнеров этап подготовки задач не должен включать чтение содержимого файлов в основном потоке.
-* **PR-3: Эффективность памяти.** Содержимое файлов должно очищаться из RAM сразу после записи в выходной файл.
-* **PR-4: Поддержка кодировок.** Система должна корректно обрабатывать UTF-8, UTF-16 и Windows-1251.
-
----
-
-## 2. Документ технической реализации
-
-### 2.1 Архитектура системы
-Программа построена на модели **Concurrent Worker Pool** (Пул параллельных воркеров).
-
-
-
-#### Компоненты потока управления:
-1.  **Главный поток (Producer):** Сканирует архивы и формирует очередь задач.
-2.  **Канал задач (`jobs`):** Буферизированный канал для передачи структур `workItem`.
-3.  **Воркеры (Consumers):** Набор из N горутин, выполняющих параллельное чтение, хеширование и парсинг.
-4.  **Синхронизатор:** `sync.WaitGroup` для контроля завершения всех процессов перед выходом.
-
-### 2.2 Пошаговая передача управления
-1.  **`main` → `processSingleZip`:** Инициализация параметров конкретного контейнера.
-2.  **Проверка Fast-skip:** Если флаг `-fast` активен, управление через `os.Stat` проверяет наличие файла. При успехе — немедленный выход через `os.Exit(10)`.
-3.  **Discovery (Оптимизированный):** * Если база хешей пуста (новый контейнер), основной поток лишь заполняет список `tasks` ссылками на `zip.File`, минуя вызовы `f.Open` и `io.ReadAll`.
-    * Это устраняет "зависание" программы перед появлением прогресс-бара.
-4.  **Развертывание воркеров:** Основной поток передает задачи в канал. Управление внутри воркера реализует **Lazy Loading**: если данные файла отсутствуют (`item.raw == nil`), воркер сам инициирует чтение и расчет SHA1 параллельно с другими воркерами.
-5.  **Завершение:** После закрытия канала воркеры завершают работу, и управление возвращается в `main` для перехода к следующему ZIP-архиву.
-
-### 2.3 Жизненный цикл переменных
-* **`item.raw` ([]byte):** Данные файла. Память выделяется либо в Discovery, либо в воркере. Ссылка на массив байтов обнуляется сразу после вызова `saveToOutputWithSha`, что позволяет Garbage Collector (GC) освобождать память итеративно.
-* **`existingHashes` (map):** Карта хешей. Загружается один раз в начале обработки ZIP для дедупликации. При ее отсутствии активируется режим ускоренного Discovery.
-* **`err`:** Все переменные ошибок проходят аудит; при критических сбоях (например, невозможность открыть файл вывода) программа завершается через `log.Fatalf`.
-
-### 2.4 Матрица состояний (Аудит логики `-fast`)
-
-| Режим `-fast` | Состояние контейнера | Логика | Результат |
-| :--- | :--- | :--- | :--- |
-| **Установлен** | **Обработан** | `os.Stat` находит файл | Мгновенный выход `Exit(10)`. |
-| **Установлен** | **Не обработан** | `os.Stat` возвращает ошибку | Быстрый Discovery -> Параллельное хеширование. |
-| **Не установлен** | **Обработан** | Сравнение счетчиков файлов | Выход `Exit(10)`, если количество совпадает. |
-| **Не установлен** | **Не обработан** | База хешей пуста | Быстрый Discovery -> Параллельное хеширование. |
-
----
-
-## 3. Инструкции по эксплуатации
-
-### Сборка
-```bash
-make build
-
---- END_FILE: ./f2bulker/README.md ---
-
---- START_FILE: ./f2bulker/backlog.md ---
-# Ebusta Project Backlog
-
-## Ingesting (f2bulker)
-- [ ] **Issue #1**: Ошибка парсинга UTF-16 (BOM ÿþ). Файл `547782.fb2` падает с `XML syntax error: invalid UTF-8`. Необходимо доработать `charsetReader` для корректной десериализации UTF-16 Little Endian. [cite: 440-442]
-- [ ] **Feature**: Поддержка группировки в DSL (скобки). [cite: 141]
-
-## System
-- [ ] **Auth**: Интеграция Auth-Manager в Orchestrator. [cite: 219-220]
-- [ ] **OS**: Переход с мока `books.json` на реальные поисковые шаблоны OpenSearch. [cite: 221]
-
---- END_FILE: ./f2bulker/backlog.md ---
-
---- START_FILE: ./README.md ---
-# Ebusta 📚
-
-Микросервисная поисковая система для архивов Flibusta. Позволяет выполнять быстрый поиск по миллионам записей через OpenSearch, используя собственный DSL (Domain Specific Language).
-
-## 🏗 Архитектура системы
-
-Система состоит из нескольких независимых сервисов, взаимодействующих по gRPC:
-
-* **Web-Adapter (The Door)**: Принимает внешние HTTP-запросы и передает их в оркестратор.
-* **Orchestrator**: Координирует работу всех сервисов, управляет Trace-ID.
-* **Message-Converter**: Парсит строку запроса в AST-дерево.
-* **Processor**: Обрабатывает бизнес-логику и выбирает стратегию поиска.
-* **Datamanager**: Слой данных, работающий с OpenSearch.
-* **Auth-Manager**: Проверяет права доступа и управляет whitelist.
-* **Ebusta-CLI**: Интерактивная оболочка для работы с системой.
-
-
-
-## 🚦 Карта портов
-
-| Сервис            | Порт (gRPC) | Функции                          |
-|:------------------|:------------|:---------------------------------|
-| Datamanager       | `:50051`    | Слой данных (OpenSearch)         |
-| Message-Converter | `:50052`    | Парсер (AST)                     |
-| Processor         | `:50053`    | Логика и выбор шаблонов          |
-| Orchestrator      | `:50054`    | Координация                      |
-| Auth-Manager      | `:50055`    | Безопасность (Whitelist)         |
-| Web-Adapter       | `:8080`     | HTTP-вход (REST)                 |
-| Metrics           | `:9091`     | Prometheus метрики (Datamanager) |
-
-## 🚀 Быстрый старт
-
-### Сборка и запуск
-Требуется установленный Go 1.21+ и Protoc.
-
-```bash
-make build   # Генерация Proto и компиляция всех сервисов
-make run     # Запуск всей системы в фоновом режиме
-
-
---- END_FILE: ./README.md ---
-
---- START_FILE: ./lisp-converter/search.proto ---
-syntax = "proto3";
-package ebusta.library.v1;
-
-option go_package = "ebusta/api/proto/v1;libraryv1";
-
-service MessageConverter {
-  rpc Convert(ConvertRequest) returns (SearchQuery);
-}
-
-message ConvertRequest {
-  string raw_query = 1;
-}
-
-message FilterNode {
-  string field = 1;
-  string value = 2;
-  int32 operator = 3;
-}
-
-message LogicalNode {
-  int32 op = 1; // 1: AND, 2: OR
-  repeated SearchQuery nodes = 2;
-}
-
-message SearchQuery {
-  oneof query {
-    FilterNode filter = 1;
-    LogicalNode logical = 2;
-  }
-}
-
---- END_FILE: ./lisp-converter/search.proto ---
-
---- START_FILE: ./errors.yaml ---
-# Сообщения для пользователя ("Дятла")
-user_errors:
-  invalid_command: "🥚 Слушай, дятел, я не понял твою команду. Попробуй 'get ID' или просто текст поиска."
-  empty_payload: "🥚 Дятел, ты забыл ввести текст после команды!"
-
-# Сообщения при сбоях системы ("Сорян, братан")
-system_errors:
-  converter_down: "🛠 Сорян, братан, у нас конвертер приуныл. Скоро починим."
-  processor_error: "🛠 Сорян, братан, труба забилась. Мы уже вызвали сантехников."
-  data_layer_down: "📉 Сорян, братан, библиотека закрыта на ремонт. Попробуй позже."
-  generic_error: "🧨 Сорян, братан, что-то пошло совсем не так. RequestID: %s"
-
---- END_FILE: ./errors.yaml ---
-
---- START_FILE: ./doc/requirements.md ---
-# Спецификация требований системы "Eboost-Library" (v2.1)
-
-## 1. Основание проекта (Project Foundation)
-
-### 1.1. Описание проблемы
-Владельцы больших личных коллекций электронных книг сталкиваются с проблемой "мертвого груза": книги хранятся локально, но доступ к ним извне (с телефона, в дороге, для друзей) ограничен. Существующие решения либо слишком тяжеловесны, либо привязаны к одному интерфейсу. 
-
-### 1.2. Концепция (Scope)
-Необходима система-посредник, которая абстрагирует хранилище и поиск через единый внутренний протокол, предоставляя доступ через разные каналы коммуникации (Telegram, IRC, CLI) с сохранением контекста пользователя.
-
----
-
-## 2. Бизнес-требования (Business Requirements)
-
-| ID | Наименование | Описание |
-| :--- | :--- | :--- |
-| **BR-1** | Мультиканальность | Единая точка входа через разные интерфейсы (TG, IRC, CLI). |
-| **BR-2** | Скорость поиска | Time-to-Content не более 3 секунд. |
-| **BR-3** | Изоляция логики | Добавление новых фронтов без изменения Core-компонентов. |
-| **BR-4** | Управляемый доступ | Ограничение доступа только для доверенного круга лиц. |
-| **BR-5** | Поддержка форматов | Обработка и выдача разных расширений (EPUB, PDF, FB2). |
-| **BR-6** | Континуитет сессий | Сохранение состояния поиска и навигации (пагинации). |
-| **BR-7** | Масштабируемость | Стабильная работа при объеме базы до 1 000 000 книг. |
-| **BR-8** | Автономность | Работа с локальными файлами без внешних зависимостей. |
-
----
-
-## 3. Требования заинтересованных сторон (Stakeholder Requirements)
-
-### 3.1. Группа: Поиск и навигация
-* **UR-1: Поиск по атрибутам.** Пользователь должен иметь возможность найти книгу по автору, названию или серии.
-    * *Трассировка:* [BR-1, BR-7, BR-2]
-* **UR-2: Просмотр результатов.** Пользователь должен иметь возможность листать страницы выдачи (пагинация) без повторного ввода запроса.
-    * *Трассировка:* [BR-6]
-* **UR-3: Уточнение формата.** При выборе книги система должна предлагать список доступных для неё форматов.
-    * *Трассировка:* [BR-5]
-
-### 3.2. Группа: Получение контента
-* **UR-4: Прямая доставка (TG).** В Telegram файл должен приходить документом (до определенного лимита размера).
-    * *Трассировка:* [BR-1, BR-8]
-* **UR-5: Ссылочная доставка (IRC/CLI).** В текстовых интерфейсах пользователь должен получать временную ссылку на скачивание.
-    * *Трассировка:* [BR-1, BR-8]
-
-### 3.3. Группа: Доступ и интерфейс
-* **UR-6: Прозрачная авторизация.** Доступ предоставляется автоматически на основе ID платформы (UID Telegram, Host IRC).
-    * *Трассировка:* [BR-4]
-* **UR-7: Унификация команд.** Командный синтаксис должен быть единообразным для всех адаптеров.
-    * *Трассировка:* [BR-1, BR-3]
-
-### 3.4. Группа: Администрирование
-* **UR-8: Управление белыми списками.** Владелец должен иметь возможность оперативно менять список разрешенных ID.
-    * *Трассировка:* [BR-4]
-
----
-
-## 4. Глоссарий
-* **UnifiedMessage** — внутренний формат структуры данных, в который преобразуются все входящие запросы.
-* **Whitelist** — список идентификаторов пользователей, имеющих доступ к системе.
-* **OpenSearch** — основной движок полнотекстового поиска.
-
---- END_FILE: ./doc/requirements.md ---
-
---- START_FILE: ./doc/architecture-IN.md ---
-cat << 'EOF' > ebusta_arch_spec.md
-# Техническая спецификация: Архитектура Ebusta (Orchestration Model)
-
-**Дата:** 05.01.2026
-**Статус:** Утверждено
-**Модель взаимодействия:** Централизованная оркестрация (Orchestration)
-
-## 1. Обзор архитектуры
-Система строится на базе центрального компонента (**Orchestrator**), который координирует работу «тонких» адаптеров, парсера DSL и сервиса данных на удаленном хосте Mercury.
-
-### Ключевые узлы:
-1. **Adapters (The Door)**: SSH/BBS, Telegram, Web. Принимают ввод, передают его в Core, получают результат и рендерят его.
-2. **Orchestrator (Core)**: Логический центр. Управляет жизненным циклом запроса.
-3. **Parser**: Библиотека для конвертации строки в `libraryv1.SearchQuery`.
-4. **Data Manager (Mercury Proxy)**: gRPC-сервис, транслирующий запросы в OpenSearch (Docker на Mercury).
-
-## 2. Спецификация UnifiedMessage
-`UnifiedMessage` является единым транспортным контейнером внутри системы.
-
-```protobuf
-message UnifiedMessage {
-    string request_id = 1;
-    
-    // Метаданные источника для обратной маршрутизации
-    message Context {
-        string client_id = 1;
-        enum SourceType {
-            BBS = 0;
-            TELEGRAM = 1;
-            WEB = 2;
-        }
-        SourceType source = 2;
-    }
-    Context context = 2;
-
-    // Полезная нагрузка (Payload)
-    oneof content {
-        libraryv1.SearchQuery query = 3;  // Структурированный запрос
-        SearchResult result = 4;          // Результаты из OpenSearch
-        string error = 5;                 // Описание ошибки
-    }
-}
-
---- END_FILE: ./doc/architecture-IN.md ---
-
---- START_FILE: ./doc/architecture.md ---
-# Архитектура системы "Eboost-Library" (v2.0)
-
-## 1. Описание проблемы
-[cite_start]Владельцы больших личных коллекций электронных книг часто сталкиваются с проблемой "мертвого груза": книги хранятся локально, но доступ к ним извне (с телефона, в дороге, для друзей) ограничен или неудобен[cite: 1, 3]. Существующие решения либо слишком тяжеловесны, либо привязаны к одному интерфейсу. [cite_start]Необходима система, которая абстрагирует хранилище и поиск, предоставляя единый доступ через разные каналы коммуникации с сохранением контекста пользователя[cite: 3, 39].
-
-## 2. Предметная область (DDD Contexts)
-Согласно принципам Domain-Driven Design, система разделена на следующие ограниченные контексты:
-* [cite_start]**Interaction (Взаимодействие):** Трансформация специфичных протоколов (Telegram, IRC, CLI) в единый бизнес-язык системы `UnifiedMessage`[cite: 4, 14].
-* [cite_start]**Identity & Access (Доступ):** Идентификация пользователей, проверка прав по Bot Token или белым спискам[cite: 6].
-* [cite_start]**Library Core (Ядро):** Оркестрация процессов разбора команд, навигации и формирования ответов[cite: 14, 15].
-* [cite_start]**Catalog (Каталог):** Полнотекстовый поиск и управление метаданными книг в OpenSearch[cite: 19, 21].
-* [cite_start]**Delivery (Доставка):** Извлечение файлов из хранилища и предоставление ссылок или бинарных данных[cite: 25, 27].
-
-## 3. Компоненты системы
-
-### Слой адаптеров (Front-end)
-* [cite_start]**TelegramAdapter:** Реализует интерфейс бота, обрабатывает Webhook/Long Polling[cite: 4].
-* [cite_start]**IrcAdapter:** Микросервис-клиент для подключения к IRC-серверам и каналам[cite: 6, 7].
-* [cite_start]**CliAdapter:** Интерфейс командной строки (Linux CLI) для удаленного обращения к ядру[cite: 10, 11].
-* [cite_start]**Translator (New):** Компонент внутри адаптеров или перед процессором, преобразующий `RawPayload` в `UnifiedMessage`[cite: 30].
-
-### Слой управления и состояния
-* **Auth-Manager (New):** Проверяет UserID на наличие в Allow-листах или внешних провайдерах (Keycloak).
-* **Session-Manager (New):** Прокси к **Redis** для хранения состояния поиска и текущего положения пользователя в каталоге.
-* [cite_start]**Config-Manager:** Централизованный сервис для хранения лимитов, шаблонов ответов и локализации[cite: 22, 23].
-
-### Слой бизнес-логики (Core)
-* [cite_start]**Processor:** Центральный сервис, выполняющий разбор команд (/book, /author) и координирующий другие службы[cite: 14, 15, 17].
-
-### Слой данных и хранилища
-* [cite_start]**Data-Manager:** Прокси-сервис для построения запросов к **OpenSearch**[cite: 19, 21].
-* [cite_start]**Book-Fetcher:** Сервис выдачи файлов по ключу из локального или объектного хранилища[cite: 25, 26, 28].
-
-## 4. Потоки данных
-
-### Поиск книги
-1.  [cite_start]**Адаптер** (TG/IRC/CLI) принимает ввод и через **Translator** создает `UnifiedMessage`[cite: 30].
-2.  **Auth-Manager** подтверждает права пользователя.
-3.  [cite_start]**Processor** запрашивает метаданные у **Data-Manager**[cite: 31].
-4.  **Processor** сохраняет ID результатов в **Session-Manager** (Redis) для поддержки пагинации.
-5.  [cite_start]Формируется ответ и возвращается пользователю через соответствующий адаптер[cite: 32, 33].
-
-### Получение файла
-1.  [cite_start]Пользователь выбирает книгу и формат[cite: 34].
-2.  [cite_start]**Processor** запрашивает файл или ссылку у **Book-Fetcher**[cite: 35, 36].
-3.  [cite_start]**Book-Fetcher** обращается к **Book Storage** и возвращает результат[cite: 37, 38].
-
-## 5. Структура проекта (Go Layout)
-```text
-.
-├── cmd/                # Точки входа (main.go) для каждого адаптера
-├── internal/           # Приватный код приложения
-│   ├── domain/         # Чистые структуры (Book, User, UnifiedMessage)
-│   ├── processor/      # Ядро (бизнес-сценарии)
-│   ├── auth/           # Проверка прав и доступ
-│   ├── session/        # Интеграция с Redis
-│   ├── translator/     # Логика маппинга сообщений
-│   ├── storage/        # Клиенты OpenSearch (Data-Manager) и FS (Fetcher)
-│   └── config/         # Config-Manager и загрузка .env/yaml
-├── pkg/                # Публичные библиотеки
-├── api/                # Протоколы обмена (gRPC/Proto или OpenAPI)
-└── deployments/        # Docker-compose и манифесты
-
---- END_FILE: ./doc/architecture.md ---
-
---- START_FILE: ./doc/ARCHITECTURE.md ---
-# Ebusta: Система поиска и доставки контента
-
-## Архитектура системы (Pipeline)
-
-Система построена на принципах микросервисной архитектуры с использованием gRPC для межсервисного взаимодействия. Весь путь сообщения от пользователя до данных разделен на изолированные этапы.
-
-### Схема потока данных (Data Flow)
-`User Input -> Adapter -> MessageConverter -> Processor -> Data-Manager`
-
----
-
-## Компоненты системы
-
-### 1. Adapters (Входные шлюзы)
-**Пример:** `cmd/web-adapter`
-- **Функция:** Прием сырых данных из внешних интерфейсов (HTTP, TG, IRC).
-- **Ответственность:** Только транспортный уровень. Преобразует внешние запросы в gRPC-вызов `MessageConverter.Convert`.
-
-### 2. MessageConverter (Семантический анализатор)
-**Путь:** `cmd/message-converter`
-- **Функция:** Парсинг и нормализация.
-- **Задача:** Извлекает "Намерение" (Intent) и очищенные данные (Payload).
-- **UnifiedMessage:** Объект, который гарантирует, что `Processor` получит стандартизированные данные независимо от источника.
-
-### 3. Processor (Бизнес-логика / Оркестратор)
-**Путь:** `cmd/processor`
-- **Функция:** Маршрутизация и принятие решений.
-- **Логика:**
-    - Если `Intent == "search"`, запрашивает данные у `Data-Manager`.
-    - Если `Intent == "download"`, инициирует процесс загрузки.
-
-### 4. Data-Manager (Слой данных)
-**Путь:** `cmd/data-manager`
-- **Функция:** Интерфейс к поисковому движку (OpenSearch).
-- **Задача:** Выполнение поисковых запросов и возврат списка объектов `Book`.
-
----
-
-## Технологический стек
-- **Язык:** Go (Golang)
-- **Связь:** gRPC (Protocol Buffers v3)
-- **Логирование:** Logrus
-- **Сборка:** Makefile
-
-## Порты и адреса (Service Map)
-| Сервис            | Порт   | Протокол |
-|-------------------|--------|----------|
-| Data-Manager      | :50051 | gRPC     |
-| MessageConverter  | :50052 | gRPC     |
-| Processor         | :50053 | gRPC     |
-| Web-Adapter       | :8080  | HTTP     |
-
-## Управление проектом
-- `make run` — Запуск всего пайплайна в фоне.
-- `make stop` — Безопасная остановка всех сервисов (через fuser и pkill).
-- `make proto` — Генерация кода из .proto файлов.
-
---- END_FILE: ./doc/ARCHITECTURE.md ---
-
---- START_FILE: ./doc/DSL_REQUIREMENTS.md ---
-# Specification: Ebusta Search DSL (v1.1)
-
-## 1. Goal
-Предоставление человекочитаемого языка запросов для поиска книг, который транслируется в структурированное дерево (AST) для поискового движка Mercury.
-
-## 2. Lexical Atoms (Лексика)
-- **Action**: `get`, `find`, `list`, `read` (зарезервированы)
-- **Field Prefixes**: `title:`, `author:`, `author_id:`, `desc:`
-- **Logic Operators**: `AND`, `OR` (регистронезависимые)
-- **Unary Operators**: `NOT`
-- **Pattern**: `/regex/` (строка, обернутая в косую черту)
-- **Literal**: `"exact phrase"`, `simple_word`, `101`
-
-## 3. Функциональные требования
-
-### UR 1: Базовый поиск
-- **UR 1.1 (Default Search)**: Любой ввод без префикса (например, `Unix`) должен интерпретироваться как поиск по всем полям (`field: any`).
-- **UR 1.2 (Case Insensitivity)**: Поиск по умолчанию нечувствителен к регистру.
-
-### UR 2: Целевой поиск (Scoping)
-- **UR 2.1 (Field Limiting)**: Использование префикса `field:` ограничивает поиск конкретным мета-полем.
-- **UR 2.2 (Regex)**: Если значение обернуто в `/ /`, система должна использовать регулярные выражения (Operator: `OP_REGEX`).
-
-### UR 3: Сложная логика (Boolean)
-- **UR 3.1 (Combination)**: Поддержка операторов `AND` и `OR` для объединения условий.
-- **UR 3.2 (Negation)**: Поддержка оператора `NOT` для исключения результатов из выдачи.
-- **UR 3.3 (Precedence)**: Приоритет операторов: `NOT` > `AND` > `OR`.
-
-### UR 4: Обратная связь (Feedback)
-- **UR 4.1 (Explanation)**: Каждый ответ системы должен содержать поле `meta.canonical_form`, отображающее дерево разбора запроса для верификации пользователем.
-- **UR 4.2 (Request Tracing)**: Каждому запросу присваивается `request_id`, который пробрасывается через всю цепочку (Adapter -> Converter -> Processor -> Mercury).
-
-## 4. Примеры валидных запросов
-- `author:Кинг AND NOT title:Куджо`
-- `title:/^Unix.*/ OR desc:linux`
-- `101` (трактуется как поиск ID или любой поиск по "101")
-
---- END_FILE: ./doc/DSL_REQUIREMENTS.md ---
-
---- START_FILE: ./doc/REQUIREMENTS.md ---
-# Software Requirements Specification (SRS) - Ebusta Pipeline
-
-Данный документ определяет технические требования к каждому компоненту конвейера обработки сообщений системы Ebusta.
-
----
-
-## 1. Web-Adapter (The Gateway)
-**Роль:** Транспортный шлюз для внешних HTTP-запросов.
-
-* **SR-1.1 (Interface):** Должен обеспечивать эндпоинт `GET /input?msg=...` для приема сырых данных.
-* **SR-1.2 (Sanity Check):** Должен возвращать `HTTP 400 Bad Request`, если параметр `msg` пуст или отсутствует.
-* **SR-1.3 (Source Identification):** Обязан при вызове следующего звена передавать метку `source: "web"`.
-* **SR-1.4 (Logic Isolation):** **Запрещено** выполнять парсинг текста, поиск подстрок или любую бизнес-логику.
-* **SR-1.5 (Error Handling):** Должен транслировать gRPC-статусы ошибок в соответствующие HTTP-коды (например, `Unavailable` -> `503 Service Unavailable`).
-
----
-
-## 2. MessageConverter (The Semantic Brain)
-**Роль:** Семантический разбор и нормализация сообщения.
-
-* **SR-2.1 (Normalization):** Должен выполнять очистку входной строки (удаление лишних пробелов в начале/конце).
-* **SR-2.2 (Intent Recognition):** Должен определять тип намерения (`Intent`) на основе командных префиксов:
-    * `get ` или `download ` -> `intent: "download"`
-    * Остальное -> `intent: "search"`
-* **SR-2.3 (Payload Extraction):** Должен возвращать в поле `Payload` только содержательную часть, очищенную от командных префиксов.
-* **SR-2.4 (Stateless):** Должен быть полностью "без состояния" (stateless) — результат парсинга зависит только от входной строки.
-* **SR-2.5 (Robustness):** Должен корректно обрабатывать пустые строки после удаления префиксов, возвращая ошибку или дефолтный интент.
-
----
-
-## 3. Processor (The Orchestrator)
-**Роль:** Центр принятия решений и маршрутизации.
-
-* **SR-3.1 (Routing):** Обязан выполнять маршрутизацию запроса строго на основе поля `Intent` из `UnifiedMessage`.
-* **SR-3.2 (Service Coordination):**
-    * При `search`: Вызывает `Data-Manager.Search()`.
-    * При `download`: (Будущее) Вызывает `Download-Manager`.
-* **SR-3.3 (Data Aggregation):** Должен упаковывать ответы от нижестоящих сервисов в единую структуру `ActionResponse`.
-* **SR-3.4 (Resilience):** Должен использовать механизмы `Context Timeout` (не более 5 секунд на запрос) при обращении к другим сервисам.
-* **SR-3.5 (Enrichment):** Имеет право добавлять метаданные к ответу (например, время обработки или статус выполнения).
-
----
-
-## 4. Data-Manager (The Storage Interface)
-**Роль:** Изолированный слой доступа к данным.
-
-* **SR-4.1 (Contract Compliance):** Должен принимать только структурированные объекты `SearchRequest`.
-* **SR-4.2 (Zero Context):** **Запрещено** иметь информацию об источниках запроса (TG/Web) или командах пользователя.
-* **SR-4.3 (Data Consistency):** Должен возвращать консистентный список объектов `Book`, даже если найден только один результат.
-* **SR-4.4 (Performance):** Должен обеспечивать быстрый поиск по индексу; в случае мока — имитировать задержку сети.
-* **SR-4.5 (Safety):** Должен ограничивать максимальное количество возвращаемых записей (не более 50 за один запрос) для защиты памяти системы.
-
----
-
-## Общие системные требования (Cross-Cutting)
-1. **Communication:** Все межсервисное взаимодействие осуществляется исключительно через gRPC.
-2. **Observability:** Каждый сервис обязан логировать факт получения запроса и результат его обработки через `logrus`.
-3. **Graceful Shutdown:** Все компоненты должны корректно завершать работу по сигналу `SIGTERM`, закрывая активные соединения.
-
-## 5. UnifiedMessage (The Internal Protocol)
-**Роль:** Единый стандарт данных внутри системы.
-
-* **SR-5.1 (Neutrality):** Объект не должен содержать специфичных для мессенджеров полей (например, `chat_id` или `irc_channel`). Вся метаинформация должна быть нормализована.
-* **SR-5.2 (Intent Categorization):** Поле `Intent` должно быть строго типизировано (строка или enum), определяющее дальнейший путь сообщения:
-    * `search` — запрос на поиск информации.
-    * `download` — запрос на получение файла.
-    * `help` — запрос системной справки.
-    * `meta` — запрос статистики или информации о сервисе.
-* **SR-5.3 (Payload Integrity):** Поле `Payload` обязано содержать только очищенные данные, готовые для передачи в поисковой движок без дополнительной обработки.
-* **SR-5.4 (Traceability):** (Будущее) Должен содержать `CorrelationID` для отслеживания пути конкретного запроса через логи всех микросервисов.
-* **SR-5.5 (Context Enrichment):** Должен включать поле `Source` (откуда пришел запрос), чтобы `Processor` мог принимать решение о лимитах (например, для Web-клиентов лимиты жестче, чем для CLI).
-
---- END_FILE: ./doc/REQUIREMENTS.md ---
-
---- START_FILE: ./doc/components.md ---
-Компонент,Роль,Описание,Входящие (In),Исходящие (Out)
-Web-Adapter,API Gateway,"Точка входа. Принимает HTTP-запросы, генерирует Trace-ID и управляет цепочкой вызовов.",HTTP :8080 (/input?msg=...),"gRPC -> Message-Converter, gRPC -> Processor"
-Message-Converter,DSL Parser,Превращает сырой текст в структурированное дерево (AST). Использует internal/parser.,gRPC :50052 (Convert),Нет
-Processor,Orchestrator,"Ядро системы. Реализует логику AST Walker: получает дерево, запрашивает данные и фильтрует их.",gRPC :50053 (HandleCommand),gRPC -> Data-Manager (GetData)
-Data-Manager,Data Provider,Хранилище. Загружает books.json и отдает сырой список книг для дальнейшей фильтрации.,gRPC :50051 (GetData),Файловая система (books.json)
-CLI,UI Client,Интерактивная консоль пользователя с поддержкой истории команд (readline).,User Input,HTTP -> Web-Adapter
-Client,Debug Tool,Утилита для прямой проверки доступности Data-Manager в обход шлюзов.,Manual Run,gRPC -> Data-Manager
-
---- END_FILE: ./doc/components.md ---
diff --git a/grpc b/grpc
--- a/grpc
+++ b/grpc
@@ -1 +1 @@
-Subproject commit 6c11552be627f182a70e09bb0fb43f13d1b6ec84
+Subproject commit 6c11552be627f182a70e09bb0fb43f13d1b6ec84-dirty
diff --git a/lisp-converter/dsl-service.lisp b/lisp-converter/dsl-service.lisp
index dc203f2..9ac669d 100644
--- a/lisp-converter/dsl-service.lisp
+++ b/lisp-converter/dsl-service.lisp
@@ -1,45 +1,64 @@
 (eval-when (:compile-toplevel :load-toplevel :execute)
-  (ql:quickload :cl-ppcre :silent t))
+  (ql:quickload '(:cl-ppcre :grpc :cl-protobufs :bordeaux-threads) :silent t))
 
 (defpackage #:ebusta-service
   (:use #:cl)
-  (:export #:start #:stop #:parse-raw-to-sexp #:parse-sexp-to-ast)
+  (:export #:start #:stop #:parse-raw-to-sexp #:parse-sexp-to-ast #:build-binary)
   (:local-nicknames (#:pb #:cl-protobufs.ebusta.library.v1)
                     (#:pb-rpc #:cl-protobufs.ebusta.library.v1-rpc)
                     (#:grpc #:grpc)
-                    (#:re #:cl-ppcre)))
+                    (#:re #:cl-ppcre)
+                    (#:bt #:bordeaux-threads)))
 
 (in-package #:ebusta-service)
 
-;; --- ПАРСИНГ (SHUNTING-YARD) ---
+;; Глобальная переменная для управления логами
+(defvar *verbose* nil)
+
+;;; --- 1. ЛЕКСИКА И ПРИОРИТЕТЫ (CORE) ---
+
 (defun get-priority (op)
-  (cond ((string-equal op "NOT") 3) ((string-equal op "AND") 2) ((string-equal op "OR") 1) (t 0)))
+  "Определяет приоритет операторов согласно UR 3.3 (NOT > AND > OR)."
+  (cond ((string-equal op "NOT") 3)
+        ((string-equal op "AND") 2)
+        ((string-equal op "OR") 1)
+        (t 0)))
 
 (defun tokenize (str)
+  "Разбивает строку на токены, учитывая кавычки и префиксы (UR 2.1)."
   (re:all-matches-as-strings "(\"[^\"]+\"|[a-zA-Z0-9_]+:|AND|OR|NOT|\\(|\\)|/|\\S+)" str))
 
+;;; --- 2. СБОРКА ДЕРЕВА (RPN -> S-EXP) ---
+
 (defun build-tree-from-rpn (rpn)
+  "Превращает постфиксный список (A B AND) в S-выражение (:AND A B)."
   (let (stack)
-    (dolist (token rpn)
+    (dolist (token rpn (car stack))
       (if (and (listp token) (eq (car token) :field))
           (push token stack)
           (let ((op (string-upcase (string token))))
             (cond 
-              ((string= op "NOT") (push `(:not ,(pop stack)) stack))
-              ((or (string= op "AND") (string= op "OR"))
-               (let* ((right (pop stack)) (left (pop stack)) (key (if (string= op "AND") :and :or)))
-                 (push `(,key ,left ,right) stack)))))))
-    (car stack)))
+              ((string= op "NOT") 
+               (push `(:not ,(pop stack)) stack))
+              ((member op '("AND" "OR") :test #'string=)
+               (let* ((right (pop stack))
+                      (left (pop stack))
+                      (key (if (string= op "AND") :and :or)))
+                 (push `(,key ,left ,right) stack)))))))))
+
+;;; --- 3. ОБРАБОТКА ПОЛЕЙ (SCOPING) ---
 
 (defun make-field-node (field val-raw)
+  "Создает узел поля, проверяя наличие регулярного выражения (UR 2.2)."
   (let* ((val (string-trim " \"" val-raw))
          (is-regex (re:scan "^/.*/$" val)))
     `(:field ,field ,(if is-regex (string-trim "/" val) val) ,@(when is-regex '(:op :regex)))))
 
 (defun process-field (token rest-tokens-var)
-  (let* ((colon-pos (position #\: token))
-         (field (subseq token 0 colon-pos))
-         (val-part (subseq token (1+ colon-pos))))
+  "Извлекает значение поля до ближайшего оператора или скобки."
+  (let* ((pos (position #\: token))
+         (field (subseq token 0 pos))
+         (val-part (subseq token (1+ pos))))
     (if (string/= "" val-part)
         (values (make-field-node field val-part) rest-tokens-var)
         (let (collected)
@@ -50,27 +69,37 @@
           (values (make-field-node field (format nil "~{~A~^ ~}" (nreverse collected)))
                   rest-tokens-var)))))
 
+;;; --- 4. SHUNTING-YARD ENGINE ---
+
 (defun parse-raw-to-sexp (str)
-  (let ((token-list (tokenize str)) (output nil) (stack nil))
+  "Главный цикл трансформации инфиксного запроса в дерево приоритетов."
+  (let ((token-list (tokenize str))
+        (output nil)
+        (stack nil))
     (loop while token-list do
       (let ((token (pop token-list)))
         (cond
           ((> (get-priority token) 0)
-           (loop while (and stack (> (get-priority (car stack)) 0) (>= (get-priority (car stack)) (get-priority token)))
+           (loop while (and stack 
+                            (> (get-priority (car stack)) 0)
+                            (>= (get-priority (car stack)) (get-priority token)))
                  do (push (pop stack) output))
            (push token stack))
           ((string= token "(") (push token stack))
           ((string= token ")")
-           (loop while (and stack (string/= (car stack) "(")) do (push (pop stack) output))
+           (loop while (and stack (string/= (car stack) "(")) 
+                 do (push (pop stack) output))
            (pop stack))
           ((find #\: token)
            (multiple-value-bind (node remaining) (process-field token token-list)
-             (push node output) (setf token-list remaining)))
+             (push node output)
+             (setf token-list remaining)))
           (t (push (make-field-node "any" token) output)))))
     (loop while stack do (push (pop stack) output))
     (build-tree-from-rpn (nreverse output))))
 
-;; --- AST BUILDER (S-EXP -> Protobuf) ---
+;;; --- 5. AST BUILDER ---
+
 (defun parse-sexp-to-ast (sexp &key request-id canonical-form)
   (let ((query (pb:make-search-query)))
     (when (and sexp (listp sexp))
@@ -93,6 +122,8 @@
     (when canonical-form (setf (pb:search-query.canonical-form query) canonical-form))
     query))
 
+;;; --- 6. gRPC INTERFACE ---
+
 (defmethod pb-rpc:convert ((request pb:convert-request) rpc)
   (declare (ignore rpc))
   (let* ((raw (pb:convert-request.raw-query request))
@@ -102,14 +133,34 @@
                (ast (parse-sexp-to-ast sexp 
                                       :request-id request-id 
                                       :canonical-form (format nil "~S" sexp))))
-          (format t "[~A] Processed raw_query: ~A~%" request-id raw)
+          ;; ВЫВОД ТОЛЬКО ПРИ ФЛАГЕ VERBOSE
+          (when *verbose*
+            (format t "[~A] Raw: ~A~%" request-id raw)
+            (format t "[~A] S-Exp: ~S~%" request-id sexp)
+            (finish-output))
           ast)
       (error (e)
         (format t "[ERR ~A] ~A~%" request-id e)
+        (finish-output)
         (pb:make-search-query :request-id request-id)))))
 
-(defun start (&key (port 50052))
+(defun start (&key (port 50052) (workers 8) (verbose nil))
+  (setf *verbose* verbose)
   (grpc:init-grpc)
-  (format t "=== EBusta DSL Engine V15 (Full Trace) Online [Port ~A] ===~%" port)
+  (format t "=== EBusta DSL Engine V19 [Port ~A, Workers ~A, Verbose ~A] ===~%" 
+          port workers *verbose*)
+  (finish-output)
   (grpc:run-grpc-proto-server (format nil "0.0.0.0:~A" port) 'pb:message-converter)
   (loop (sleep 1)))
+
+(defun build-binary ()
+  "Сборка с разбором аргументов командной строки."
+  #+sbcl
+  (sb-ext:save-lisp-and-die "dsl-converter"
+                            :executable t
+                            :toplevel (lambda ()
+                                        (let ((args sb-ext:*posix-argv*))
+                                          (start :port 50052 
+                                                 :workers 8
+                                                 :verbose (or (member "-v" args :test #'string=)
+                                                              (member "--verbose" args :test #'string=)))))))
--- END SECTION: GIT DIFF ---

--- START_FILE: ./quicklisp.lisp ---
;;;;
;;;; This is quicklisp.lisp, the quickstart file for Quicklisp. To use
;;;; it, start Lisp, then (load "quicklisp.lisp")
;;;;
;;;; Quicklisp is beta software and comes with no warranty of any kind.
;;;;
;;;; For more information about the Quicklisp beta, see:
;;;;
;;;;    http://www.quicklisp.org/beta/
;;;;
;;;; If you have any questions or comments about Quicklisp, please
;;;; contact:
;;;;
;;;;    Zach Beane <zach@quicklisp.org>
;;;;

(cl:in-package #:cl-user)
(cl:defpackage #:qlqs-user
  (:use #:cl))
(cl:in-package #:qlqs-user)

(defpackage #:qlqs-info
  (:export #:*version*))

(defvar qlqs-info:*version* "2015-01-28")

(defpackage #:qlqs-impl
  (:use #:cl)
  (:export #:*implementation*)
  (:export #:definterface
           #:defimplementation)
  (:export #:lisp
           #:abcl
           #:allegro
           #:ccl
           #:clasp
           #:clisp
           #:cmucl
           #:cormanlisp
           #:ecl
           #:gcl
           #:lispworks
	   #:mkcl
           #:scl
           #:sbcl))

(defpackage #:qlqs-impl-util
  (:use #:cl #:qlqs-impl)
  (:export #:call-with-quiet-compilation))

(defpackage #:qlqs-network
  (:use #:cl #:qlqs-impl)
  (:export #:open-connection
           #:write-octets
           #:read-octets
           #:close-connection
           #:with-connection))

(defpackage #:qlqs-progress
  (:use #:cl)
  (:export #:make-progress-bar
           #:start-display
           #:update-progress
           #:finish-display))

(defpackage #:qlqs-http
  (:use #:cl #:qlqs-network #:qlqs-progress)
  (:export #:fetch
           #:*proxy-url*
           #:*maximum-redirects*
           #:*default-url-defaults*))

(defpackage #:qlqs-minitar
  (:use #:cl)
  (:export #:unpack-tarball))

(defpackage #:quicklisp-quickstart
  (:use #:cl #:qlqs-impl #:qlqs-impl-util #:qlqs-http #:qlqs-minitar)
  (:export #:install
           #:help
           #:*proxy-url*
           #:*asdf-url*
           #:*quicklisp-tar-url*
           #:*setup-url*
           #:*help-message*
           #:*after-load-message*
           #:*after-initial-setup-message*))


;;;
;;; Defining implementation-specific packages and functionality
;;;

(in-package #:qlqs-impl)

(eval-when (:compile-toplevel :load-toplevel :execute)
  (defun error-unimplemented (&rest args)
    (declare (ignore args))
    (error "Not implemented")))

(defmacro neuter-package (name)
  `(eval-when (:compile-toplevel :load-toplevel :execute)
     (let ((definition (fdefinition 'error-unimplemented)))
       (do-external-symbols (symbol ,(string name))
         (unless (fboundp symbol)
           (setf (fdefinition symbol) definition))))))

(eval-when (:compile-toplevel :load-toplevel :execute)
  (defun feature-expression-passes-p (expression)
    (cond ((keywordp expression)
           (member expression *features*))
          ((consp expression)
           (case (first expression)
             (or
              (some 'feature-expression-passes-p (rest expression)))
             (and
              (every 'feature-expression-passes-p (rest expression)))))
          (t (error "Unrecognized feature expression -- ~S" expression)))))


(defmacro define-implementation-package (feature package-name &rest options)
  (let* ((output-options '((:use)
                           (:export #:lisp)))
         (prep (cdr (assoc :prep options)))
         (class-option (cdr (assoc :class options)))
         (class (first class-option))
         (superclasses (rest class-option))
         (import-options '())
         (effectivep (feature-expression-passes-p feature)))
    (dolist (option options)
      (ecase (first option)
        ((:prep :class))
        ((:import-from
          :import)
         (push option import-options))
        ((:export
          :shadow
          :intern
          :documentation)
         (push option output-options))
        ((:reexport-from)
         (push (cons :export (cddr option)) output-options)
         (push (cons :import-from (cdr option)) import-options))))
    `(eval-when (:compile-toplevel :load-toplevel :execute)
       ,@(when effectivep
               prep)
       (defclass ,class ,superclasses ())
       (defpackage ,package-name ,@output-options
                   ,@(when effectivep
                           import-options))
       ,@(when effectivep
               `((setf *implementation* (make-instance ',class))))
       ,@(unless effectivep
                 `((neuter-package ,package-name))))))

(defmacro definterface (name lambda-list &body options)
  (let* ((forbidden (intersection lambda-list lambda-list-keywords))
         (gf-options (remove :implementation options :key #'first))
         (implementations (set-difference options gf-options)))
    (when forbidden
      (error "~S not allowed in definterface lambda list" forbidden))
    (flet ((method-option (class body)
             `(:method ((*implementation* ,class) ,@lambda-list)
                ,@body)))
      (let ((generic-name (intern (format nil "%~A" name))))
        `(eval-when (:compile-toplevel :load-toplevel :execute)
           (defgeneric ,generic-name (lisp ,@lambda-list)
             ,@gf-options
             ,@(mapcar (lambda (implementation)
                         (destructuring-bind (class &rest body)
                             (rest implementation)
                           (method-option class body)))
                       implementations))
           (defun ,name ,lambda-list
             (,generic-name *implementation* ,@lambda-list)))))))

(defmacro defimplementation (name-and-options
                             lambda-list &body body)
  (destructuring-bind (name &key (for t) qualifier)
      (if (consp name-and-options)
          name-and-options
          (list name-and-options))
    (unless for
      (error "You must specify an implementation name."))
    (let ((generic-name (find-symbol (format nil "%~A" name))))
      (unless (and generic-name
                   (fboundp generic-name))
        (error "~S does not name an implementation function" name))
      `(defmethod ,generic-name
           ,@(when qualifier (list qualifier))
         ,(list* `(*implementation* ,for) lambda-list) ,@body))))


;;; Bootstrap implementations

(defvar *implementation* nil)
(defclass lisp () ())


;;; Allegro Common Lisp

(define-implementation-package :allegro #:qlqs-allegro
  (:documentation
   "Allegro Common Lisp - http://www.franz.com/products/allegrocl/")
  (:class allegro)
  (:reexport-from #:socket
                  #:make-socket)
  (:reexport-from #:excl
                  #:read-vector))


;;; Armed Bear Common Lisp

(define-implementation-package :abcl #:qlqs-abcl
  (:documentation
   "Armed Bear Common Lisp - http://common-lisp.net/project/armedbear/")
  (:class abcl)
  (:reexport-from #:system
                  #:make-socket
                  #:get-socket-stream))

;;; Clozure CL

(define-implementation-package :ccl #:qlqs-ccl
  (:documentation
   "Clozure Common Lisp - http://www.clozure.com/clozurecl.html")
  (:class ccl)
  (:reexport-from #:ccl
                  #:make-socket))


;;; CLASP

(define-implementation-package :clasp #:qlqs-clasp
  (:documentation "CLASP - http://github.com/drmeister/clasp")
  (:class clasp)
  (:prep
   (require 'sockets))
  (:intern #:host-network-address)
  (:reexport-from #:sb-bsd-sockets
                  #:get-host-by-name
                  #:host-ent-address
                  #:socket-connect
                  #:socket-make-stream
                  #:inet-socket))


;;; GNU CLISP

(define-implementation-package :clisp #:qlqs-clisp
  (:documentation "GNU CLISP - http://clisp.cons.org/")
  (:class clisp)
  (:reexport-from #:socket
                  #:socket-connect)
  (:reexport-from #:ext
                  #:read-byte-sequence))


;;; CMUCL

(define-implementation-package :cmu #:qlqs-cmucl
  (:documentation "CMU Common Lisp - http://www.cons.org/cmucl/")
  (:class cmucl)
  (:reexport-from #:ext
                  #:*gc-verbose*)
  (:reexport-from #:system
                  #:make-fd-stream)
  (:reexport-from #:extensions
                  #:connect-to-inet-socket))

(defvar qlqs-cmucl:*gc-verbose* nil)


;;; Scieneer CL

(define-implementation-package :scl #:qlqs-scl
  (:documentation "Scieneer Common Lisp - http://www.scieneer.com/scl/")
  (:class scl)
  (:reexport-from #:system
                  #:make-fd-stream)
  (:reexport-from #:extensions
                  #:connect-to-inet-socket))

;;; ECL

(define-implementation-package :ecl #:qlqs-ecl
  (:documentation "ECL - http://ecls.sourceforge.net/")
  (:class ecl)
  (:prep
   (require 'sockets))
  (:intern #:host-network-address)
  (:reexport-from #:sb-bsd-sockets
                  #:get-host-by-name
                  #:host-ent-address
                  #:socket-connect
                  #:socket-make-stream
                  #:inet-socket))


;;; LispWorks

(define-implementation-package :lispworks #:qlqs-lispworks
  (:documentation "LispWorks - http://www.lispworks.com/")
  (:class lispworks)
  (:prep
   (require "comm"))
  (:reexport-from #:comm
                  #:open-tcp-stream
                  #:get-host-entry))


;;; SBCL

(define-implementation-package :sbcl #:qlqs-sbcl
  (:class sbcl)
  (:documentation
   "Steel Bank Common Lisp - http://www.sbcl.org/")
  (:prep
   (require 'sb-bsd-sockets))
  (:intern #:host-network-address)
  (:reexport-from #:sb-ext
                  #:compiler-note)
  (:reexport-from #:sb-bsd-sockets
                  #:get-host-by-name
                  #:inet-socket
                  #:host-ent-address
                  #:socket-connect
                  #:socket-make-stream))

;;; MKCL

(define-implementation-package :mkcl #:qlqs-mkcl
  (:class mkcl)
  (:documentation
   "ManKai Common Lisp - http://common-lisp.net/project/mkcl/")
  (:prep
   (require 'sockets))
  (:intern #:host-network-address)
  (:reexport-from #:sb-bsd-sockets
                  #:get-host-by-name
                  #:inet-socket
                  #:host-ent-address
                  #:socket-connect
                  #:socket-make-stream))

;;;
;;; Utility function
;;;

(in-package #:qlqs-impl-util)

(definterface call-with-quiet-compilation (fun)
  (:implementation t
    (let ((*load-verbose* nil)
          (*compile-verbose* nil)
          (*load-print* nil)
          (*compile-print* nil))
      (handler-bind ((warning #'muffle-warning))
        (funcall fun)))))

(defimplementation (call-with-quiet-compilation :for sbcl :qualifier :around)
    (fun)
  (declare (ignorable fun))
  (handler-bind ((qlqs-sbcl:compiler-note #'muffle-warning))
    (call-next-method)))

(defimplementation (call-with-quiet-compilation :for cmucl :qualifier :around)
    (fun)
  (declare (ignorable fun))
  (let ((qlqs-cmucl:*gc-verbose* nil))
    (call-next-method)))


;;;
;;; Low-level networking implementations
;;;

(in-package #:qlqs-network)

(definterface host-address (host)
  (:implementation t
    host)
  (:implementation mkcl
    (qlqs-mkcl:host-ent-address (qlqs-mkcl:get-host-by-name host)))
  (:implementation sbcl
    (qlqs-sbcl:host-ent-address (qlqs-sbcl:get-host-by-name host))))

(definterface open-connection (host port)
  (:implementation t
    (declare (ignorable host port))
    (error "Sorry, quicklisp in implementation ~S is not supported yet."
           (lisp-implementation-type)))
  (:implementation allegro
    (qlqs-allegro:make-socket :remote-host host
                             :remote-port port))
  (:implementation abcl
    (let ((socket (qlqs-abcl:make-socket host port)))
      (qlqs-abcl:get-socket-stream socket :element-type '(unsigned-byte 8))))
  (:implementation ccl
    (qlqs-ccl:make-socket :remote-host host
                         :remote-port port))
  (:implementation clasp
    (let* ((endpoint (qlqs-clasp:host-ent-address
                      (qlqs-clasp:get-host-by-name host)))
           (socket (make-instance 'qlqs-clasp:inet-socket
                                  :protocol :tcp
                                  :type :stream)))
      (qlqs-clasp:socket-connect socket endpoint port)
      (qlqs-clasp:socket-make-stream socket
                                  :element-type '(unsigned-byte 8)
                                  :input t
                                  :output t
                                  :buffering :full)))
  (:implementation clisp
    (qlqs-clisp:socket-connect port host :element-type '(unsigned-byte 8)))
  (:implementation cmucl
    (let ((fd (qlqs-cmucl:connect-to-inet-socket host port)))
      (qlqs-cmucl:make-fd-stream fd
                                :element-type '(unsigned-byte 8)
                                :binary-stream-p t
                                :input t
                                :output t)))
  (:implementation scl
    (let ((fd (qlqs-scl:connect-to-inet-socket host port)))
      (qlqs-scl:make-fd-stream fd
			       :element-type '(unsigned-byte 8)
			       :input t
			       :output t)))
  (:implementation ecl
    (let* ((endpoint (qlqs-ecl:host-ent-address
                      (qlqs-ecl:get-host-by-name host)))
           (socket (make-instance 'qlqs-ecl:inet-socket
                                  :protocol :tcp
                                  :type :stream)))
      (qlqs-ecl:socket-connect socket endpoint port)
      (qlqs-ecl:socket-make-stream socket
                                  :element-type '(unsigned-byte 8)
                                  :input t
                                  :output t
                                  :buffering :full)))
  (:implementation lispworks
    (qlqs-lispworks:open-tcp-stream host port
                                   :direction :io
                                   :errorp t
                                   :read-timeout nil
                                   :element-type '(unsigned-byte 8)
                                   :timeout 5))
  (:implementation mkcl
    (let* ((endpoint (qlqs-mkcl:host-ent-address
                      (qlqs-mkcl:get-host-by-name host)))
           (socket (make-instance 'qlqs-mkcl:inet-socket
                                  :protocol :tcp
                                  :type :stream)))
      (qlqs-mkcl:socket-connect socket endpoint port)
      (qlqs-mkcl:socket-make-stream socket
                                   :element-type '(unsigned-byte 8)
                                   :input t
                                   :output t
                                   :buffering :full)))
  (:implementation sbcl
    (let* ((endpoint (qlqs-sbcl:host-ent-address
                      (qlqs-sbcl:get-host-by-name host)))
           (socket (make-instance 'qlqs-sbcl:inet-socket
                                  :protocol :tcp
                                  :type :stream)))
      (qlqs-sbcl:socket-connect socket endpoint port)
      (qlqs-sbcl:socket-make-stream socket
                                   :element-type '(unsigned-byte 8)
                                   :input t
                                   :output t
                                   :buffering :full))))

(definterface read-octets (buffer connection)
  (:implementation t
    (read-sequence buffer connection))
  (:implementation allegro
    (qlqs-allegro:read-vector buffer connection))
  (:implementation clisp
    (qlqs-clisp:read-byte-sequence buffer connection
                                  :no-hang nil
                                  :interactive t)))

(definterface write-octets (buffer connection)
  (:implementation t
    (write-sequence buffer connection)
    (finish-output connection)))

(definterface close-connection (connection)
  (:implementation t
    (ignore-errors (close connection))))

(definterface call-with-connection (host port fun)
  (:implementation t
    (let (connection)
      (unwind-protect
           (progn
             (setf connection (open-connection host port))
             (funcall fun connection))
        (when connection
          (close connection))))))

(defmacro with-connection ((connection host port) &body body)
  `(call-with-connection ,host ,port (lambda (,connection) ,@body)))


;;;
;;; A text progress bar
;;;

(in-package #:qlqs-progress)

(defclass progress-bar ()
  ((start-time
    :initarg :start-time
    :accessor start-time)
   (end-time
    :initarg :end-time
    :accessor end-time)
   (progress-character
    :initarg :progress-character
    :accessor progress-character)
   (character-count
    :initarg :character-count
    :accessor character-count
    :documentation "How many characters wide is the progress bar?")
   (characters-so-far
    :initarg :characters-so-far
    :accessor characters-so-far)
   (update-interval
    :initarg :update-interval
    :accessor update-interval
    :documentation "Update the progress bar display after this many
    internal-time units.")
   (last-update-time
    :initarg :last-update-time
    :accessor last-update-time
    :documentation "The display was last updated at this time.")
   (total
    :initarg :total
    :accessor total
    :documentation "The total number of units tracked by this progress bar.")
   (progress
    :initarg :progress
    :accessor progress
    :documentation "How far in the progress are we?")
   (pending
    :initarg :pending
    :accessor pending
    :documentation "How many raw units should be tracked in the next
    display update?"))
  (:default-initargs
   :progress-character #\=
   :character-count 50
   :characters-so-far 0
   :update-interval (floor internal-time-units-per-second 4)
   :last-update-time 0
   :total 0
   :progress 0
   :pending 0))

(defgeneric start-display (progress-bar))
(defgeneric update-progress (progress-bar unit-count))
(defgeneric update-display (progress-bar))
(defgeneric finish-display (progress-bar))
(defgeneric elapsed-time (progress-bar))
(defgeneric units-per-second (progress-bar))

(defmethod start-display (progress-bar)
  (setf (last-update-time progress-bar) (get-internal-real-time))
  (setf (start-time progress-bar) (get-internal-real-time))
  (fresh-line)
  (finish-output))

(defmethod update-display (progress-bar)
  (incf (progress progress-bar) (pending progress-bar))
  (setf (pending progress-bar) 0)
  (setf (last-update-time progress-bar) (get-internal-real-time))
  (let* ((showable (floor (character-count progress-bar)
                          (/ (total progress-bar) (progress progress-bar))))
         (needed (- showable (characters-so-far progress-bar))))
    (setf (characters-so-far progress-bar) showable)
    (dotimes (i needed)
      (write-char (progress-character progress-bar)))
    (finish-output)))

(defmethod update-progress (progress-bar unit-count)
  (incf (pending progress-bar) unit-count)
  (let ((now (get-internal-real-time)))
    (when (< (update-interval progress-bar)
             (- now (last-update-time progress-bar)))
      (update-display progress-bar))))

(defmethod finish-display (progress-bar)
  (update-display progress-bar)
  (setf (end-time progress-bar) (get-internal-real-time))
  (terpri)
  (format t "~:D bytes in ~$ seconds (~$KB/sec)"
          (total progress-bar)
          (elapsed-time progress-bar)
          (/  (units-per-second progress-bar) 1024))
  (finish-output))

(defmethod elapsed-time (progress-bar)
  (/ (- (end-time progress-bar) (start-time progress-bar))
     internal-time-units-per-second))

(defmethod units-per-second (progress-bar)
  (if (plusp (elapsed-time progress-bar))
      (/ (total progress-bar) (elapsed-time progress-bar))
      0))

(defun kb/sec (progress-bar)
  (/ (units-per-second progress-bar) 1024))



(defparameter *uncertain-progress-chars* "?")

(defclass uncertain-size-progress-bar (progress-bar)
  ((progress-char-index
    :initarg :progress-char-index
    :accessor progress-char-index)
   (units-per-char
    :initarg :units-per-char
    :accessor units-per-char))
  (:default-initargs
   :total 0
   :progress-char-index 0
   :units-per-char (floor (expt 1024 2) 50)))

(defmethod update-progress :after ((progress-bar uncertain-size-progress-bar)
                            unit-count)
  (incf (total progress-bar) unit-count))

(defmethod progress-character ((progress-bar uncertain-size-progress-bar))
  (let ((index (progress-char-index progress-bar)))
    (prog1
        (char *uncertain-progress-chars* index)
      (setf (progress-char-index progress-bar)
            (mod (1+ index) (length *uncertain-progress-chars*))))))

(defmethod update-display ((progress-bar uncertain-size-progress-bar))
  (setf (last-update-time progress-bar) (get-internal-real-time))
  (multiple-value-bind (chars pend)
      (floor (pending progress-bar) (units-per-char progress-bar))
    (setf (pending progress-bar) pend)
    (dotimes (i chars)
      (write-char (progress-character progress-bar))
      (incf (characters-so-far progress-bar))
      (when (<= (character-count progress-bar)
                (characters-so-far progress-bar))
        (terpri)
        (setf (characters-so-far progress-bar) 0)
        (finish-output)))
    (finish-output)))

(defun make-progress-bar (total)
  (if (or (not total) (zerop total))
      (make-instance 'uncertain-size-progress-bar)
      (make-instance 'progress-bar :total total)))

;;;
;;; A simple HTTP client
;;;

(in-package #:qlqs-http)

;;; Octet data

(deftype octet ()
  '(unsigned-byte 8))

(defun make-octet-vector (size)
  (make-array size :element-type 'octet
              :initial-element 0))

(defun octet-vector (&rest octets)
  (make-array (length octets) :element-type 'octet
              :initial-contents octets))

;;; ASCII characters as integers

(defun acode (char)
  (cond ((eql char :cr)
         13)
        ((eql char :lf)
         10)
        (t
         (let ((code (char-code char)))
           (if (<= 0 code 127)
               code
               (error "Character ~S is not in the ASCII character set"
                      char))))))

(defvar *whitespace*
  (list (acode #\Space) (acode #\Tab) (acode :cr) (acode :lf)))

(defun whitep (code)
  (member code *whitespace*))

(defun ascii-vector (string)
  (let ((vector (make-octet-vector (length string))))
    (loop for char across string
          for code = (char-code char)
          for i from 0
          if (< 127 code) do
          (error "Invalid character for ASCII -- ~A" char)
          else
          do (setf (aref vector i) code))
    vector))

(defun ascii-subseq (vector start end)
  "Return a subseq of octet-specialized VECTOR as a string."
  (let ((string (make-string (- end start))))
    (loop for i from 0
          for j from start below end
          do (setf (char string i) (code-char (aref vector j))))
    string))

(defun ascii-downcase (code)
  (if (<= 65 code 90)
      (+ code 32)
      code))

(defun ascii-equal (a b)
  (eql (ascii-downcase a) (ascii-downcase b)))

(defmacro acase (value &body cases)
  (flet ((convert-case-keys (keys)
           (mapcar (lambda (key)
                     (etypecase key
                       (integer key)
                       (character (char-code key))
                       (symbol
                        (ecase key
                          (:cr 13)
                          (:lf 10)
                          ((t) t)))))
                   (if (consp keys) keys (list keys)))))
    `(case ,value
       ,@(mapcar (lambda (case)
                   (destructuring-bind (keys &rest body)
                       case
                     `(,(if (eql keys t)
                            t
                            (convert-case-keys keys))
                        ,@body)))
                 cases))))

;;; Pattern matching (for finding headers)

(defclass matcher ()
  ((pattern
    :initarg :pattern
    :reader pattern)
   (pos
    :initform 0
    :accessor match-pos)
   (matchedp
    :initform nil
    :accessor matchedp)))

(defun reset-match (matcher)
  (setf (match-pos matcher) 0
        (matchedp matcher) nil))

(define-condition match-failure (error) ())

(defun match (matcher input &key (start 0) end error)
  (let ((i start)
        (end (or end (length input)))
        (match-end (length (pattern matcher))))
    (with-slots (pattern pos)
        matcher
      (loop
       (cond ((= pos match-end)
              (let ((match-start (- i pos)))
                (setf pos 0)
                (setf (matchedp matcher) t)
                (return (values match-start (+ match-start match-end)))))
             ((= i end)
              (return nil))
             ((= (aref pattern pos)
                 (aref input i))
              (incf i)
              (incf pos))
             (t
              (if error
                  (error 'match-failure)
                  (if (zerop pos)
                      (incf i)
                      (setf pos 0)))))))))

(defun ascii-matcher (string)
  (make-instance 'matcher
                 :pattern (ascii-vector string)))

(defun octet-matcher (&rest octets)
  (make-instance 'matcher
                 :pattern (apply 'octet-vector octets)))

(defun acode-matcher (&rest codes)
  (make-instance 'matcher
                 :pattern (make-array (length codes)
                                      :element-type 'octet
                                      :initial-contents
                                      (mapcar 'acode codes))))


;;; "Connection Buffers" are a kind of callback-driven,
;;; pattern-matching chunky stream. Callbacks can be called for a
;;; certain number of octets or until one or more patterns are seen in
;;; the input. cbufs automatically refill themselves from a
;;; connection as needed.

(defvar *cbuf-buffer-size* 8192)

(define-condition end-of-data (error) ())

(defclass cbuf ()
  ((data
    :initarg :data
    :accessor data)
   (connection
    :initarg :connection
    :accessor connection)
   (start
    :initarg :start
    :accessor start)
   (end
    :initarg :end
    :accessor end)
   (eofp
    :initarg :eofp
    :accessor eofp))
  (:default-initargs
   :data (make-octet-vector *cbuf-buffer-size*)
   :connection nil
   :start 0
   :end 0
   :eofp nil)
  (:documentation "A CBUF is a connection buffer that keeps track of
  incoming data from a connection. Several functions make it easy to
  treat a CBUF as a kind of chunky, callback-driven stream."))

(define-condition cbuf-progress ()
  ((size
    :initarg :size
    :accessor cbuf-progress-size
    :initform 0)))

(defun call-processor (fun cbuf start end)
  (signal 'cbuf-progress :size (- end start))
  (funcall fun (data cbuf) start end))

(defun make-cbuf (connection)
  (make-instance 'cbuf :connection connection))

(defun make-stream-writer (stream)
  "Create a callback for writing data to STREAM."
  (lambda (data start end)
    (write-sequence data stream :start start :end end)))

(defgeneric size (cbuf)
  (:method ((cbuf cbuf))
    (- (end cbuf) (start cbuf))))

(defgeneric emptyp (cbuf)
  (:method ((cbuf cbuf))
    (zerop (size cbuf))))

(defgeneric refill (cbuf)
  (:method ((cbuf cbuf))
    (when (eofp cbuf)
      (error 'end-of-data))
    (setf (start cbuf) 0)
    (setf (end cbuf)
          (read-octets (data cbuf)
                       (connection cbuf)))
    (cond ((emptyp cbuf)
           (setf (eofp cbuf) t)
           (error 'end-of-data))
          (t (size cbuf)))))

(defun process-all (fun cbuf)
  (unless (emptyp cbuf)
    (call-processor fun cbuf (start cbuf) (end cbuf))))

(defun multi-cmatch (matchers cbuf)
  (let (start end)
    (dolist (matcher matchers (values start end))
      (multiple-value-bind (s e)
          (match matcher (data cbuf)
                 :start (start cbuf)
                 :end (end cbuf))
        (when (and s (or (null start) (< s start)))
          (setf start s
                end e))))))

(defun cmatch (matcher cbuf)
  (if (consp matcher)
      (multi-cmatch matcher cbuf)
      (match matcher (data cbuf) :start (start cbuf) :end (end cbuf))))

(defun call-until-end (fun cbuf)
  (handler-case
      (loop
       (process-all fun cbuf)
       (refill cbuf))
    (end-of-data ()
      (return-from call-until-end))))

(defun show-cbuf (context cbuf)
  (format t "cbuf: ~A ~D - ~D~%" context (start cbuf) (end cbuf)))

(defun call-for-n-octets (n fun cbuf)
  (let ((remaining n))
    (loop
     (when (<= remaining (size cbuf))
       (let ((end (+ (start cbuf) remaining)))
         (call-processor fun cbuf (start cbuf) end)
         (setf (start cbuf) end)
         (return)))
     (process-all fun cbuf)
     (decf remaining (size cbuf))
     (refill cbuf))))

(defun call-until-matching (matcher fun cbuf)
  (loop
   (multiple-value-bind (start end)
       (cmatch matcher cbuf)
     (when start
       (call-processor fun cbuf (start cbuf) end)
       (setf (start cbuf) end)
       (return)))
   (process-all fun cbuf)
   (refill cbuf)))

(defun ignore-data (data start end)
  (declare (ignore data start end)))

(defun skip-until-matching (matcher cbuf)
  (call-until-matching matcher 'ignore-data cbuf))


;;; Creating HTTP requests as octet buffers

(defclass octet-sink ()
  ((storage
    :initarg :storage
    :accessor storage))
  (:default-initargs
   :storage (make-array 1024 :element-type 'octet
                        :fill-pointer 0
                        :adjustable t))
  (:documentation "A simple stream-like target for collecting
  octets."))

(defun add-octet (octet sink)
  (vector-push-extend octet (storage sink)))

(defun add-octets (octets sink &key (start 0) end)
  (setf end (or end (length octets)))
  (loop for i from start below end
        do (add-octet (aref octets i) sink)))

(defun add-string (string sink)
  (loop for char across string
        for code = (char-code char)
        do (add-octet code sink)))

(defun add-strings (sink &rest strings)
  (mapc (lambda (string) (add-string string sink)) strings))

(defun add-newline (sink)
  (add-octet 13 sink)
  (add-octet 10 sink))

(defun sink-buffer (sink)
  (subseq (storage sink) 0))

(defvar *proxy-url* nil)

(defun full-proxy-path (host port path)
  (format nil "~:[http~;https~]://~A~:[:~D~;~*~]~A"
                       (= port 443)
                       host
                       (or (= port 80)
                           (= port 443))
                       port
                       path))

(defun make-request-buffer (host port path &key (method "GET"))
  (setf method (string method))
  (when *proxy-url*
    (setf path (full-proxy-path host port path)))
  (let ((sink (make-instance 'octet-sink)))
    (flet ((add-line (&rest strings)
             (apply #'add-strings sink strings)
             (add-newline sink)))
      (add-line method " " path " HTTP/1.1")
      (add-line "Host: " host (if (= port 80) ""
                                  (format nil ":~D" port)))
      (add-line "Connection: close")
      ;; FIXME: get this version string from somewhere else.
      (add-line "User-Agent: quicklisp-bootstrap/"
                qlqs-info:*version*)
      (add-newline sink)
      (sink-buffer sink))))

(defun sink-until-matching (matcher cbuf)
  (let ((sink (make-instance 'octet-sink)))
    (call-until-matching
     matcher
     (lambda (buffer start end)
       (add-octets buffer sink :start start :end end))
     cbuf)
    (sink-buffer sink)))


;;; HTTP headers

(defclass header ()
  ((data
    :initarg :data
    :accessor data)
   (status
    :initarg :status
    :accessor status)
   (name-starts
    :initarg :name-starts
    :accessor name-starts)
   (name-ends
    :initarg :name-ends
    :accessor name-ends)
   (value-starts
    :initarg :value-starts
    :accessor value-starts)
   (value-ends
    :initarg :value-ends
    :accessor value-ends)))

(defmethod print-object ((header header) stream)
  (print-unreadable-object (header stream :type t)
    (prin1 (status header) stream)))

(defun matches-at (pattern target pos)
  (= (mismatch pattern target :start2 pos) (length pattern)))

(defun header-value-indexes (field-name header)
  (loop with data = (data header)
        with pattern = (ascii-vector (string-downcase field-name))
        for start across (name-starts header)
        for i from 0
        when (matches-at pattern data start)
        return (values (aref (value-starts header) i)
                       (aref (value-ends header) i))))

(defun ascii-header-value (field-name header)
  (multiple-value-bind (start end)
      (header-value-indexes field-name header)
    (when start
      (ascii-subseq (data header) start end))))

(defun all-field-names (header)
  (map 'list
       (lambda (start end)
         (ascii-subseq (data header) start end))
       (name-starts header)
       (name-ends header)))

(defun headers-alist (header)
  (mapcar (lambda (name)
            (cons name (ascii-header-value name header)))
          (all-field-names header)))

(defmethod describe-object :after ((header header) stream)
  (format stream "~&Decoded headers:~%  ~S~%" (headers-alist header)))

(defun content-length (header)
  (let ((field-value (ascii-header-value "content-length" header)))
    (when field-value
      (let ((value (ignore-errors (parse-integer field-value))))
        (or value
            (error "Content-Length header field value is not a number -- ~A"
                   field-value))))))

(defun chunkedp (header)
  (string= (ascii-header-value "transfer-encoding" header) "chunked"))

(defun location (header)
  (ascii-header-value "location" header))

(defun status-code (vector)
  (let* ((space (position (acode #\Space) vector))
         (c1 (- (aref vector (incf space)) 48))
         (c2 (- (aref vector (incf space)) 48))
         (c3 (- (aref vector (incf space)) 48)))
    (+ (* c1 100)
       (* c2  10)
       (* c3   1))))

(defun force-downcase-field-names (header)
  (loop with data = (data header)
        for start across (name-starts header)
        for end across (name-ends header)
        do (loop for i from start below end
                 for code = (aref data i)
                 do (setf (aref data i) (ascii-downcase code)))))

(defun skip-white-forward (pos vector)
  (position-if-not 'whitep vector :start pos))

(defun skip-white-backward (pos vector)
  (let ((nonwhite (position-if-not 'whitep vector :end pos :from-end t)))
    (if nonwhite
        (1+ nonwhite)
        pos)))

(defun contract-field-value-indexes (header)
  "Header field values exclude leading and trailing whitespace; adjust
the indexes in the header accordingly."
  (loop with starts = (value-starts header)
        with ends = (value-ends header)
        with data = (data header)
        for i from 0
        for start across starts
        for end across ends
        do
        (setf (aref starts i) (skip-white-forward start data))
        (setf (aref ends i) (skip-white-backward end data))))

(defun next-line-pos (vector)
  (let ((pos 0))
    (labels ((finish (&optional (i pos))
               (return-from next-line-pos i))
             (after-cr (code)
               (acase code
                 (:lf (finish pos))
                 (t (finish (1- pos)))))
             (pending (code)
               (acase code
                 (:cr #'after-cr)
                 (:lf (finish pos))
                 (t #'pending))))
      (let ((state #'pending))
        (loop
         (setf state (funcall state (aref vector pos)))
         (incf pos))))))

(defun make-hvector ()
  (make-array 16 :fill-pointer 0 :adjustable t))

(defun process-header (vector)
  "Create a HEADER instance from the octet data in VECTOR."
  (let* ((name-starts (make-hvector))
         (name-ends (make-hvector))
         (value-starts (make-hvector))
         (value-ends (make-hvector))
         (header (make-instance 'header
                                :data vector
                                :status 999
                                :name-starts name-starts
                                :name-ends name-ends
                                :value-starts value-starts
                                :value-ends value-ends))
         (mark nil)
         (pos (next-line-pos vector)))
    (unless pos
      (error "Unable to process HTTP header"))
    (setf (status header) (status-code vector))
    (labels ((save (value vector)
               (vector-push-extend value vector))
             (mark ()
               (setf mark pos))
             (clear-mark ()
               (setf mark nil))
             (finish ()
               (if mark
                   (save mark value-ends)
                   (save pos value-ends))
              (force-downcase-field-names header)
              (contract-field-value-indexes header)
              (return-from process-header header))
             (in-new-line (code)
               (acase code
                 ((#\Tab #\Space) (setf mark nil) #'in-value)
                 (t
                  (when mark
                    (save mark value-ends))
                  (clear-mark)
                  (save pos name-starts)
                  (in-name code))))
             (after-cr (code)
               (acase code
                 (:lf #'in-new-line)
                 (t (in-new-line code))))
             (pending-value (code)
               (acase code
                 ((#\Tab #\Space) #'pending-value)
                 (:cr #'after-cr)
                 (:lf #'in-new-line)
                 (t (save pos value-starts) #'in-value)))
             (in-name (code)
               (acase code
                 (#\:
                  (save pos name-ends)
                  (save (1+ pos) value-starts)
                  #'in-value)
                 ((:cr :lf)
                  (finish))
                 ((#\Tab #\Space)
                  (error "Unexpected whitespace in header field name"))
                 (t
                  (unless (<= 0 code 127)
                    (error "Unexpected non-ASCII header field name"))
                  #'in-name)))
             (in-value (code)
               (acase code
                 (:lf (mark) #'in-new-line)
                 (:cr (mark) #'after-cr)
                 (t #'in-value))))
      (let ((state #'in-new-line))
        (loop
         (incf pos)
         (when (<= (length vector) pos)
           (error "No header found in response"))
         (setf state (funcall state (aref vector pos))))))))


;;; HTTP URL parsing

(defclass url ()
  ((hostname
    :initarg :hostname
    :accessor hostname
    :initform nil)
   (port
    :initarg :port
    :accessor port
    :initform 80)
   (path
    :initarg :path
    :accessor path
    :initform "/")))

(defun parse-urlstring (urlstring)
  (setf urlstring (string-trim " " urlstring))
  (let* ((pos (mismatch urlstring "http://" :test 'char-equal))
         (mark pos)
         (url (make-instance 'url)))
    (labels ((save ()
               (subseq urlstring mark pos))
             (mark ()
               (setf mark pos))
             (finish ()
               (return-from parse-urlstring url))
             (hostname-char-p (char)
               (position char "ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_."
                         :test 'char-equal))
             (at-start (char)
               (case char
                 (#\/
                  (setf (port url) nil)
                  (mark)
                  #'in-path)
                 (t
                  #'in-host)))
             (in-host (char)
               (case char
                 ((#\/ :end)
                  (setf (hostname url) (save))
                  (mark)
                  #'in-path)
                 (#\:
                  (setf (hostname url) (save))
                  (mark)
                  #'in-port)
                 (t
                  (unless (hostname-char-p char)
                    (error "~S is not a valid URL" urlstring))
                  #'in-host)))
             (in-port (char)
               (case char
                 ((#\/ :end)
                  (setf (port url)
                        (parse-integer urlstring
                                       :start (1+ mark)
                                       :end pos))
                  (mark)
                  #'in-path)
                 (t
                  (unless (digit-char-p char)
                    (error "Bad port in URL ~S" urlstring))
                  #'in-port)))
             (in-path (char)
               (case char
                 ((#\# :end)
                  (setf (path url) (save))
                  (finish)))
               #'in-path))
      (let ((state #'at-start))
        (loop
         (when (<= (length urlstring) pos)
           (funcall state :end)
           (finish))
         (setf state (funcall state (aref urlstring pos)))
         (incf pos))))))

(defun url (thing)
  (if (stringp thing)
      (parse-urlstring thing)
      thing))

(defgeneric request-buffer (method url)
  (:method (method url)
    (setf url (url url))
    (make-request-buffer (hostname url) (port url) (path url)
                         :method method)))

(defun urlstring (url)
  (format nil "~@[http://~A~]~@[:~D~]~A"
          (hostname url)
          (and (/= 80 (port url)) (port url))
          (path url)))

(defmethod print-object ((url url) stream)
  (print-unreadable-object (url stream :type t)
    (prin1 (urlstring url) stream)))

(defun merge-urls (url1 url2)
  (setf url1 (url url1))
  (setf url2 (url url2))
  (make-instance 'url
                 :hostname (or (hostname url1)
                               (hostname url2))
                 :port (or (port url1)
                           (port url2))
                 :path (or (path url1)
                           (path url2))))


;;; Requesting an URL and saving it to a file

(defparameter *maximum-redirects* 10)
(defvar *default-url-defaults* (url "http://src.quicklisp.org/"))

(defun read-http-header (cbuf)
  (let ((header-data (sink-until-matching (list (acode-matcher :lf :lf)
                                                (acode-matcher :cr :cr)
                                                (acode-matcher :cr :lf :cr :lf))
                                 cbuf)))
    (process-header header-data)))

(defun read-chunk-header (cbuf)
  (let* ((header-data (sink-until-matching (acode-matcher :cr :lf) cbuf))
         (end (or (position (acode :cr) header-data)
                  (position (acode #\;) header-data))))
    (values (parse-integer (ascii-subseq header-data 0 end) :radix 16))))

(defun save-chunk-response (stream cbuf)
  "For a chunked response, read all chunks and write them to STREAM."
  (let ((fun (make-stream-writer stream))
        (matcher (acode-matcher :cr :lf)))
    (loop
     (let ((chunk-size (read-chunk-header cbuf)))
       (when (zerop chunk-size)
         (return))
       (call-for-n-octets chunk-size fun cbuf)
       (skip-until-matching matcher cbuf)))))

(defun save-response (file header cbuf)
  (with-open-file (stream file
                          :direction :output
                          :if-exists :supersede
                          :element-type 'octet)
    (let ((content-length (content-length header)))
      (cond ((chunkedp header)
             (save-chunk-response stream cbuf))
            (content-length
             (call-for-n-octets content-length
                                (make-stream-writer stream)
                                cbuf))
            (t
             (call-until-end (make-stream-writer stream) cbuf))))))

(defun call-with-progress-bar (size fun)
  (let ((progress-bar (make-progress-bar size)))
    (start-display progress-bar)
    (flet ((update (condition)
             (update-progress progress-bar
                              (cbuf-progress-size condition))))
      (handler-bind ((cbuf-progress #'update))
        (funcall fun)))
    (finish-display progress-bar)))

(defun fetch (url file &key (follow-redirects t) quietly
              (maximum-redirects *maximum-redirects*))
  "Request URL and write the body of the response to FILE."
  (setf url (merge-urls url *default-url-defaults*))
  (setf file (merge-pathnames file))
  (let ((redirect-count 0)
        (original-url url)
        (connect-url (or (url *proxy-url*) url))
        (stream (if quietly
                    (make-broadcast-stream)
                    *trace-output*)))
    (loop
     (when (<= maximum-redirects redirect-count)
       (error "Too many redirects for ~A" original-url))
     (with-connection (connection (hostname connect-url) (port connect-url))
       (let ((cbuf (make-instance 'cbuf :connection connection))
             (request (request-buffer "GET" url)))
         (write-octets request connection)
         (let ((header (read-http-header cbuf)))
           (loop while (= (status header) 100)
                 do (setf header (read-http-header cbuf)))
           (cond ((= (status header) 200)
                  (let ((size (content-length header)))
                    (format stream "~&; Fetching ~A~%" url)
                    (if (and (numberp size)
                             (plusp size))
                        (format stream "; ~$KB~%" (/ size 1024))
                        (format stream "; Unknown size~%"))
                    (if quietly
                        (save-response file header cbuf)
                        (call-with-progress-bar (content-length header)
                                                (lambda ()
                                                  (save-response file header cbuf))))))
                 ((not (<= 300 (status header) 399))
                  (error "Unexpected status for ~A: ~A"
                         url (status header))))
           (if (and follow-redirects (<= 300 (status header) 399))
               (let ((new-urlstring (ascii-header-value "location" header)))
                 (when (not new-urlstring)
                   (error "Redirect code ~D received, but no Location: header"
                          (status header)))
                 (incf redirect-count)
                 (setf url (merge-urls new-urlstring
                                       url))
                 (format stream "~&; Redirecting to ~A~%" url))
               (return (values header (and file (probe-file file)))))))))))


;;; A primitive tar unpacker

(in-package #:qlqs-minitar)

(defun make-block-buffer ()
  (make-array 512 :element-type '(unsigned-byte 8) :initial-element 0))

(defun skip-n-blocks (n stream)
  (let ((block (make-block-buffer)))
    (dotimes (i n)
      (read-sequence block stream))))

(defun ascii-subseq (vector start end)
  (let ((string (make-string (- end start))))
    (loop for i from 0
          for j from start below end
          do (setf (char string i) (code-char (aref vector j))))
    string))

(defun block-asciiz-string (block start length)
  (let* ((end (+ start length))
         (eos (or (position 0 block :start start :end end)
                            end)))
    (ascii-subseq block start eos)))

(defun prefix (header)
  (when (plusp (aref header 345))
    (block-asciiz-string header 345 155)))

(defun name (header)
  (block-asciiz-string header 0 100))

(defun payload-size (header)
  (values (parse-integer (block-asciiz-string header 124 12) :radix 8)))

(defun nth-block (n file)
  (with-open-file (stream file :element-type '(unsigned-byte 8))
    (let ((block (make-block-buffer)))
      (skip-n-blocks (1- n) stream)
      (read-sequence block stream)
      block)))

(defun payload-type (code)
  (case code
    (0 :file)
    (48 :file)
    (53 :directory)
    (t :unsupported)))

(defun full-path (header)
  (let ((prefix (prefix header))
        (name (name header)))
    (if prefix
        (format nil "~A/~A" prefix name)
        name)))

(defun save-file (file size stream)
  (multiple-value-bind (full-blocks partial)
      (truncate size 512)
    (ensure-directories-exist file)
    (with-open-file (outstream file
                     :direction :output
                     :if-exists :supersede
                     :element-type '(unsigned-byte 8))
      (let ((block (make-block-buffer)))
        (dotimes (i full-blocks)
          (read-sequence block stream)
          (write-sequence block outstream))
        (when (plusp partial)
          (read-sequence block stream)
          (write-sequence block outstream :end partial))))))

(defun unpack-tarball (tarfile &key (directory *default-pathname-defaults*))
  (let ((block (make-block-buffer)))
    (with-open-file (stream tarfile :element-type '(unsigned-byte 8))
      (loop
       (let ((size (read-sequence block stream)))
         (when (zerop size)
           (return))
         (unless (= size 512)
           (error "Bad size on tarfile"))
         (when (every #'zerop block)
           (return))
         (let* ((payload-code (aref block 156))
                (payload-type (payload-type payload-code))
                (tar-path (full-path block))
                (full-path (merge-pathnames tar-path directory))
                (payload-size (payload-size block)))
         (case payload-type
           (:file
            (save-file full-path payload-size stream))
           (:directory
            (ensure-directories-exist full-path))
           (t
            (warn "Unknown tar block payload code -- ~D" payload-code)
            (skip-n-blocks (ceiling (payload-size block) 512) stream)))))))))

(defun contents (tarfile)
  (let ((block (make-block-buffer))
        (result '()))
    (with-open-file (stream tarfile :element-type '(unsigned-byte 8))
      (loop
        (let ((size (read-sequence block stream)))
          (when (zerop size)
            (return (nreverse result)))
          (unless (= size 512)
            (error "Bad size on tarfile"))
          (when (every #'zerop block)
            (return (nreverse result)))
          (let* ((payload-type (payload-type (aref block 156)))
                 (tar-path (full-path block))
                 (payload-size (payload-size block)))
            (skip-n-blocks (ceiling payload-size 512) stream)
            (case payload-type
              (:file
               (push tar-path result))
              (:directory
               (push tar-path result)))))))))


;;;
;;; The actual bootstrapping work
;;;

(in-package #:quicklisp-quickstart)

(defvar *home*
  (merge-pathnames (make-pathname :directory '(:relative "quicklisp"))
                   (user-homedir-pathname)))

(defun qmerge (pathname)
  (merge-pathnames pathname *home*))

(defun renaming-fetch (url file)
  (let ((tmpfile (qmerge "tmp/fetch.dat")))
    (fetch url tmpfile)
    (rename-file tmpfile file)))

(defvar *quickstart-parameters* nil
  "This plist is populated with parameters that may carry over to the
  initial configuration of the client, e.g. :proxy-url
  or :initial-dist-url")

(defvar *quicklisp-hostname* "beta.quicklisp.org")

(defvar *client-info-url*
  (format nil "http://~A/client/quicklisp.sexp"
          *quicklisp-hostname*))

(defclass client-info ()
  ((setup-url
    :reader setup-url
    :initarg :setup-url)
   (asdf-url
    :reader asdf-url
    :initarg :asdf-url)
   (client-tar-url
    :reader client-tar-url
    :initarg :client-tar-url)
   (version
    :reader version
    :initarg :version)
   (plist
    :reader plist
    :initarg :plist)
   (source-file
    :reader source-file
    :initarg :source-file)))

(defmethod print-object ((client-info client-info) stream)
  (print-unreadable-object (client-info stream :type t)
    (prin1 (version client-info) stream)))

(defun safely-read (stream)
  (let ((*read-eval* nil))
    (read stream)))

(defun fetch-client-info-plist (url)
  "Fetch and return the client info data at URL."
  (let ((local-client-info-file (qmerge "tmp/client-info.sexp")))
    (ensure-directories-exist local-client-info-file)
    (renaming-fetch url local-client-info-file)
    (with-open-file (stream local-client-info-file)
      (list* :source-file local-client-info-file
             (safely-read stream)))))

(defun fetch-client-info (url)
  (let ((plist (fetch-client-info-plist url)))
    (destructuring-bind (&key setup asdf client-tar version
                              source-file
                              &allow-other-keys)
        plist
      (unless (and setup asdf client-tar version)
        (error "Invalid data from client info URL -- ~A" url))
      (make-instance 'client-info
                     :setup-url (getf setup :url)
                     :asdf-url (getf asdf :url)
                     :client-tar-url (getf client-tar :url)
                     :version version
                     :plist plist
                     :source-file source-file))))

(defun client-info-url-from-version (version)
  (format nil "http://~A/client/~A/client-info.sexp"
          *quicklisp-hostname*
          version))

(defun distinfo-url-from-version (version)
  (format nil "http://~A/dist/~A/distinfo.txt"
          *quicklisp-hostname*
          version))

(defvar *help-message*
  (format nil "~&~%  ==== quicklisp quickstart install help ====~%~%    ~
               quicklisp-quickstart:install can take the following ~
               optional arguments:~%~%      ~
                 :path \"/path/to/installation/\"~%~%      ~
                 :proxy \"http://your.proxy:port/\"~%~%      ~
                 :client-url <url>~%~%      ~
                 :client-version <version>~%~%      ~
                 :dist-url <url>~%~%      ~
                 :dist-version <version>~%~%"))

(defvar *after-load-message*
  (format nil "~&~%  ==== quicklisp quickstart ~A loaded ====~%~%    ~
               To continue with installation, evaluate: (quicklisp-quickstart:install)~%~%    ~
               For installation options, evaluate: (quicklisp-quickstart:help)~%~%"
          qlqs-info:*version*))

(defvar *after-initial-setup-message*
  (with-output-to-string (*standard-output*)
    (format t "~&~%  ==== quicklisp installed ====~%~%")
    (format t "    To load a system, use: (ql:quickload \"system-name\")~%~%")
    (format t "    To find systems, use: (ql:system-apropos \"term\")~%~%")
    (format t "    To load Quicklisp every time you start Lisp, use: (ql:add-to-init-file)~%~%")
    (format t "    For more information, see http://www.quicklisp.org/beta/~%~%")))

(defun initial-install (&key (client-url *client-info-url*) dist-url)
  (setf *quickstart-parameters*
        (list :proxy-url *proxy-url*
              :initial-dist-url dist-url))
  (ensure-directories-exist (qmerge "tmp/"))
  (let ((client-info (fetch-client-info client-url))
        (tmptar (qmerge "tmp/quicklisp.tar"))
        (setup (qmerge "setup.lisp"))
        (asdf (qmerge "asdf.lisp")))
    (renaming-fetch (client-tar-url client-info) tmptar)
    (unpack-tarball tmptar :directory (qmerge "./"))
    (renaming-fetch (setup-url client-info) setup)
    (renaming-fetch (asdf-url client-info) asdf)
    (rename-file (source-file client-info) (qmerge "client-info.sexp"))
    (load setup :verbose nil :print nil)
    (write-string *after-initial-setup-message*)
    (finish-output)))

(defun help ()
  (write-string *help-message*)
  t)

(defun non-empty-file-namestring (pathname)
  (let ((string (file-namestring pathname)))
    (unless (or (null string)
                (equal string ""))
      string)))

(defun install (&key ((:path *home*) *home*)
                  ((:proxy *proxy-url*) *proxy-url*)
                  client-url
                  client-version
                  dist-url
                  dist-version)
  (setf *home* (merge-pathnames *home* (truename *default-pathname-defaults*)))
  (let ((name (non-empty-file-namestring *home*)))
    (when name
      (warn "Making ~A part of the install pathname directory"
            name)
      ;; This corrects a pathname like "/foo/bar" to "/foo/bar/" and
      ;; "foo" to "foo/"
      (setf *home*
            (make-pathname :defaults *home*
                           :directory (append (pathname-directory *home*)
                                              (list name))))))
  (let ((setup-file (qmerge "setup.lisp")))
    (when (probe-file setup-file)
      (multiple-value-bind (result proceed)
          (with-simple-restart (load-setup "Load ~S" setup-file)
            (error "Quicklisp has already been installed. Load ~S instead."
                   setup-file))
        (declare (ignore result))
        (when proceed
          (return-from install (load setup-file))))))
  (if (find-package '#:ql)
      (progn
        (write-line "!!! Quicklisp has already been set up. !!!")
        (write-string *after-initial-setup-message*)
        t)
      (call-with-quiet-compilation
       (lambda ()
         (let ((client-url (or client-url
                               (and client-version
                                    (client-info-url-from-version client-version))
                               *client-info-url*))
               ;; It's ok for dist-url to be nil; there's a default in
               ;; the client
               (dist-url (or dist-url
                             (and dist-version
                                  (distinfo-url-from-version dist-version)))))
           (initial-install :client-url client-url
                            :dist-url dist-url))))))

(write-string *after-load-message*)

;;; End of quicklisp.lisp

--- END_FILE: ./quicklisp.lisp ---

--- START_FILE: ./internal/parser/parser_test.go ---
package parser

import (
	"ebusta/api/proto/v1"
	"testing"
)

func TestParser(t *testing.T) {
	tests := []struct {
		name     string
		input    string
		validate func(*testing.T, *libraryv1.SearchQuery)
	}{
		{
			name:  "Simple Any Search",
			input: "Unix",
			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
				f := q.GetFilter()
				if f == nil || f.Field != "any" || f.Value != "Unix" {
					t.Errorf("Expected any:Unix, got %+v", f)
				}
			},
		},
		{
			name:  "Field Search",
			input: "author:Кинг",
			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
				f := q.GetFilter()
				if f == nil || f.Field != "author" || f.Value != "Кинг" {
					t.Errorf("Expected author:Кинг, got %+v", f)
				}
			},
		},
		{
			name:  "Logical AND",
			input: "author:Кинг AND title:Оно",
			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
				l := q.GetLogical()
				if l == nil || l.Op != libraryv1.LogicalOp_AND || len(l.Nodes) != 2 {
					t.Errorf("Expected AND with 2 nodes, got %+v", l)
				}
			},
		},
		{
			name:  "Negation NOT",
			input: "NOT title:Куджо",
			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
				n := q.GetNegation()
				if n == nil {
					t.Fatalf("Expected negation node, got nil")
				}
				f := n.Node.GetFilter()
				if f.Field != "title" || f.Value != "Куджо" {
					t.Errorf("Expected NOT title:Куджо, got %s:%s", f.Field, f.Value)
				}
			},
		},
		{
			name:  "Regex Detection",
			input: "title:/^Unix.*/",
			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
				f := q.GetFilter()
				if f.Operator != libraryv1.Operator_OP_REGEX {
					t.Errorf("Expected REGEX operator, got %v", f.Operator)
				}
			},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			p := NewParser(tt.input)
			query := p.Parse()
			tt.validate(t, query)
		})
	}
}

--- END_FILE: ./internal/parser/parser_test.go ---

--- START_FILE: ./internal/parser/lexer.go ---
package parser

import (
	"strings"
)

// ==========================================
// LEXER DEFINITIONS
// ==========================================

type TokenType int

const (
	TOKEN_EOF TokenType = iota
	TOKEN_ERROR
	TOKEN_IDENT     // author, title, Кинг
	TOKEN_STRING    // "Стивен Кинг"
	TOKEN_COLON     // :
	TOKEN_AND       // AND
	TOKEN_OR        // OR
	TOKEN_NOT       // NOT, -
	TOKEN_LPAREN    // (
	TOKEN_RPAREN    // )
	TOKEN_EQUALS    // =
	TOKEN_CONTAINS  // ~
)

type Token struct {
	Type  TokenType
	Value string
	Pos   int
}

type Lexer struct {
	input  string
	pos    int
	start  int
	width  int
	tokens []Token
}

// newLexer создает лексер (используется в parser.go)
func newLexer(input string) *Lexer {
	return &Lexer{input: input}
}

// NextToken возвращает следующий токен (используется в parser.go)
func (l *Lexer) NextToken() Token {
	l.skipWhitespace()
	if l.pos >= len(l.input) {
		return Token{Type: TOKEN_EOF}
	}

	ch := l.input[l.pos]

	switch {
	case isLetter(ch):
		return l.scanIdentifier()
	case ch == '"':
		return l.scanString()
	case ch == ':':
		l.pos++
		return Token{Type: TOKEN_COLON, Value: ":"}
	case ch == '(':
		l.pos++
		return Token{Type: TOKEN_LPAREN, Value: "("}
	case ch == ')':
		l.pos++
		return Token{Type: TOKEN_RPAREN, Value: ")"}
	case ch == '-': // Минус как NOT
		l.pos++
		return Token{Type: TOKEN_NOT, Value: "-"}
	case ch == '=':
		l.pos++
		return Token{Type: TOKEN_EQUALS, Value: "="}
	case ch == '~':
		l.pos++
		return Token{Type: TOKEN_CONTAINS, Value: "~"}
	}

	return Token{Type: TOKEN_ERROR, Value: string(ch)}
}

func (l *Lexer) skipWhitespace() {
	for l.pos < len(l.input) && (l.input[l.pos] == ' ' || l.input[l.pos] == '\t') {
		l.pos++
	}
}

func (l *Lexer) scanIdentifier() Token {
	start := l.pos
	for l.pos < len(l.input) && isLetter(l.input[l.pos]) {
		l.pos++
	}
	lit := l.input[start:l.pos]
	
	switch strings.ToUpper(lit) {
	case "AND":
		return Token{Type: TOKEN_AND, Value: lit}
	case "OR":
		return Token{Type: TOKEN_OR, Value: lit}
	case "NOT":
		return Token{Type: TOKEN_NOT, Value: lit}
	}
	return Token{Type: TOKEN_IDENT, Value: lit}
}

func (l *Lexer) scanString() Token {
	l.pos++ // skip opening quote
	start := l.pos
	for l.pos < len(l.input) && l.input[l.pos] != '"' {
		l.pos++
	}
	lit := l.input[start:l.pos]
	if l.pos < len(l.input) {
		l.pos++ // skip closing quote
	}
	return Token{Type: TOKEN_STRING, Value: lit}
}

func isLetter(ch byte) bool {
	return (ch >= 'a' && ch <= 'z') || (ch >= 'A' && ch <= 'Z') || (ch >= '0' && ch <= '9') || ch > 127 || ch == '_' || ch == '.'
}

--- END_FILE: ./internal/parser/lexer.go ---

--- START_FILE: ./internal/parser/parser.go ---
package parser

import (
	"fmt"
	"ebusta/api/proto/v1"
)

// ==========================================
// PUBLIC API
// ==========================================

// Parse - точка входа. Создает лексер и парсер.
func Parse(input string) *libraryv1.SearchQuery {
	l := newLexer(input)
	p := newParser(l)
	return p.parseSearchQuery()
}

// ==========================================
// PARSER LOGIC
// ==========================================

type Parser struct {
	l       *Lexer
	curTok  Token
	peekTok Token
}

func newParser(l *Lexer) *Parser {
	p := &Parser{l: l}
	p.nextToken()
	p.nextToken()
	return p
}

func (p *Parser) nextToken() {
	p.curTok = p.peekTok
	p.peekTok = p.l.NextToken()
}

// Expression -> Term { OR Term }
func (p *Parser) parseSearchQuery() *libraryv1.SearchQuery {
	if p.curTok.Type == TOKEN_EOF {
		return nil
	}
	return p.parseExpression()
}

func (p *Parser) parseExpression() *libraryv1.SearchQuery {
	left := p.parseTerm()

	for p.curTok.Type == TOKEN_OR {
		p.nextToken() // eat OR
		right := p.parseTerm()
		left = &libraryv1.SearchQuery{
			Node: &libraryv1.SearchQuery_Logical{
				Logical: &libraryv1.LogicalNode{
					Op:    libraryv1.LogicalOp_OR,
					Nodes: []*libraryv1.SearchQuery{left, right},
				},
			},
		}
	}
	return left
}

// Term -> Factor { AND Factor }
func (p *Parser) parseTerm() *libraryv1.SearchQuery {
	left := p.parseFactor()

	for p.curTok.Type == TOKEN_AND {
		p.nextToken() // eat AND
		right := p.parseFactor()
		left = &libraryv1.SearchQuery{
			Node: &libraryv1.SearchQuery_Logical{
				Logical: &libraryv1.LogicalNode{
					Op:    libraryv1.LogicalOp_AND,
					Nodes: []*libraryv1.SearchQuery{left, right},
				},
			},
		}
	}
	return left
}

// Factor -> ( Expr ) | NOT Factor | Filter
func (p *Parser) parseFactor() *libraryv1.SearchQuery {
	switch p.curTok.Type {
	case TOKEN_LPAREN:
		p.nextToken() // eat (
		exp := p.parseExpression()
		if p.curTok.Type != TOKEN_RPAREN {
			fmt.Println("Error: expected )") 
		}
		p.nextToken() // eat )
		return exp

	case TOKEN_NOT:
		p.nextToken() // eat NOT
		right := p.parseFactor()
		return &libraryv1.SearchQuery{
			Node: &libraryv1.SearchQuery_Negation{
				Negation: &libraryv1.NotNode{
					Node: right,
				},
			},
		}
	
	default:
		return p.parseFilter()
	}
}

// Filter -> IDENT [OP] VALUE
func (p *Parser) parseFilter() *libraryv1.SearchQuery {
	if p.curTok.Type == TOKEN_IDENT && (p.peekTok.Type == TOKEN_COLON || p.peekTok.Type == TOKEN_EQUALS || p.peekTok.Type == TOKEN_CONTAINS) {
		field := p.curTok.Value
		p.nextToken() // eat field
		
		var op libraryv1.Operator
		switch p.curTok.Type {
		case TOKEN_COLON:    op = libraryv1.Operator_OP_CONTAINS
		case TOKEN_EQUALS:   op = libraryv1.Operator_OP_EQUALS
		case TOKEN_CONTAINS: op = libraryv1.Operator_OP_CONTAINS
		}
		
		p.nextToken() // eat op
		
		value := p.curTok.Value
		p.nextToken() // eat value

		return &libraryv1.SearchQuery{
			Node: &libraryv1.SearchQuery_Filter{
				Filter: &libraryv1.FilterNode{
					Field:    field,
					Value:    value,
					Operator: op,
				},
			},
		}
	}

	// Implicit "any" search
	val := p.curTok.Value
	p.nextToken()
	
	return &libraryv1.SearchQuery{
		Node: &libraryv1.SearchQuery_Filter{
			Filter: &libraryv1.FilterNode{
				Field:    "any",
				Value:    val,
				Operator: libraryv1.Operator_OP_CONTAINS,
			},
		},
	}
}

--- END_FILE: ./internal/parser/parser.go ---

--- START_FILE: ./internal/logger/logger.go ---
package logger

import (
	"context"
	"time"
	"github.com/sirupsen/logrus"
)

type ctxKey string
const RequestIDKey ctxKey = "requestId"

func init() {
	logrus.SetFormatter(&logrus.TextFormatter{
		FullTimestamp:   true,
		TimestampFormat: "15:04:05",
		ForceColors:     true,
		DisableColors:   false,
	})
}

func For(ctx context.Context) *logrus.Entry {
	id, ok := ctx.Value(RequestIDKey).(string)
	if !ok {
		return logrus.NewEntry(logrus.StandardLogger())
	}
	return logrus.WithField("request_id", id)
}

func ContextWithID(ctx context.Context, id string) context.Context {
	return context.WithValue(ctx, RequestIDKey, id)
}

func Track(ctx context.Context, msg string) func() {
	start := time.Now()
	return func() {
		dur := time.Since(start)
		entry := For(ctx).WithField("duration", dur.String())
		
		if dur > 500*time.Millisecond {
			entry.Warnf("%s completed (SLOW)", msg)
		} else {
			entry.Infof("%s completed", msg)
		}
	}
}

--- END_FILE: ./internal/logger/logger.go ---

--- START_FILE: ./internal/metrics/metrics.go ---
package metrics

import (
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promauto"
)

var (
	HttpRequestsTotal = promauto.NewCounterVec(prometheus.CounterOpts{
		Name: "ebusta_gateway_requests_total",
		Help: "Total number of HTTP requests to gateway",
	}, []string{"method", "path", "status"})

	HttpRequestDuration = promauto.NewHistogramVec(prometheus.HistogramOpts{
		Name:    "ebusta_gateway_request_duration_seconds",
		Help:    "Duration of HTTP requests in seconds",
		Buckets: prometheus.DefBuckets,
	}, []string{"path"})
)

--- END_FILE: ./internal/metrics/metrics.go ---

--- START_FILE: ./internal/storage/datamanager/config/config.go ---
package config

import (
	"time"
	"github.com/kelseyhightower/envconfig"
)

type Config struct {
	BindAddr    string        `env:"BIND_ADDR" default:":8082"`
	OSScheme    string        `env:"OS_SCHEME" default:"http"`
	OSHost      string        `env:"OS_HOST" default:"mercury"`
	OSPort      string        `env:"OS_PORT" default:"9200"`
	OSIndex     string        `env:"OS_INDEX" default:"ebusta"`
	ESUser      string        `env:"ES_USER"`
	ESPass      string        `env:"ES_PASS"`
	HTTPTimeout time.Duration `env:"HTTP_TIMEOUT" default:"5s"`
	LogJSON     bool          `env:"LOG_JSON" default:"false"`
	LogLevel    string        `env:"LOG_LEVEL" default:"INFO"`
	LogPath     string        `env:"LOG_PATH"` // Default is empty, logs to stdout
}

func (c *Config) Validate() error {
	if c.BindAddr == "" {
		return ErrInvalid("bind address is required")
	}
	if c.OSHost == "" || c.OSPort == "" || c.OSIndex == "" {
		return ErrInvalid("OS_HOST/OS_PORT/OS_INDEX are required")
	}
	return nil
}

type invalidErr string
func (e invalidErr) Error() string { return string(e) }
func ErrInvalid(msg string) error { return invalidErr(msg) }

func Load() (Config, error) {
	var cfg Config
	if err := envconfig.Process("", &cfg); err != nil {
		return cfg, err
	}
	return cfg, cfg.Validate()
}

--- END_FILE: ./internal/storage/datamanager/config/config.go ---

--- START_FILE: ./internal/storage/datamanager/delivery/grpc.go ---
package delivery

import (
	"context"
	"ebusta/api/proto/v1"
	"ebusta/internal/logger"
)

type DataManagerServer struct {
	libraryv1.UnimplementedLibraryServiceServer
}

// ИСПРАВЛЕНИЕ: Метод должен называться SearchBooks, чтобы соответствовать интерфейсу
func (s *DataManagerServer) SearchBooks(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
	// Если логгер еще не настроен, используем простой принт или заглушку
	if logger.For(ctx) != nil {
		defer logger.Track(ctx, "Storage: DB Search Operation")()
	}

	// Моковые данные для теста
	books := []*libraryv1.Book{
		{
			Id:      "101",
			Title:   "The Art of Unix Programming",
			Authors: []string{"Eric S. Raymond"},
		},
	}

	return &libraryv1.SearchResponse{
		Books: books,
		Total: int32(len(books)),
	}, nil
}

func (s *DataManagerServer) GetAuthors(ctx context.Context, req *libraryv1.ListRequest) (*libraryv1.ListResponse, error) {
	return &libraryv1.ListResponse{Items: []string{"King", "Tolkien"}}, nil
}

--- END_FILE: ./internal/storage/datamanager/delivery/grpc.go ---

--- START_FILE: ./internal/storage/datamanager/delivery/handlers.go ---
package delivery

import (
	"ebusta/api/proto/v1"
	"encoding/json"
	"log"
)

func MapOSResponseToGrpc(body []byte) ([]*libraryv1.Book, int32) {
	// Total выносим в interface{}, так как OS может вернуть и число, и объект
	var raw struct {
		Hits struct {
			Total interface{} `json:"total"`
			Hits  []struct {
				ID     string `json:"_id"`
				Source struct {
					Title   string   `json:"title"`
					Authors []string `json:"authors"`
				} `json:"_source"`
			} `json:"hits"`
		} `json:"hits"`
	}

	if err := json.Unmarshal(body, &raw); err != nil {
		log.Printf("❌ DataManager Parsing Error: %v", err)
		return nil, 0
	}

	var totalValue int32
	// Гибкое извлечение Total (поддержка объекта и числа)
	switch v := raw.Hits.Total.(type) {
	case float64:
		totalValue = int32(v)
	case map[string]interface{}:
		if val, ok := v["value"].(float64); ok {
			totalValue = int32(val)
		}
	}

	var books []*libraryv1.Book
	for _, h := range raw.Hits.Hits {
		// Защита от пустых авторов
		authors := h.Source.Authors
		if authors == nil {
			authors = []string{"Unknown"}
		}
		
		books = append(books, &libraryv1.Book{
			Id:      h.ID,
			Title:   h.Source.Title,
			Authors: authors,
		})
	}

	// Если хиты есть, а total 0 (бывает при определенных настройках OS)
	if totalValue == 0 && len(books) > 0 {
		totalValue = int32(len(books))
	}

	return books, totalValue
}

--- END_FILE: ./internal/storage/datamanager/delivery/handlers.go ---

--- START_FILE: ./internal/storage/datamanager/shaping/shaping.go ---
package shaping

import (
	"encoding/json"
	"fmt"
)

// --- Search shaping ---
type searchHit struct {
	Source struct {
		Title   string   `json:"title"`
		Authors []string `json:"authors"`
		FileInfo struct {
			Container string `json:"container"`
			Filename  string `json:"filename"`
		} `json:"fileInfo"`
	} `json:"_source"`
}
type searchResp struct {
	Hits struct {
		Total struct{ Value int `json:"value"` } `json:"total"`
		Hits  []searchHit `json:"hits"`
	} `json:"hits"`
}

// ShapeSearch flattens OpenSearch hits into a smaller payload.
func ShapeSearch(data []byte, from, size int) ([]byte, error) {
	var r searchResp
	if err := json.Unmarshal(data, &r); err != nil {
		return nil, fmt.Errorf("decode hits: %w", err)
	}
	type item struct {
		Title    string   `json:"title"`
		Authors  []string `json:"authors"`
		Download string   `json:"download,omitempty"`
	}
	out := struct {
		Total    int    `json:"total"`
		From     int    `json:"from"`
		Size     int    `json:"size"`
		NextFrom int    `json:"next_from"`
		Items    []item `json:"items"`
	}{
		Total:    r.Hits.Total.Value,
		From:     from,
		Size:     size,
		NextFrom: from + size,
		Items:    make([]item, 0, len(r.Hits.Hits)), // ensure [] not null
	}
	for _, h := range r.Hits.Hits {
		dl := ""
		if h.Source.FileInfo.Container != "" && h.Source.FileInfo.Filename != "" {
			dl = h.Source.FileInfo.Container + "/" + h.Source.FileInfo.Filename
		}
		out.Items = append(out.Items, item{
			Title:    h.Source.Title,
			Authors:  h.Source.Authors,
			Download: dl,
		})
	}
	return json.MarshalIndent(out, "", "  ")
}

// --- Composite/aggregation shaping (best-effort generic) ---
type composite struct {
	AfterKey any `json:"after_key"`
	Buckets  any `json:"buckets"`
}
type aggResp struct {
	Aggregations map[string]composite `json:"aggregations"`
}

func ShapeComposite(data []byte) ([]byte, error) {
	var r aggResp
	if err := json.Unmarshal(data, &r); err != nil {
		return nil, fmt.Errorf("decode aggregations: %w", err)
	}
	if len(r.Aggregations) == 0 {
		// pass-through
		return data, nil
	}
	// pick first aggregation
	for name, c := range r.Aggregations {
		out := map[string]any{
			"name":       name,
			"buckets":    c.Buckets,
			"after_key":  c.AfterKey,
		}
		return json.MarshalIndent(out, "", "  ")
	}
	return data, nil
}

--- END_FILE: ./internal/storage/datamanager/shaping/shaping.go ---

--- START_FILE: ./internal/storage/datamanager/shaping/shaping_test.go ---
package shaping

import "testing"

func TestShapeSearch(t *testing.T) {
	jsonIn := []byte(`{"hits":{"total":{"value":2},"hits":[{"_source":{"title":"A","authors":["X"],"fileInfo":{"container":"c","filename":"a.fb2"}}},{"_source":{"title":"B","authors":["Y"],"fileInfo":{"container":"d","filename":"b.fb2"}}}]}}`)
	out, err := ShapeSearch(jsonIn, 0, 10)
	if err != nil { t.Fatalf("unexpected error: %v", err) }
	mustContain(t, string(out), `"total": 2`)
	mustContain(t, string(out), `"items": [`)
	mustContain(t, string(out), `"download": "c/a.fb2"`)
}

func mustContain(t *testing.T, s, sub string) {
	t.Helper()
	if !contains(s, sub) { t.Fatalf("expected substring %q in %s", sub, s) }
}

func contains(s, sub string) bool { return len(s) >= len(sub) && (s == sub || (len(sub) > 0 && (stringIndex(s, sub) >= 0))) }
func stringIndex(s, sub string) int {
	for i := 0; i+len(sub) <= len(s); i++ {
		if s[i:i+len(sub)] == sub { return i }
	}
	return -1
}

--- END_FILE: ./internal/storage/datamanager/shaping/shaping_test.go ---

--- START_FILE: ./internal/storage/datamanager/proxy/proxy.go ---
package proxy

import (
	"bytes"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"sync"
	"time"

	"github.com/sirupsen/logrus"

	"ebusta/internal/storage/datamanager/config"
)

type Proxy struct {
	cfg     config.Config
	client  *http.Client
	logger  *logrus.Logger
	baseURL string
	once    sync.Once
}

func New(cfg config.Config, logger *logrus.Logger) *Proxy {
	return &Proxy{
		cfg:    cfg,
		logger: logger,
		client: newHTTPClient(cfg),
	}
}

func newHTTPClient(cfg config.Config) *http.Client {
	t := &http.Transport{
		MaxIdleConns:        100,
		IdleConnTimeout:     90 * time.Second,
		DisableCompression:  false,
		ForceAttemptHTTP2:   true,
	}
	return &http.Client{Transport: t, Timeout: cfg.HTTPTimeout}
}

func (p *Proxy) BaseURL() string {
	p.once.Do(func() {
		p.baseURL = fmt.Sprintf("%s://%s:%s/%s/_search/template", p.cfg.OSScheme, p.cfg.OSHost, p.cfg.OSPort, p.cfg.OSIndex)
	})
	return p.baseURL
}

// Structured error envelope
type ErrorEnvelope struct {
	Error ErrorBody `json:"error"`
}
type ErrorBody struct {
	Code    string      `json:"code"`
	Message string      `json:"message"`
	Details interface{} `json:"details,omitempty"`
}

func WriteError(w http.ResponseWriter, status int, code, message string, details interface{}) {
	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(status)
	_ = json.NewEncoder(w).Encode(ErrorEnvelope{
		Error: ErrorBody{Code: code, Message: message, Details: details},
	})
}

// DoTemplate executes a stored template by id with params.
func (p *Proxy) DoTemplate(ctx context.Context, id string, params map[string]any) ([]byte, int, error) {
	body := map[string]any{
		"id":     id,
		"params": params,
	}
	
	// This now only logs if LOG_LEVEL=DEBUG
	if p.logger.IsLevelEnabled(logrus.DebugLevel) {
		p.logger.WithFields(logrus.Fields{
			"template": id,
			"params":   params,
		}).Debug("os.request") // Changed from Info to Debug
	}
	
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, 0, fmt.Errorf("marshal body: %w", err)
	}

	req, err := http.NewRequestWithContext(ctx, http.MethodPost, p.BaseURL(), bytes.NewReader(buf))
	if err != nil {
		return nil, 0, fmt.Errorf("failed to create request: %w", err)
	}
	req.Header.Set("Content-Type", "application/json")
	if p.cfg.ESUser != "" || p.cfg.ESPass != "" {
		req.SetBasicAuth(p.cfg.ESUser, p.cfg.ESPass)
	}

	res, err := p.client.Do(req)
	if err != nil {
		return nil, 0, fmt.Errorf("upstream do: %w", err)
	}
	defer res.Body.Close()

	data, _ := io.ReadAll(res.Body)
	
	// This now only logs if LOG_LEVEL=DEBUG
	if p.logger.IsLevelEnabled(logrus.DebugLevel) {
		p.logger.WithFields(logrus.Fields{
			"template": id,
			"status": res.StatusCode,
			"response_body": string(data),
		}).Debug("os.response")
	}
	
	return data, res.StatusCode, nil
}

// DecodeAfter supports raw JSON or base64(JSON).
func DecodeAfter(s string) (any, error) {
	if s == "" {
		return nil, nil
	}
	// try raw JSON first
	var v any
	if json.Unmarshal([]byte(s), &v) == nil {
		return v, nil
	}
	// try base64
	b, err := base64.StdEncoding.DecodeString(s)
	if err != nil {
		return nil, fmt.Errorf("invalid after (not json or base64): %w", err)
	}
	if err := json.Unmarshal(b, &v); err != nil {
		return nil, fmt.Errorf("invalid after (bad json): %w", err)
	}
	return v, nil
}

--- END_FILE: ./internal/storage/datamanager/proxy/proxy.go ---

--- START_FILE: ./internal/middleware/logging.go ---
package middleware

import (
	"net/http"
	"time"

	"github.com/sirupsen/logrus"
)

// RequestLogger logs incoming requests at the INFO level.
func RequestLogger(log *logrus.Logger) func(http.Handler) http.Handler {
	return func(next http.Handler) http.Handler {
		return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
			start := time.Now()
			
			// Serve the request
			next.ServeHTTP(w, r)
			
			// Log the request
			log.WithFields(logrus.Fields{
				"method": r.Method,
				"path":   r.URL.Path,
//				"query":  r.URL.RawQuery,
				"query":  r.URL.Query(),
				"remote": r.RemoteAddr,
				"agent":  r.UserAgent(),
				"took":   time.Since(start),
			}).Info("http.request")
		})
	}
}

--- END_FILE: ./internal/middleware/logging.go ---

--- START_FILE: ./internal/middleware/middleware.go ---
package middleware

import (
	"net/http"
	"strings"
)

// CORS allows basic CORS for browser apps.
func CORS(next http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Access-Control-Allow-Origin", "*")
		w.Header().Set("Access-Control-Allow-Methods", "GET,POST,OPTIONS")
		w.Header().Set("Access-Control-Allow-Headers", "Content-Type,Authorization")
		if strings.ToUpper(r.Method) == "OPTIONS" {
			w.WriteHeader(http.StatusNoContent)
			return
		}
		next.ServeHTTP(w, r)
	})
}

--- END_FILE: ./internal/middleware/middleware.go ---

--- START_FILE: ./ebusta.yaml ---
datamanager:
  opensearch_url: "http://cloud-1:9200"
  index_name: "flibusta_merged_index"
  debug: true

orchestrator:
  storage_addr: "localhost:50051"
  processor_addr: "localhost:50053"

web:
  port: 8080

--- END_FILE: ./ebusta.yaml ---

--- START_FILE: ./api/proto/v1/library_simple.proto ---
syntax = "proto2";

package libraryv1;

message FilterNode {
  optional string field = 1;
  optional string value = 2;
  optional int32 operator = 3;
}

message LogicalNode {
  repeated SearchQuery nodes = 1;
}

message NotNode {
  optional SearchQuery node = 1;
}

message SearchQuery {
  optional FilterNode filter = 1;
  optional LogicalNode logical = 2;
  optional NotNode negation = 3;
}

--- END_FILE: ./api/proto/v1/library_simple.proto ---

--- START_FILE: ./api/proto/v1/auth.proto ---
syntax = "proto3";

package libraryv1;

option go_package = "ebusta/api/proto/v1;libraryv1";

service AuthService {
  // Проверка доступа пользователя
  rpc CheckAccess (AccessRequest) returns (AccessResponse);
}

message AccessRequest {
  string user_id = 1;      // ID (например, Telegram UID или ник в BBS)
  string platform = 2;     // Источник (web, telegram, cli, bbs)
  string trace_id = 3;     // Для сквозного логирования
}

message AccessResponse {
  bool allowed = 1;        // Разрешен ли вход
  string reason = 2;       // Причина отказа
  string user_role = 3;    // Роль пользователя (admin, family, guest)
}

--- END_FILE: ./api/proto/v1/auth.proto ---

--- START_FILE: ./api/proto/v1/library_grpc.pb.go ---
// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
// versions:
// - protoc-gen-go-grpc v1.6.0
// - protoc             v3.21.12
// source: api/proto/v1/library.proto

package libraryv1

import (
	context "context"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.64.0 or later.
const _ = grpc.SupportPackageIsVersion9

const (
	OrchestratorService_Search_FullMethodName = "/libraryv1.OrchestratorService/Search"
)

// OrchestratorServiceClient is the client API for OrchestratorService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type OrchestratorServiceClient interface {
	Search(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
}

type orchestratorServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewOrchestratorServiceClient(cc grpc.ClientConnInterface) OrchestratorServiceClient {
	return &orchestratorServiceClient{cc}
}

func (c *orchestratorServiceClient) Search(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(SearchResponse)
	err := c.cc.Invoke(ctx, OrchestratorService_Search_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// OrchestratorServiceServer is the server API for OrchestratorService service.
// All implementations must embed UnimplementedOrchestratorServiceServer
// for forward compatibility.
type OrchestratorServiceServer interface {
	Search(context.Context, *SearchRequest) (*SearchResponse, error)
	mustEmbedUnimplementedOrchestratorServiceServer()
}

// UnimplementedOrchestratorServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedOrchestratorServiceServer struct{}

func (UnimplementedOrchestratorServiceServer) Search(context.Context, *SearchRequest) (*SearchResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method Search not implemented")
}
func (UnimplementedOrchestratorServiceServer) mustEmbedUnimplementedOrchestratorServiceServer() {}
func (UnimplementedOrchestratorServiceServer) testEmbeddedByValue()                             {}

// UnsafeOrchestratorServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to OrchestratorServiceServer will
// result in compilation errors.
type UnsafeOrchestratorServiceServer interface {
	mustEmbedUnimplementedOrchestratorServiceServer()
}

func RegisterOrchestratorServiceServer(s grpc.ServiceRegistrar, srv OrchestratorServiceServer) {
	// If the following call panics, it indicates UnimplementedOrchestratorServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&OrchestratorService_ServiceDesc, srv)
}

func _OrchestratorService_Search_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SearchRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(OrchestratorServiceServer).Search(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: OrchestratorService_Search_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(OrchestratorServiceServer).Search(ctx, req.(*SearchRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// OrchestratorService_ServiceDesc is the grpc.ServiceDesc for OrchestratorService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var OrchestratorService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "libraryv1.OrchestratorService",
	HandlerType: (*OrchestratorServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Search",
			Handler:    _OrchestratorService_Search_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "api/proto/v1/library.proto",
}

const (
	ProcessorService_Process_FullMethodName = "/libraryv1.ProcessorService/Process"
)

// ProcessorServiceClient is the client API for ProcessorService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type ProcessorServiceClient interface {
	Process(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
}

type processorServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewProcessorServiceClient(cc grpc.ClientConnInterface) ProcessorServiceClient {
	return &processorServiceClient{cc}
}

func (c *processorServiceClient) Process(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(SearchResponse)
	err := c.cc.Invoke(ctx, ProcessorService_Process_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// ProcessorServiceServer is the server API for ProcessorService service.
// All implementations must embed UnimplementedProcessorServiceServer
// for forward compatibility.
type ProcessorServiceServer interface {
	Process(context.Context, *SearchRequest) (*SearchResponse, error)
	mustEmbedUnimplementedProcessorServiceServer()
}

// UnimplementedProcessorServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedProcessorServiceServer struct{}

func (UnimplementedProcessorServiceServer) Process(context.Context, *SearchRequest) (*SearchResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method Process not implemented")
}
func (UnimplementedProcessorServiceServer) mustEmbedUnimplementedProcessorServiceServer() {}
func (UnimplementedProcessorServiceServer) testEmbeddedByValue()                          {}

// UnsafeProcessorServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to ProcessorServiceServer will
// result in compilation errors.
type UnsafeProcessorServiceServer interface {
	mustEmbedUnimplementedProcessorServiceServer()
}

func RegisterProcessorServiceServer(s grpc.ServiceRegistrar, srv ProcessorServiceServer) {
	// If the following call panics, it indicates UnimplementedProcessorServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&ProcessorService_ServiceDesc, srv)
}

func _ProcessorService_Process_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SearchRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ProcessorServiceServer).Process(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: ProcessorService_Process_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ProcessorServiceServer).Process(ctx, req.(*SearchRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// ProcessorService_ServiceDesc is the grpc.ServiceDesc for ProcessorService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var ProcessorService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "libraryv1.ProcessorService",
	HandlerType: (*ProcessorServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Process",
			Handler:    _ProcessorService_Process_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "api/proto/v1/library.proto",
}

const (
	StorageService_SearchBooks_FullMethodName = "/libraryv1.StorageService/SearchBooks"
)

// StorageServiceClient is the client API for StorageService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type StorageServiceClient interface {
	SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
}

type storageServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewStorageServiceClient(cc grpc.ClientConnInterface) StorageServiceClient {
	return &storageServiceClient{cc}
}

func (c *storageServiceClient) SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(SearchResponse)
	err := c.cc.Invoke(ctx, StorageService_SearchBooks_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// StorageServiceServer is the server API for StorageService service.
// All implementations must embed UnimplementedStorageServiceServer
// for forward compatibility.
type StorageServiceServer interface {
	SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error)
	mustEmbedUnimplementedStorageServiceServer()
}

// UnimplementedStorageServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedStorageServiceServer struct{}

func (UnimplementedStorageServiceServer) SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method SearchBooks not implemented")
}
func (UnimplementedStorageServiceServer) mustEmbedUnimplementedStorageServiceServer() {}
func (UnimplementedStorageServiceServer) testEmbeddedByValue()                        {}

// UnsafeStorageServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to StorageServiceServer will
// result in compilation errors.
type UnsafeStorageServiceServer interface {
	mustEmbedUnimplementedStorageServiceServer()
}

func RegisterStorageServiceServer(s grpc.ServiceRegistrar, srv StorageServiceServer) {
	// If the following call panics, it indicates UnimplementedStorageServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&StorageService_ServiceDesc, srv)
}

func _StorageService_SearchBooks_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SearchRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(StorageServiceServer).SearchBooks(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: StorageService_SearchBooks_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(StorageServiceServer).SearchBooks(ctx, req.(*SearchRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// StorageService_ServiceDesc is the grpc.ServiceDesc for StorageService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var StorageService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "libraryv1.StorageService",
	HandlerType: (*StorageServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "SearchBooks",
			Handler:    _StorageService_SearchBooks_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "api/proto/v1/library.proto",
}

const (
	AuthService_CheckAccess_FullMethodName = "/libraryv1.AuthService/CheckAccess"
)

// AuthServiceClient is the client API for AuthService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type AuthServiceClient interface {
	CheckAccess(ctx context.Context, in *AccessRequest, opts ...grpc.CallOption) (*AccessResponse, error)
}

type authServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewAuthServiceClient(cc grpc.ClientConnInterface) AuthServiceClient {
	return &authServiceClient{cc}
}

func (c *authServiceClient) CheckAccess(ctx context.Context, in *AccessRequest, opts ...grpc.CallOption) (*AccessResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(AccessResponse)
	err := c.cc.Invoke(ctx, AuthService_CheckAccess_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// AuthServiceServer is the server API for AuthService service.
// All implementations must embed UnimplementedAuthServiceServer
// for forward compatibility.
type AuthServiceServer interface {
	CheckAccess(context.Context, *AccessRequest) (*AccessResponse, error)
	mustEmbedUnimplementedAuthServiceServer()
}

// UnimplementedAuthServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedAuthServiceServer struct{}

func (UnimplementedAuthServiceServer) CheckAccess(context.Context, *AccessRequest) (*AccessResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method CheckAccess not implemented")
}
func (UnimplementedAuthServiceServer) mustEmbedUnimplementedAuthServiceServer() {}
func (UnimplementedAuthServiceServer) testEmbeddedByValue()                     {}

// UnsafeAuthServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to AuthServiceServer will
// result in compilation errors.
type UnsafeAuthServiceServer interface {
	mustEmbedUnimplementedAuthServiceServer()
}

func RegisterAuthServiceServer(s grpc.ServiceRegistrar, srv AuthServiceServer) {
	// If the following call panics, it indicates UnimplementedAuthServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&AuthService_ServiceDesc, srv)
}

func _AuthService_CheckAccess_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(AccessRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(AuthServiceServer).CheckAccess(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: AuthService_CheckAccess_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(AuthServiceServer).CheckAccess(ctx, req.(*AccessRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// AuthService_ServiceDesc is the grpc.ServiceDesc for AuthService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var AuthService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "libraryv1.AuthService",
	HandlerType: (*AuthServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "CheckAccess",
			Handler:    _AuthService_CheckAccess_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "api/proto/v1/library.proto",
}

const (
	MessageConverterService_Convert_FullMethodName = "/libraryv1.MessageConverterService/Convert"
)

// MessageConverterServiceClient is the client API for MessageConverterService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type MessageConverterServiceClient interface {
	Convert(ctx context.Context, in *RawInput, opts ...grpc.CallOption) (*UnmarshaledMessage, error)
}

type messageConverterServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewMessageConverterServiceClient(cc grpc.ClientConnInterface) MessageConverterServiceClient {
	return &messageConverterServiceClient{cc}
}

func (c *messageConverterServiceClient) Convert(ctx context.Context, in *RawInput, opts ...grpc.CallOption) (*UnmarshaledMessage, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(UnmarshaledMessage)
	err := c.cc.Invoke(ctx, MessageConverterService_Convert_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// MessageConverterServiceServer is the server API for MessageConverterService service.
// All implementations must embed UnimplementedMessageConverterServiceServer
// for forward compatibility.
type MessageConverterServiceServer interface {
	Convert(context.Context, *RawInput) (*UnmarshaledMessage, error)
	mustEmbedUnimplementedMessageConverterServiceServer()
}

// UnimplementedMessageConverterServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedMessageConverterServiceServer struct{}

func (UnimplementedMessageConverterServiceServer) Convert(context.Context, *RawInput) (*UnmarshaledMessage, error) {
	return nil, status.Error(codes.Unimplemented, "method Convert not implemented")
}
func (UnimplementedMessageConverterServiceServer) mustEmbedUnimplementedMessageConverterServiceServer() {
}
func (UnimplementedMessageConverterServiceServer) testEmbeddedByValue() {}

// UnsafeMessageConverterServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to MessageConverterServiceServer will
// result in compilation errors.
type UnsafeMessageConverterServiceServer interface {
	mustEmbedUnimplementedMessageConverterServiceServer()
}

func RegisterMessageConverterServiceServer(s grpc.ServiceRegistrar, srv MessageConverterServiceServer) {
	// If the following call panics, it indicates UnimplementedMessageConverterServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&MessageConverterService_ServiceDesc, srv)
}

func _MessageConverterService_Convert_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(RawInput)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(MessageConverterServiceServer).Convert(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: MessageConverterService_Convert_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(MessageConverterServiceServer).Convert(ctx, req.(*RawInput))
	}
	return interceptor(ctx, in, info, handler)
}

// MessageConverterService_ServiceDesc is the grpc.ServiceDesc for MessageConverterService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var MessageConverterService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "libraryv1.MessageConverterService",
	HandlerType: (*MessageConverterServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Convert",
			Handler:    _MessageConverterService_Convert_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "api/proto/v1/library.proto",
}

const (
	LibraryService_SearchBooks_FullMethodName = "/libraryv1.LibraryService/SearchBooks"
	LibraryService_GetAuthors_FullMethodName  = "/libraryv1.LibraryService/GetAuthors"
)

// LibraryServiceClient is the client API for LibraryService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
//
// Legacy
type LibraryServiceClient interface {
	SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
	GetAuthors(ctx context.Context, in *ListRequest, opts ...grpc.CallOption) (*ListResponse, error)
}

type libraryServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewLibraryServiceClient(cc grpc.ClientConnInterface) LibraryServiceClient {
	return &libraryServiceClient{cc}
}

func (c *libraryServiceClient) SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(SearchResponse)
	err := c.cc.Invoke(ctx, LibraryService_SearchBooks_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *libraryServiceClient) GetAuthors(ctx context.Context, in *ListRequest, opts ...grpc.CallOption) (*ListResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(ListResponse)
	err := c.cc.Invoke(ctx, LibraryService_GetAuthors_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// LibraryServiceServer is the server API for LibraryService service.
// All implementations must embed UnimplementedLibraryServiceServer
// for forward compatibility.
//
// Legacy
type LibraryServiceServer interface {
	SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error)
	GetAuthors(context.Context, *ListRequest) (*ListResponse, error)
	mustEmbedUnimplementedLibraryServiceServer()
}

// UnimplementedLibraryServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedLibraryServiceServer struct{}

func (UnimplementedLibraryServiceServer) SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method SearchBooks not implemented")
}
func (UnimplementedLibraryServiceServer) GetAuthors(context.Context, *ListRequest) (*ListResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method GetAuthors not implemented")
}
func (UnimplementedLibraryServiceServer) mustEmbedUnimplementedLibraryServiceServer() {}
func (UnimplementedLibraryServiceServer) testEmbeddedByValue()                        {}

// UnsafeLibraryServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to LibraryServiceServer will
// result in compilation errors.
type UnsafeLibraryServiceServer interface {
	mustEmbedUnimplementedLibraryServiceServer()
}

func RegisterLibraryServiceServer(s grpc.ServiceRegistrar, srv LibraryServiceServer) {
	// If the following call panics, it indicates UnimplementedLibraryServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&LibraryService_ServiceDesc, srv)
}

func _LibraryService_SearchBooks_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SearchRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(LibraryServiceServer).SearchBooks(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: LibraryService_SearchBooks_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(LibraryServiceServer).SearchBooks(ctx, req.(*SearchRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _LibraryService_GetAuthors_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ListRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(LibraryServiceServer).GetAuthors(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: LibraryService_GetAuthors_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(LibraryServiceServer).GetAuthors(ctx, req.(*ListRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// LibraryService_ServiceDesc is the grpc.ServiceDesc for LibraryService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var LibraryService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "libraryv1.LibraryService",
	HandlerType: (*LibraryServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "SearchBooks",
			Handler:    _LibraryService_SearchBooks_Handler,
		},
		{
			MethodName: "GetAuthors",
			Handler:    _LibraryService_GetAuthors_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "api/proto/v1/library.proto",
}

--- END_FILE: ./api/proto/v1/library_grpc.pb.go ---

--- START_FILE: ./api/proto/v1/lisp_library.proto ---
syntax = "proto3";
package libraryv1;

message FilterNode {
  string field = 1;
  string value = 2;
  int32 operator = 3;
}

message LogicalNode {
  repeated SearchQuery nodes = 1;
}

message NotNode {
  SearchQuery node = 1;
}

message SearchQuery {
  FilterNode filter = 1;
  LogicalNode logical = 2;
  NotNode negation = 3;
}

--- END_FILE: ./api/proto/v1/lisp_library.proto ---

--- START_FILE: ./api/proto/v1/library.pb.go ---
// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v3.21.12
// source: api/proto/v1/library.proto

package libraryv1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type LogicalOp int32

const (
	LogicalOp_AND LogicalOp = 0
	LogicalOp_OR  LogicalOp = 1
	LogicalOp_NOT LogicalOp = 2
)

// Enum value maps for LogicalOp.
var (
	LogicalOp_name = map[int32]string{
		0: "AND",
		1: "OR",
		2: "NOT",
	}
	LogicalOp_value = map[string]int32{
		"AND": 0,
		"OR":  1,
		"NOT": 2,
	}
)

func (x LogicalOp) Enum() *LogicalOp {
	p := new(LogicalOp)
	*p = x
	return p
}

func (x LogicalOp) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (LogicalOp) Descriptor() protoreflect.EnumDescriptor {
	return file_api_proto_v1_library_proto_enumTypes[0].Descriptor()
}

func (LogicalOp) Type() protoreflect.EnumType {
	return &file_api_proto_v1_library_proto_enumTypes[0]
}

func (x LogicalOp) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use LogicalOp.Descriptor instead.
func (LogicalOp) EnumDescriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{0}
}

type Operator int32

const (
	Operator_OP_EQUALS   Operator = 0
	Operator_OP_CONTAINS Operator = 1
	Operator_OP_REGEX    Operator = 2
)

// Enum value maps for Operator.
var (
	Operator_name = map[int32]string{
		0: "OP_EQUALS",
		1: "OP_CONTAINS",
		2: "OP_REGEX",
	}
	Operator_value = map[string]int32{
		"OP_EQUALS":   0,
		"OP_CONTAINS": 1,
		"OP_REGEX":    2,
	}
)

func (x Operator) Enum() *Operator {
	p := new(Operator)
	*p = x
	return p
}

func (x Operator) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Operator) Descriptor() protoreflect.EnumDescriptor {
	return file_api_proto_v1_library_proto_enumTypes[1].Descriptor()
}

func (Operator) Type() protoreflect.EnumType {
	return &file_api_proto_v1_library_proto_enumTypes[1]
}

func (x Operator) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Operator.Descriptor instead.
func (Operator) EnumDescriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{1}
}

type SearchRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Query         string                 `protobuf:"bytes,1,opt,name=query,proto3" json:"query,omitempty"`
	TemplateId    string                 `protobuf:"bytes,2,opt,name=template_id,json=templateId,proto3" json:"template_id,omitempty"`
	Limit         int32                  `protobuf:"varint,3,opt,name=limit,proto3" json:"limit,omitempty"`
	Offset        int32                  `protobuf:"varint,4,opt,name=offset,proto3" json:"offset,omitempty"`
	TraceId       string                 `protobuf:"bytes,5,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SearchRequest) Reset() {
	*x = SearchRequest{}
	mi := &file_api_proto_v1_library_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SearchRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SearchRequest) ProtoMessage() {}

func (x *SearchRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SearchRequest.ProtoReflect.Descriptor instead.
func (*SearchRequest) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{0}
}

func (x *SearchRequest) GetQuery() string {
	if x != nil {
		return x.Query
	}
	return ""
}

func (x *SearchRequest) GetTemplateId() string {
	if x != nil {
		return x.TemplateId
	}
	return ""
}

func (x *SearchRequest) GetLimit() int32 {
	if x != nil {
		return x.Limit
	}
	return 0
}

func (x *SearchRequest) GetOffset() int32 {
	if x != nil {
		return x.Offset
	}
	return 0
}

func (x *SearchRequest) GetTraceId() string {
	if x != nil {
		return x.TraceId
	}
	return ""
}

type SearchResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Status        string                 `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
	Total         int32                  `protobuf:"varint,2,opt,name=total,proto3" json:"total,omitempty"`
	Books         []*Book                `protobuf:"bytes,3,rep,name=books,proto3" json:"books,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SearchResponse) Reset() {
	*x = SearchResponse{}
	mi := &file_api_proto_v1_library_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SearchResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SearchResponse) ProtoMessage() {}

func (x *SearchResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SearchResponse.ProtoReflect.Descriptor instead.
func (*SearchResponse) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{1}
}

func (x *SearchResponse) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *SearchResponse) GetTotal() int32 {
	if x != nil {
		return x.Total
	}
	return 0
}

func (x *SearchResponse) GetBooks() []*Book {
	if x != nil {
		return x.Books
	}
	return nil
}

type Book struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	Title         string                 `protobuf:"bytes,2,opt,name=title,proto3" json:"title,omitempty"`
	Authors       []string               `protobuf:"bytes,3,rep,name=authors,proto3" json:"authors,omitempty"`
	Container     string                 `protobuf:"bytes,4,opt,name=container,proto3" json:"container,omitempty"`
	Filename      string                 `protobuf:"bytes,5,opt,name=filename,proto3" json:"filename,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Book) Reset() {
	*x = Book{}
	mi := &file_api_proto_v1_library_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Book) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Book) ProtoMessage() {}

func (x *Book) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Book.ProtoReflect.Descriptor instead.
func (*Book) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{2}
}

func (x *Book) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *Book) GetTitle() string {
	if x != nil {
		return x.Title
	}
	return ""
}

func (x *Book) GetAuthors() []string {
	if x != nil {
		return x.Authors
	}
	return nil
}

func (x *Book) GetContainer() string {
	if x != nil {
		return x.Container
	}
	return ""
}

func (x *Book) GetFilename() string {
	if x != nil {
		return x.Filename
	}
	return ""
}

type ListRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Query         string                 `protobuf:"bytes,1,opt,name=query,proto3" json:"query,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListRequest) Reset() {
	*x = ListRequest{}
	mi := &file_api_proto_v1_library_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListRequest) ProtoMessage() {}

func (x *ListRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListRequest.ProtoReflect.Descriptor instead.
func (*ListRequest) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{3}
}

func (x *ListRequest) GetQuery() string {
	if x != nil {
		return x.Query
	}
	return ""
}

type ListResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Items         []string               `protobuf:"bytes,1,rep,name=items,proto3" json:"items,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListResponse) Reset() {
	*x = ListResponse{}
	mi := &file_api_proto_v1_library_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListResponse) ProtoMessage() {}

func (x *ListResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListResponse.ProtoReflect.Descriptor instead.
func (*ListResponse) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{4}
}

func (x *ListResponse) GetItems() []string {
	if x != nil {
		return x.Items
	}
	return nil
}

type AccessRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	UserId        string                 `protobuf:"bytes,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`
	Platform      string                 `protobuf:"bytes,2,opt,name=platform,proto3" json:"platform,omitempty"`
	TraceId       string                 `protobuf:"bytes,3,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AccessRequest) Reset() {
	*x = AccessRequest{}
	mi := &file_api_proto_v1_library_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AccessRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AccessRequest) ProtoMessage() {}

func (x *AccessRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AccessRequest.ProtoReflect.Descriptor instead.
func (*AccessRequest) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{5}
}

func (x *AccessRequest) GetUserId() string {
	if x != nil {
		return x.UserId
	}
	return ""
}

func (x *AccessRequest) GetPlatform() string {
	if x != nil {
		return x.Platform
	}
	return ""
}

func (x *AccessRequest) GetTraceId() string {
	if x != nil {
		return x.TraceId
	}
	return ""
}

type AccessResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Allowed       bool                   `protobuf:"varint,1,opt,name=allowed,proto3" json:"allowed,omitempty"`
	Reason        string                 `protobuf:"bytes,2,opt,name=reason,proto3" json:"reason,omitempty"`
	UserRole      string                 `protobuf:"bytes,3,opt,name=user_role,json=userRole,proto3" json:"user_role,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AccessResponse) Reset() {
	*x = AccessResponse{}
	mi := &file_api_proto_v1_library_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AccessResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AccessResponse) ProtoMessage() {}

func (x *AccessResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AccessResponse.ProtoReflect.Descriptor instead.
func (*AccessResponse) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{6}
}

func (x *AccessResponse) GetAllowed() bool {
	if x != nil {
		return x.Allowed
	}
	return false
}

func (x *AccessResponse) GetReason() string {
	if x != nil {
		return x.Reason
	}
	return ""
}

func (x *AccessResponse) GetUserRole() string {
	if x != nil {
		return x.UserRole
	}
	return ""
}

type RawInput struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Исправлено: переименовано в 'data', чтобы появился метод GetData(), который ждет message-converter
	Data          string `protobuf:"bytes,1,opt,name=data,proto3" json:"data,omitempty"`
	TraceId       string `protobuf:"bytes,2,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RawInput) Reset() {
	*x = RawInput{}
	mi := &file_api_proto_v1_library_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RawInput) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RawInput) ProtoMessage() {}

func (x *RawInput) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RawInput.ProtoReflect.Descriptor instead.
func (*RawInput) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{7}
}

func (x *RawInput) GetData() string {
	if x != nil {
		return x.Data
	}
	return ""
}

func (x *RawInput) GetTraceId() string {
	if x != nil {
		return x.TraceId
	}
	return ""
}

type MessageMeta struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	TraceId       string                 `protobuf:"bytes,1,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
	CanonicalForm string                 `protobuf:"bytes,2,opt,name=canonical_form,json=canonicalForm,proto3" json:"canonical_form,omitempty"`
	Platform      string                 `protobuf:"bytes,3,opt,name=platform,proto3" json:"platform,omitempty"`
	UserId        string                 `protobuf:"bytes,4,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`
	// Исправлено: добавлено поле, которое требует message-converter
	AstPlan       string `protobuf:"bytes,5,opt,name=ast_plan,json=astPlan,proto3" json:"ast_plan,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MessageMeta) Reset() {
	*x = MessageMeta{}
	mi := &file_api_proto_v1_library_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MessageMeta) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MessageMeta) ProtoMessage() {}

func (x *MessageMeta) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MessageMeta.ProtoReflect.Descriptor instead.
func (*MessageMeta) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{8}
}

func (x *MessageMeta) GetTraceId() string {
	if x != nil {
		return x.TraceId
	}
	return ""
}

func (x *MessageMeta) GetCanonicalForm() string {
	if x != nil {
		return x.CanonicalForm
	}
	return ""
}

func (x *MessageMeta) GetPlatform() string {
	if x != nil {
		return x.Platform
	}
	return ""
}

func (x *MessageMeta) GetUserId() string {
	if x != nil {
		return x.UserId
	}
	return ""
}

func (x *MessageMeta) GetAstPlan() string {
	if x != nil {
		return x.AstPlan
	}
	return ""
}

type UnmarshaledMessage struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Meta          *MessageMeta           `protobuf:"bytes,1,opt,name=meta,proto3" json:"meta,omitempty"`
	Query         *SearchQuery           `protobuf:"bytes,2,opt,name=query,proto3" json:"query,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UnmarshaledMessage) Reset() {
	*x = UnmarshaledMessage{}
	mi := &file_api_proto_v1_library_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UnmarshaledMessage) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UnmarshaledMessage) ProtoMessage() {}

func (x *UnmarshaledMessage) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UnmarshaledMessage.ProtoReflect.Descriptor instead.
func (*UnmarshaledMessage) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{9}
}

func (x *UnmarshaledMessage) GetMeta() *MessageMeta {
	if x != nil {
		return x.Meta
	}
	return nil
}

func (x *UnmarshaledMessage) GetQuery() *SearchQuery {
	if x != nil {
		return x.Query
	}
	return nil
}

type Response struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Status        string                 `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
	Books         []*Book                `protobuf:"bytes,2,rep,name=books,proto3" json:"books,omitempty"`
	Meta          *ResponseMeta          `protobuf:"bytes,3,opt,name=meta,proto3" json:"meta,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Response) Reset() {
	*x = Response{}
	mi := &file_api_proto_v1_library_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Response) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Response) ProtoMessage() {}

func (x *Response) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Response.ProtoReflect.Descriptor instead.
func (*Response) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{10}
}

func (x *Response) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *Response) GetBooks() []*Book {
	if x != nil {
		return x.Books
	}
	return nil
}

func (x *Response) GetMeta() *ResponseMeta {
	if x != nil {
		return x.Meta
	}
	return nil
}

type ResponseMeta struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	TraceId       string                 `protobuf:"bytes,1,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
	CanonicalForm string                 `protobuf:"bytes,2,opt,name=canonical_form,json=canonicalForm,proto3" json:"canonical_form,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ResponseMeta) Reset() {
	*x = ResponseMeta{}
	mi := &file_api_proto_v1_library_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ResponseMeta) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ResponseMeta) ProtoMessage() {}

func (x *ResponseMeta) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ResponseMeta.ProtoReflect.Descriptor instead.
func (*ResponseMeta) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{11}
}

func (x *ResponseMeta) GetTraceId() string {
	if x != nil {
		return x.TraceId
	}
	return ""
}

func (x *ResponseMeta) GetCanonicalForm() string {
	if x != nil {
		return x.CanonicalForm
	}
	return ""
}

type SearchQuery struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Node:
	//
	//	*SearchQuery_Filter
	//	*SearchQuery_Logical
	//	*SearchQuery_Negation
	Node          isSearchQuery_Node `protobuf_oneof:"node"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SearchQuery) Reset() {
	*x = SearchQuery{}
	mi := &file_api_proto_v1_library_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SearchQuery) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SearchQuery) ProtoMessage() {}

func (x *SearchQuery) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SearchQuery.ProtoReflect.Descriptor instead.
func (*SearchQuery) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{12}
}

func (x *SearchQuery) GetNode() isSearchQuery_Node {
	if x != nil {
		return x.Node
	}
	return nil
}

func (x *SearchQuery) GetFilter() *FilterNode {
	if x != nil {
		if x, ok := x.Node.(*SearchQuery_Filter); ok {
			return x.Filter
		}
	}
	return nil
}

func (x *SearchQuery) GetLogical() *LogicalNode {
	if x != nil {
		if x, ok := x.Node.(*SearchQuery_Logical); ok {
			return x.Logical
		}
	}
	return nil
}

func (x *SearchQuery) GetNegation() *NotNode {
	if x != nil {
		if x, ok := x.Node.(*SearchQuery_Negation); ok {
			return x.Negation
		}
	}
	return nil
}

type isSearchQuery_Node interface {
	isSearchQuery_Node()
}

type SearchQuery_Filter struct {
	Filter *FilterNode `protobuf:"bytes,1,opt,name=filter,proto3,oneof"`
}

type SearchQuery_Logical struct {
	Logical *LogicalNode `protobuf:"bytes,2,opt,name=logical,proto3,oneof"`
}

type SearchQuery_Negation struct {
	Negation *NotNode `protobuf:"bytes,3,opt,name=negation,proto3,oneof"`
}

func (*SearchQuery_Filter) isSearchQuery_Node() {}

func (*SearchQuery_Logical) isSearchQuery_Node() {}

func (*SearchQuery_Negation) isSearchQuery_Node() {}

type FilterNode struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Field         string                 `protobuf:"bytes,1,opt,name=field,proto3" json:"field,omitempty"`
	Value         string                 `protobuf:"bytes,2,opt,name=value,proto3" json:"value,omitempty"`
	Operator      Operator               `protobuf:"varint,3,opt,name=operator,proto3,enum=libraryv1.Operator" json:"operator,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FilterNode) Reset() {
	*x = FilterNode{}
	mi := &file_api_proto_v1_library_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FilterNode) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FilterNode) ProtoMessage() {}

func (x *FilterNode) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FilterNode.ProtoReflect.Descriptor instead.
func (*FilterNode) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{13}
}

func (x *FilterNode) GetField() string {
	if x != nil {
		return x.Field
	}
	return ""
}

func (x *FilterNode) GetValue() string {
	if x != nil {
		return x.Value
	}
	return ""
}

func (x *FilterNode) GetOperator() Operator {
	if x != nil {
		return x.Operator
	}
	return Operator_OP_EQUALS
}

type LogicalNode struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Op            LogicalOp              `protobuf:"varint,1,opt,name=op,proto3,enum=libraryv1.LogicalOp" json:"op,omitempty"`
	Nodes         []*SearchQuery         `protobuf:"bytes,2,rep,name=nodes,proto3" json:"nodes,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LogicalNode) Reset() {
	*x = LogicalNode{}
	mi := &file_api_proto_v1_library_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LogicalNode) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LogicalNode) ProtoMessage() {}

func (x *LogicalNode) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LogicalNode.ProtoReflect.Descriptor instead.
func (*LogicalNode) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{14}
}

func (x *LogicalNode) GetOp() LogicalOp {
	if x != nil {
		return x.Op
	}
	return LogicalOp_AND
}

func (x *LogicalNode) GetNodes() []*SearchQuery {
	if x != nil {
		return x.Nodes
	}
	return nil
}

type NotNode struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Важно: имя поля 'node' генерирует поле 'Node' в Go структуре, что нужно парсеру
	Node          *SearchQuery `protobuf:"bytes,1,opt,name=node,proto3" json:"node,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *NotNode) Reset() {
	*x = NotNode{}
	mi := &file_api_proto_v1_library_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *NotNode) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*NotNode) ProtoMessage() {}

func (x *NotNode) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use NotNode.ProtoReflect.Descriptor instead.
func (*NotNode) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{15}
}

func (x *NotNode) GetNode() *SearchQuery {
	if x != nil {
		return x.Node
	}
	return nil
}

var File_api_proto_v1_library_proto protoreflect.FileDescriptor

const file_api_proto_v1_library_proto_rawDesc = "" +
	"\n" +
	"\x1aapi/proto/v1/library.proto\x12\tlibraryv1\"\x8f\x01\n" +
	"\rSearchRequest\x12\x14\n" +
	"\x05query\x18\x01 \x01(\tR\x05query\x12\x1f\n" +
	"\vtemplate_id\x18\x02 \x01(\tR\n" +
	"templateId\x12\x14\n" +
	"\x05limit\x18\x03 \x01(\x05R\x05limit\x12\x16\n" +
	"\x06offset\x18\x04 \x01(\x05R\x06offset\x12\x19\n" +
	"\btrace_id\x18\x05 \x01(\tR\atraceId\"e\n" +
	"\x0eSearchResponse\x12\x16\n" +
	"\x06status\x18\x01 \x01(\tR\x06status\x12\x14\n" +
	"\x05total\x18\x02 \x01(\x05R\x05total\x12%\n" +
	"\x05books\x18\x03 \x03(\v2\x0f.libraryv1.BookR\x05books\"\x80\x01\n" +
	"\x04Book\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12\x14\n" +
	"\x05title\x18\x02 \x01(\tR\x05title\x12\x18\n" +
	"\aauthors\x18\x03 \x03(\tR\aauthors\x12\x1c\n" +
	"\tcontainer\x18\x04 \x01(\tR\tcontainer\x12\x1a\n" +
	"\bfilename\x18\x05 \x01(\tR\bfilename\"#\n" +
	"\vListRequest\x12\x14\n" +
	"\x05query\x18\x01 \x01(\tR\x05query\"$\n" +
	"\fListResponse\x12\x14\n" +
	"\x05items\x18\x01 \x03(\tR\x05items\"_\n" +
	"\rAccessRequest\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\tR\x06userId\x12\x1a\n" +
	"\bplatform\x18\x02 \x01(\tR\bplatform\x12\x19\n" +
	"\btrace_id\x18\x03 \x01(\tR\atraceId\"_\n" +
	"\x0eAccessResponse\x12\x18\n" +
	"\aallowed\x18\x01 \x01(\bR\aallowed\x12\x16\n" +
	"\x06reason\x18\x02 \x01(\tR\x06reason\x12\x1b\n" +
	"\tuser_role\x18\x03 \x01(\tR\buserRole\"9\n" +
	"\bRawInput\x12\x12\n" +
	"\x04data\x18\x01 \x01(\tR\x04data\x12\x19\n" +
	"\btrace_id\x18\x02 \x01(\tR\atraceId\"\x9f\x01\n" +
	"\vMessageMeta\x12\x19\n" +
	"\btrace_id\x18\x01 \x01(\tR\atraceId\x12%\n" +
	"\x0ecanonical_form\x18\x02 \x01(\tR\rcanonicalForm\x12\x1a\n" +
	"\bplatform\x18\x03 \x01(\tR\bplatform\x12\x17\n" +
	"\auser_id\x18\x04 \x01(\tR\x06userId\x12\x19\n" +
	"\bast_plan\x18\x05 \x01(\tR\aastPlan\"n\n" +
	"\x12UnmarshaledMessage\x12*\n" +
	"\x04meta\x18\x01 \x01(\v2\x16.libraryv1.MessageMetaR\x04meta\x12,\n" +
	"\x05query\x18\x02 \x01(\v2\x16.libraryv1.SearchQueryR\x05query\"v\n" +
	"\bResponse\x12\x16\n" +
	"\x06status\x18\x01 \x01(\tR\x06status\x12%\n" +
	"\x05books\x18\x02 \x03(\v2\x0f.libraryv1.BookR\x05books\x12+\n" +
	"\x04meta\x18\x03 \x01(\v2\x17.libraryv1.ResponseMetaR\x04meta\"P\n" +
	"\fResponseMeta\x12\x19\n" +
	"\btrace_id\x18\x01 \x01(\tR\atraceId\x12%\n" +
	"\x0ecanonical_form\x18\x02 \x01(\tR\rcanonicalForm\"\xac\x01\n" +
	"\vSearchQuery\x12/\n" +
	"\x06filter\x18\x01 \x01(\v2\x15.libraryv1.FilterNodeH\x00R\x06filter\x122\n" +
	"\alogical\x18\x02 \x01(\v2\x16.libraryv1.LogicalNodeH\x00R\alogical\x120\n" +
	"\bnegation\x18\x03 \x01(\v2\x12.libraryv1.NotNodeH\x00R\bnegationB\x06\n" +
	"\x04node\"i\n" +
	"\n" +
	"FilterNode\x12\x14\n" +
	"\x05field\x18\x01 \x01(\tR\x05field\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value\x12/\n" +
	"\boperator\x18\x03 \x01(\x0e2\x13.libraryv1.OperatorR\boperator\"a\n" +
	"\vLogicalNode\x12$\n" +
	"\x02op\x18\x01 \x01(\x0e2\x14.libraryv1.LogicalOpR\x02op\x12,\n" +
	"\x05nodes\x18\x02 \x03(\v2\x16.libraryv1.SearchQueryR\x05nodes\"5\n" +
	"\aNotNode\x12*\n" +
	"\x04node\x18\x01 \x01(\v2\x16.libraryv1.SearchQueryR\x04node*%\n" +
	"\tLogicalOp\x12\a\n" +
	"\x03AND\x10\x00\x12\x06\n" +
	"\x02OR\x10\x01\x12\a\n" +
	"\x03NOT\x10\x02*8\n" +
	"\bOperator\x12\r\n" +
	"\tOP_EQUALS\x10\x00\x12\x0f\n" +
	"\vOP_CONTAINS\x10\x01\x12\f\n" +
	"\bOP_REGEX\x10\x022T\n" +
	"\x13OrchestratorService\x12=\n" +
	"\x06Search\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse2R\n" +
	"\x10ProcessorService\x12>\n" +
	"\aProcess\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse2T\n" +
	"\x0eStorageService\x12B\n" +
	"\vSearchBooks\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse2Q\n" +
	"\vAuthService\x12B\n" +
	"\vCheckAccess\x12\x18.libraryv1.AccessRequest\x1a\x19.libraryv1.AccessResponse2X\n" +
	"\x17MessageConverterService\x12=\n" +
	"\aConvert\x12\x13.libraryv1.RawInput\x1a\x1d.libraryv1.UnmarshaledMessage2\x93\x01\n" +
	"\x0eLibraryService\x12B\n" +
	"\vSearchBooks\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse\x12=\n" +
	"\n" +
	"GetAuthors\x12\x16.libraryv1.ListRequest\x1a\x17.libraryv1.ListResponseB\x1fZ\x1debusta/api/proto/v1;libraryv1b\x06proto3"

var (
	file_api_proto_v1_library_proto_rawDescOnce sync.Once
	file_api_proto_v1_library_proto_rawDescData []byte
)

func file_api_proto_v1_library_proto_rawDescGZIP() []byte {
	file_api_proto_v1_library_proto_rawDescOnce.Do(func() {
		file_api_proto_v1_library_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_api_proto_v1_library_proto_rawDesc), len(file_api_proto_v1_library_proto_rawDesc)))
	})
	return file_api_proto_v1_library_proto_rawDescData
}

var file_api_proto_v1_library_proto_enumTypes = make([]protoimpl.EnumInfo, 2)
var file_api_proto_v1_library_proto_msgTypes = make([]protoimpl.MessageInfo, 16)
var file_api_proto_v1_library_proto_goTypes = []any{
	(LogicalOp)(0),             // 0: libraryv1.LogicalOp
	(Operator)(0),              // 1: libraryv1.Operator
	(*SearchRequest)(nil),      // 2: libraryv1.SearchRequest
	(*SearchResponse)(nil),     // 3: libraryv1.SearchResponse
	(*Book)(nil),               // 4: libraryv1.Book
	(*ListRequest)(nil),        // 5: libraryv1.ListRequest
	(*ListResponse)(nil),       // 6: libraryv1.ListResponse
	(*AccessRequest)(nil),      // 7: libraryv1.AccessRequest
	(*AccessResponse)(nil),     // 8: libraryv1.AccessResponse
	(*RawInput)(nil),           // 9: libraryv1.RawInput
	(*MessageMeta)(nil),        // 10: libraryv1.MessageMeta
	(*UnmarshaledMessage)(nil), // 11: libraryv1.UnmarshaledMessage
	(*Response)(nil),           // 12: libraryv1.Response
	(*ResponseMeta)(nil),       // 13: libraryv1.ResponseMeta
	(*SearchQuery)(nil),        // 14: libraryv1.SearchQuery
	(*FilterNode)(nil),         // 15: libraryv1.FilterNode
	(*LogicalNode)(nil),        // 16: libraryv1.LogicalNode
	(*NotNode)(nil),            // 17: libraryv1.NotNode
}
var file_api_proto_v1_library_proto_depIdxs = []int32{
	4,  // 0: libraryv1.SearchResponse.books:type_name -> libraryv1.Book
	10, // 1: libraryv1.UnmarshaledMessage.meta:type_name -> libraryv1.MessageMeta
	14, // 2: libraryv1.UnmarshaledMessage.query:type_name -> libraryv1.SearchQuery
	4,  // 3: libraryv1.Response.books:type_name -> libraryv1.Book
	13, // 4: libraryv1.Response.meta:type_name -> libraryv1.ResponseMeta
	15, // 5: libraryv1.SearchQuery.filter:type_name -> libraryv1.FilterNode
	16, // 6: libraryv1.SearchQuery.logical:type_name -> libraryv1.LogicalNode
	17, // 7: libraryv1.SearchQuery.negation:type_name -> libraryv1.NotNode
	1,  // 8: libraryv1.FilterNode.operator:type_name -> libraryv1.Operator
	0,  // 9: libraryv1.LogicalNode.op:type_name -> libraryv1.LogicalOp
	14, // 10: libraryv1.LogicalNode.nodes:type_name -> libraryv1.SearchQuery
	14, // 11: libraryv1.NotNode.node:type_name -> libraryv1.SearchQuery
	2,  // 12: libraryv1.OrchestratorService.Search:input_type -> libraryv1.SearchRequest
	2,  // 13: libraryv1.ProcessorService.Process:input_type -> libraryv1.SearchRequest
	2,  // 14: libraryv1.StorageService.SearchBooks:input_type -> libraryv1.SearchRequest
	7,  // 15: libraryv1.AuthService.CheckAccess:input_type -> libraryv1.AccessRequest
	9,  // 16: libraryv1.MessageConverterService.Convert:input_type -> libraryv1.RawInput
	2,  // 17: libraryv1.LibraryService.SearchBooks:input_type -> libraryv1.SearchRequest
	5,  // 18: libraryv1.LibraryService.GetAuthors:input_type -> libraryv1.ListRequest
	3,  // 19: libraryv1.OrchestratorService.Search:output_type -> libraryv1.SearchResponse
	3,  // 20: libraryv1.ProcessorService.Process:output_type -> libraryv1.SearchResponse
	3,  // 21: libraryv1.StorageService.SearchBooks:output_type -> libraryv1.SearchResponse
	8,  // 22: libraryv1.AuthService.CheckAccess:output_type -> libraryv1.AccessResponse
	11, // 23: libraryv1.MessageConverterService.Convert:output_type -> libraryv1.UnmarshaledMessage
	3,  // 24: libraryv1.LibraryService.SearchBooks:output_type -> libraryv1.SearchResponse
	6,  // 25: libraryv1.LibraryService.GetAuthors:output_type -> libraryv1.ListResponse
	19, // [19:26] is the sub-list for method output_type
	12, // [12:19] is the sub-list for method input_type
	12, // [12:12] is the sub-list for extension type_name
	12, // [12:12] is the sub-list for extension extendee
	0,  // [0:12] is the sub-list for field type_name
}

func init() { file_api_proto_v1_library_proto_init() }
func file_api_proto_v1_library_proto_init() {
	if File_api_proto_v1_library_proto != nil {
		return
	}
	file_api_proto_v1_library_proto_msgTypes[12].OneofWrappers = []any{
		(*SearchQuery_Filter)(nil),
		(*SearchQuery_Logical)(nil),
		(*SearchQuery_Negation)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_api_proto_v1_library_proto_rawDesc), len(file_api_proto_v1_library_proto_rawDesc)),
			NumEnums:      2,
			NumMessages:   16,
			NumExtensions: 0,
			NumServices:   6,
		},
		GoTypes:           file_api_proto_v1_library_proto_goTypes,
		DependencyIndexes: file_api_proto_v1_library_proto_depIdxs,
		EnumInfos:         file_api_proto_v1_library_proto_enumTypes,
		MessageInfos:      file_api_proto_v1_library_proto_msgTypes,
	}.Build()
	File_api_proto_v1_library_proto = out.File
	file_api_proto_v1_library_proto_goTypes = nil
	file_api_proto_v1_library_proto_depIdxs = nil
}

--- END_FILE: ./api/proto/v1/library.pb.go ---

--- START_FILE: ./api/proto/v1/library.proto ---
syntax = "proto3";

package libraryv1;

option go_package = "ebusta/api/proto/v1;libraryv1";

// ==========================================
// 1. SERVICES
// ==========================================

service OrchestratorService {
  rpc Search (SearchRequest) returns (SearchResponse);
}

service ProcessorService {
  rpc Process (SearchRequest) returns (SearchResponse);
}

service StorageService {
  rpc SearchBooks (SearchRequest) returns (SearchResponse);
}

service AuthService {
  rpc CheckAccess (AccessRequest) returns (AccessResponse);
}

service MessageConverterService {
  rpc Convert (RawInput) returns (UnmarshaledMessage);
}

// Legacy
service LibraryService {
  rpc SearchBooks (SearchRequest) returns (SearchResponse);
  rpc GetAuthors (ListRequest) returns (ListResponse);
}

// ==========================================
// 2. MESSAGES
// ==========================================

message SearchRequest {
  string query = 1;
  string template_id = 2;
  int32 limit = 3;
  int32 offset = 4;
  string trace_id = 5;
}

message SearchResponse {
  string status = 1;
  int32 total = 2;
  repeated Book books = 3;
}

message Book {
  string id = 1;
  string title = 2;
  repeated string authors = 3;
  string container = 4;
  string filename = 5;
}

message ListRequest {
  string query = 1;
}

message ListResponse {
  repeated string items = 1;
}

// --- AUTH ---

message AccessRequest {
  string user_id = 1;
  string platform = 2;
  string trace_id = 3;
}

message AccessResponse {
  bool allowed = 1;
  string reason = 2;
  string user_role = 3;
}

// ==========================================
// 3. CONVERTER & AST (Fixed for existing code)
// ==========================================

message RawInput {
  // Исправлено: переименовано в 'data', чтобы появился метод GetData(), который ждет message-converter
  string data = 1; 
  string trace_id = 2;
}

message MessageMeta {
  string trace_id = 1;
  string canonical_form = 2;
  string platform = 3;
  string user_id = 4;
  // Исправлено: добавлено поле, которое требует message-converter
  string ast_plan = 5; 
}

message UnmarshaledMessage {
  MessageMeta meta = 1;
  SearchQuery query = 2;
}

message Response {
  string status = 1;
  repeated Book books = 2;
  ResponseMeta meta = 3;
}

message ResponseMeta {
  string trace_id = 1;
  string canonical_form = 2;
}

// --- AST NODES (Strictly for parser.go) ---

enum LogicalOp {
  AND = 0;
  OR = 1;
  NOT = 2;
}

enum Operator {
  OP_EQUALS = 0;
  OP_CONTAINS = 1;
  OP_REGEX = 2;
}

message SearchQuery {
  oneof node {
    FilterNode filter = 1;
    LogicalNode logical = 2;
    NotNode negation = 3;
  }
}

message FilterNode {
  string field = 1;
  string value = 2;
  Operator operator = 3;
}

message LogicalNode {
  LogicalOp op = 1;
  repeated SearchQuery nodes = 2;
}

message NotNode {
  // Важно: имя поля 'node' генерирует поле 'Node' в Go структуре, что нужно парсеру
  SearchQuery node = 1; 
}

--- END_FILE: ./api/proto/v1/library.proto ---

--- START_FILE: ./opensearch/templates/fl_authors_all.json ---
{
  "script": {
    "lang": "mustache",
    "source": "{\n  \"size\": 0,\n  \"aggs\": {\n    \"authors\": {\n      \"composite\": {\n        \"size\": {{size}},\n        \"sources\": [ { \"a\": { \"terms\": { \"field\": \"authors.kw\" } } } ]{{#after}},\n        \"after\": {{after}}{{/after}}\n      }\n    }\n  }\n}\n"
  }
}


--- END_FILE: ./opensearch/templates/fl_authors_all.json ---

--- START_FILE: ./opensearch/templates/fl_author_fuzzy.json ---
{
  "script": {
    "lang": "mustache",
    "source": {
      "query": {
        "match": {
          "authors": {
            "query": "{{author}}",
            "operator": "and"
          }
        }
      },
      "size": "{{size}}",
      "from": "{{from}}",
      "_source": ["title", "authors", "fileInfo.container", "fileInfo.filename"],
      "track_total_hits": false
    }
  }
}

--- END_FILE: ./opensearch/templates/fl_author_fuzzy.json ---

--- START_FILE: ./opensearch/templates/fl_author_exact.json ---
{
  "script": {
    "lang": "mustache",
    "source": {
      "query": { "term": { "authors.kw": "{{author}}" } },
      "collapse": { "field": "title.kw", "inner_hits": { "name": "best", "size": 1, "sort": [{"fileInfo.size": "desc"}] } },
      "size": "{{size}}{{^size}}20{{/size}}"
    }
  }
}

--- END_FILE: ./opensearch/templates/fl_author_exact.json ---

--- START_FILE: ./opensearch/templates/fl_names_token_prefix.json ---
{
  "script": {
    "lang": "mustache",
    "source": "{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        { \"multi_match\": { \"query\": \"{{query}}\", \"type\": \"phrase_prefix\", \"fields\": [\"authors^3\",\"title^1\"] } },\n        { \"match\": { \"authors.prefix\": { \"query\": \"{{query}}\", \"boost\": 4 } } },\n        { \"match\": { \"title.prefix\":   { \"query\": \"{{query}}\", \"boost\": 2 } } }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"size\": {{size}},\n  \"from\": {{from}},\n  \"sort\": [{ \"title.kw\": { \"order\": \"asc\" } }],\n  \"track_total_hits\": false,\n  \"_source\": [\"title\",\"authors\",\"fileInfo.container\",\"fileInfo.filename\"],\n  \"highlight\": { \"fields\": { \"authors\": {}, \"title\": {} } }\n}"
  }
}
--- END_FILE: ./opensearch/templates/fl_names_token_prefix.json ---

--- START_FILE: ./opensearch/templates/fl_title_match.json ---
{
  "script": {
    "lang": "mustache",
    "source": {
      "query": {
        "match": {
          "title": {
            "query": "{{query}}",
            "operator": "and"
          }
        }
      },
      "from": "{{from}}",
      "size": "{{size}}"
    }
  }
}

--- END_FILE: ./opensearch/templates/fl_title_match.json ---

--- START_FILE: ./opensearch/templates/fl_title_substring.json ---
{
  "script": {
    "lang": "mustache",
    "source": "{\n  \"from\": 0,\n  \"size\": {{size}},\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"*{{query}}*\",\n      \"fields\": [\"title.kw\", \"authors.kw\"],\n      \"analyze_wildcard\": true,\n      \"default_operator\": \"and\"\n    }\n  },\n  \"_source\": [\"title\", \"authors\", \"year\", \"fileInfo.container\", \"fileInfo.filename\"]\n}\n"
  }
}


--- END_FILE: ./opensearch/templates/fl_title_substring.json ---

--- START_FILE: ./opensearch/templates/fl_title_prefix.json ---
{
  "script": {
    "lang": "mustache",
    "source": "{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        { \"match\": { \"title.prefix\": { \"query\": \"{{query}}\", \"boost\": 5 } } },\n        { \"match_phrase_prefix\": { \"title\": { \"query\": \"{{query}}\", \"boost\": 2 } } },\n        { \"term\": { \"title.kw\": { \"value\": \"{{query}}\", \"boost\": 20 } } }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"size\": {{size}},\n  \"from\": {{from}},\n  \"sort\": [{ \"title.kw\": { \"order\": \"asc\" } }],\n  \"track_total_hits\": false,\n  \"_source\": [\"title\",\"authors\",\"fileInfo.container\",\"fileInfo.filename\"],\n  \"highlight\": { \"fields\": { \"title\": {} } }\n}"
  }
}
--- END_FILE: ./opensearch/templates/fl_title_prefix.json ---

--- START_FILE: ./opensearch/templates/fl_mixed_search.json ---
{
  "script": {
    "lang": "mustache",
    "source": {
      "query": {
        "multi_match": {
          "query": "{{query}}",
          "fields": ["title^3", "authors", "annotation"],
          "type": "best_fields",
          "fuzziness": "AUTO"
        }
      },
      "collapse": {
        "field": "title.kw",
        "inner_hits": { "name": "best", "size": 1, "sort": [{"fileInfo.size": "desc"}] }
      },
      "from": "{{from}}{{^from}}0{{/from}}",
      "size": "{{size}}{{^size}}10{{/size}}"
    }
  }
}

--- END_FILE: ./opensearch/templates/fl_mixed_search.json ---

--- START_FILE: ./opensearch/templates/fl_titles_all.json ---
{
  "script": {
    "lang": "mustache",
    "source": "{\n  \"size\": 0,\n  \"aggs\": {\n    \"titles\": {\n      \"composite\": {\n        \"size\": {{size}},\n        \"sources\": [ { \"t\": { \"terms\": { \"field\": \"title.kw\" } } } ]{{#after}},\n        \"after\": {{after}}{{/after}}\n      }\n    }\n  }\n}\n"
  }
}


--- END_FILE: ./opensearch/templates/fl_titles_all.json ---

--- START_FILE: ./opensearch/flibusta_merged_index.fixed.json ---
{
  "settings": {
    "index": {
      "number_of_shards": 1,
      "number_of_replicas": 1,
      "refresh_interval": "1s"
    },
    "analysis": {
      "filter": {
        "ru_stop": {
          "type": "stop",
          "stopwords": "_russian_"
        },
        "ru_stemmer": {
          "type": "stemmer",
          "language": "russian"
        },
        "en_stop": {
          "type": "stop",
          "stopwords": "_english_"
        },
        "en_stemmer": {
          "type": "stemmer",
          "language": "english"
        },
        "shingle_2_3": {
          "type": "shingle",
          "min_shingle_size": 2,
          "max_shingle_size": 3
        }
      },
      "char_filter": {
        "quotes": {
          "type": "mapping",
          "mappings": [
            "“=>\"",
            "”=>\"",
            "‘=>'",
            "’=>'"
          ]
        }
      },
      "normalizer": {
        "lc_ascii": {
          "type": "custom",
          "filter": [
            "lowercase",
            "asciifolding"
          ]
        }
      },
      "analyzer": {
        "mixed_text": {
          "type": "custom",
          "tokenizer": "standard",
          "char_filter": [
            "quotes"
          ],
          "filter": [
            "lowercase",
            "ru_stop",
            "ru_stemmer",
            "en_stop",
            "en_stemmer"
          ]
        },
        "autocomplete": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase"
          ]
        },
        "autocomplete_edge": {
          "type": "custom",
          "tokenizer": "edge_ngram_tokenizer",
          "filter": [
            "lowercase"
          ]
        },
        "shingled": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "shingle_2_3"
          ]
        }
      },
      "tokenizer": {
        "edge_ngram_tokenizer": {
          "type": "edge_ngram",
          "min_gram": 2,
          "max_gram": 20,
          "token_chars": [
            "letter",
            "digit"
          ]
        }
      }
    }
  },
  "mappings": {
    "dynamic": "strict",
    "properties": {
      "id": {
        "type": "keyword"
      },
      "docId": {
        "type": "keyword"
      },
      "source": {
        "type": "keyword"
      },
      "ingestedAt": {
        "type": "date"
      },
      "title": {
        "type": "text",
        "analyzer": "mixed_text",
        "fields": {
          "kw": {
            "type": "keyword",
            "normalizer": "lc_ascii"
          },
          "ac": {
            "type": "text",
            "analyzer": "autocomplete_edge",
            "search_analyzer": "autocomplete"
          },
          "sh": {
            "type": "text",
            "analyzer": "shingled"
          }
        }
      },
      "authors": {
        "type": "text",
        "analyzer": "mixed_text",
        "fields": {
          "kw": {
            "type": "keyword",
            "normalizer": "lc_ascii"
          },
          "ac": {
            "type": "text",
            "analyzer": "autocomplete_edge",
            "search_analyzer": "autocomplete"
          }
        }
      },
      "genres": {
        "type": "keyword",
        "normalizer": "lc_ascii"
      },
      "languages": {
        "type": "keyword",
        "normalizer": "lc_ascii"
      },
      "year": {
        "type": "integer"
      },
      "annotation": {
        "type": "text",
        "analyzer": "mixed_text"
      },
      "sequences": {
        "type": "nested",
        "properties": {
          "name": {
            "type": "text",
            "analyzer": "mixed_text",
            "fields": {
              "kw": {
                "type": "keyword",
                "normalizer": "lc_ascii"
              },
              "ac": {
                "type": "text",
                "analyzer": "autocomplete_edge",
                "search_analyzer": "autocomplete"
              }
            }
          },
          "number": {
            "type": "float"
          }
        }
      },
      "fileInfo": {
        "type": "object",
        "properties": {
          "container": {
            "type": "keyword"
          },
          "filename": {
            "type": "keyword"
          },
          "size": {
            "type": "long"
          },
          "sha1": {
            "type": "keyword"
          }
        }
      },
      "suggest_title": {
        "type": "completion"
      },
      "suggest_author": {
        "type": "completion"
      }
    }
  }
}
--- END_FILE: ./opensearch/flibusta_merged_index.fixed.json ---

--- START_FILE: ./opensearch/os-setup-config.yaml ---
opensearch:
  url: "http://cloud-1:9200"
  index_name: "flibusta_merged_index"

paths:
  index_file: "./flibusta_merged_index.fixed.json"
  templates_dir: "./templates"

logging:
  log_path: "os-setup.log"

--- END_FILE: ./opensearch/os-setup-config.yaml ---

--- START_FILE: ./cmd/datamanager/main.go ---
package main

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net"
	"net/http"
	"os"

	"ebusta/api/proto/v1"
	"github.com/spf13/viper"
	"google.golang.org/grpc"
)

type storageServer struct {
	libraryv1.UnimplementedStorageServiceServer
	osBaseURL string
	indexName string
	debug     bool
}

func (s *storageServer) SearchBooks(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
	templateID := req.TemplateId
	if templateID == "" {
		templateID = "fl_mixed_search"
	}
	
	var paramName string
	switch templateID {
	case "fl_author_exact", "fl_author_fuzzy":
		paramName = "author"
	case "fl_title_substring", "fl_titles_all":
		paramName = "query"
	default:
		paramName = "query"
	}

	osReqBody := map[string]interface{}{
		"id": templateID,
		"params": map[string]interface{}{
			paramName: req.Query,
			"from":    0,
			"size":    req.Limit,
		},
	}
	
	if val, ok := osReqBody["params"].(map[string]interface{})["size"].(int32); ok && val == 0 {
		osReqBody["params"].(map[string]interface{})["size"] = 10
	}

	jsonData, _ := json.Marshal(osReqBody)
	targetURL := fmt.Sprintf("%s/%s/_search/template", s.osBaseURL, s.indexName)
	log.Printf("📤 [OS-REQ] URL: %s | BODY: %s", targetURL, string(jsonData))

	resp, err := http.Post(targetURL, "application/json", bytes.NewBuffer(jsonData))
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	body, _ := io.ReadAll(resp.Body)
	
	// ГИБКИЙ ПАРСИНГ: Total может быть числом, объектом или отсутствовать
	var osRaw struct {
		Hits struct {
			Total interface{} `json:"total"`
			Hits  []struct {
				Source struct {
					Title   string   `json:"title"`
					Authors []string `json:"authors"`
				} `json:"_source"`
				ID string `json:"_id"`
			} `json:"hits"`
		} `json:"hits"`
	}

	if err := json.Unmarshal(body, &osRaw); err != nil {
		log.Printf("❌ Storage parse error: %v", err)
		return &libraryv1.SearchResponse{Status: "error"}, nil
	}

	var totalValue int32
	switch v := osRaw.Hits.Total.(type) {
	case float64:
		totalValue = int32(v)
	case map[string]interface{}:
		if val, ok := v["value"].(float64); ok {
			totalValue = int32(val)
		}
	}

	res := &libraryv1.SearchResponse{}
	for _, hit := range osRaw.Hits.Hits {
		res.Books = append(res.Books, &libraryv1.Book{
			Id:      hit.ID,
			Title:   hit.Source.Title,
			Authors: hit.Source.Authors,
		})
	}

	// FALLBACK: Если хиты есть, а total 0 или не распарсился
	if totalValue == 0 && len(res.Books) > 0 {
		totalValue = int32(len(res.Books))
	}
	res.Total = totalValue

	log.Printf("📥 [OS-RESP] Found: %d books", totalValue)
	return res, nil
}

func main() {
	viper.SetConfigName("ebusta")
	viper.SetConfigType("yaml")
	viper.AddConfigPath(".")
	viper.ReadInConfig()

	osBaseURL := viper.GetString("datamanager.opensearch_url")
	indexName := viper.GetString("datamanager.index_name")
	debug := os.Getenv("DEBUG") != ""

	lis, err := net.Listen("tcp", ":50051")
	if err != nil { log.Fatalf("failed to listen: %v", err) }

	s := grpc.NewServer()
	libraryv1.RegisterStorageServiceServer(s, &storageServer{
		osBaseURL: osBaseURL,
		indexName: indexName,
		debug:     debug,
	})

	log.Println("💾 DataManager (Storage) started on :50051")
	s.Serve(lis)
}

--- END_FILE: ./cmd/datamanager/main.go ---

--- START_FILE: ./cmd/bulker/main.go ---
package main

import (
	"archive/zip"
	"bufio"
	"bytes"
	"crypto/sha1"
	"encoding/hex"
	"encoding/json"
	"encoding/xml"
	"flag"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"github.com/schollz/progressbar/v3"
	"github.com/sirupsen/logrus"
	"golang.org/x/text/encoding/charmap"
	"golang.org/x/text/encoding/unicode"
	"gopkg.in/yaml.v3"
)

type Config struct {
	OpenSearch struct {
		IndexName string `yaml:"index_name"`
	} `yaml:"opensearch"`
	Paths struct {
		WarnDir   string `yaml:"warn_dir"`
		OutputDir string `yaml:"output_dir"`
		SourceDir string `yaml:"source_dir"`
	} `yaml:"paths"`
	Processing struct {
		Threads int `yaml:"threads"`
	} `yaml:"processing"`
}

type docOut struct {
	Title      string    `json:"title"`
	Authors    []string  `json:"authors,omitempty"`
	IngestedAt time.Time `json:"ingestedAt"`
	FileInfo   struct {
		Container string `json:"container"`
		Filename  string `json:"filename"`
		Sha1      string `json:"sha1"`
		Size      int64  `json:"size"`
	} `json:"fileInfo"`
}

var (
	cfg          Config
	log          = logrus.New()
	outFile      *os.File
	outMu        sync.Mutex
	bar          *progressbar.ProgressBar
	rescuedCount int32
	// Флаги управления
	flagRescan  *bool
	flagVerbose *bool
)

func main() {
	configPath := flag.String("config", "./config.yaml", "Path to config file")
	container := flag.String("container", "", "Process only this specific ZIP from source_dir")
	rescue := flag.Bool("rescue", false, "Rescue mode")
	flagRescan = flag.Bool("rescan", false, "Force rescan all files ignoring existing output")
	flagVerbose = flag.Bool("verbose", false, "Detailed check by hashing every file")
	flag.Parse()

	cFile, err := os.ReadFile(*configPath)
	if err != nil {
		fmt.Printf("Error: Cannot read config file at %s\n", *configPath)
		os.Exit(1)
	}
	_ = yaml.Unmarshal(cFile, &cfg)

	log.SetFormatter(&logrus.TextFormatter{FullTimestamp: true, ForceColors: true})
	_ = os.MkdirAll(cfg.Paths.OutputDir, 0755)

	if *rescue {
		runRescueMode()
		fmt.Printf("\n🏁 Rescue Finished. Successfully processed: %d files.\n", atomic.LoadInt32(&rescuedCount))
	} else if *container != "" {
		fullPath := filepath.Join(cfg.Paths.SourceDir, *container)
		dstPath := filepath.Join(cfg.Paths.OutputDir, *container+".jsonl")
		processSingleZip(fullPath, dstPath)
	} else {
		archives, _ := filepath.Glob(filepath.Join(cfg.Paths.SourceDir, "*.zip"))
		for _, zipPath := range archives {
			dstPath := filepath.Join(cfg.Paths.OutputDir, filepath.Base(zipPath)+".jsonl")
			processSingleZip(zipPath, dstPath)
		}
	}
}

// Нормализация файла: удаление дубликатов и перезапись
func normalizeJSONL(path string) (int, error) {
	baseName := filepath.Base(path)
	log.Infof("[%s] Normalization started: scanning for unique IDs...", baseName)

	f, err := os.Open(path)
	if err != nil {
		return 0, err
	}
	defer f.Close()

	tmpPath := path + ".tmp"
	tmpFile, err := os.Create(tmpPath)
	if err != nil {
		return 0, err
	}
	defer tmpFile.Close()

	hashes := make(map[string]bool)
	scanner := bufio.NewScanner(f)
	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
	count := 0

	for scanner.Scan() {
		line1 := scanner.Text()
		if strings.Contains(line1, `"_index"`) {
			match := re.FindStringSubmatch(line1)
			if len(match) > 1 {
				id := match[1]
				if scanner.Scan() {
					line2 := scanner.Text()
					if !hashes[id] {
						hashes[id] = true
						_, _ = tmpFile.WriteString(line1 + "\n")
						_, _ = tmpFile.WriteString(line2 + "\n")
						count++
					}
				}
			}
		}
	}

	log.Infof("[%s] Writing normalized file to disk (%d unique records)...", baseName, count)

	f.Close()
	tmpFile.Close()

	if err := os.Rename(tmpPath, path); err != nil {
		return 0, err
	}

	log.Infof("[%s] Normalization finished successfully.", baseName)
	return count, nil
}

func countExistingDocs(path string) int {
	count := 0
	f, err := os.Open(path)
	if err != nil { return 0 }
	defer f.Close()
	scanner := bufio.NewScanner(f)
	for scanner.Scan() {
		if strings.Contains(scanner.Text(), `"_index"`) { count++ }
	}
	return count
}

func loadExistingHashes(path string) map[string]bool {
	hashes := make(map[string]bool)
	f, err := os.Open(path)
	if err != nil { return hashes }
	defer f.Close()
	scanner := bufio.NewScanner(f)
	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
	for scanner.Scan() {
		line := scanner.Text()
		if strings.Contains(line, `"_index"`) {
			match := re.FindStringSubmatch(line)
			if len(match) > 1 { hashes[match[1]] = true }
		}
	}
	return hashes
}

func processSingleZip(zipPath, dstPath string) {
	containerName := filepath.Base(zipPath)
	z, err := zip.OpenReader(zipPath)
	if err != nil {
		log.Errorf("Failed to open zip %s: %v", zipPath, err)
		return
	}
	defer z.Close()

	zipFb2Count := 0
	for _, f := range z.File {
		if strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { zipFb2Count++ }
	}

	// 1. Быстрая проверка и интеграция нормализации
	if !*flagRescan && !*flagVerbose {
		jsonlDocCount := countExistingDocs(dstPath)
		if jsonlDocCount > 0 {
			if zipFb2Count == jsonlDocCount {
				log.Infof("[%s] Quick check: counts match (%d). Skipping container.", containerName, zipFb2Count)
				z.Close()
				os.Exit(10)
			} else {
				log.Infof("[%s] Count mismatch (ZIP: %d, JSONL: %d). Starting normalization...", containerName, zipFb2Count, jsonlDocCount)
				
				newCount, err := normalizeJSONL(dstPath)
				
				// Новая проверка после нормализации
				log.Infof("[%s] New check after normalization: count is %d.", containerName, newCount)
				
				if err == nil {
					if newCount == zipFb2Count {
						log.Infof("[%s] Result: Counts match! Skipping container.", containerName)
						z.Close()
						os.Exit(10)
					} else {
						log.Infof("[%s] Result: Still mismatch. Proceeding to detailed check.", containerName)
					}
				} else {
					log.Errorf("[%s] Normalization failed: %v. Proceeding to detailed check.", containerName, err)
				}
			}
		}
	}

	existingHashes := make(map[string]bool)
	if !*flagRescan {
		existingHashes = loadExistingHashes(dstPath)
		if len(existingHashes) > 0 && *flagVerbose {
			log.Infof("[%s] Found %d already processed documents.", containerName, len(existingHashes))
		}
	}

	type workItem struct {
		file *zip.File
		raw  []byte
		sha  string
	}
	var tasks []workItem

	for _, f := range z.File {
		if !strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { continue }
		rc, err := f.Open()
		if err != nil {
			log.Errorf("Read error %s: %v", f.Name, err)
			continue
		}
		raw, _ := io.ReadAll(rc)
		rc.Close()
		sum := sha1.Sum(raw)
		sha := hex.EncodeToString(sum[:])
		if existingHashes[sha] {
			if *flagVerbose { log.Infof("Skipping %s (already exists in output)", f.Name) }
			continue
		}
		tasks = append(tasks, workItem{file: f, raw: raw, sha: sha})
	}

	if len(tasks) == 0 {
		log.Infof("Container %s is fully processed. Nothing new.", containerName)
		z.Close()
		os.Exit(10)
	}

	openOutputFile(dstPath)
	defer outFile.Close()
	bar = progressbar.Default(int64(len(tasks)), "🚢 "+containerName)
	jobs := make(chan workItem)
	var wg sync.WaitGroup
	for i := 0; i < cfg.Processing.Threads; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for item := range jobs {
				doc, err := parseResilient(item.raw)
				if err != nil {
					log.Errorf("FAILED: %s | %v", item.file.Name, err)
					saveToWarn(item.file.Name, item.raw, err)
				} else {
					saveToOutputWithSha(item.file.Name, containerName, item.raw, item.sha, doc)
				}
				_ = bar.Add(1)
			}
		}()
	}
	for _, task := range tasks { jobs <- task }
	close(jobs)
	wg.Wait()
}

func runRescueMode() {
	files, _ := filepath.Glob(filepath.Join(cfg.Paths.WarnDir, "*fb2"))
	if len(files) == 0 { return }
	dstPath := filepath.Join(cfg.Paths.OutputDir, "rescued_items.jsonl")
	openOutputFile(dstPath)
	defer outFile.Close()
	bar = progressbar.Default(int64(len(files)), "🩹 Rescuing")
	jobs := make(chan string)
	var wg sync.WaitGroup
	for i := 0; i < cfg.Processing.Threads; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for path := range jobs {
				data, err := os.ReadFile(path)
				if err != nil || len(data) == 0 {
					_ = os.Remove(path)
					_ = os.Remove(path + ".log")
					_ = bar.Add(1)
					continue
				}
				doc, err := parseResilient(data)
				if err == nil {
					if saveToOutput(filepath.Base(path), "rescued", data, doc) {
						_ = os.Remove(path)
						_ = os.Remove(path + ".log")
						atomic.AddInt32(&rescuedCount, 1)
					}
				} else { log.Errorf("FAILED: %s | %v", filepath.Base(path), err) }
				_ = bar.Add(1)
			}
		}()
	}
	for _, f := range files { jobs <- f }
	close(jobs)
	wg.Wait()
}

func parseResilient(data []byte) (*docOut, error) {
	if len(data) == 0 { return nil, fmt.Errorf("empty file") }
	utf8Data := convertToUTF8(data)
	doc, err := parseFB2(utf8Data)
	if err == nil { return doc, nil }
	return parseWithRegex(utf8Data)
}

func convertToUTF8(data []byte) []byte {
	if len(data) < 2 { return data }
	if (data[0] == 0xFF && data[1] == 0xFE) || (data[0] == 0xFE && data[1] == 0xFF) {
		dec := unicode.UTF16(unicode.LittleEndian, unicode.UseBOM).NewDecoder()
		out, _ := dec.Bytes(data)
		return out
	}
	if len(data) > 10 && data[1] == 0 && data[3] == 0 {
		dec := unicode.UTF16(unicode.LittleEndian, unicode.IgnoreBOM).NewDecoder()
		out, _ := dec.Bytes(data)
		return out
	}
	header := string(data[:min(len(data), 500)])
	if strings.Contains(strings.ToLower(header), "windows-1251") {
		out, _ := charmap.Windows1251.NewDecoder().Bytes(data)
		return out
	}
	return bytes.ToValidUTF8(data, []byte(" "))
}

func parseWithRegex(data []byte) (*docOut, error) {
	doc := &docOut{}
	reTitle := regexp.MustCompile(`(?is)<book-title[^>]*>(.*?)</book-title>`)
	if m := reTitle.FindSubmatch(data); len(m) > 1 { doc.Title = strings.TrimSpace(string(m[1])) }
	reAuthor := regexp.MustCompile(`(?is)<author[^>]*>(.*?)</author>`)
	reFirst := regexp.MustCompile(`(?is)<first-name[^>]*>(.*?)</first-name>`)
	reLast := regexp.MustCompile(`(?is)<last-name[^>]*>(.*?)</last-name>`)
	authors := reAuthor.FindAllSubmatch(data, -1)
	for _, a := range authors {
		fn, ln := reFirst.FindSubmatch(a[1]), reLast.FindSubmatch(a[1])
		name := ""
		if len(fn) > 1 { name += string(fn[1]) + " " }
		if len(ln) > 1 { name += string(ln[1]) }
		if name = strings.TrimSpace(name); name != "" { doc.Authors = append(doc.Authors, name) }
	}
	if doc.Title == "" { return nil, fmt.Errorf("regex failed") }
	return doc, nil
}

func openOutputFile(path string) {
	var err error
	outFile, err = os.OpenFile(path, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
	if err != nil { log.Fatal(err) }
}

func saveToOutput(filename, container string, raw []byte, doc *docOut) bool {
	sum := sha1.Sum(raw)
	sha := hex.EncodeToString(sum[:])
	return saveToOutputWithSha(filename, container, raw, sha, doc)
}

func saveToOutputWithSha(filename, container string, raw []byte, sha string, doc *docOut) bool {
	doc.FileInfo.Container, doc.FileInfo.Filename, doc.FileInfo.Sha1, doc.FileInfo.Size = container, filename, sha, int64(len(raw))
	doc.IngestedAt = time.Now()
	action, _ := json.Marshal(map[string]map[string]any{"index": {"_index": cfg.OpenSearch.IndexName, "_id": sha}})
	data, _ := json.Marshal(doc)
	outMu.Lock()
	defer outMu.Unlock()
	_, _ = outFile.Write(append(action, '\n'))
	_, _ = outFile.Write(append(data, '\n'))
	return true
}

func saveToWarn(filename string, data []byte, err error) {
	_ = os.WriteFile(filepath.Join(cfg.Paths.WarnDir, filename), data, 0644)
	_ = os.WriteFile(filepath.Join(cfg.Paths.WarnDir, filename+".log"), []byte(err.Error()), 0644)
}

func parseFB2(data []byte) (*docOut, error) {
	d := xml.NewDecoder(bytes.NewReader(data))
	d.CharsetReader = func(charset string, input io.Reader) (io.Reader, error) { return input, nil }
	d.Strict = false
	var doc docOut
	var inTitle bool
	for {
		t, err := d.Token()
		if err != nil || t == nil { break }
		switch se := t.(type) {
		case xml.StartElement:
			if se.Name.Local == "title-info" { inTitle = true }
			if se.Name.Local == "book-title" && inTitle { _ = d.DecodeElement(&doc.Title, &se) }
			if se.Name.Local == "author" && inTitle {
				var a struct { First string `xml:"first-name"`; Last string `xml:"last-name"` }
				_ = d.DecodeElement(&a, &se)
				if n := strings.TrimSpace(a.First + " " + a.Last); n != "" { doc.Authors = append(doc.Authors, n) }
			}
		case xml.EndElement:
			if se.Name.Local == "title-info" { inTitle = false }
		}
	}
	if doc.Title == "" { return nil, fmt.Errorf("xml: no title") }
	return &doc, nil
}

func min(a, b int) int { if a < b { return a }; return b }

--- END_FILE: ./cmd/bulker/main.go ---

--- START_FILE: ./cmd/processor/main.go ---
package main

import (
	"context"
	"log"
	"net"
	"strings"

	"ebusta/api/proto/v1"
	"google.golang.org/grpc"
)

type processorServer struct {
	libraryv1.UnimplementedProcessorServiceServer
	storage libraryv1.StorageServiceClient
}

func (s *processorServer) Process(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
	fullQuery := req.Query
	qLower := strings.ToLower(fullQuery)
	log.Printf("🧠 Processor: Handling '%s'", fullQuery)

	// 1. Сложные запросы (AND/OR)
	if strings.Contains(qLower, " and ") || strings.Contains(qLower, " or ") {
		cleanQuery := fullQuery
		for _, prefix := range []string{"author:", "title:", "Author:", "Title:"} {
			cleanQuery = strings.ReplaceAll(cleanQuery, prefix, "")
		}
		log.Printf("🧠 Processor: Complex query cleaned: '%s'", cleanQuery)
		return s.storage.SearchBooks(ctx, &libraryv1.SearchRequest{
			Query:      strings.TrimSpace(cleanQuery),
			TemplateId: "fl_mixed_search",
			Limit:      req.Limit,
			TraceId:    req.TraceId,
		})
	}

	// 2. Обработка префикса title: (Каскадный поиск)
	if strings.HasPrefix(qLower, "title:") {
		cleanTitle := strings.TrimSpace(strings.TrimPrefix(fullQuery, "title:"))
		
		// Попытка 1: Строгий substring
		subReq := &libraryv1.SearchRequest{
			Query:      cleanTitle,
			TemplateId: "fl_title_substring",
			Limit:      req.Limit,
			TraceId:    req.TraceId,
		}
		resp, err := s.storage.SearchBooks(ctx, subReq)
		
		if err == nil && resp.Total > 0 {
			return resp, nil
		}

		// Попытка 2: Умный Match (анализатор разберется с регистром)
		log.Printf("⚠️ Substring search found 0, switching to fl_title_match for: %s", cleanTitle)
		subReq.TemplateId = "fl_title_match"
		return s.storage.SearchBooks(ctx, subReq)
	}

	// 3. Обработка префикса author: (уже настроена)
	if strings.HasPrefix(qLower, "author:") {
		cleanAuthor := strings.TrimSpace(strings.TrimPrefix(fullQuery, "author:"))
		subReq := &libraryv1.SearchRequest{
			Query:      cleanAuthor,
			TemplateId: "fl_author_exact",
			Limit:      req.Limit,
			TraceId:    req.TraceId,
		}
		resp, err := s.storage.SearchBooks(ctx, subReq)
		if err == nil && resp.Total > 0 {
			return resp, nil
		}
		log.Printf("⚠️ Switching to fuzzy for: %s", cleanAuthor)
		subReq.TemplateId = "fl_author_fuzzy"
		return s.storage.SearchBooks(ctx, subReq)
	}

	return s.storage.SearchBooks(ctx, req)
}

func main() {
	lis, err := net.Listen("tcp", ":50053")
	if err != nil { log.Fatal(err) }
	conn, err := grpc.Dial("localhost:50051", grpc.WithInsecure())
	if err != nil { log.Fatal(err) }
	defer conn.Close()
	s := grpc.NewServer()
	libraryv1.RegisterProcessorServiceServer(s, &processorServer{storage: libraryv1.NewStorageServiceClient(conn)})
	log.Println("🧠 Ebusta Processor started on :50053")
	s.Serve(lis)
}

--- END_FILE: ./cmd/processor/main.go ---

--- START_FILE: ./cmd/cli/main.go ---
package main

import (
	"context"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"strings"
	"time"

	"ebusta/api/proto/v1"
	"github.com/peterh/liner"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
)

var (
	debugMode   bool
	historyPath = filepath.Join(os.TempDir(), ".ebusta_history")
)

func main() {
	if os.Getenv("DEBUG") != "" {
		debugMode = true
		log.Println("🐞 DEBUG MODE: ENABLED")
	}

	conn, err := grpc.Dial("localhost:50054", grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		log.Fatalf("❌ Failed to connect to Orchestrator: %v", err)
	}
	defer conn.Close()

	client := libraryv1.NewOrchestratorServiceClient(conn)

	if len(os.Args) > 1 {
		query := strings.Join(os.Args[1:], " ")
		runSearch(client, query)
	} else {
		runInteractiveLoop(client)
	}
}

func runInteractiveLoop(client libraryv1.OrchestratorServiceClient) {
	line := liner.NewLiner()
	defer line.Close()

	line.SetCtrlCAborts(true)

	// Загружаем историю из файла, если он есть
	if f, err := os.Open(historyPath); err == nil {
		line.ReadHistory(f)
		f.Close()
	}

	fmt.Println("🚀 Ebusta CLI Interactive Mode (with History Support)")
	fmt.Println("Use UP/DOWN arrows for history. Type 'exit' to stop.")
	fmt.Println("---------------------------------")

	for {
		if text, err := line.Prompt("ebusta> "); err == nil {
			text = strings.TrimSpace(text)
			if text == "" {
				continue
			}
			if text == "exit" || text == "quit" {
				fmt.Println("Bye!")
				break
			}

			// Добавляем в историю и сохраняем
			line.AppendHistory(text)
			runSearch(client, text)

			// Сохраняем историю после каждого успешного ввода
			if f, err := os.Create(historyPath); err == nil {
				line.WriteHistory(f)
				f.Close()
			}
		} else if err == liner.ErrPromptAborted {
			fmt.Println("Aborted")
			break
		} else {
			log.Print("Error reading line: ", err)
			break
		}
	}
}

func runSearch(client libraryv1.OrchestratorServiceClient, query string) {
	if debugMode {
		log.Printf("📡 Sending query: '%s'", query)
	}

	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	resp, err := client.Search(ctx, &libraryv1.SearchRequest{
		Query:   query,
		TraceId: "cli-user",
	})

	if err != nil {
		log.Printf("❌ Error: %v", err)
		return
	}

	if resp.Total == 0 && len(resp.Books) == 0 {
		fmt.Println("No results found.")
		return
	}

	fmt.Printf("%-40s | %-40s | %s\n", "ID", "Title", "Authors")
	fmt.Println(strings.Repeat("-", 100))

	for _, b := range resp.Books {
		fmt.Printf("%-40s | %-40s | %s\n", 
			b.Id, 
			truncate(b.Title, 38), 
			truncate(strings.Join(b.Authors, ", "), 30),
		)
	}
}

func truncate(s string, max int) string {
	runes := []rune(s)
	if len(runes) > max {
		return string(runes[:max]) + "..."
	}
	return s
}

--- END_FILE: ./cmd/cli/main.go ---

--- START_FILE: ./cmd/client/main.go ---
package main

import (
	"context"
	"log"
	"time"

	"ebusta/api/proto/v1" // Убедись, что модуль называется так же, как в go.mod
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
)

func main() {
	// Подключаемся к серверу Data-Manager
	conn, err := grpc.Dial("localhost:50051", grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		log.Fatalf("did not connect: %v", err)
	}
	defer conn.Close()

	c := libraryv1.NewLibraryServiceClient(conn)

	ctx, cancel := context.WithTimeout(context.Background(), time.Second)
	defer cancel()

	log.Println("--- Ebusta gRPC Client: Sending Search Request ---")
	
	// ИСПРАВЛЕНИЕ 1: Метод называется SearchBooks
	r, err := c.SearchBooks(ctx, &libraryv1.SearchRequest{
		Query: "Flibusta rules",
		Limit: 5,
	})
	if err != nil {
		log.Fatalf("could not search: %v", err)
	}

	// ИСПРАВЛЕНИЕ 2: Используем GetTotal() вместо GetTotalFound()
	log.Printf("Response from server: Found %d books", r.GetTotal())
	
	for _, book := range r.GetBooks() {
		log.Printf("-> Book: [%s] %s (Authors: %v)", book.GetId(), book.GetTitle(), book.GetAuthors())
	}
}

--- END_FILE: ./cmd/client/main.go ---

--- START_FILE: ./cmd/web-adapter/main.go ---
package main

import (
	"context"
	"fmt"
	"log"
	"net/http"
	"os"
	"strings"
	"time"

	"ebusta/api/proto/v1"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
)

func main() {
	// 1. Подключение к Orchestrator (порт 50054)
	orchHost := os.Getenv("ORCHESTRATOR_HOST")
	if orchHost == "" {
		orchHost = "localhost:50054"
	}

	conn, err := grpc.Dial(orchHost, grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		log.Fatalf("did not connect: %v", err)
	}
	defer conn.Close()

	// ИСПРАВЛЕНИЕ 1: Правильное имя клиента (OrchestratorServiceClient)
	client := libraryv1.NewOrchestratorServiceClient(conn)

	http.HandleFunc("/input", func(w http.ResponseWriter, r *http.Request) {
		query := r.URL.Query().Get("msg")
		if query == "" {
			query = r.URL.Query().Get("q")
		}
		
		if query == "" {
			http.Error(w, "Please provide 'msg' parameter", http.StatusBadRequest)
			return
		}

		log.Printf("🌍 Web Adapter received: %s", query)

		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
		defer cancel()

		// ИСПРАВЛЕНИЕ 2: Используем SearchRequest и метод Search
		resp, err := client.Search(ctx, &libraryv1.SearchRequest{
			Query: query,
		})

		if err != nil {
			http.Error(w, fmt.Sprintf("Error calling Orchestrator: %v", err), http.StatusInternalServerError)
			return
		}

		// Форматируем простой текстовый ответ
		w.Header().Set("Content-Type", "text/plain; charset=utf-8")
		
		if len(resp.Books) == 0 {
			fmt.Fprintf(w, "No books found for: %s\n", query)
			return
		}

		fmt.Fprintf(w, "Found %d books:\n", len(resp.Books))
		fmt.Fprintln(w, strings.Repeat("-", 40))
		for _, b := range resp.Books {
			authors := strings.Join(b.Authors, ", ")
			fmt.Fprintf(w, "[%s] %s — %s\n", b.Id, b.Title, authors)
		}
	})

	port := os.Getenv("PORT")
	if port == "" {
		port = "8080"
	}

	log.Printf("🌍 Web Adapter started on :%s", port)
	if err := http.ListenAndServe(":"+port, nil); err != nil {
		log.Fatalf("failed to serve: %v", err)
	}
}

--- END_FILE: ./cmd/web-adapter/main.go ---

--- START_FILE: ./cmd/auth-manager/whitelist.yaml ---
users:
  - id: "serge_dev_cli"
    platform: "cli"
    role: "admin"
  - id: "12345678"
    platform: "telegram"
    role: "family"

--- END_FILE: ./cmd/auth-manager/whitelist.yaml ---

--- START_FILE: ./cmd/auth-manager/main.go ---
package main

import (
	"context"
	"log"
	"net"
	"os"

	"ebusta/api/proto/v1"
	"google.golang.org/grpc"
	"gopkg.in/yaml.v3"
)

type UserEntry struct {
	ID       string `yaml:"id"`
	Platform string `yaml:"platform"`
	Role     string `yaml:"role"`
}

type Whitelist struct {
	Users []UserEntry `yaml:"users"`
}

type authServer struct {
	libraryv1.UnimplementedAuthServiceServer
	whitelist Whitelist
}

func (s *authServer) CheckAccess(ctx context.Context, req *libraryv1.AccessRequest) (*libraryv1.AccessResponse, error) {
	log.Printf("[%s] Auth check: user=%s platform=%s", req.TraceId, req.UserId, req.Platform)

	for _, u := range s.whitelist.Users {
		if u.ID == req.UserId && u.Platform == req.Platform {
			return &libraryv1.AccessResponse{
				Allowed:  true,
				UserRole: u.Role,
			}, nil
		}
	}

	return &libraryv1.AccessResponse{
		Allowed: false,
		Reason:  "Access denied: user not in whitelist for this platform",
	}, nil
}

func main() {
	data, err := os.ReadFile("cmd/auth-manager/whitelist.yaml")
	if err != nil {
		log.Fatalf("Failed to read whitelist: %v", err)
	}

	var wl Whitelist
	if err := yaml.Unmarshal(data, &wl); err != nil {
		log.Fatalf("Failed to parse whitelist: %v", err)
	}

	lis, err := net.Listen("tcp", ":50055")
	if err != nil {
		log.Fatalf("failed to listen: %v", err)
	}

	s := grpc.NewServer()
	libraryv1.RegisterAuthServiceServer(s, &authServer{whitelist: wl})

	log.Println("🛡  Auth-Manager started on :50055")
	if err := s.Serve(lis); err != nil {
		log.Fatalf("failed to serve: %v", err)
	}
}

--- END_FILE: ./cmd/auth-manager/main.go ---

--- START_FILE: ./cmd/orchestrator/main.go ---
package main

import (
	"context"
	"log"
	"net"

	"ebusta/api/proto/v1"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
)

type orchestratorServer struct {
	libraryv1.UnimplementedOrchestratorServiceServer
	processorClient libraryv1.ProcessorServiceClient
}

func (s *orchestratorServer) Search(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
	log.Printf("🎼 Orchestrator received: %s", req.Query)
	return s.processorClient.Process(ctx, req)
}

func main() {
	// Orchestrator -> Processor
	conn, err := grpc.Dial("localhost:50053", grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		log.Fatalf("failed to connect to processor: %v", err)
	}

	lis, err := net.Listen("tcp", ":50054")
	if err != nil {
		log.Fatalf("failed to listen: %v", err)
	}

	s := grpc.NewServer()
	libraryv1.RegisterOrchestratorServiceServer(s, &orchestratorServer{
		processorClient: libraryv1.NewProcessorServiceClient(conn),
	})

	log.Println("🎼 Orchestrator started on :50054")
	s.Serve(lis)
}

--- END_FILE: ./cmd/orchestrator/main.go ---

--- START_FILE: ./cmd/message-converter/main.go ---
package main

import (
	"context"
	"fmt"
	"log"
	"net"

	"ebusta/api/proto/v1"
	"ebusta/internal/parser"
	"google.golang.org/grpc"
)

type server struct {
	libraryv1.UnimplementedMessageConverterServiceServer
}

func (s *server) Convert(ctx context.Context, req *libraryv1.RawInput) (*libraryv1.UnmarshaledMessage, error) {
	log.Printf("🔄 Converter parsing: %s", req.Data)

	// Теперь эта функция существует в internal/parser/parser.go
	queryAst := parser.Parse(req.Data)

	return &libraryv1.UnmarshaledMessage{
		Meta: &libraryv1.MessageMeta{
			TraceId:       req.TraceId,
			CanonicalForm: req.Data,
			// Преобразуем структуру AST в строку для логов/отладки
			AstPlan:       fmt.Sprintf("%v", queryAst),
		},
		Query: queryAst,
	}, nil
}

func main() {
	lis, err := net.Listen("tcp", ":50052")
	if err != nil {
		log.Fatalf("failed to listen: %v", err)
	}

	s := grpc.NewServer()
	libraryv1.RegisterMessageConverterServiceServer(s, &server{})

	log.Println("🔄 MessageConverter started on :50052")
	if err := s.Serve(lis); err != nil {
		log.Fatalf("failed to serve: %v", err)
	}
}

--- END_FILE: ./cmd/message-converter/main.go ---

--- START_FILE: ./backlog-parser.md ---
Цель: Перевод Processor на полную поддержку Ebusta Search DSL v1.1 через обход дерева SearchQuery.
+3

1. Рефакторинг контракта взаимодействия
Изменить логику обработки в cmd/processor/main.go , чтобы сервис извлекал поле query типа SearchQuery из входящего сообщения UnmarshaledMessage.
+4

Обеспечить передачу структурированного объекта SearchQuery от Message-Converter к Processor через gRPC.
+3

2. Реализация компонента AST Walker
Разработать рекурсивную функцию обхода дерева SearchQuery в internal/processor.
+2

Реализовать обработку узла LogicalNode для поддержки операторов AND и OR.
+1

Реализовать обработку узла NotNode для поддержки инверсии запросов (negation).
+1

3. Маппинг узлов на шаблоны OpenSearch
Заменить проверку strings.HasPrefix(queryLower, "author:") на извлечение FilterNode с полем field: "author".
+1

Привязать FilterNode  к существующим шаблонам данных:


field: "author" -> fl_author_exact / fl_author_fuzzy.


field: "title" -> fl_title_substring / fl_title_prefix.


field: "any" -> fl_mixed_search.
+1

Интегрировать поддержку Operator:
+1


OP_REGEX -> трансляция в регулярные выражения OpenSearch.


OP_EQUALS -> точное совпадение.
+1

4. Координация логических условий
Реализовать трансляцию LogicalNode в структуру bool query (must, should, must_not) для OpenSearch.
+3

Обеспечить соблюдение приоритетов операторов: NOT > AND > OR.

5. Тестирование и верификация
Добавить интеграционные тесты в tests/smoke_full.sh для проверки цепочки: DSL-строка -> Message-Converter (AST) -> Processor (Walker) -> Data-Manager.
+2

Верифицировать поле meta.canonical_form в ответе для подтверждения корректности разобранного дерева.
+1

Аудит готовности:


Переменные: Поля LogicalOp, Operator и SearchQuery уже объявлены в api/proto/v1/library.proto.
+1


Функции: Парсер parser.Parse(req.Data) уже интегрирован в cmd/message-converter/main.go.


Инфраструктура: Шаблоны OpenSearch (fl_mixed_search, fl_author_exact и др.) готовы к приему структурированных параметров.

--- END_FILE: ./backlog-parser.md ---

--- START_FILE: ./books.json ---
[
  {"id": "1", "title": "Оно", "authors": ["Стивен Кинг"]},
  {"id": "2", "title": "Сияние", "authors": ["Стивен Кинг"]},
  {"id": "3", "title": "The Hobbit", "authors": ["J.R.R. Tolkien"]}
]

--- END_FILE: ./books.json ---

--- START_FILE: ./go.mod ---
module ebusta

go 1.24.0

toolchain go1.24.11

require (
	github.com/kelseyhightower/envconfig v1.4.0
	github.com/peterh/liner v1.2.2
	github.com/prometheus/client_golang v1.23.2
	github.com/schollz/progressbar/v3 v3.19.0
	github.com/sirupsen/logrus v1.9.3
	github.com/spf13/viper v1.21.0
	golang.org/x/text v0.31.0
	google.golang.org/grpc v1.78.0
	google.golang.org/protobuf v1.36.10
	gopkg.in/yaml.v3 v3.0.1
)

require (
	github.com/beorn7/perks v1.0.1 // indirect
	github.com/cespare/xxhash/v2 v2.3.0 // indirect
	github.com/fsnotify/fsnotify v1.9.0 // indirect
	github.com/go-viper/mapstructure/v2 v2.4.0 // indirect
	github.com/mattn/go-runewidth v0.0.16 // indirect
	github.com/mitchellh/colorstring v0.0.0-20190213212951-d06e56a500db // indirect
	github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect
	github.com/pelletier/go-toml/v2 v2.2.4 // indirect
	github.com/prometheus/client_model v0.6.2 // indirect
	github.com/prometheus/common v0.66.1 // indirect
	github.com/prometheus/procfs v0.16.1 // indirect
	github.com/rivo/uniseg v0.4.7 // indirect
	github.com/sagikazarmark/locafero v0.11.0 // indirect
	github.com/sourcegraph/conc v0.3.1-0.20240121214520-5f936abd7ae8 // indirect
	github.com/spf13/afero v1.15.0 // indirect
	github.com/spf13/cast v1.10.0 // indirect
	github.com/spf13/pflag v1.0.10 // indirect
	github.com/subosito/gotenv v1.6.0 // indirect
	go.yaml.in/yaml/v2 v2.4.2 // indirect
	go.yaml.in/yaml/v3 v3.0.4 // indirect
	golang.org/x/net v0.47.0 // indirect
	golang.org/x/sys v0.38.0 // indirect
	golang.org/x/term v0.37.0 // indirect
	google.golang.org/genproto/googleapis/rpc v0.0.0-20251029180050-ab9386a59fda // indirect
)

--- END_FILE: ./go.mod ---

--- START_FILE: ./grpc/examples/client/helloworld_server.cc ---
// Copyright 2021 Google LLC
//
// Use of this source code is governed by an MIT-style
// license that can be found in the LICENSE file or at
// https://opensource.org/licenses/MIT.

#include <fstream>
#include <iostream>
#include <memory>
#include <sstream>

#include <absl/flags/parse.h>
#include <absl/flags/flag.h>
#include <absl/strings/ascii.h>
#include <absl/strings/str_cat.h>
#include <grpc/grpc.h>
#include <grpcpp/security/server_credentials.h>
#include <grpcpp/server.h>
#include <grpcpp/server_builder.h>
#include <grpcpp/server_context.h>
#include "examples/client/helloworld.grpc.pb.h"

using grpc::InsecureServerCredentials;
using grpc::Server;
using grpc::ServerBuilder;
using grpc::ServerContext;
using grpc::ServerReader;
using grpc::ServerReaderWriter;
using grpc::ServerWriter;
using grpc::SslServerCredentials;
using grpc::SslServerCredentialsOptions;
using grpc::Status;
using lisp::grpc::integration_testing::HelloReply;
using lisp::grpc::integration_testing::HelloRequest;
using lisp::grpc::integration_testing::grpc_gen::Greeter;

ABSL_FLAG(int32_t, port, 0, "Port server listening on.");
ABSL_FLAG(std::string, auth_mechanism, "", "Authentication mechanism.");
ABSL_FLAG(std::string, root_cert_path, "", "Path to root certificates.");
ABSL_FLAG(std::string, private_key_path, "", "Path to private key.");
ABSL_FLAG(std::string, certificate_chain_path, "",
          "Path to certificate chain.");

class GreeterServiceImpl final : public Greeter::Service {
  Status SayHello(ServerContext* context, const HelloRequest* request,
                  HelloReply* reply) override {
    reply->set_message(absl::StrCat("Hello ", request->name()));
    return Status::OK;
  }

  Status SayHelloServerStream(ServerContext* context,
                              const HelloRequest* request,
                              ServerWriter<HelloReply>* stream)
      override {
    HelloReply reply = HelloReply();
    for(int i = 0; i < request->num_responses(); i++) {
      reply.set_message(absl::StrCat("Hello ", request->name(), " ", i));
      stream->Write(reply);
    }
    return ::grpc::Status::OK;
  }

  Status SayHelloClientStream(ServerContext* context,
                              ServerReader<HelloRequest>* stream,
                              HelloReply* reply)
      override {
    std::string reply_string = "Hello ";
    HelloRequest request;
    while (stream->Read(&request)) {
      absl::StrAppend(&reply_string, request.name());
    }
    reply->set_message(reply_string);
    return ::grpc::Status::OK;
  }

  Status SayHelloBidirectionalStream(
      ServerContext* context,
      ServerReaderWriter<HelloReply, HelloRequest>* stream)
      override {
    HelloRequest request;
    while (stream->Read(&request)) {
      HelloReply reply = HelloReply();
      for(int i = 0; i < request.num_responses(); i++) {
        reply.set_message(absl::StrCat("Hello ", request.name(), " ", i));
        stream->Write(reply);
      }
    }
    return ::grpc::Status::OK;
  }

};

std::string readFileIntoString(const std::string& path) {
  std::ifstream input_file(path);
  if (!input_file.is_open()) {
    std::cerr << "Could not open the file - '" << path << "'" << std::endl;
  }
  return std::string((std::istreambuf_iterator<char>(input_file)),
                     std::istreambuf_iterator<char>());
}

bool fileExists(const std::string& path) {
  std::ifstream f(path.c_str());
  return f.good();
}

void RunServer() {
  const int port = absl::GetFlag(FLAGS_port);
  QCHECK(port > 0) << "Please specify a valid server port";
  std::string server_address = absl::StrCat("localhost:", port);
  GreeterServiceImpl service;

  ServerBuilder builder;
  std::shared_ptr<grpc::ServerCredentials> creds;

  // Set up authentication mechanism (or lack therof) for the server.
  std::string auth_mechanism = absl::GetFlag(FLAGS_auth_mechanism);
  absl::AsciiStrToLower(&auth_mechanism);
  absl::RemoveExtraAsciiWhitespace(&auth_mechanism);
  if (auth_mechanism == "insecure") {
    creds = grpc::InsecureServerCredentials();
  } else if (auth_mechanism == "ssl") {
    const std::string root_cert_path = absl::GetFlag(FLAGS_root_cert_path);
    if (root_cert_path.empty() || !fileExists(root_cert_path)) {
      std::cout << "A valid root certificate must be specified, got: '"
                << root_cert_path << "'" << std::endl;
      return;
    }
    const std::string private_key_path = absl::GetFlag(FLAGS_private_key_path);
    if (private_key_path.empty() || !fileExists(private_key_path)) {
      std::cout << "A valid private key must be specified, got: '"
                << private_key_path << "'" << std::endl;
      return;
    }
    const std::string cert_chain_path =
        absl::GetFlag(FLAGS_certificate_chain_path);
    if (cert_chain_path.empty() || !fileExists(cert_chain_path)) {
      std::cout << "A valid certificate chain must be specified, got: '"
                << cert_chain_path << "'" << std::endl;
      return;
    }
    grpc::SslServerCredentialsOptions ssl_opts;
    ssl_opts.pem_root_certs = readFileIntoString(root_cert_path);
    grpc::SslServerCredentialsOptions::PemKeyCertPair pkcp = {
        readFileIntoString(private_key_path),
        readFileIntoString(cert_chain_path),
    };
    ssl_opts.pem_key_cert_pairs.push_back(pkcp);
    creds = grpc::SslServerCredentials(ssl_opts);
  } else {
    std::cout << "A valid authentication mechanism must be specified, got: '"
               << auth_mechanism << "'" << std::endl;
    return;
  }

  builder.AddListeningPort(server_address, creds);
  builder.RegisterService(&service);
  std::unique_ptr<Server> server(builder.BuildAndStart());
  std::cout << "Server listening on " << server_address << std::endl;
  server->Wait();
}

int main(int argc, char** argv) {
  absl::ParseCommandLine(argc, argv);
  RunServer();
  return 0;
}

--- END_FILE: ./grpc/examples/client/helloworld_server.cc ---

--- START_FILE: ./grpc/examples/client/client-ssl.lisp ---
;; Copyright 2016-2021 Google LLC
;;
;; Use of this source code is governed by an MIT-style
;; license that can be found in the LICENSE file or at
;; https://opensource.org/licenses/MIT.

;;  A simple test for gRPC Client in Common Lisp using SSL for channel authentication.

(defpackage #:testing-client-ssl
  (:use #:common-lisp)
  (:local-nicknames (#:testing #:cl-protobufs.lisp.grpc.integration-testing)
                    (#:testing-rpc #:cl-protobufs.lisp.grpc.integration-testing-rpc)
                    (#:log #:google.log)
                    (#:flag #:ace.flag))
  (:export #:main))

(in-package #:testing-client-ssl)

(flag:define hostname "localhost"
  "Name of server that will be connected to."
  :names ("hostname")
  :type STRING)

(flag:define port-number 8080
  "Port of server to establish connection to."
  :names ("port")
  :type INTEGER)

(flag:define root-cert-path ""
  "Path to root certificate file."
  :names ("root_cert_path")
  :type STRING)

(flag:define private-key-path ""
  "Path to private key file."
  :names ("private_key_path")
  :type STRING)

(flag:define cert-chain-path ""
  "Path to certificate chain file."
  :names ("cert_chain_path")
  :type STRING)

(defun main ()
  (google:init)
  (grpc:init-grpc)
  (let ((pem-root-certs (uiop:read-file-string (truename root-cert-path)))
        (private-key (uiop:read-file-string (truename private-key-path)))
        (cert-chain (uiop:read-file-string (truename cert-chain-path))))
    (grpc:with-ssl-channel
        (channel
         ((concatenate 'string hostname ":" (write-to-string port-number))
          (:pem-root-certs pem-root-certs
           :private-key private-key
           :cert-chain cert-chain)))

      ;; Unary streaming
      (let* ((message (testing:make-hello-request :name "Neo"))
             (response (testing-rpc:call-say-hello channel message)))
        (log:info "Response: ~A" (testing:hello-reply.message response)))

      ;; Server Streaming
      (let* ((message (testing:make-hello-request :name "Neo"
                                                  :num-responses 3))
             (response (testing-rpc:call-say-hello-server-stream channel message)))
        (loop for message in response
              do
           (log:info "Response: ~A" (testing:hello-reply.message message)))))
    (grpc:shutdown-grpc)))

--- END_FILE: ./grpc/examples/client/client-ssl.lisp ---

--- START_FILE: ./grpc/examples/client/README.md ---
# gRPC Client Example

## Insecure Example

The code in `client-insecure.lisp` shows how to make a gRPC client call over an insecure channel.

To run this example, first start the server:

```sh
blaze run //third_party/lisp/grpc/examples/client:helloworld_server -- --port=50051 --auth_mechanism="insecure"
```

Then run the client:

```sh
blaze run //third_party/lisp/grpc/examples/client:client-insecure -- --port=50051 --logtostderr
```

<!-- BEGIN_INTERNAL -->
## LOAS2 Example

The code in `client-loas2.lisp` shows how to make a gRPC client call utilizing LOAS2 for
authentication.

To run this example, first start the server:

```sh
blaze run //third_party/lisp/grpc/examples/client:helloworld_server -- --port=50051 --auth_mechanism="loas2"
```

Then run the client:

```sh
blaze run //third_party/lisp/grpc/examples/client:client-loas2 -- --port 50051 --logtostderr
```
<!-- END_INTERNAL -->

## SSL Example

The code in `client-ssl.lisp` shows how to make a gRPC client call over a secure channel, using SSL
for authentication.

To run this example, first start the server:

```sh
blaze run //third_party/lisp/grpc/examples/client:helloworld_server -- --port=50051 --auth_mechanism="ssl" --root_cert_path=<Path to root certificate> --private_key_path=<Path to private key> --certificate_chain_path=<Path to certificate chain>
```

Then run the client:

```sh
blaze run //third_party/lisp/grpc/examples/client:client-ssl -- --port=50051 --logtostderr --root_cert_path=<Path to root certificate> --private_key_path=<Path to private key> --cert_chain_path=<Path to certificate chain>
```

--- END_FILE: ./grpc/examples/client/README.md ---

--- START_FILE: ./grpc/examples/client/client-insecure.lisp ---
;; Copyright 2016-2021 Google LLC
;;
;; Use of this source code is governed by an MIT-style
;; license that can be found in the LICENSE file or at
;; https://opensource.org/licenses/MIT.

;;  A simple test for gRPC Client in Common Lisp using an insecure channel.

(defpackage #:testing-client-insecure
  (:use #:common-lisp)
  (:local-nicknames (#:testing #:cl-protobufs.lisp.grpc.integration-testing)
                    (#:testing-rpc #:cl-protobufs.lisp.grpc.integration-testing-rpc)
                    (#:flag #:ace.flag))
  (:export #:main))

(in-package #:testing-client-insecure)

(flag:define hostname "localhost"
  "Name of server that will be connected to."
  :names ("hostname")
  :type STRING)

(flag:define port-number 8080
  "Port of server to establish connection to."
  :names ("port")
  :type INTEGER)

(defun main ()
  (grpc:init-grpc)
  (unwind-protect
       (grpc:with-insecure-channel
           (channel (concatenate 'string hostname ":" (write-to-string port-number)))

         ;; Unary streaming
         (format nil "Trying unary call")
         (let* ((message (testing:make-hello-request :name "Neo"))
                (response (testing-rpc:call-say-hello channel message)))
           (format nil "Response: ~A" (testing:hello-reply.message response)))

         ;; Server Streaming
         (format nil "Trying server streaming call")
         (let* ((message (testing:make-hello-request
                          :name "Neo" :num-responses 3))
                (response (testing-rpc:call-say-hello-server-stream channel message)))
           (loop for message in response
                 do
              (format nil "Response: ~A" (testing:hello-reply.message message))))

         ;; Client Streaming
         (format nil "Trying client streaming call")
         (let* ((messages (list (testing:make-hello-request :name "Pika")
                                (testing:make-hello-request :name "Chu")
                                (testing:make-hello-request :name "Char")
                                (testing:make-hello-request :name "Mander")))
                (response (testing-rpc:call-say-hello-client-stream channel messages)))
           (format nil "Response: ~A" (testing:hello-reply.message response)))

         ;; Bidirectional Streaming.
         (format nil "Trying bidirectional streaming call")
         (let* ((messages (list (testing:make-hello-request
                                 :name "Pika" :num-responses 1)
                                (testing:make-hello-request
                                 :name "Chu" :num-responses 2)
                                (testing:make-hello-request
                                 :name "Char" :num-responses 3)))
                (response (testing-rpc:call-say-hello-bidirectional-stream channel messages)))
           (loop for message in response
                 do
              (format nil "Response: ~A" (testing:hello-reply.message message))))

         (format nil "Trying different streaming")
         (let ((call (testing-rpc:say-hello-bidirectional-stream/start channel)))
           (testing-rpc:say-hello-server-stream/send
            call (testing:make-hello-request :name "pika" :num-responses 3))
           (loop repeat 3
                 for message = (testing-rpc:say-hello-server-stream/receive call)
                 while message do
                   (format nil "Response: ~A" (testing:hello-reply.message message)))
           (testing-rpc:say-hello-server-stream/send
            call (testing:make-hello-request :name "chu" :num-responses 2))
           (testing-rpc:say-hello-server-stream/close call)
           (loop repeat 2
                 for message = (testing-rpc:say-hello-server-stream/receive call)
                 while message do
                   (format nil "Response: ~A" (testing:hello-reply.message message)))
           (testing-rpc:say-hello-server-stream/cleanup call)))

    (grpc:shutdown-grpc)))

--- END_FILE: ./grpc/examples/client/client-insecure.lisp ---

--- START_FILE: ./grpc/examples/client/helloworld.proto ---
// Copyright 2021 Google LLC
//
// Use of this source code is governed by an MIT-style
// license that can be found in the LICENSE file or at
// https://opensource.org/licenses/MIT.

syntax = "proto3";

package lisp.grpc.integration_testing;

message HelloRequest {
  optional string name = 1;
  optional int32 num_responses = 2;
}

message HelloReply {
  optional string message = 1;
}

service Greeter {
  // Receives a HelloRequest and response with a HelloReply.
  rpc SayHello(HelloRequest) returns (HelloReply) {}
  // Receive a HelloRequest requesting some number of responses in num_responses
  // and response with a HelloReply num_responses times.
  rpc SayHelloServerStream(HelloRequest) returns (stream HelloReply) {}
  // Receive a number of requests and concatenate the name field of each
  // HelloRequest. Return the final string in HelloReply.
  rpc SayHelloClientStream(stream HelloRequest) returns (HelloReply) {}
  // Receive a number of HelloRequest requesting some number of responses in num_responses.
  // Respond to each HelloRequest with a HelloReply num_responses times.
  rpc SayHelloBidirectionalStream(stream HelloRequest) returns (stream HelloReply) {}
}

--- END_FILE: ./grpc/examples/client/helloworld.proto ---

--- START_FILE: ./grpc/server.lisp ---
;;; Copyright 2021 Google LLC
;;;
;;; Use of this source code is governed by an MIT-style
;;; license that can be found in the LICENSE file or at
;;; https://opensource.org/licenses/MIT.

;;;; Public Interface for gRPC

(in-package #:grpc)

(cffi:defcfun ("create_new_grpc_call_details"
               create-grpc-call-details )
  :pointer)

(cffi:defcfun ("delete_grpc_call_details"
               call-details-destroy )
  :void
  (call-details :pointer))

(cffi:defcfun ("start_server" start-server )
  :pointer
  (cq :pointer)
  (server-credentials :pointer)
  (server-address :string))

(cffi:defcfun ("register_method" register-method )
  :pointer
  (server :pointer)
  (method-name :string)
  (server-address :string))

(cffi:defcfun ("grpc_run_server" run-server )
  :pointer
  (server :pointer)
  (server-credentials :pointer))

(cffi:defcfun ("lisp_grpc_server_request_call" grpc-server-request-call )
  :pointer
  (server :pointer)
  (details :pointer)
  (request-metadata :pointer)
  (cq-bound :pointer)
  (cq-notify :pointer)
  (tag :pointer))

(cffi:defcfun ("shutdown_server" shutdown-server )
  :void
  (server :pointer)
  (cq :pointer)
  (tag :pointer))

(defun start-call-on-server (server)
  "Make gRPC SERVER call and return a call struct"
  (let* ((tag (cffi:foreign-alloc :int))
         (metadata (create-new-grpc-metadata-array))
         (call-details (create-grpc-call-details))
         (c-call (grpc-server-request-call server call-details
                                           metadata
                                           grpc::*completion-queue*
                                           grpc::*completion-queue* tag))
         (method (get-call-method call-details)))
    (assert (not (cffi:null-pointer-p c-call)))
    (metadata-destroy metadata)
    (call-details-destroy call-details)
    (cffi:foreign-free tag)
    (grpc::make-call :c-call c-call
                     :c-tag (cffi:null-pointer)
                     :c-ops (cffi:null-pointer)
                     :method-name method
                     :ops-plist nil)))

(defun send-initial-metadata (call)
  "Send the GRPC_OP_SEND_INITIAL_METADATA from the server through a CALL"
  (declare (type call call))
  (let* ((num-ops 1)
         (c-call (call-c-call call))
         (tag (cffi:foreign-alloc :int))
         (ops (create-new-grpc-ops num-ops))
         (ops-plist (prepare-ops ops :send-metadata t))
         (call-code (call-start-batch c-call ops num-ops tag)))
    (declare (ignore ops-plist))
    (unless (eql call-code :grpc-call-ok)
      (cffi:foreign-free tag)
      (grpc-ops-free ops num-ops)
      (error 'grpc-call-error :call-error call-code))
    (let ((cqp-p (completion-queue-pluck *completion-queue* tag)))
      (grpc-ops-free ops num-ops)
      (cffi:foreign-free tag)
      cqp-p)))

(defun server-send-status (call)
  "Send the GRPC_OP_SEND_STATUS_FROM_SERVER from the server through a CALL"
  (declare (type call call))
  (let* ((num-ops 1)
         (c-call (call-c-call call))
         (tag (cffi:foreign-alloc :int))
         (ops (create-new-grpc-ops num-ops))
         (ops-plist (prepare-ops ops :server-send-status :grpc-status-ok))
         (call-code (call-start-batch c-call ops num-ops tag)))
    (declare (ignore ops-plist))
    (unless (eql call-code :grpc-call-ok)
      (cffi:foreign-free tag)
      (grpc-ops-free ops num-ops)
      (error 'grpc-call-error :call-error call-code))
    (let ((cqp-p (completion-queue-pluck *completion-queue* tag)))
      (grpc-ops-free ops num-ops)
      (cffi:foreign-free tag)
      cqp-p)))

(defun server-recv-close (call)
  "Send the GRPC_OP_RECV_STATUS_ON_CLIENT from the server through a CALL"
  (declare (type call call))
  (let* ((num-ops 1)
         (c-call (call-c-call call))
         (tag (cffi:foreign-alloc :int))
         (ops (create-new-grpc-ops num-ops))
         (ops-plist (prepare-ops ops :server-recv-close t))
         (call-code (call-start-batch c-call ops num-ops tag)))
    (declare (ignore ops-plist))
    (unless (eql call-code :grpc-call-ok)
      (cffi:foreign-free tag)
      (grpc-ops-free ops num-ops)
      (error 'grpc-call-error :call-error call-code))
    (let ((cqp-p (completion-queue-pluck *completion-queue* tag)))
      (grpc-ops-free ops num-ops)
      (cffi:foreign-free tag)
      cqp-p)))

(defun dispatch-requests (methods server &key (exit-count nil))
  "Block on the SERVER for a call then dispatch the call to the
proper method in METHODS based on the call method name. EXIT-COUNT
allows the caller to specify the number of times dispatch-call
can receive a call."
  (loop for calls-received from 0
        while (or (not exit-count)
                  (< calls-received exit-count))
        do
     (let* ((call (start-call-on-server server))
            (messages (receive-message call))
            (message (apply #'concatenate '(array (unsigned-byte 8) (*)) messages)))
       (send-initial-metadata call)
       (unwind-protect
            (let* ((method (find (call-method-name call)
                                 methods
                                 :test #'string=
                                 :key #'method-details-name))
                   (deserialized-message
                    (funcall (method-details-deserializer method) message))
                   (response
                    (funcall (method-details-action method)
                             deserialized-message call))
                   (serialized-response
                    (funcall (method-details-serializer method) response)))
              (send-message call serialized-response)
              (server-send-status call)
              (server-recv-close call))
         (free-call-data call)))))

(defun run-grpc-server (address methods
                        &key
                        (server-creds
                         (grpc-insecure-server-credentials-create))
                        (cq grpc::*completion-queue*)
                        (num-threads 1)
                        (dispatch-requests #'dispatch-requests))
  "Start a gRPC server.
Parameters
  ADDRESS: The address to run the server on.
  METHODS: The methods to start. Should be a list of method-details.
  SERVER-CREDS: Pointer to the gRPC server credentials.
  CQ: The completion queue to use.
  NUM-THREADS: The number of threads to have running.
  DISPATCH-CALL: A function to use to dispatch calls.
                 Useful for debugging."
  (let* ((server (start-server cq server-creds address))
         threads)

    (dolist (method methods)
      (format t "~s~%" (method-details-name method))
      (register-method server (method-details-name method) address))
    (run-server server server-creds)

    (unwind-protect
         (dotimes (i num-threads)
           (push
            (bordeaux-threads:make-thread
             (lambda ()
               (funcall dispatch-requests methods server))
             :name (format nil "Dispatch Request Thread ~a" i))
            threads))

      (dolist (thread threads)
        (bordeaux-threads:join-thread thread))

    (shutdown-server server cq (cffi:foreign-alloc :int)))))

--- END_FILE: ./grpc/server.lisp ---

--- START_FILE: ./grpc/tests/integration-test.lisp ---
;;; Copyright 2022 Google LLC
;;;
;;; Use of this source code is governed by an MIT-style
;;; license that can be found in the LICENSE file or at
;;; https://opensource.org/licenses/MIT.

;;  A simple integration test for gRPC Client and Server in Common Lisp

(defpackage #:grpc.test.server
  (:use #:cl
        #:clunit
        #:grpc)
  (:export :run))

(in-package #:grpc.test.server)

(defsuite server-suite (grpc.test:root-suite))

(defun run (&key use-debugger)
  "Run all tests in the test suite.
Parameters
  USE-DEBUGGER: On assert failure bring up the debugger."
  (clunit:run-suite 'server-suite :use-debugger use-debugger
                                  :signal-condition-on-fail t))

(defun run-server (sem hostname method-name port-number)
  (grpc::run-grpc-server
   (concatenate 'string
                hostname ":"
                (write-to-string port-number))
   (list
    (grpc::make-method-details
     :name method-name
     :serializer #'flexi-streams:string-to-octets
     :deserializer
     (lambda (message)
       (flexi-streams:octets-to-string
        message
        :external-format
        :utf-8))
     :action
     (lambda (message call)
       (declare (ignore call))
       (format t "~% response: ~A ~%" message)
       (concatenate 'string
                    message
                    " Back"))))
   :dispatch-requests
   (lambda (method server)
     (bordeaux-threads:signal-semaphore sem)
     (grpc::dispatch-requests method server :exit-count 1))))

(deftest test-client-server-integration-success (server-suite)
  ;; init
  (grpc:init-grpc)
  (unwind-protect
       (let* ((expected-client-response "Hello World Back")
              (hostname "localhost")
              (method-name "xyz")
              (port-number 8000)
              (sem (bordeaux-threads:make-semaphore))
              (thread (bordeaux-threads:make-thread
                       (lambda () (run-server sem hostname method-name
                                              port-number)))))
         (bordeaux-threads:wait-on-semaphore sem)
         (grpc:with-insecure-channel
             (channel
              (concatenate 'string hostname ":" (write-to-string port-number)))
           (let* ((message "Hello World")
                  (response (grpc:grpc-call channel method-name
                                            (flexi-streams:string-to-octets message)
                                            nil nil))
                  (actual-client-response (flexi-streams:octets-to-string
                                           (car response))))
             (assert-true (string=  actual-client-response expected-client-response))
             (bordeaux-threads:join-thread thread)))))
  (grpc:shutdown-grpc))

--- END_FILE: ./grpc/tests/integration-test.lisp ---

--- START_FILE: ./grpc/tests/test.proto ---
// Copyright 2021 Google LLC
//
// Use of this source code is governed by an MIT-style
// license that can be found in the LICENSE file or at
// https://opensource.org/licenses/MIT.

syntax = "proto3";

package lisp.grpc.unit_testing;

message HelloRequest {
  optional string name = 1;
  optional int32 num_responses = 2;
}

message HelloReply {
  optional string message = 1;
}

service Greeter {
  // Receives a HelloRequest and response with a HelloReply.
  rpc SayHello(HelloRequest) returns (HelloReply) {}
  // Receive a HelloRequest requesting some number of responses in num_responses
  // and response with a HelloReply num_responses times.
  rpc SayHelloServerStream(HelloRequest) returns (stream HelloReply) {}
  // Receive a number of requests and concatenate the name field of each
  // HelloRequest. Return the final string in HelloReply.
  rpc SayHelloClientStream(stream HelloRequest) returns (HelloReply) {}
  // Receive a number of HelloRequest requesting some number of responses in num_responses.
  // Respond to each HelloRequest with a HelloReply num_responses times.
  rpc SayHelloBidirectionalStream(stream HelloRequest) returns (stream HelloReply) {}
}

--- END_FILE: ./grpc/tests/test.proto ---

--- START_FILE: ./grpc/tests/cl-protobuf-integration-test.lisp ---
;;; Copyright 2022 Google LLC
;;;
;;; Use of this source code is governed by an MIT-style
;;; license that can be found in the LICENSE file or at
;;; https://opensource.org/licenses/MIT.

;;  A simple integration test for gRPC Client and Server in Common Lisp

(defpackage #:grpc.test.proto-server
  (:use #:cl
        #:clunit
        #:grpc)
  (:local-nicknames
   (#:ut #:cl-protobufs.lisp.grpc.unit-testing)
   (#:ut-rpc #:cl-protobufs.lisp.grpc.unit-testing-rpc))
  (:export :run))

(in-package #:grpc.test.proto-server)

(defsuite proto-server-suite (grpc.test:root-suite))

(defun run (&key use-debugger)
  "Run all tests in the test suite.
Parameters
  USE-DEBUGGER: On assert failure bring up the debugger."
  (clunit:run-suite 'proto-server-suite :use-debugger use-debugger
                                        :signal-condition-on-fail t))

(defmethod ut-rpc::say-hello ((request ut:hello-request) rpc)
  (declare (ignore rpc))
  (ut:make-hello-reply
   :message
   (concatenate 'string
                (ut:hello-request.name request)
                " Back")))

(defun run-server (sem hostname port-number)
  (grpc::run-grpc-proto-server
   (concatenate 'string
                hostname ":"
                (write-to-string port-number))
   'ut:greeter
   :dispatch-requests
   (lambda (method server)
     (bordeaux-threads:signal-semaphore sem)
     (grpc::dispatch-requests method server :exit-count 1))))

(deftest test-client-server-integration-success (proto-server-suite)
  ;; init
  (grpc:init-grpc)
  (unwind-protect
       (let* ((expected-client-response "Hello World Back")
              (hostname "localhost")
              (port-number 8000)
              (sem (bordeaux-threads:make-semaphore))
              (thread (bordeaux-threads:make-thread
                       (lambda () (run-server sem hostname port-number)))))

         (bordeaux-threads:wait-on-semaphore sem)

         (grpc:with-insecure-channel
             (channel (concatenate 'string hostname ":"
                                   (write-to-string port-number)))
           ;; Unary streaming
           (let* ((message (ut:make-hello-request :name "Hello World"))
                  (response (ut-rpc:call-say-hello channel message)))
             (assert-true (string= (ut:hello-reply.message response)
                                   expected-client-response))))
         (bordeaux-threads:join-thread thread))
    (grpc:shutdown-grpc)))

--- END_FILE: ./grpc/tests/cl-protobuf-integration-test.lisp ---

--- START_FILE: ./grpc/tests/pkgdcl.lisp ---
;;; Copyright 2021 Google LLC
;;;
;;; Use of this source code is governed by an MIT-style
;;; license that can be found in the LICENSE file or at
;;; https://opensource.org/licenses/MIT.

(in-package "CL-USER")

(defpackage #:grpc.test
  (:use #:cl)
  (:export #:root-suite
           #:run-all
           #:run-suite
           #:with-mocked-functions))

--- END_FILE: ./grpc/tests/pkgdcl.lisp ---

--- START_FILE: ./grpc/tests/protobuf-integration-test.lisp ---
;;; Copyright 2021 Google LLC
;;;
;;; Use of this source code is governed by an MIT-style
;;; license that can be found in the LICENSE file or at
;;; https://opensource.org/licenses/MIT.

(defpackage #:grpc.test.protobuf-integration
  (:use #:cl
        #:clunit
        #:cl-protobufs
        #:grpc)
  (:import-from #:grpc.test #:with-mocked-functions)
  (:local-nicknames (#:test-proto #:cl-protobufs.lisp.grpc.unit-testing))
  (:export :run))

(in-package #:grpc.test.protobuf-integration)

(defsuite protobuf-integration-suite (grpc.test:root-suite))

(defun run (&key use-debugger)
  "Run all tests in the test suite.
Parameters
  USE-DEBUGGER: On assert failure bring up the debugger."
  (clunit:run-suite 'protobuf-integration-suite :use-debugger use-debugger
                                                :signal-condition-on-fail t))

(deftest test-get-qualified-method-name (protobuf-integration-suite)
  "Validates the qualified name can be parsed from the provided method descriptor."
  (let* ((method-descriptor (make-instance 'cl-protobufs:method-descriptor
                                           :service-name "Greeter"
                                           :name "SayHello"
                                           :qualified-name "lisp.grpc.test.SayHello"))
         (expected-qualified-method-name "/lisp.grpc.test.Greeter/SayHello")
         (qualified-method-name (grpc::get-qualified-method-name method-descriptor)))
    (assert-true (string= expected-qualified-method-name qualified-method-name))))

(deftest test-start-call-unary-rpc (protobuf-integration-suite)
  "Validate the start-call method properly handles the scenario in which a single request is sent to
the server and a single response is returned."
  (let ((request (test-proto:make-hello-request :name "Neo"))
        (expected-response (test-proto:make-hello-reply :message "Hello, Neo"))
        (method (make-instance 'cl-protobufs:method-descriptor
                               :service-name "Greeter"
                               :name "SayHello"
                               :qualified-name "lisp.grpc.test.SayHello"
                               :output-type 'test-proto:hello-reply
                               :output-streaming nil
                               :input-streaming nil))
        (qualified-method-name "/lisp.grpc.test.Greeter/SayHello"))
    (with-mocked-functions ((grpc-call
                             (channel
                              service-method-name
                              bytes-to-send
                              server-stream
                              client-stream)
                             ;; No need to allocate extra memory for a channel that won't be used
                             ;; since we're mocking the underlying call.
                             (declare (ignore channel))
                             (assert-true (string= service-method-name qualified-method-name))
                             (assert-equalp bytes-to-send
                                            (cl-protobufs:serialize-to-bytes request))
                             (assert-eq server-stream nil)
                             (assert-eq client-stream nil)
                             (list (cl-protobufs:serialize-to-bytes expected-response))))
      (let ((actual-response (grpc::start-call "channel" method request nil)))
        (assert-equalp actual-response expected-response)))))

(deftest test-start-call-server-streaming-rpc (protobuf-integration-suite)
  "Validate the start-call method properly handles the scenario in which a single request is sent to
the server and a stream of responses are returned."
  (let ((request (test-proto:make-hello-request :name "Neo" :num-responses 3))
        (expected-response (list (test-proto:make-hello-reply :message "Hello, Neo 0")
                                 (test-proto:make-hello-reply :message "Hello, Neo 1")
                                 (test-proto:make-hello-reply :message "Hello, Neo 2")))
        (method (make-instance 'cl-protobufs:method-descriptor
                               :service-name "Greeter"
                               :name "SayHelloServerStream"
                               :qualified-name "lisp.grpc.test.SayHelloServerStream"
                               :output-type 'test-proto:hello-reply
                               :output-streaming t
                               :input-streaming nil))
        (qualified-method-name "/lisp.grpc.test.Greeter/SayHelloServerStream"))
    (with-mocked-functions ((grpc-call
                             (channel
                              service-method-name
                              bytes-to-send
                              server-stream
                              client-stream)
                             ;; No need to allocate extra memory for a channel that won't be used
                             ;; since we're mocking the underlying call.
                             (declare (ignore channel))
                             (assert-true (string= service-method-name qualified-method-name))
                             (assert-equalp bytes-to-send
                                            (cl-protobufs:serialize-to-bytes request))
                             (assert-eq server-stream t)
                             (assert-eq client-stream nil)
                             (loop for message in expected-response
                                   collect (list (cl-protobufs:serialize-to-bytes message)))))
      (let ((actual-response (grpc::start-call "channel" method request nil)))
        (assert-equalp actual-response expected-response)))))

(deftest test-start-call-client-streaming-rpc (protobuf-integration-suite)
  "Validate the start-call method properly handles the scenario in which a stream of requests are
sent to the server and a single response is returned."
  (let ((request (list (test-proto:make-hello-request :name "Neo")
                       (test-proto:make-hello-request :name "Morpheus")
                       (test-proto:make-hello-request :name "Trinity")))
        (expected-response (test-proto:make-hello-reply :message "Hello, Neo Morpheus Trinity"))
        (method (make-instance 'cl-protobufs:method-descriptor
                               :service-name "Greeter"
                               :name "SayHelloClientStream"
                               :qualified-name "lisp.grpc.test.SayHelloClientStream"
                               :output-type 'test-proto:hello-reply
                               :output-streaming nil
                               :input-streaming t))
        (qualified-method-name "/lisp.grpc.test.Greeter/SayHelloClientStream"))
    (with-mocked-functions ((grpc-call
                             (channel
                              service-method-name
                              bytes-to-send
                              server-stream
                              client-stream)
                             ;; No need to allocate extra memory for a channel that won't be used
                             ;; since we're mocking the underlying call.
                             (declare (ignore channel))
                             (assert-true (string= service-method-name qualified-method-name))
                             (assert-equalp bytes-to-send
                                            (mapcar #'cl-protobufs:serialize-to-bytes request))
                             (assert-eq server-stream nil)
                             (assert-eq client-stream t)
                             (list (cl-protobufs:serialize-to-bytes expected-response))))
      (let ((actual-response (grpc::start-call "channel" method request nil)))
        (assert-equalp actual-response expected-response)))))

(deftest test-start-call-bidirectional-streaming (protobuf-integration-suite)
  "Validate the start-call method properly handles the scenario in which a stream of requests are
sent to the server and a stream of responses are returned."
  (let ((request (list (test-proto:make-hello-request :name "Neo" :num-responses 1)
                       (test-proto:make-hello-request :name "Morpheus" :num-responses 2)
                       (test-proto:make-hello-request :name "Trinity" :num-responses 1)))
        (expected-response (list (test-proto:make-hello-reply :message "Hello, Neo 0")
                                 (test-proto:make-hello-reply :message "Hello, Morpheus 1")
                                 (test-proto:make-hello-reply :message "Hello, Neo 1")
                                 (test-proto:make-hello-reply :message "Hello, Trinity 0")
                                 (test-proto:make-hello-reply :message "Hello, Morpheus 0")))
        (method (make-instance 'cl-protobufs:method-descriptor
                               :service-name "Greeter"
                               :name "SayHelloBidirectionalStream"
                               :qualified-name "lisp.grpc.test.SayHelloBidirectionalSream"
                               :output-type 'test-proto:hello-reply
                               :output-streaming t
                               :input-streaming t))
        (qualified-method-name "/lisp.grpc.test.Greeter/SayHelloBidirectionalStream"))
    (with-mocked-functions ((grpc-call
                             (channel
                              service-method-name
                              bytes-to-send
                              server-stream
                              client-stream)
                             ;; No need to allocate extra memory for a channel that won't be used
                             ;; since we're mocking the underlying call.
                             (declare (ignore channel))
                             (assert-true (string= service-method-name qualified-method-name))
                             (assert-equalp bytes-to-send
                                            (mapcar #'cl-protobufs:serialize-to-bytes request))
                             (assert-eq server-stream t)
                             (assert-eq client-stream t)
                             (loop for message in expected-response
                                   collect (list (cl-protobufs:serialize-to-bytes message)))))
      (let ((actual-response (grpc::start-call "channel" method request nil)))
        (assert-equalp actual-response expected-response)))))

--- END_FILE: ./grpc/tests/protobuf-integration-test.lisp ---

--- START_FILE: ./grpc/tests/root-suite.lisp ---
;;; Copyright 2021 Google LLC
;;;
;;; Use of this source code is governed by an MIT-style
;;; license that can be found in the LICENSE file or at
;;; https://opensource.org/licenses/MIT.

(in-package #:grpc.test)

;;; A suite to contain all other test suites so there's an easy entry point to run all tests.
(clunit:defsuite root-suite ())

(defun run-all ()
  "Run all tests."
  (clunit:run-suite 'root-suite :signal-condition-on-fail t))

(defun %generate-temporary-binding-name (binding)
  "Generates the temporary binding name to store the original function."
  (cons (car binding) (gensym)))

(defun %let-binding-expr (name)
  "Returns the LET binding that binds the original function to the temporary function name."
  (destructuring-bind (function-name . temporary-name) name
    `(,temporary-name (symbol-function ',function-name))))

(defun %set-mock-binding (binding)
  "Saves the mock function body to the symbol-function."
  (destructuring-bind (function-name &rest function-expr) binding
    `(setf (symbol-function ',function-name) (lambda ,@function-expr))))

(defun %reset-original-function-binding (name)
  "Rebind the original function to the symbol-function."
  (destructuring-bind (function-name . temporary-name) name
    `(setf (symbol-function ',function-name) ,temporary-name)))

(defmacro with-mocked-functions (bindings &body body)
  "Mocks the functions defined in BINDINGS before executing BODY."
  (let ((names (mapcar #'%generate-temporary-binding-name bindings)))
    `(let (,@(mapcar #'%let-binding-expr names))
       ,@(mapcar #'%set-mock-binding bindings)
       (prog1 (progn ,@body)
         ,@(mapcar #'%reset-original-function-binding names)))))

--- END_FILE: ./grpc/tests/root-suite.lisp ---

--- START_FILE: ./grpc/tests/server-test.lisp ---
;;; Copyright 2022 Google LLC
;;;
;;; Use of this source code is governed by an MIT-style
;;; license that can be found in the LICENSE file or at
;;; https://opensource.org/licenses/MIT.

(defpackage #:grpc.test.server
  (:use #:cl
        #:clunit
        #:grpc)
  (:import-from #:grpc.test #:with-mocked-functions)
  (:export :run))

(in-package #:grpc.test.server)

(defsuite server-suite (grpc.test:root-suite))

(defun run (&key use-debugger)
  "Run all tests in the test suite.
Parameters
  USE-DEBUGGER: On assert failure bring up the debugger."
  (clunit:run-suite 'server-suite :use-debugger use-debugger
                                  :signal-condition-on-fail t))

(defun make-null-call ()
  "A helper function that returns a grpc::make-call object with the aprropriate parameters"
  (grpc::make-call :c-call (cffi:null-pointer)
                   :c-tag (cffi:foreign-alloc :int)
                   :c-ops (cffi:null-pointer)
                   :ops-plist nil))

(deftest test-server-check-error-success (server-suite)
  "Validate that send-initial-metadata, send-message, server-send-status,
server-recv-close, receive-message methods properly handle the scenario
 and check for errors when a call code of grpc-call-error is sent."
  (let* ((call-object (make-null-call))
         (message "Test")
         (text-result (flexi-streams:string-to-octets message)))
    (with-mocked-functions ((grpc::call-start-batch
                             (c-call ops num-ops tag)
                             (declare (ignore c-call ops num-ops tag))
                             :grpc-call-error))
      (assert-condition grpc::grpc-call-error
                        (grpc::send-initial-metadata call-object))
      (assert-condition grpc::grpc-call-error
                        (grpc::send-message call-object text-result))
      (assert-condition grpc::grpc-call-error
                        (grpc::server-send-status call-object))
      (assert-condition grpc::grpc-call-error
                        (grpc::server-recv-close call-object))
      (assert-condition grpc::grpc-call-error
                        (grpc::receive-message call-object)))))

(deftest test-server-return-true-success (server-suite)
  "Validate that send-initial-metadata, send-message,
server-send-status, server-recv-close, receive-message methods
properly handle the scenario and return true when a call code
 of grpc-call-ok is sent."
  (let* ((call-object (make-null-call))
         (message "Test")
         (text-result (flexi-streams:string-to-octets message)))
    (with-mocked-functions ((grpc::call-start-batch
                             (c-call ops num-ops tag)
                             (declare (ignore c-call ops num-ops tag))
                             :grpc-call-ok)
                            (grpc::completion-queue-pluck
                             (completion_queue tag)
                             (declare (ignore completion_queue tag))
                             t))
      (assert-true (grpc::send-initial-metadata call-object))
      (assert-true (grpc::send-message call-object text-result))
      (assert-true (grpc::server-send-status call-object))
      (assert-true (grpc::server-recv-close call-object)))))

(deftest test-server-receive-message-completion-queue-pluck-nil-success
    (server-suite)
  "Validate that receive-message method properly handles the scenario and
returns nil when a call code of grpc-call-ok and nil for completion-queue-pluck
 is sent"
  (let ((call-object (make-null-call)))
    (with-mocked-functions ((grpc::call-start-batch
                             (c-call ops num-ops tag)
                             (declare (ignore c-call ops num-ops tag))
                             :grpc-call-ok)
                            (grpc::completion-queue-pluck
                             (completion_queue tag)
                             (declare (ignore completion_queue tag))
                             nil))
      (assert-false (grpc::receive-message call-object)))))

(deftest test-server-receive-message-get-grpc-op-recv-message-null-pointer-success
    (server-suite)
  "Validate that receive-message method properly handles the scenario and
returns nil when a call code of grpc-call-ok, nil for completion-queue-pluck
 and null-pointer for get-grpc-op-recv-message is sent"
  (let ((call-object (make-null-call)))
    (with-mocked-functions ((grpc::call-start-batch
                             (c-call ops num-ops tag)
                             (declare (ignore c-call ops num-ops tag))
                             :grpc-call-ok)
                            (grpc::completion-queue-pluck
                             (completion_queue tag)
                             (declare (ignore completion_queue tag))
                             t)
                            (grpc::get-grpc-op-recv-message
                             (op index)
                             (declare (ignore op index))
                             (cffi:null-pointer)))
      (assert-false (grpc::receive-message call-object)))))

--- END_FILE: ./grpc/tests/server-test.lisp ---

--- START_FILE: ./grpc/client_auth.cc ---
// Copyright 2021 Google LLC
//
// Use of this source code is governed by an MIT-style
// license that can be found in the LICENSE file or at
// https://opensource.org/licenses/MIT.

#include <grpc/grpc_security.h>
#include <grpcpp/security/credentials.h>

namespace lisp {
namespace grpc {

extern "C" {

grpc_ssl_pem_key_cert_pair* create_grpc_ssl_pem_key_cert_pair(
    const char* private_key, const char* cert_chain) {
  // The validation check in the underlying cpp code will raise an error if either
  // of these is null and the overall struct isn't also a nullptr.
  // https://github.com/grpc/grpc/blob/master/src/core/lib/security/credentials/ssl/ssl_credentials.cc#L99-L101
  if (private_key == nullptr || cert_chain == nullptr) {
    return nullptr;
  }
  grpc_ssl_pem_key_cert_pair* keypair = new grpc_ssl_pem_key_cert_pair;
  *keypair = (grpc_ssl_pem_key_cert_pair) {
    .private_key = private_key,
    .cert_chain = cert_chain};
  return keypair;
}

void delete_grpc_ssl_pem_key_cert_pair(
    grpc_ssl_pem_key_cert_pair* keypair) {
  delete keypair;
}

grpc_ssl_verify_peer_options* create_grpc_ssl_verify_peer_options(
    int (*verify_peer_callback)(const char* target_name, const char* peer_pem, void* userdata),
    void* verify_peer_callback_userdata,
    void (*verify_peer_destruct)(void* userdata)) {
  grpc_ssl_verify_peer_options* options = new grpc_ssl_verify_peer_options;
  *options = (grpc_ssl_verify_peer_options) {
    .verify_peer_callback = verify_peer_callback,
    .verify_peer_callback_userdata = verify_peer_callback_userdata,
    .verify_peer_destruct = verify_peer_destruct};
  return options;
}

void delete_grpc_ssl_verify_peer_options(
    grpc_ssl_verify_peer_options* options) {
  delete options;
}

}  // extern "C"
}  // namespace grpc
}  // namespace lisp

--- END_FILE: ./grpc/client_auth.cc ---

--- START_FILE: ./grpc/grpc.lisp ---
;; Copyright 2016-2021 Google LLC
;;
;; Use of this source code is governed by an MIT-style
;; license that can be found in the LICENSE file or at
;; https://opensource.org/licenses/MIT.

;;  A wrapper for using gRPC in Common Lisp.

(defpackage #:grpc
  (:use #:common-lisp)
  (:local-nicknames
   (#:proto-impl #:cl-protobufs.implementation)
   (#:proto #:cl-protobufs))
  (:export
   ;; Client Functions
   #:init-grpc
   #:shutdown-grpc
   #:with-insecure-channel
   #:with-ssl-channel
   #:grpc-call
   #:check-server-status))

--- END_FILE: ./grpc/grpc.lisp ---

--- START_FILE: ./grpc/CONTRIBUTING.md ---
# How to Contribute

We'd love to accept your patches and contributions to this project. There are
just a few small guidelines you need to follow.

## Contributor License Agreement

Contributions to this project must be accompanied by a Contributor License
Agreement (CLA). You (or your employer) retain the copyright to your
contribution; this simply gives us permission to use and redistribute your
contributions as part of the project. Head over to
<https://cla.developers.google.com/> to see your current agreements on file or
to sign a new one.

You generally only need to submit a CLA once, so if you've already submitted one
(even if it was for a different project), you probably don't need to do it
again.

## Code reviews

All submissions, including submissions by project members, require review. We
use GitHub pull requests for this purpose. Consult
[GitHub Help](https://help.github.com/articles/about-pull-requests/) for more
information on using pull requests.

## Community Guidelines

This project follows
[Google's Open Source Community Guidelines](https://opensource.google/conduct/).

--- END_FILE: ./grpc/CONTRIBUTING.md ---

--- START_FILE: ./grpc/Makefile ---
# Copyright 2021 Google LLC
GRPC_ROOT ?= /usr/local
LIBS = -lgrpc -lgpr
CXXFLAGS = $(shell pkg-config grpc --cflags) -I$(GRPC_ROOT)/include -fPIC
LDFLAGS = -L$(GRPC_ROOT)/lib $(LIBS)
OFILES = client.o client_auth.o server.o

default_target: grpc.so

.PHONY : default_target clean

grpc.so: ${OFILES}
	$(CXX)  -pthread -shared -Wl,--no-undefined ${OFILES} -o $@ $(LDFLAGS)

clean:
	rm -f ${OFILES} grpc.so

client.o: client.cc
client_auth.o: client_auth.cc
server.o: server.cc

--- END_FILE: ./grpc/Makefile ---

--- START_FILE: ./grpc/libraries.lisp ---
;;; Copyright 2021 Google LLC
;;;
;;; Use of this source code is governed by an MIT-style
;;; license that can be found in the LICENSE file or at
;;; https://opensource.org/licenses/MIT.

;;;; Load foreign libraries.

(in-package #:grpc)

(eval-when (:compile-toplevel :load-toplevel :execute)
  (cffi:define-foreign-library grpc-client-wrapper
	;; Load lib on mac
	(:darwin #.(namestring (asdf:system-relative-pathname "grpc" "grpc.so")))
    ;; Load the C wrapper directly from the source directory.
    (t (:default #.(namestring
                    (asdf:system-relative-pathname "grpc" "grpc")))))
  (cffi:load-foreign-library 'grpc-client-wrapper))

--- END_FILE: ./grpc/libraries.lisp ---

--- START_FILE: ./grpc/README.md ---
# gRPC Library in Common Lisp

[![SBCL-Tests](https://github.com/qitab/grpc/actions/workflows/SBCL-test.yml/badge.svg)](https://github.com/qitab/grpc/actions/workflows/SBCL-test.yml)
[![CCL-Tests](https://github.com/qitab/grpc/actions/workflows/CCL-test.yml/badge.svg)](https://github.com/qitab/grpc/actions/workflows/CCL-test.yml)



## Overview

This package defines a [gRPC](https://grpc.io/) client library for Common Lisp.
It wraps gRPC core functions with CFFI calls and uses those core functions to
create and use a client. client.lisp contains all the necessary functions to
create a gRPC client by creating channels (connections between client and
server) and calls (requests to a server).

Currently there is support for synchronous and streaming calls over

SSL, and insecure channels.

Support for implementing gRPC servers is in development.

## Usage

To create a client, a channel must first be created. Depending on the expected
authentication mechanism (or lack thereof), different channel creation macros
are available.

### Channel Creation

#### Insecure Channels

If using an insecure channel, use the `with-insecure-channel` macro. This macro
expects a symbol to bind the channel to and the server address.

```lisp
(with-insecure-channel (channel "localhost:8080")
;; Code that uses channel
...)
```

#### SSL Channels

If using an SSL channel, use the `with-ssl-channel` macro. This macro
expects a symbol to bind the channel, the server address and
certificate data to make the call.

```lisp
(with-ssl-channel (channel
                    ("localhost:8080"
                      (:pem-root-certs pem-root-certs
                       :private-key private-key
                       :cert-chain cert-chain)))
;; Code that uses channel
...)
```



### Sending RPC Requests

Once a channel has been created, RPC requests to the server can occur.
It is possible to send binary data directly over `gRPC` but most applications using
`gRPC` will expect a Protocol Buffer encoded message. For details on Protocol buffer
integration please see [Protocol Buffer Integration](#protocol-buffer-integration).

A message can be sent directly through `gRPC` using `grpc-call`.
This expects the channel that was previously created, the service name and method to be
called, and the request message serialized to bytes. The `grpc-call` method also
takes `server-stream` and `client-stream` arguments which state whether the message
should use server or client side streaming as discussed in
[Types of Services](#types-of-services)

```lisp
(grpc:grpc-call channel
                "/serviceName/ServiceMethod"
                serialized-message server-stream client-stream)
;; Returns the response a list of byte vectors for each response
```

### Types of Services

An RPC can support any of `unary`, `mono-directional`, or `bidirectional` streaming.
This must be decided beforehand by the server and client.

There are two different types of `mono-directional-streaming` RPC's:
1. Server Side Streaming.
2. Client Side Streaming.

See https://grpc.io/docs/what-is-grpc/core-concepts/#rpc-life-cycle  for details.

#### Unary RPC

A unary RPC sends one message and receives one message.
The `grpc-call` function takes in a single vector for `bytes-to-send`
and return a single octet-vector.

#### Server Side Streaming RPC

A server side streaming RPC sends one message and receives multiple messages.
The `grpc-call` function takes in a single vector for `bytes-to-send`
and return a list of octet-vectors corresponding to the received messages.

#### Client Side Streaming RPC

A client side streaming RPC sends some number of messages and receives a single message.
The `grpc-call` function takes in a list of vectors for `bytes-to-send`
and returns an octet-vector corresponding to the received message.

#### Bidirectional Streaming RPC

A bidirectional streaming RPC sends any number of messages and receives any number of messages.
The `grpc-call` function takes in a list of vectors for `bytes-to-send`
and returns a list of octet-vectors corresponding to the received messages.

### Protocol Buffer Integration

gRPC can work with or without Protocol Buffer support. With that said,
it is common to use a Protocol Buffer library in conjunction with gRPC.
We have implemented support for the `cl-protobufs` library.

The Qitab team provides supports `cl-protobufs` but doesn't guarantee continued support
for other data format libraries.

To use gRPC with `cl-protobufs` you must load `cl-protobufs` and `gRPC` with
`grpc-protobuf-integration.lisp` into your running lisp image.

Example:

Define a protocol buffer service with methods as:

```proto
package testing;

message HelloRequest {
  optional string name = 1;
}

message HelloReply {
  optional string message = 1;
}

service Greeter {
  // Receives a HelloRequest and responds with a HelloReply.
  rpc SayHello(HelloRequest) returns (HelloReply) {}
  // Receive a HelloRequest requesting some number of responses in num_responses
  // and response with a HelloReply num_responses times.
  rpc SayHelloServerStream(HelloRequest) returns (stream HelloReply) {}
  // Receive a number of requests and concatenate the name field of each
  // HelloRequest. Return the final string in HelloReply.
  rpc SayHelloClientStream(stream HelloRequest) returns (HelloReply) {}
  // Receive a number of HelloRequest requesting some number of responses in num_responses.
  // Respond to each HelloRequest with a HelloReply num_responses times.
  rpc SayHelloBidirectionalStream(stream HelloRequest) returns (stream HelloReply) {}
}
```

We create two packages:

* `cl-protobufs.testing`
* `cl-protobufs.testing-rpc`

The package `cl-protobufs.testing` contains the `hello-request` and `hello-reply`  protocol
buffer messages.

#### One Shot Client Calls.

The package `cl-protobufs.testing-rpc` contains a stub for `call-say-hello`.
A message can be sent to a server implementing the `Greeter` service with:

```lisp
  (grpc:with-insecure-channel
      (channel (concatenate 'string hostname ":" (write-to-string port-number)))
    (let* ((request (cl-protobufs.testing:make-hello-request :name "Neo"))
           (response (cl-protobufs.testing-rpc:call-say-hello channel message)))
      ...))
```

If the service implements client-side streaming `message` should be a list
of `hello-request` messages to be sent to the server. If the service implements
server-side streaming then response will contain a list of `hello-reply`
messages.

#### Asynchronous Client Streaming

For streaming calls we create:

-   `cl-protobufs.testing-rpc:<service-name>/start`
-   `cl-protobufs.testing-rpc:<service-name>/send`
-   `cl-protobufs.testing-rpc:<service-name>/receive`
-   `cl-protobufs.testing-rpc:<service-name>/close`
-   `cl-protobufs.testing-rpc:<service-name>/cleanup`

functions.

We will use `SayHelloBidirectionalStream` service as an example below.

```
(testing-rpc:say-hello-bidirectional-stream/start channel)
```

Takes in a `channel` object and returns a `call` object that the user must keep
until the call is `closed` and `cleanup` is called.

```
(testing-rpc:say-hello-bidirectional-stream/send call message)
```

Takes in the `call` object and a `message` and sends a message to the client.

```
(testing-rpc:say-hello-server-stream/receive call)
```

Blocks until a message is received, then returns that message.
`NIL` will be returned if the server closes the channel.

```
(testing-rpc:say-hello-server-stream/close call)
```

Will `close` the channel on the client side.

```
(testing-rpc:say-hello-server-stream/cleanup call)
```

Will safely cleanup any data leftover in the `call` object.

#### Example

This example can be found in examples/client/client-insecure.lisp.

## Further Reading

-   See https://grpc.io for more information on gRPC.
-   See examples/client/README.md for an example of how to run the example code.
-   For more on Cl-Protobufs read  https://github.com/qitab/cl-protobufs

--- END_FILE: ./grpc/README.md ---

--- START_FILE: ./grpc/version.sexp ---
"0.9"

--- END_FILE: ./grpc/version.sexp ---

--- START_FILE: ./grpc/client.cc ---
// Copyright 2021 Google LLC
//
// Use of this source code is governed by an MIT-style
// license that can be found in the LICENSE file or at
// https://opensource.org/licenses/MIT.

#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include <cstddef>

#include <grpc/byte_buffer.h>
#include <grpc/grpc.h>
#include <grpc/impl/grpc_types.h>
#include <grpc/impl/slice_type.h>
#include <grpc/slice.h>
#include <grpc/status.h>
#include <grpc/support/time.h>

namespace lisp {
namespace lisp_grpc {

extern "C" {

// Creates a grpc_call* given a 'channel', which manages the
// connection to the server, and 'call_name' which will tell the server
// how to understand information from the call, and the 'cq'
// which will start the actual call and return if successful when
// grpc_completion_queue_pluck or grpc_completion_queue_next is called.
grpc_call* lisp_grpc_channel_create_call(grpc_channel* channel,
                                         const char* call_name,
                                         grpc_completion_queue* cq) {
  return grpc_channel_create_call(
      channel, nullptr, GRPC_PROPAGATE_DEFAULTS, cq,
      grpc_slice_from_copied_string(call_name), nullptr,
      gpr_inf_future(GPR_CLOCK_MONOTONIC), nullptr);
}

// Prepares ops for completion queue pluck/next
// and returns a grpc_call_error, and if successful a
// call is added to the completion queue.
// Upon success lisp_grpc_completion_queue_pluck must be called
// with tag.
grpc_call_error lisp_grpc_call_start_batch(grpc_call* call, const grpc_op* ops,
                                           size_t num_ops, void* tag) {
  return grpc_call_start_batch(call, ops, num_ops, tag, nullptr);
}

// Checks the completion queue 'cq' for an element associated with
// 'tag' and if successful will start all the operations that were prepared
// in lisp_grpc_call_start_batch.
// This function will return a grpc_event* which will be checked to see if
// the operations were successful.
bool lisp_grpc_completion_queue_pluck(grpc_completion_queue* cq, void* tag) {
  grpc_event event = grpc_completion_queue_pluck(
      cq, tag, gpr_inf_future(GPR_CLOCK_MONOTONIC), nullptr);
  return event.success != 0;
}

// Creates enough memory for tag
void* new_tag(int num) {
  return new int(num);
}

grpc_metadata_array* create_new_grpc_metadata_array() {
  grpc_metadata_array* arr = new grpc_metadata_array();
  grpc_metadata_array_init(arr);
  return arr;
}

void delete_grpc_metadata_array(grpc_metadata_array* metadata) {
  grpc_metadata_array_destroy(metadata);
  delete metadata;
}

// Allocates a grpc_op* pointer for 'num_ops' number of grpc_op.
// The ownership is passed to the creator.
grpc_op* create_new_grpc_ops(int num_ops) {
  return (grpc_op*)calloc(num_ops, sizeof(grpc_op));
}

// Frees all memory associated with ops.
void grpc_ops_free(grpc_op* ops, int size) {
  int i = 0;
  for (i = 0; i < size; i++) {
    if (ops[i].op == GRPC_OP_SEND_INITIAL_METADATA) {
      delete ops[i].data.send_initial_metadata.metadata;
    }
    if (ops[i].op == GRPC_OP_SEND_MESSAGE) {
      grpc_byte_buffer_destroy(ops[i].data.send_message.send_message);
    }
    if (ops[i].op == GRPC_OP_RECV_MESSAGE) {
      delete ops[i].data.recv_message.recv_message;
    }
    if (ops[i].op == GRPC_OP_RECV_STATUS_ON_CLIENT) {
      grpc_metadata_array_destroy(ops[i].data.recv_status_on_client.
                                  trailing_metadata);
    }
    delete ops[i].data.recv_status_on_client.status;
    delete ops[i].data.recv_status_on_client.status_details;
    if (ops[i].op == GRPC_OP_RECV_INITIAL_METADATA) {
      grpc_metadata_array_destroy(ops[i].data.recv_initial_metadata
                                      .recv_initial_metadata);

    }
    if (ops[i].op == GRPC_OP_SEND_INITIAL_METADATA) {
      free(ops[i].data.send_initial_metadata.metadata);
    }
    if (ops[i].op == GRPC_OP_SEND_STATUS_FROM_SERVER) {
      delete ops[i].data.send_status_from_server.trailing_metadata;
    }
    if (ops[i].op == GRPC_OP_RECV_CLOSE_ON_SERVER) {
      free(ops[i].data.recv_close_on_server.cancelled);
    }

  }
  free(ops);
}

// Takes in a preallocated grpc_op array.
// Stores the given metadata, flags, and count for the
// GRPC_OP_SEND_INITIAL_METADATA operation.
void lisp_grpc_make_send_metadata_op(grpc_op* op, int index,
                                     grpc_metadata* metadata,
                                     size_t count, uint32_t flags) {
  op[index].op = GRPC_OP_SEND_INITIAL_METADATA;
  op[index].data.send_initial_metadata.count = count;
  op[index].data.send_initial_metadata.metadata = metadata;
  op[index].flags = flags;
  op[index].reserved = nullptr;
}

// Takes in a preallocated grpc_op array.
// Stores the given request for the
// GRPC_OP_SEND_MESSAGE operation.
void lisp_grpc_make_send_message_op(grpc_op* op, int index,
                                     grpc_byte_buffer* request) {
  op[index].op = GRPC_OP_SEND_MESSAGE;
  op[index].data.send_message.send_message = request;
  op[index].reserved = nullptr;
}

// Takes in a preallocated grpc_op array.
// Stores the given response for the
// GRPC_OP_RECV_MESSAGE operation.
void lisp_grpc_make_recv_message_op(grpc_op* op, int index, int flags) {
  op[index].op = GRPC_OP_RECV_MESSAGE;
  op[index].data.recv_message.recv_message = new grpc_byte_buffer*;
  op[index].reserved = nullptr;
  op[index].flags = flags;
}

grpc_byte_buffer* lisp_grpc_op_recv_message(grpc_op* op, int index) {
  return op[index].data.recv_message.recv_message == nullptr
             ? nullptr
             : *op[index].data.recv_message.recv_message;
}

// Takes in a preallocated grpc_op array.
// Stores the given metadata for the
// GRPC_OP_RECV_INITIAL_METADATA operation.
void lisp_grpc_make_recv_metadata_op(grpc_op* op, int index) {
  op[index].op = GRPC_OP_RECV_INITIAL_METADATA;
  op[index].data.recv_initial_metadata.recv_initial_metadata =
      create_new_grpc_metadata_array();
  op[index].reserved = nullptr;
}

grpc_metadata_array* lisp_grpc_op_get_initial_metadata(grpc_op* ops, int index)
{
  return ops[index].data.recv_initial_metadata.recv_initial_metadata;
}


// Takes in a preallocated grpc_op array.
// Stores the given flags for the
// GRPC_OP_SEND_CLOSE_FROM_CLIENT operation.
void lisp_grpc_client_make_close_op(grpc_op* op, int index, uint32_t flags) {
  op[index].op = GRPC_OP_SEND_CLOSE_FROM_CLIENT;
  op[index].flags = flags;
  op[index].reserved = nullptr;
}

// Takes in a preallocated grpc_op array.
// Stores the given trailing_metadata, status, details, and flags for the
// GRPC_OP_RECV_STATUS_ON_CLIENT operation.
void lisp_grpc_client_make_recv_status_op(grpc_op* op, int index, int flags) {
  op[index].op = GRPC_OP_RECV_STATUS_ON_CLIENT;
  op[index].data.recv_status_on_client.trailing_metadata =
      create_new_grpc_metadata_array();
  op[index].data.recv_status_on_client.status = new grpc_status_code();
  op[index].data.recv_status_on_client.status_details = new grpc_slice();
  op[index].flags = flags;
  op[index].reserved = nullptr;
}

grpc_metadata_array* lisp_grpc_op_get_trailing_metadata(grpc_op* ops, int index)
{
  return ops[index].data.recv_status_on_client.trailing_metadata;
}

grpc_status_code lisp_grpc_op_get_status(grpc_op* ops, int index) {
  return *ops[index].data.recv_status_on_client.status;
}

grpc_slice* lisp_grpc_op_get_status_details(grpc_op* ops, int index) {
  return ops[index].data.recv_status_on_client.status_details;
}

// Takes in a preallocated grpc_op array.
// Stores the given trailing_metadata, metadata_count, status, and flags, for
// the GRPC_OP_SEND_STATUS_FROM_SERVER operation.
void lisp_grpc_server_make_send_status_op(grpc_op* op,
                                          int index,
                                          grpc_metadata* trailing_metadata,
                                          uint32_t metadata_count,
                                          grpc_status_code status,
                                          uint32_t flags) {
  op[index].op = GRPC_OP_SEND_STATUS_FROM_SERVER;
  op[index].data.send_status_from_server.trailing_metadata = trailing_metadata;
  op[index].data.send_status_from_server.status = status;
  op[index].data.send_status_from_server.trailing_metadata_count =
      metadata_count;
  op[index].flags = flags;
  op[index].reserved = nullptr;
}

// Takes in a preallocated grpc_op array.
// Stores the given metadata, cancelled and flags for the
// GRPC_OP_RECV_CLOSE_ON_SERVER operation.
void lisp_grpc_server_make_close_op(grpc_op* op, int index, int* cancelled,
                                    uint32_t flags ) {
  op[index].op = GRPC_OP_RECV_CLOSE_ON_SERVER;
  op[index].data.recv_close_on_server.cancelled = cancelled;
  op[index].flags = flags;
  op[index].reserved = nullptr;
}

// Takes in a preallocated grpc_op array.
// Stores the given metadata, flags, and count for the
// GRPC_OP_SEND_STATUS_FROM_SERVER operation.
void lisp_grpc_make_send_status_from_server_op(grpc_op* op,
                                               int index,
                                               grpc_metadata* trailing_metadata,
                                               uint32_t metadata_count,
                                               grpc_status_code status,
                                               uint32_t flags) {
  op[index].op = GRPC_OP_SEND_STATUS_FROM_SERVER;
  op[index].data.send_status_from_server.trailing_metadata = trailing_metadata;
  op[index].data.send_status_from_server.trailing_metadata_count =
      metadata_count;
  op[index].data.send_status_from_server.status = status;
  op[index].flags = flags;
  op[index].reserved = nullptr;
}

// Auxiliary Functions

// This takes a string str and converts it to a grpc_slice.
grpc_slice* convert_string_to_grpc_slice(const char* str) {
  grpc_slice* slice = new grpc_slice();
  *slice = grpc_slice_from_copied_string(str);
  return slice;
}

// This takes a grpc_slice 'slice' and converts it to a grpc_byte_buffer*
// that can be sent to the server.
grpc_byte_buffer* convert_grpc_slice_to_grpc_byte_buffer(grpc_slice* slice) {
  grpc_byte_buffer* ret = new grpc_byte_buffer();
  ret = grpc_raw_byte_buffer_create(slice, 1);
  return ret;
}

grpc_byte_buffer* create_empty_grpc_byte_buffer() {
  return new grpc_byte_buffer();
}

grpc_slice* create_empty_grpc_slice() {
  return new grpc_slice();
}

grpc_status_code* create_empty_grpc_status_code() {
  return (grpc_status_code*) calloc(1, sizeof(grpc_status_code));
}

grpc_slice* get_grpc_slice_from_grpc_byte_buffer(grpc_byte_buffer* buf,
                                                 int index) {
  return &(buf->data.raw.slice_buffer.slices[index]);
}

int grpc_byte_buffer_slice_buffer_count(grpc_byte_buffer* buf) {
  return buf->data.raw.slice_buffer.count;
}

char* convert_grpc_slice_to_string(grpc_slice* slice) {
  return grpc_slice_to_c_string(*slice);
}

void free_grpc_slice(grpc_slice* slice) {
  free(slice);
}

grpc_byte_buffer* convert_bytes_to_grpc_byte_buffer(char* buf, size_t len) {
  grpc_slice slice = grpc_slice_from_copied_buffer(buf, len);
  grpc_byte_buffer* ret = new grpc_byte_buffer();
  ret = grpc_raw_byte_buffer_create(&slice, 1);
  return ret;
}

char* convert_grpc_byte_buffer_to_bytes(grpc_byte_buffer* buf, int index) {
  grpc_slice slice = buf->data.raw.slice_buffer.slices[index];
  return grpc_slice_to_c_string(slice);
}

grpc_slice* convert_bytes_to_grpc_slice(char* buf, size_t len) {
  grpc_slice* slice = new grpc_slice();
  *slice = grpc_slice_from_copied_buffer(buf, len);
  return slice;
}

}
}  // namespace lisp_grpc
}  // namespace lisp

--- END_FILE: ./grpc/client.cc ---

--- START_FILE: ./grpc/shared.lisp ---
;;; Copyright 2021 Google LLC
;;;
;;; Use of this source code is governed by an MIT-style
;;; license that can be found in the LICENSE file or at
;;; https://opensource.org/licenses/MIT.

;;;; Lisp wrappers

(in-package #:grpc)

;; Conditions
(define-condition grpc-call-error (error)
  ((call-error :initarg :call-error
               :initform nil
               :accessor call-error))
  (:report (lambda (condition stream)
             (format stream "GRPC CALL ERROR: ~A.~&" (call-error condition)))))

;; Globals

(defvar *completion-queue* nil "The global completion queue used to
manage grpc calls.")

;; gRPC Enums
(cffi:defcenum grpc-security-level
  "Security levels of grpc transport security. It represents an inherent
property of a backend connection and is determined by a channel credential
used to create the connection."
  :GRPC-SECURITY-MIN
  :GRPC-SECURITY-NONE
  :GRPC-INTEGRITY-ONLY
  :GRPC-PRIVACY-AND-INTEGRITY
  :GRPC-SECURITY-MAX)

(cffi:defcenum grpc-ssl-client-certificate-request-type
  "SSL Client Certificate Request Types are how the gRPC Server should handle
SSL Authentication"
  :GRPC-SSL-DONT-REQUEST-CLIENT-CERTIFICATE
  :GRPC-SSL-REQUEST-CLIENT-CERTIFICATE-BUT-DONT-VERIFY
  :GRPC-SSL-REQUEST-CLIENT-CERTIFICATE-AND-VERIFY
  :GRPC-SSL-REQUEST-AND-REQUIRE-CLIENT-CERTIFICATE-BUT-DONT-VERIFY
  :GRPC-SSL-REQUEST-AND-REQUIRE-CLIENT-CERTIFICATE-AND-VERIFY)

(cffi:defcenum grpc-call-error
  "This enum represents all the possible return values from
grpc_call_start_batch."
  :GRPC-CALL-OK
  :GRPC-CALL-ERROR
  :GRPC-CALL-ERROR-NOT-ON-SERVER
  :GRPC-CALL-ERROR-NOT-ON-CLIENT
  :GRPC-CALL-ERROR-ALREADY-ACCEPTED
  :GRPC-CALL-ERROR-ALREADY-INVOKED
  :GRPC-CALL-ERROR-NOT-INVOKED
  :GRPC-CALL-ERROR-ALREADY-FINISHED
  :GRPC-CALL-ERROR-TOO-MANY-OPERATIONS
  :GRPC-CALL-ERROR-INVALID-FLAGS
  :GRPC-CALL-ERROR-INVALID-METADATA
  :GRPC-CALL-ERROR-INVALID-MESSAGE
  :GRPC-CALL-ERROR-NOT-SERVER-COMPLETION-QUEUE
  :GRPC-CALL-ERROR-BATCH-TOO-BIG
  :GRPC-CALL-ERROR-PAYLOAD-TYPE-MISMATCH
  :GRPC-CALL-ERROR-COMPLETION-QUEUE-SHUTDOWN)

(cffi:defcenum grpc-status-code
  "The grpc-status-code enum values"
  :GRPC-STATUS-OK
  :GRPC-STATUS-CANCELLED
  :GRPC-STATUS-UNKNOWN
  :GRPC-STATUS-INVALID-ARGUMENT
  :GRPC-STATUS-DEADLINE-EXCEEDED
  :GRPC-STATUS-NOT-FOUND
  :GRPC-STATUS-ALREADY-EXISTS
  :GRPC-STATUS-PERMISSION-DENIED
  :GRPC-STATUS-RESOURCE-EXHAUSTED
  :GRPC-STATUS-FAILED-PRECONDITION
  :GRPC-STATUS-ABORTED
  :GRPC-STATUS-OUT-OF-RANGE
  :GRPC-STATUS-UNIMPLEMENTED
  :GRPC-STATUS-INTERNAL
  :GRPC-STATUS-UNAVAILABLE
  :GRPC-STATUS-DATA-LOSS
  :GRPC-STATUS-UNAUTHENTICATED)

;; gRPC Credentials wrappers

(cffi:defcfun ("create_grpc_ssl_pem_key_cert_pair"
               create-grpc-ssl-pem-key-cert-pair) :pointer
  (private-key :string)
  (cert-chain :string))

(cffi:defcfun ("delete_grpc_ssl_pem_key_cert_pair" grpc-ssl-pem-key-cert-pair-delete)
  :void
  "Deletes KEYPAIR, a grpc_ssl_pem_key_cert_pair object."
  (keypair :pointer))

(cffi:defcfun ("create_grpc_ssl_verify_peer_options"
               create-grpc-ssl-verify-peer-options) :pointer
  (verify-peer-callback :pointer)
  (verify-peer-callback-userdata :pointer)
  (verify-peer-destruct :pointer))

(cffi:defcfun ("delete_grpc_ssl_verify_peer_options" grpc-ssl-verify-peer-options-delete)
  :void
  "Deletes OPTIONS, a grpc_ssl_verify_peer_options object."
  (options :pointer))

(defun c-grpc-client-new-ssl-credentials
    (pem-roots-certs pem-key-cert-pair verify-options)
  "Creates an SSL credentials object.
The security level of the resulting connection is GRPC_PRIVACY_AND_INTEGRITY.
 - PEM-ROOTS-CERTS is the PEM encoding of the server root certificates.
 - PEM-KEY-CERT-PAIR is a pointer on the object containing client's private
   key and certificate chain.
 - VERIFY-OPTIONS holds additional options controlling how peer certificates
   are verified."
  (cffi:foreign-funcall "grpc_ssl_credentials_create_ex"
                        :string pem-roots-certs
                        :pointer pem-key-cert-pair
                        :pointer verify-options
                        :pointer (cffi-sys:null-pointer)
                        :pointer))

(defun c-grpc-client-new-metadata-credentials (plugin min-security-level)
  "This method creates a local channel credential object. The security
level of the resulting connection is GRPC_PRIVACY_AND_INTEGRITY for UDS and
GRPC_SECURITY_NONE for LOCAL_TCP. It is used for experimental purpose
for now and subject to change."
  (cffi:foreign-funcall "grpc_metadata_credentials_create_from_plugin"
                        :pointer plugin grpc-security-level min-security-level :pointer))

(defun c-grpc-client-new-alts-credentials (options min-security-level)
  "This method creates an ALTS channel credential object. The security
level of the resulting connection is GRPC_PRIVACY_AND_INTEGRITY."
  (cffi:foreign-funcall "grpc_alts_credentials_create"
                        :pointer options grpc-security-level min-security-level :pointer))

(defun c-grpc-client-new-access-token-credentials (access_token)
  "Creates an Oauth2 Access Token credentials with an access token
that was acquired by an out of band mechanism."
  (cffi:foreign-funcall "grpc_access_token_credentials_create"
                        :string access_token
                        :pointer (cffi-sys:null-pointer)
                        :pointer))

(defun c-grpc-client-new-composite-call-credentials (creds1 creds2)
  "Creates a composite call credentials object."
  (cffi:foreign-funcall "grpc_composite_call_credentials_create"
                        :pointer creds1
                        :pointer creds2
                        :pointer (cffi-sys:null-pointer)
                        :pointer))

(defun c-grpc-client-new-composite-channel-credentials
    (channel-creds call-creds)
  "Creates a composite channel credentials object. The security level of
resulting connection is determined by CHANNEL-CREDS."
  (cffi:foreign-funcall "grpc_composite_channel_credentials_create"
                        :pointer channel-creds
                        :pointer call-creds
                        :pointer (cffi-sys:null-pointer)
                        :pointer))

(defun c-grpc-client-new-local-credentials (type)
  "This method creates a local channel credential object. The security
level of the resulting connection is GRPC_PRIVACY_AND_INTEGRITY for UDS and
GRPC_SECURITY_NONE for LOCAL_TCP."
  (cffi:foreign-funcall "grpc_local_credentials_create" :pointer type :pointer))

(defun c-grpc-client-new-tls-credentials (options)
  "Creates a TLS channel credential object based on the grpc_tls_credentials_options
specified by callers. The security level of the resulting connection is
GRPC_PRIVACY_AND_INTEGRITY."
  (cffi:foreign-funcall "grpc_tls_credentials_create" :pointer options :pointer))

(defun c-grpc-client-new-google-default-credentials (options)
  "Creates default credentials to connect to a google gRPC service.
WARNING: Do NOT use this credentials to connect to a non-google service as
this could result in an oauth2 token leak. The security level of the
resulting connection is GRPC_PRIVACY_AND_INTEGRITY."
  (cffi:foreign-funcall "grpc_google_default_credentials_create"
                        :pointer options :pointer))

(defun c-grpc-client-new-google-compute-engine-credentials ()
  "Creates a compute engine credentials object for connecting to Google.
WARNING: Do NOT use this credentials to connect to a non-google service as
this could result in an oauth2 token leak."
  (cffi:foreign-funcall "grpc_google_compute_engine_credentials_create"
                        :pointer (cffi-sys:null-pointer) :pointer))

(defun c-grpc-client-new-xds-credentials (fallback-credentials)
  "This method creates an xDS channel credentials object."
  (cffi:foreign-funcall "grpc_xds_credentials_create"
                        :pointer fallback-credentials :pointer))

(defun c-grpc-client-new-external-account-credentials (json-string scopes-string)
  "Builds External Account credentials.
 - JSON-STRING is the JSON string containing the credentials options.
 - SCOPES-STRING contains the scopes to be binded with the credentials."
  (cffi:foreign-funcall "grpc_external_account_credentials_create"
                        :string json-string :string scopes-string :pointer))

(defun c-grpc-client-new-refresh-token-credentials (json-refresh)
  "Creates an Oauth2 Refresh Token credentials object for connecting to Google.

WARNING: Do NOT use this credentials to connect to a non-google service as
         this could result in an oauth2 token leak.

   - JSON-REFRESH-TOKEN is the JSON string containing the refresh token itself
     along with a client_id and client_secret"
  (cffi:foreign-funcall "grpc_google_refresh_token_credentials_create"
                        :string json-refresh :pointer (cffi-sys:null-pointer) :pointer))

(defun c-grpc-client-new-google-iam-credentials (authorization-token authorirt-selector)
  "Creates an IAM credentials object for connecting to Google."
  (cffi:foreign-funcall "grpc_google_iam_credentials_create"
                        :string authorization-token
                        :string authorirt-selector
                        :pointer (cffi-sys:null-pointer)
                        :pointer))

(defun c-grpc-client-new-sts-credentials (options)
  "Creates an STS credentials following the STS Token Exchanged specifed in the
   IETF draft https://tools.ietf.org/html/draft-ietf-oauth-token-exchange-16."
  (cffi:foreign-funcall "grpc_sts_credentials_create"
                        :pointer options :pointer (cffi-sys:null-pointer) :pointer))

;; gRPC Server Credentials

(defun c-grpc-server-new-ssl-credentials (options)
  "Creates an SSL server_credentials object using the provided options struct."
  (cffi:foreign-funcall "grpc_ssl_server_credentials_create_with_options"
                        :pointer options :pointer))

(defun c-grpc-server-new-ssl-credentials-options (client-certificate-request certificate-config)
  "Creates an options object using a certificate config. Use this method when
the certificates and keys of the SSL server will not change during the
server's lifetime."
  (cffi:foreign-funcall
   "grpc_ssl_server_credentials_create_options_using_config"
   grpc-ssl-client-certificate-request-type client-certificate-request
   :pointer certificate-config :pointer))

(defun c-grpc-server-new-local-credentials (type)
  "This method creates a local server credential object"
  (cffi:foreign-funcall "grpc_local_server_credentials_create"
                        :pointer type :pointer))

(defun c-grpc-server-new-tls-credentials (options)
  "Creates a TLS server credential object based on the grpc_tls_credentials_options
 specified by callers."
  (cffi:foreign-funcall "grpc_tls_server_credentials_create"
                        :pointer options :pointer))

(defun c-grpc-server-new-xds-credentials (fallback-credentials)
  "his method creates an xDS server credentials object."
  (cffi:foreign-funcall "grpc_xds_server_credentials_create"
                        :pointer fallback-credentials :pointer))

(defun c-grpc-server-new-alts-credentials (fallback-credentials)
  "This method creates an ALTS server credential object."
  (cffi:foreign-funcall "grpc_alts_server_credentials_create"
                        :pointer fallback-credentials :pointer))

(defun c-grpc-completion-queue-create-for-pluck ()
  "This wrapper creates a completion_queue* that is used to start a batch
of operation and check the success."
  (cffi:foreign-funcall "grpc_completion_queue_create_for_pluck"
                        :pointer (cffi-sys:null-pointer) :pointer))

;; Wrapped grpc-client.cc functions

(cffi:defcfun ("grpc_ops_free" grpc-ops-free) :void
  "Deletes and destroys all memory in fields of OPS upto index SIZE
before freeing ops."
  (ops :pointer) (size :int))

(cffi:defcfun ("grpc_channel_credentials_release" grpc-credentials-release)
  :void
  "Releases CREDENTIALS."
  (credentials :pointer))

(cffi:defcfun ("grpc_byte_buffer_destroy" grpc-byte-buffer-destroy ) :void
  "Destroys BYTE-BUFFER, a grpc_byte_buffer object."
  (byte-buffer :pointer))

(cffi:defcfun ("grpc_call_unref" grpc-call-unref) :void
  "Unrefs CALL, a grpc_call object."
  (call :pointer))

(cffi:defcfun ("grpc_channel_destroy" grpc-channel-destroy) :void
  "Closes and destroys CHANNEL, a grpc_channel object."
  (channel :pointer))

(cffi:defcfun ("create_new_grpc_metadata_array" create-new-grpc-metadata-array )
  :pointer)

(cffi:defcfun ("create_empty_grpc_byte_buffer" create-grpc-byte-buffer )
  :pointer)

(cffi:defcfun ("create_empty_grpc_slice" create-grpc-slice) :pointer)

(cffi:defcfun ("create_empty_grpc_status_code" create-grpc-status-code)
  :pointer)

(cffi:defcfun ("lisp_grpc_op_get_status" recv-status-on-client-code) grpc-status-code
  (ops :pointer)
  (index :int))

(cffi:defcfun ("convert_string_to_grpc_slice" convert-string-to-grpc-slice)
  :pointer
  (str :string))

(cffi:defcfun ("get_grpc_slice_from_grpc_byte_buffer"
               get-grpc-slice-from-grpc-byte-buffer )
  :pointer
  (buf :pointer)
  (index :int))

(cffi:defcfun ("grpc_byte_buffer_slice_buffer_count"
               get-grpc-byte-buffer-slice-buffer-count ) :int
  (op :pointer))

(cffi:defcfun ("grpc_insecure_credentials_create"
               grpc-insecure-credentials-create)
  :pointer)

(cffi:defcfun ("grpc_insecure_server_credentials_create"
               grpc-insecure-server-credentials-create)
  :pointer)

(cffi:defcfun ("delete_grpc_metadata_array" metadata-destroy)
  :void
  (metadata :pointer))

(cffi:defcfun ("free_grpc_slice" free-slice)
  :void
  (slice :pointer))

(defun get-call-method (call-details)
  "Get the call method from a grpc_call_details BUFFER."
  (let ((c-bytes
         (cffi:foreign-funcall "grpc_call_method"
                               :pointer call-details
                               :pointer)))
    (prog1 (cffi:foreign-string-to-lisp c-bytes)
      (cffi:foreign-funcall "free"
                            :pointer c-bytes
                            :void))))

(defun get-bytes-from-grpc-byte-buffer (buffer index)
  "Get a lisp-vector of bytes from the grpc_slice at INDEX
i of grpc_byte_buffer BUFFER."
  (let ((c-bytes
         (cffi:foreign-funcall "convert_grpc_byte_buffer_to_bytes"
                               :pointer buffer
                               :int index
                               :pointer)))
    (prog1 (cffi:foreign-array-to-lisp c-bytes
                                       (list :array :uint8
                                             (cffi:foreign-funcall
                                              "strlen"
                                              :pointer c-bytes :int)))
      (cffi:foreign-funcall "free"
                            :pointer c-bytes
                            :void))))


(defun convert-bytes-to-grpc-byte-buffer (bytes)
  "Given a lisp-vector of BYTES convert them to a grpc_byte_buffer."
  (let ((array (cffi:foreign-alloc :unsigned-char :initial-contents bytes)))
    (prog1
        (cffi:foreign-funcall "convert_bytes_to_grpc_byte_buffer"
                               :pointer array
                               :int (length bytes)
                               :pointer)
      (cffi:foreign-free array))))

(defun convert-metadata-flag-to-integer (flag)
  "Converts FLAG, a metadata symbol, to its integer equivalent."
  (case flag (grpc-write-through-flag #x4)
        (grpc-metadata-idempotent-flag #x10)
        (grpc-metadata-wait-for-ready-flag #x20)
        (grpc-metadata-cacheable-request-flag #x40)
        (grpc-metadata-wait-for-ready-explicitly-set-flag #x80)
        (grpc-metadata-corked-flag #x100)
        (otherwise flag)))

(defstruct method-details
  (name "" :type string)
  (serializer #'identity :type function)
  (deserializer #'identity :type function)
  (action #'identity :type function)
  (server-stream nil :type boolean)
  (client-stream nil :type boolean))

;; Completion Queue Functions

(cffi:defcfun ("lisp_grpc_call_start_batch" call-start-batch )
  grpc-call-error
  (call :pointer)
  (ops :pointer)
  (num-ops :int)
  (tag :pointer))

(cffi:defcfun ("lisp_grpc_completion_queue_pluck" completion-queue-pluck )
  :bool
  (completion-queue :pointer)
  (tag :pointer))

;; Wrappers to create operations

(cffi:defcfun ("lisp_grpc_op_recv_message" get-grpc-op-recv-message ) :pointer
  (op :pointer)
  (index :int))

(cffi:defcfun ("create_new_grpc_ops" create-new-grpc-ops) :pointer
  "Creates a grpc_op* that is used to add NUM-OPS operations to,
these operation guide the interaction between the client and server."
  (num-ops :int))

(defun make-send-metadata-op (op metadata
                              &key count flag
                                index)
  "Sets OP[INDEX] to a Send Initial Metadata operation by adding metadata
METADATA, the count of metadata COUNT, and the flag FLAG."
  (cffi:foreign-funcall "lisp_grpc_make_send_metadata_op"
                        :pointer op
                        :int index
                        :pointer metadata
                        :int count
                        :int (convert-metadata-flag-to-integer flag)
                        :void))

(defun make-send-message-op (op message &key index)
  "Sets OP[INDEX] to a 'Send Message' operation that sends MESSAGE
to the server."
  (cffi:foreign-funcall "lisp_grpc_make_send_message_op"
                        :pointer op
                        :int index
                        :pointer message
                        :void))

(defun make-client-recv-status-op (op &key flag index)
  "Sets OP[INDEX] to a 'RECEIVE STATUS' operation, sets the FLAG of the op."
  (cffi:foreign-funcall "lisp_grpc_client_make_recv_status_op"
                        :pointer op
                        :int index
                        :int flag
                        :void))

(defun make-recv-message-op (op &key flag index)
  "Sets OP[INDEX] to a Receive Message operation with FLAG."
  (cffi:foreign-funcall "lisp_grpc_make_recv_message_op"
                        :pointer op
                        :int index
                        :int flag
                        :void))

(defun make-recv-metadata-op (op &key index)
  "Set OP[INDEX] to a Receive Initial Metadata operation with FLAG."
  (cffi:foreign-funcall "lisp_grpc_make_recv_metadata_op"
                        :pointer op
                        :int index
                        :void))

(defun make-client-close-op (op &key flag index)
  "Sets OP[INDEX] to a Send Close From Client operation with FLAG."
  (cffi:foreign-funcall "lisp_grpc_client_make_close_op"
                        :pointer op
                        :int index
                        :int flag
                        :void))

(defun make-send-status-from-server-op (op &key metadata count status flag index)
  "Sets OP[INDEX] to a Send Status from server operation by adding metadata
METADATA, the server STATUS, the count of metadata COUNT, and the flag FLAG."
  (cffi:foreign-funcall "lisp_grpc_make_send_status_from_server_op"
                        :pointer op
                        :int index
                        :pointer metadata
                        :int count
                        grpc-status-code status
                        :int flag
                        :void))

(defun make-recv-close-on-server-op (op &key cancelled flag index)
  "Sets OP[INDEX] to a Receive Close on Server operation by adding cancelled CANCELLED
and the flag FLAG"
  (cffi:foreign-funcall "lisp_grpc_server_make_close_op"
                        :pointer op
                        :int index
                        :pointer cancelled
                        :int flag
                        :void))


(defun prepare-ops (ops
                    &key
                    send-metadata send-message client-close
                    client-recv-status recv-metadata
                    recv-message server-recv-close server-send-status)
  "Prepares OPS to send MESSAGE to the server. The keys SEND-METADATA
SEND-MESSAGE CLIENT-CLOSE CLIENT-RECV-STATUS RECV-METADATA RECV-MESSAGE
SERVER-RECV-CLOSE SERVER-SEND-STATUS are all different types of ops that the user may
want. Returns a plist containing keys being the op type and values being the index."
  (let ((cur-index -1)
        ops-plist)
    (flet ((next-marker (message-type)
             (setf (getf ops-plist message-type) (incf cur-index))))

      (when send-metadata
        (make-send-metadata-op ops (cffi:null-pointer)
                               :count 0 :flag 0 :index (next-marker :send-metadata)))
      (when send-message
        (make-send-message-op ops send-message :index (next-marker :send-message)))
      (when client-close
        (make-client-close-op ops :flag 0 :index (next-marker :client-close)))
      (when client-recv-status
        (make-client-recv-status-op ops :flag 0 :index (next-marker :client-recv-status)))
      (when recv-metadata
        (make-recv-metadata-op ops :index (next-marker :recv-metadata)))
      (when recv-message
        (make-recv-message-op ops :flag 0 :index (next-marker :recv-message)))
      (when server-recv-close
        (make-recv-close-on-server-op ops :cancelled (cffi:foreign-alloc :int) :flag 0 :index (next-marker :server-close)))
      (when server-send-status
        (make-send-status-from-server-op ops :metadata (cffi:null-pointer) :count 0 :status server-send-status :flag 0 :index (next-marker :server-send-status))))
    ops-plist))

;; Conversion, deletion functions

;; Hack since :size defctype doesn't work in
;; cffi:foreign-funcall externally
(cffi:defctype :size #+64-bit :uint64 #+32-bit :uint32)

(defun convert-bytes-to-grpc-slice (bytes)
  "Takes a list of bytes BYTES and returns a pointer to the corresponding
grpc_slice*."
  (let ((array (cffi:foreign-alloc :unsigned-char :initial-contents bytes)))
    (cffi:foreign-funcall "convert_bytes_to_grpc_slice"
                          :pointer array
                          :size (length bytes)
                          :pointer)))

(defun convert-grpc-slice-to-bytes (slice)
  "Takes SLICE and returns its content as a vector of bytes."
  (let* ((slice-string-pointer
          (cffi:foreign-funcall
           "convert_grpc_slice_to_string" :pointer slice
                                          :pointer)))
    (cffi:foreign-array-to-lisp slice-string-pointer
                                (list :array :uint8
                                      (cffi:foreign-funcall
                                           "strlen"
                                           :pointer slice-string-pointer :int)))))

;; General gRPC functions

(defun init-grpc ()
  "Initializes the grpc library and the global *completion-queue* so that
grpc functions can be used and the queue can be managed. Call before any gRPC
functions or macros are called and only call once."
  (cffi:foreign-funcall "grpc_init" :void)
  (unless *completion-queue*
    (setf *completion-queue* (grpc::c-grpc-completion-queue-create-for-pluck))))

(defun shutdown-grpc ()
  "Shuts down the grpc library which frees up any internal memory and
destroys *completion-queue*. Call when finished with all gRPC functions and
macros and only call once."
  (when *completion-queue*
    (cffi:foreign-funcall "grpc_completion_queue_shutdown"
                          :pointer *completion-queue*)
    (cffi:foreign-funcall "grpc_completion_queue_destroy"
                          :pointer *completion-queue*)
    (setf *completion-queue* nil))
  (cffi:foreign-funcall "grpc_shutdown"))

;; Shared structures

(defstruct call
  (c-call nil :type cffi:foreign-pointer)
  (c-tag nil :type cffi:foreign-pointer)
  (c-ops nil :type cffi:foreign-pointer)
  (method-name "" :type string)
  ;; This is a plist where the key is a keyword for a type of op
  ;; and the value is the index of that op in an op-array.
  (ops-plist nil :type list))

;; Shared call functions

(defun receive-message (call)
  "Receive a message from the client for a CALL."
  (declare (type call call))
  (let* ((tag (cffi:foreign-alloc :int))
         (c-call (call-c-call call))
         (receive-op (create-new-grpc-ops 1))
         (ops-plist (prepare-ops receive-op :recv-message t))
         (call-code (call-start-batch c-call receive-op 1 tag)))
    (unless (eql call-code :grpc-call-ok)
      (grpc-ops-free receive-op 1)
      (cffi:foreign-free tag)
      (error 'grpc-call-error :call-error call-code))
    (when (completion-queue-pluck *completion-queue* tag)
      (cffi:foreign-free tag)
      (let* ((response-byte-buffer
              (get-grpc-op-recv-message receive-op (getf ops-plist :recv-message)))
             (message
              (unless (cffi:null-pointer-p response-byte-buffer)
                (loop for index from 0
                        to (1- (get-grpc-byte-buffer-slice-buffer-count
                                response-byte-buffer))
                      collecting (get-bytes-from-grpc-byte-buffer
                                  response-byte-buffer index)
                        into message
                      finally
                   (grpc-byte-buffer-destroy response-byte-buffer)
                   (return message)))))
        (grpc-ops-free receive-op 1)
        message))))

(defun send-message (call bytes-to-send)
  "Send the GRPC_OP_SEND_MESSAGE message encoded in BYTES-TO-SEND to the server through a CALL"
  (declare (type call call))
  (let* ((num-ops 1)
         (c-call (call-c-call call))
         (tag (cffi:foreign-alloc :int))
         (ops (create-new-grpc-ops num-ops))
         (grpc-slice
          (convert-bytes-to-grpc-byte-buffer bytes-to-send))
         (ops-plist (prepare-ops ops :send-message grpc-slice))
         (call-code (call-start-batch c-call ops num-ops tag)))
    (declare (ignore ops-plist))
    (unless (eql call-code :grpc-call-ok)
      (cffi:foreign-free tag)
      (grpc-ops-free ops num-ops)
      (error 'grpc-call-error :call-error call-code))
    (let ((cqp-p (completion-queue-pluck *completion-queue* tag)))
      (grpc-ops-free ops num-ops)
      (cffi:foreign-free tag)
      cqp-p)))

(defun free-call-data (call)
  "Free the call data stored in CALL-OBJ."
  (declare (type call call))
  (let* ((c-call (call-c-call call))
         (tag (call-c-tag call))
         (ops (call-c-ops call)))
    (unless (cffi:null-pointer-p ops)
      (completion-queue-pluck *completion-queue* tag)
      (cffi:foreign-free tag)
      (grpc-ops-free ops (/ (length (call-ops-plist call)) 2)))
    (grpc-call-unref c-call)))

--- END_FILE: ./grpc/shared.lisp ---

--- START_FILE: ./grpc/server.cc ---
#include <iostream>
#include <optional>
#include <string>

#include <grpc/grpc.h>
#include <grpc/grpc_security.h>
#include <grpc/grpc_security_constants.h>
#include <grpc/impl/slice_type.h>
#include <grpc/status.h>

namespace lisp {
namespace lisp_grpc {

extern "C" {
grpc_call_details* create_new_grpc_call_details() {
  grpc_call_details* details = new grpc_call_details();
  grpc_call_details_init(details);
  return details;
}

char* grpc_call_method(grpc_call_details* call_details) {
  return grpc_slice_to_c_string(call_details->method);
}

void delete_grpc_call_details(grpc_call_details* call_details) {
  grpc_call_details_destroy(call_details);
  delete call_details;
}

grpc_call* lisp_grpc_server_request_call(
    grpc_server* server, grpc_call_details* details,
    grpc_metadata_array* request_metadata,
    grpc_completion_queue* cq_bound_to_call,
    grpc_completion_queue* cq_for_notification,
    void* tag) {
  grpc_call* internal_call = nullptr;
  grpc_call_error error = grpc_server_request_call(server,
                                                   &internal_call,
                                                   details,
                                                   request_metadata,
                                                   cq_bound_to_call,
                                                   cq_for_notification,
                                                   tag);

  if (error != GRPC_CALL_OK) {
    return nullptr;
  }

  grpc_event event = grpc_completion_queue_pluck(cq_bound_to_call,
                                                 tag,
                                                 gpr_inf_future(GPR_CLOCK_MONOTONIC),
                                                 nullptr);

  if (event.success == 0)
    return nullptr;
  return internal_call;
}

grpc_server* grpc_run_server(grpc_server* server,
                             grpc_server_credentials* server_creds){
  // Start a server and release a server credentials object
  grpc_server_start(server);
  grpc_server_credentials_release(server_creds);
  return server;
}

void* register_method(grpc_server* server, const char* method_name, const char* server_address){
    return grpc_server_register_method(server,
                                       const_cast<char*>(("/"+std::string(method_name)).c_str()),
                                       server_address,
                                       {}, 0);
}

grpc_server* start_server(grpc_completion_queue* cq,
                          grpc_server_credentials* server_creds,
                          const char* server_address) {
  // create the server
  grpc_server* server = grpc_server_create(nullptr, nullptr);

  grpc_server_register_completion_queue(server, cq, nullptr);

  grpc_server_add_http2_port(server, server_address, server_creds);

  return server;
}

void shutdown_server(grpc_server* server, grpc_completion_queue* cq, void* tag) {
  if (server == nullptr) return;
  grpc_server_shutdown_and_notify(server, cq, tag);
  grpc_completion_queue_pluck(cq,
                              tag,
                              gpr_inf_future(GPR_CLOCK_MONOTONIC),
                              nullptr);
  grpc_server_destroy(server);
}

// Creates a grpc_call* given a 'channel', which manages the
}
}  // namespace lisp_grpc
}  // namespace lisp

--- END_FILE: ./grpc/server.cc ---

--- START_FILE: ./grpc/protobuf-integration.lisp ---
;;; Copyright 2021 Google LLC
;;;
;;; Use of this source code is governed by an MIT-style
;;; license that can be found in the LICENSE file or at
;;; https://opensource.org/licenses/MIT.

;;;; cl-protobufs integration.
;;;; In a separate file so users can decide whether to use gRPC to
;;;; send bytes or to use the service functionality from cl-protobufs.


(in-package #:grpc)

(define-condition proto-call-error (error)
  ((call-error :initarg :call-error
               :initform nil
               :accessor call-error))
  (:report (lambda (condition stream)
             (format stream "PROTO CALL ERROR: ~A." (call-error condition)))))

;;; Tell the cl-protobufs method-call stubs who's in charge of RPC.
(setq cl-protobufs:*rpc-call-function* 'start-call)
(setq cl-protobufs:*rpc-streaming-client-function* 'handle-client-stream-call)

(defun get-qualified-method-name (method)
  "Get the qualified METHOD name /service-name/method-name for a method
given a cl-protobufs method-descriptor."
  (let ((service-name (proto:proto-service-name method))
        (rpc-name (proto:proto-name method))
        ;; Package name is needed for service name
        ;; but not provided directly in the method, so take
        ;; it from the qualified name.
        (package-name
         (subseq (proto:proto-qualified-name method) 0
                 (position #\. (proto:proto-qualified-name method) :from-end t))))
    (concatenate 'string "/" package-name "." service-name "/" rpc-name)))

(defgeneric start-call (channel method request response &key callback)
  (:documentation
   "Starts a gRPC call for METHOD.

Parameters:
    CHANNEL is the channel to send a call over.
    METHOD is the cl-protobuf method we wish to call.
    REQUEST is the proto message to send.
    RESPONSE is not supported.
    CALLBACK is not currently supported."))

(defmethod start-call (channel method request response &key callback)
  (assert (not (or callback response)) nil "CALLBACK and RESPONSE args not supported.")
  (let* ((qualified-method-name (get-qualified-method-name method))
         (output-type (proto:proto-output-type method))
         (server-stream (proto:proto-output-streaming-p method))
         (client-stream (proto:proto-input-streaming-p method))
         (bytes (if client-stream
                    (mapcar #'proto:serialize-to-bytes request)
                    (proto:serialize-to-bytes request)))
         (response (grpc-call channel qualified-method-name bytes
                              server-stream client-stream)))
    (flet ((deserialize-result (bytes)
             (proto:deserialize-from-bytes
              output-type
              (apply #'concatenate 'proto:byte-vector bytes))))
      (if server-stream
          (mapcar #'deserialize-result response)
          (deserialize-result response)))))

(defstruct (proto-call (:include call))
  (output-type nil :type symbol)
  (client-stream-closed-p nil :type boolean)
  (call-cleaned-up-p nil :type boolean)
  (client-stream-p nil :type boolean)
  (server-stream-p nil :type boolean)
  (initial-message-sent-p nil :type boolean))

(defgeneric handle-client-stream-call (type &key channel method request call)
  (:documentation
   "Dispatch for different stream call types.

Parameters:
    TYPE is the type of call this should be..
    CHANNEL is the channel to send a call over.
    METHOD is the cl-protobuf method-descriptor for the method we wish to call.
    REQUEST is the proto message to send.
    CALL contains a proto-call object."))

(defmethod handle-client-stream-call ((type (eql :start)) &key channel method request call)
  "Start a gRPC call over a CHANNEL to a specific rpc METHOD.
Ignores TYPE REQUEST and CALL."
  (declare (ignore type request call))
  (let* ((qualified-method-name (get-qualified-method-name method))
         (call (start-grpc-call channel qualified-method-name)))
    (make-proto-call
     :c-call (call-c-call call)
     :c-tag (call-c-tag call)
     :c-ops (call-c-ops call)
     :ops-plist (call-ops-plist call)
     :server-stream-p (proto:proto-output-streaming-p method)
     :client-stream-p (proto:proto-input-streaming-p method)
     :output-type (proto:proto-output-type method))))

(defmethod handle-client-stream-call ((type (eql :send)) &key channel method request call)
  "Send a REQUEST over a CALL.
Ignores TYPE CHANNEL and METHOD."
  (declare (ignore type channel method))
  (when (proto-call-client-stream-closed-p call)
    (error 'proto-call-error :call-error "Tried to send message on closed stream"))
  (when (proto-call-call-cleaned-up-p call)
    (error 'proto-call-error :call-error "Tried to send message with call cleaned up."))
  (when (and (not (proto-call-client-stream-p call))
             (proto-call-initial-message-sent-p call))
    (error 'proto-call-error :call-error
           "Tried to send multiple messages from a non-streaming client."))
  (setf (proto-call-initial-message-sent-p call) t)
  (send-message call (proto:serialize-to-bytes request)))

(defmethod handle-client-stream-call ((type (eql :receive)) &key channel method request call)
  "Receive a message from a CHANNEL.
Ignores TYPE CHANNEL METHOD and REQUEST."
  (declare (ignore type channel method request))
  (when (proto-call-call-cleaned-up-p call)
    (error 'proto-call-error :call-error "Tried to received message with call cleaned up."))
  (unless (proto-call-initial-message-sent-p call)
    (error 'proto-call-error :call-error "Tried to received message before sending a message."))
  (proto:deserialize-from-bytes
   (proto-call-output-type call)
   (apply #'concatenate 'proto:byte-vector (receive-message call))))

(defmethod handle-client-stream-call ((type (eql :close)) &key channel method request call)
  "Close a CALL from the client-side. Server side remains open.
Ignores TYPE CHANNEL METHOD and REQUEST."
  (declare (ignore type channel method request))
  (setf (proto-call-client-stream-closed-p call) t)
  (client-close call))

(defmethod handle-client-stream-call ((type (eql :cleanup)) &key channel method request call)
  "Cleanup the CALL data stored in a proto-call structure.
Ignores TYPE CHANNEL METHOD and REQUEST."
  (declare (ignore type channel method request))
  (unless (proto-call-client-stream-closed-p call)
    (error 'proto-call-error :call-error "Tried to cleanup call before closing the call."))
  (free-call-data call))

(defun run-grpc-proto-server (address service-name
                              &key
                              (server-creds
                               (grpc-insecure-server-credentials-create))
                              (cq grpc::*completion-queue*)
                              (num-threads 1)
                              (dispatch-requests #'dispatch-requests))
  "Start a gRPC server using protocol buffers.
Parameters
  ADDRESS: The address to run the server on.
  SERVICE-NAME: The symbol naming the service to run.
  SERVER-CREDS: Pointer to the gRPC server credentials.
  CQ: The completion queue to use.
  NUM-THREADS: The number of threads to have running.
  DISPATCH-CALL: A function to use to dispatch calls.
                 Useful for debugging."
  (let* ((service (proto:find-service-descriptor service-name))
         method-details-list)
    (dolist (method (proto:proto-methods service))
      (push
       (make-method-details
        :name (get-qualified-method-name method)
        :serializer #'proto:serialize-to-bytes
        :deserializer (lambda (bytes)
                        (proto:deserialize-from-bytes
                         (proto:proto-input-type method)
                         bytes))
        :action (lambda (message call)
                  (funcall (proto:proto-server-stub method)
                           message call)))
       method-details-list))
    (run-grpc-server address method-details-list
                     :server-creds server-creds
                     :cq cq
                     :num-threads num-threads
                     :dispatch-requests dispatch-requests)))

(cl:export '(run-grpc-proto-server))

--- END_FILE: ./grpc/protobuf-integration.lisp ---

--- START_FILE: ./grpc/grpc.asd ---
;;;; -*- Mode: LISP; Syntax: Ansi-Common-Lisp; Base: 10; -*-

#.(unless (or #+asdf3.1 (version<= "3.1" (asdf-version)))
    (error "You need ASDF >= 3.1 to load this system correctly."))

(defsystem :grpc
  :author "Jonathan Godbout <jgodbout@google.com>"
  :version (:read-file-form "version.sexp")
  :description "Lisp wrapper for gRPC"
  :license "MIT"
  :depends-on (:cl-protobufs :cffi :bordeaux-threads)
  :serial t
  :in-order-to ((test-op (test-op :grpc/tests)))
  :components ((:file "grpc")
               (:file "libraries")
               (:file "shared")
               (:file "client")
               (:file "server")
               (:file "protobuf-integration")))

(defsystem :grpc/tests
  :name "Protobufs Tests"
  :author "Jonathan Godbout"
  :version "0.1"
  :licence "MIT-style"
  :maintainer '("Jon Godbout" "Carl Gay" "Nick Groszewski")
  :description      "Test code for gRPC for Common Lisp"
  :long-description "Test code for gRPC for Common Lisp"
  :defsystem-depends-on (:cl-protobufs.asdf)
  :depends-on (:grpc :clunit2 :flexi-streams :bordeaux-threads)
  :serial t
  :pathname "tests/"
  :components
  ((:module "packages"
    :serial t
    :pathname ""
    :components ((:file "pkgdcl")))
   (:module "root-suite"
    :serial t
    :pathname ""
    :components ((:file "root-suite")))
   (:module "integration-test"
    :serial t
    :pathname ""
    :depends-on ("packages")
    :components ((:file "integration-test")))
   (:module "cl-protobuf-integration-test"
    :serial t
    :pathname ""
    :depends-on ("packages")
    :components ((:protobuf-source-file "test")
                 (:file "cl-protobuf-integration-test"))))
  :perform (test-op (o c)
                    (uiop:symbol-call '#:grpc.test '#:run-all)))

--- END_FILE: ./grpc/grpc.asd ---

--- START_FILE: ./grpc/client.lisp ---
;;; Copyright 2021 Google LLC
;;;
;;; Use of this source code is governed by an MIT-style
;;; license that can be found in the LICENSE file or at
;;; https://opensource.org/licenses/MIT.

;;;; Public Interface for gRPC

(in-package #:grpc)

;; gRPC Client Channel wrappers
(defun c-grpc-client-new-channel (creds target args)
  "Creates a secure channel to TARGET using the passed-in
credentials CREDS. Additional channel level configuration MAY be provided
by grpc_channel_ARGS."
  (cffi:foreign-funcall "grpc_channel_create"
                        :string target
                        :pointer creds
                        :pointer args
                        :pointer))

(defun c-grpc-client-new-default-channel (call-creds user-provided-audience)
  "Creates default credentials to connect to a google gRPC service.
WARNING: Do NOT use this credentials to connect to a non-google service as
this could result in an oauth2 token leak. The security level of the
resulting connection is GRPC_PRIVACY_AND_INTEGRITY.

 - CALL-CREDS is an optional parameter will be attached to the
   returned channel credentials object.

 - USER-PROVIDED-AUDIENCE is an optional field for user to override the
   audience in the JWT token if used."
  (cffi:foreign-funcall "grpc_google_default_credentials_create"
                        :pointer call-creds
                        :string user-provided-audience
                        :pointer))

;; Functions for gRPC Client

(defun create-channel (target &optional
                              (creds (cffi:null-pointer))
                              (args (cffi:null-pointer)))
  "A wrapper to create a channel for the client to TARGET with
additional args ARGS for client information. If CREDS is passed then a secure
channel will be created using CREDS else an insecure channel will be used."
  (c-grpc-client-new-channel creds target args))

(defun service-method-call (channel call-name cq)
  "A wrapper to create a grpc_call pointer that will be used to call CALL-NAME
on the CHANNEL provided and store the result in the completion queue CQ."
  (cffi:foreign-funcall "lisp_grpc_channel_create_call"
                        :pointer channel :string call-name :pointer cq
                        :pointer))


;; Auxiliary Functions

(defun convert-grpc-slice-to-grpc-byte-buffer (slice)
  "Takes a grpc_slice* SLICE and returns a pointer to the corresponding
grpc_byte_buffer*."
  (cffi:foreign-funcall "convert_grpc_slice_to_grpc_byte_buffer"
                        :pointer slice
                        :pointer))

;; Exported Functions

(defmacro with-insecure-channel
    ((bound-channel address) &body body)
  "Creates a gRPC insecure channel to ADDRESS. Binds the channel to BOUND-CHANNEL, runs BODY,
and returns its values. After the body has run, the channel is destroyed."
  `(let ((,bound-channel (create-channel
                          ,address (grpc::grpc-insecure-credentials-create))))
     (unwind-protect (progn ,@body)
       (grpc-channel-destroy ,bound-channel))))

(defmacro with-ssl-channel
    ((bound-channel (address (&key
                                (pem-root-certs nil)
                                (private-key nil)
                                (cert-chain nil)
                                (verify-peer-callback (cffi:null-pointer))
                                (verify-peer-callback-userdata (cffi:null-pointer))
                                (verify-peer-destruct (cffi:null-pointer)))))
     &body body)
  "Creates a gRPC secure channel to ADDRESS using SSL, which requires parameters to create the
SSL credentials and binds the channel to BOUND-CHANNEL. Then, BODY is run and returns its values.
After BODY has run, memory is freed for the SSL credentials and SSL credential options.

List containing the parameters values will correspond to fields of the
grpc_ssl_pem_key_cert_pair and grpc_ssl_verify_peer_options structs:
  (PEM-ROOT-CERTS<string> PRIVATE-KEY<string> CERT-CHAIN<string>
   VERIFY-PEER-CALLBACK<> PEER-CALLBACK-USERDATA<> VERIFY-PEER-DESTRUCT<>)

Allows the gRPC secure channel to be used in a memory-safe and concise manner."
  `(let* ((pem-root-certs (if ,pem-root-certs
                              (cffi:foreign-string-alloc ,pem-root-certs)
                              (cffi:null-pointer)))
          (private-key (if ,private-key
                           (cffi:foreign-string-alloc ,private-key)
                           (cffi:null-pointer)))
          (cert-chain (if ,cert-chain
                          (cffi:foreign-string-alloc ,cert-chain)
                          (cffi:null-pointer)))
          (ssl-pem-key-cert-pair (create-grpc-ssl-pem-key-cert-pair private-key cert-chain))
          (ssl-verify-peer-options
            (create-grpc-ssl-verify-peer-options ,verify-peer-callback
                                                 ,verify-peer-callback-userdata
                                                 ,verify-peer-destruct))
          (ssl-credentials
            (c-grpc-client-new-ssl-credentials
             pem-root-certs
             ssl-pem-key-cert-pair
             ssl-verify-peer-options))
          (,bound-channel (create-channel ,address ssl-credentials)))
     (unwind-protect (progn ,@body)
       (cffi:foreign-string-free pem-root-certs)
       (cffi:foreign-string-free private-key)
       (cffi:foreign-string-free cert-chain)
       (grpc-ssl-pem-key-cert-pair-delete ssl-pem-key-cert-pair)
       (grpc-ssl-verify-peer-options-delete ssl-verify-peer-options)
       (grpc-credentials-release ssl-credentials)
       (grpc-channel-destroy ,bound-channel))))

(defun client-close (call)
  "Close the client side of a CALL."
  (declare (type call call))
  (let* ((c-call (call-c-call call))
         (tag (cffi:foreign-alloc :int))
         (close-op (create-new-grpc-ops 1))
         (ops-plist (prepare-ops close-op :client-close t))
         (call-code (call-start-batch c-call close-op 1 tag)))
    (declare (ignore ops-plist))
    (unless (eql call-code :grpc-call-ok)
      (grpc-ops-free close-op 1)
      (error 'grpc-call-error :call-error call-code))
    (let ((ok (completion-queue-pluck *completion-queue* tag)))
      (cffi:foreign-free tag)
      (unless ok (check-server-status call))
      (values))))

(defun check-server-status (call)
  "Check the server status with data from a CALL object"
  (declare (type call call))
  (%check-server-status
   (call-c-ops call)
   (getf (call-ops-plist call) :client-recv-status)))

(defun %check-server-status (ops receive-status-on-client-index)
  "Verify the server status is :grpc-status-ok. Requires the OPS containing the
RECEIVE_STATUS_ON_CLIENT op and RECEIVE-STATUS-ON-CLIENT-INDEX in the ops."
  (let ((server-status
          (recv-status-on-client-code ops receive-status-on-client-index)))
    (unless (eql server-status :grpc-status-ok)
      (error 'grpc-call-error :call-error server-status))))

(defconstant +num-ops-for-starting-call+ 3)

(defun start-grpc-call (channel service-method-name)
  "Start a grpc call. Requires a pointer to a grpc CHANNEL object, and a SERVICE-METHOD-NAME
string to direct the call to."
  (let* ((num-ops-for-sending-message +num-ops-for-starting-call+)
         (c-call (service-method-call channel service-method-name
                                      *completion-queue*))
         (ops (create-new-grpc-ops num-ops-for-sending-message))
         (tag (cffi:foreign-alloc :int))
         (ops-plist
           (prepare-ops ops :send-metadata t
                            :client-recv-status t
                            :recv-metadata t)))
    (call-start-batch c-call ops +num-ops-for-starting-call+ tag)
    (make-call :c-call c-call
               :c-tag tag
               :c-ops ops
               :ops-plist ops-plist)))

(defun grpc-call (channel service-method-name bytes-to-send
                  server-stream client-stream)
  "Uses CHANNEL to call SERVICE-METHOD-NAME on the server with BYTES-TO-SEND
as the arguement to the method and returns the response<list of byte arrays>
from the server. If we are doing a client or bidirectional streaming call then
BYTES-TO-SEND should be a list of byte-vectors each containing a message to
send in a single call to the server. In the case of a server or bidirectional
call we return a list a list of byte vectors each being a response from the server,
otherwise it's a single byte vector list containing a single response."
  (let* ((call (start-grpc-call channel service-method-name)))
    (unwind-protect
         (progn
           (if client-stream
               (loop for bytes in bytes-to-send
                     do
                        (send-message call bytes))
               (send-message call bytes-to-send))
           (client-close call)
           (if server-stream
               (loop for message = (receive-message call)
                     while message
                     collect message)
               (receive-message call)))
      (free-call-data call))))

--- END_FILE: ./grpc/client.lisp ---

--- START_FILE: ./Makefile ---
# EBusta Project Makefile
LISP_DIR=$(shell pwd)/lisp-converter
GRPC_DIR=$(shell pwd)/grpc
TESTS_DIR=$(shell pwd)/tests

.PHONY: run-dsl-server debug-dsl-server test-dsl test-compliance build-bin clean

# Стандартный тихий запуск
run-dsl-server:
	./dsl-converter

# Запуск с логами запросов
debug-dsl-server:
	./dsl-converter --verbose

build-bin:
	sbcl --noinform \
		--eval '(push (truename "$(GRPC_DIR)/") asdf:*central-registry*)' \
		--eval '(push (truename "$(LISP_DIR)/") asdf:*central-registry*)' \
		--eval '(ql:quickload :ebusta-search :silent t)' \
		--load "$(LISP_DIR)/dsl-service.lisp" \
		--eval '(ebusta-service:build-binary)' \
		--quit

test-dsl:
	$(LISP_DIR)/grpcurl -plaintext \
		-import-path $(LISP_DIR) \
		-proto $(LISP_DIR)/search.proto \
		-d '{"raw_query": "author:\"Стивен Кинг\" AND title:Куджо"}' \
		localhost:50052 ebusta.library.v1.MessageConverter/Convert

test-compliance:
	bash $(TESTS_DIR)/test_compliance.sh

clean:
	rm -f dsl-converter

--- END_FILE: ./Makefile ---

--- START_FILE: ./EBusta_Search_Technical_Spec_v1.1.md ---
# Техническая спецификация: Поисковая система Ebusta (v1.1)

## 1. Обзор архитектуры
[cite_start]Система Ebusta представляет собой микросервисную поисковую платформу, предназначенную для индексации и поиска по архивам электронных книг[cite: 326]. [cite_start]Взаимодействие между компонентами осуществляется через gRPC[cite: 409].

### Потоковый конвейер (Pipeline)
1.  [cite_start]**Web-Adapter**: Принимает внешние HTTP-запросы и передает их в оркестратор[cite: 328, 411].
2.  [cite_start]**Orchestrator**: Координирует работу микросервисов и управляет идентификаторами трассировки (`Trace-ID`)[cite: 329].
3.  [cite_start]**Message-Converter**: Преобразует сырую строку запроса в абстрактное синтаксическое дерево (AST)[cite: 329, 413].
4.  [cite_start]**Processor**: Центральный узел бизнес-логики, выбирающий стратегию поиска на основе AST[cite: 330, 415].
5.  [cite_start]**Data-Manager**: Выполняет функции прокси-сервиса для взаимодействия с OpenSearch[cite: 330, 417].
6.  [cite_start]**OpenSearch**: Движок полнотекстового поиска, выполняющий запросы по индексу `flibusta_merged_index`[cite: 369].



---

## 2. Ebusta Search DSL (v1.1)

[cite_start]DSL (Domain Specific Language) предоставляет пользователю гибкий интерфейс для управления параметрами поиска[cite: 426].

### 2.1 Лексические атомы и префиксы (Scopes)
Система поддерживает следующие префиксы для уточнения области поиска:
* [cite_start]`title:` — Поиск по названию книги[cite: 426].
* [cite_start]`author:` — Поиск по имени автора[cite: 426].
* [cite_start]`author_id:` — Поиск по внутреннему идентификатору автора[cite: 426].
* [cite_start]`desc:` — Поиск по аннотации/описанию[cite: 426].
* **`id:`** — Поиск по уникальному идентификатору документа или SHA1-хешу файла.
* **`file:`** — Поиск по конкретному имени файла (например, `743373.fb2`).
* **`container:`** — Поиск по имени ZIP-архива.

### 2.2 Логические операторы и выражения
* [cite_start]**Операторы**: `AND`, `OR`, `NOT` (регистронезависимые)[cite: 426].
* [cite_start]**Приоритет**: `NOT` > `AND` > `OR`[cite: 433].
* [cite_start]**Регулярные выражения**: Поддерживаются паттерны вида `/regex/`[cite: 426, 430].
* [cite_start]**Точные фразы**: Поиск по фразе в кавычках: `"Мастер и Маргарита"`[cite: 426].

---

## 3. Внутреннее представление: SearchQuery (AST)

[cite_start]Структура данных `SearchQuery` реализована в формате Protocol Buffers (`library.proto`)[cite: 173].

### Компоненты дерева:
* [cite_start]**FilterNode**: Листовой узел, содержащий поля `field`, `value` и `operator` (`OP_EQUALS`, `OP_CONTAINS`, `OP_REGEX`)[cite: 175].
* [cite_start]**LogicalNode**: Узел ветвления, объединяющий другие запросы через логические операции[cite: 176].
* [cite_start]**NotNode**: Узел инверсии для реализации оператора `NOT`[cite: 174, 177].



---

## 4. Интеграция с данными (OpenSearch)

### 4.1 Схема индекса
[cite_start]Индекс `flibusta_merged_index` использует строгий маппинг (`dynamic: strict`)[cite: 197].
* [cite_start]**Текстовые поля**: Поля `title` и `authors` используют анализатор `mixed_text` для поддержки русского и английского языков[cite: 198, 200].
* [cite_start]**Поля ключевых слов**: Подполя `.kw` используются для точного поиска и схлопывания дублей[cite: 198, 201].
* [cite_start]**Технические метаданные**: Объект `fileInfo` хранит `container`, `filename` и `size`[cite: 205].

### 4.2 Дедупликация и ранжирование
[cite_start]Для борьбы с дубликатами используется механизм **Collapse** по полю `title.kw`[cite: 185].
* [cite_start]В результатах поиска всегда возвращается «лучшая» версия книги (секция `inner_hits` с именем `best`), отсортированная по максимальному размеру файла (`fileInfo.size`)[cite: 185, 186].

---

## 5. Текущая реализация и стратегия развития

### 5.1 Анализ состояния (Status Quo)
[cite_start]На текущий момент компонент **Parser** (`internal/parser`) успешно разбирает строку в AST в сервисе `Message-Converter`[cite: 244]. [cite_start]Однако сервис **Processor** все еще использует упрощенную логику разбора строк через `strings.HasPrefix`[cite: 231, 233].

### 5.2 План внедрения AST Walker
[cite_start]Целью является полный переход на рекурсивный обход дерева `SearchQuery` в процессоре[cite: 249]:
1.  [cite_start]**Извлечение**: Перевод `cmd/processor/main.go` на работу с полем `query` из сообщения `UnmarshaledMessage`[cite: 247].
2.  **Маппинг**: Привязка новых префиксов (`id`, `file`, `container`) к соответствующим полям индекса OpenSearch в шаблонах.
3.  [cite_start]**Логика**: Реализация трансляции `LogicalNode` в структуру `bool query` (must, should, must_not) для OpenSearch[cite: 254].
4.  [cite_start]**Валидация**: Обеспечение возврата `meta.canonical_form` для отображения дерева разбора пользователю[cite: 434, 467].

---
*Документ актуален на: 2026-01-25*

--- END_FILE: ./EBusta_Search_Technical_Spec_v1.1.md ---

--- START_FILE: ./f2bulker/config.yaml ---
opensearch:
  index_name: "flibusta_merged_index"
  url: "http://cloud-1:9200"

paths:
  warn_dir: "./data/warn"
  output_dir: "./data/out"
  source_dir: "/mnt/fb2/fb2.Flibusta.Net"

processing:
  threads: 4

logging:
  log_path: "f2bulker.log"

metrics:
  pushgateway_url: "http://localhost:9091"

# Пауза в секундах между архивами, чтобы сервер остыл
sleep_between_zips: 600 


uploading:
  log_path: "uploader.log"
  sleep_between_uploads: 30

--- END_FILE: ./f2bulker/config.yaml ---

--- START_FILE: ./f2bulker/cmd/bulker/main.go ---
package main

import (
	"archive/zip"
	"bufio"
	"bytes"
	"crypto/sha1"
	"encoding/hex"
	"encoding/json"
	"encoding/xml"
	"flag"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"github.com/schollz/progressbar/v3"
	"github.com/sirupsen/logrus"
	"golang.org/x/text/encoding/charmap"
	"golang.org/x/text/encoding/unicode"
	"gopkg.in/yaml.v3"
)

type Config struct {
	OpenSearch struct {
		IndexName string `yaml:"index_name"`
	} `yaml:"opensearch"`
	Paths struct {
		WarnDir   string `yaml:"warn_dir"`
		OutputDir string `yaml:"output_dir"`
		SourceDir string `yaml:"source_dir"`
	} `yaml:"paths"`
	Processing struct {
		Threads int `yaml:"threads"`
	} `yaml:"processing"`
}

type docOut struct {
	Title      string    `json:"title"`
	Authors    []string  `json:"authors,omitempty"`
	IngestedAt time.Time `json:"ingestedAt"`
	FileInfo   struct {
		Container string `json:"container"`
		Filename  string `json:"filename"`
		Sha1      string `json:"sha1"`
		Size      int64  `json:"size"`
	} `json:"fileInfo"`
}

var (
	cfg           Config
	log           = logrus.New()
	outFile       *os.File
	outMu         sync.Mutex
	bar           *progressbar.ProgressBar
	rescuedCount  int32
	flagRescan    *bool
	flagVerbose   *bool
	flagSuperFast *bool
)

func main() {
	configPath := flag.String("config", "./config.yaml", "Path to config file")
	container := flag.String("container", "", "Process specific ZIP")
	rescue := flag.Bool("rescue", false, "Rescue mode")
	flagRescan = flag.Bool("rescan", false, "Force rescan all")
	flagVerbose = flag.Bool("verbose", false, "Detailed check")
	flagSuperFast = flag.Bool("fast", false, "Ultra-fast skip if output exists")
	flag.Parse()

	cFile, err := os.ReadFile(*configPath)
	if err != nil {
		fmt.Printf("Error reading config: %v\n", err)
		os.Exit(1)
	}
	if err := yaml.Unmarshal(cFile, &cfg); err != nil {
		fmt.Printf("Error parsing YAML: %v\n", err)
		os.Exit(1)
	}

	log.SetFormatter(&logrus.TextFormatter{FullTimestamp: true, ForceColors: true})
	_ = os.MkdirAll(cfg.Paths.OutputDir, 0755)

	if *rescue {
		runRescueMode()
	} else if *container != "" {
		processSingleZip(filepath.Join(cfg.Paths.SourceDir, *container), filepath.Join(cfg.Paths.OutputDir, *container+".jsonl"))
	} else {
		archives, _ := filepath.Glob(filepath.Join(cfg.Paths.SourceDir, "*.zip"))
		for _, zipPath := range archives {
			processSingleZip(zipPath, filepath.Join(cfg.Paths.OutputDir, filepath.Base(zipPath)+".jsonl"))
		}
	}
}

func normalizeJSONL(path string) (int, error) {
	f, err := os.Open(path)
	if err != nil { return 0, err }
	defer f.Close()
	tmpPath := path + ".tmp"
	tmpFile, err := os.Create(tmpPath)
	if err != nil { return 0, err }
	defer tmpFile.Close()

	hashes := make(map[string]bool)
	scanner := bufio.NewScanner(f)
	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
	count := 0
	for scanner.Scan() {
		line1 := scanner.Text()
		if strings.Contains(line1, `"_index"`) {
			match := re.FindStringSubmatch(line1)
			if len(match) > 1 {
				id := match[1]
				if scanner.Scan() {
					line2 := scanner.Text()
					if !hashes[id] {
						hashes[id] = true
						_, _ = tmpFile.WriteString(line1 + "\n")
						_, _ = tmpFile.WriteString(line2 + "\n")
						count++
					}
				}
			}
		}
	}
	_ = os.Rename(tmpPath, path)
	return count, nil
}

func countExistingDocs(path string) int {
	count := 0
	f, err := os.Open(path)
	if err != nil { return 0 }
	defer f.Close()
	scanner := bufio.NewScanner(f)
	for scanner.Scan() {
		if strings.Contains(scanner.Text(), `"_index"`) { count++ }
	}
	return count
}

func loadExistingHashes(path string) map[string]bool {
	hashes := make(map[string]bool)
	f, err := os.Open(path)
	if err != nil { return hashes }
	defer f.Close()
	scanner := bufio.NewScanner(f)
	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
	for scanner.Scan() {
		line := scanner.Text()
		if strings.Contains(line, `"_index"`) {
			match := re.FindStringSubmatch(line)
			if len(match) > 1 { hashes[match[1]] = true }
		}
	}
	return hashes
}

func processSingleZip(zipPath, dstPath string) {
	containerName := filepath.Base(zipPath)
	if *flagSuperFast && !*flagRescan {
		if info, err := os.Stat(dstPath); err == nil && info.Size() > 0 {
			log.Infof("[%s] Fast-skip: exists.", containerName)
			os.Exit(10)
		}
	}

	z, err := zip.OpenReader(zipPath)
	if err != nil { return }
	defer z.Close()

	fb2Count := 0
	for _, f := range z.File {
		if strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { fb2Count++ }
	}

	if !*flagRescan && !*flagVerbose {
		if jsonlCount := countExistingDocs(dstPath); jsonlCount > 0 {
			if fb2Count == jsonlCount {
				os.Exit(10)
			} else {
				newCount, _ := normalizeJSONL(dstPath)
				if newCount == fb2Count { os.Exit(10) }
			}
		}
	}

	existingHashes := make(map[string]bool)
	if !*flagRescan { existingHashes = loadExistingHashes(dstPath) }

	type workItem struct {
		file *zip.File
		raw  []byte
		sha  string
	}
	var tasks []workItem

	for _, f := range z.File {
		if !strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { continue }
		
		if len(existingHashes) == 0 && !*flagRescan && !*flagVerbose {
			tasks = append(tasks, workItem{file: f})
			continue
		}

		rc, err := f.Open()
		if err != nil { continue }
		data, _ := io.ReadAll(rc)
		rc.Close()
		sum := sha1.Sum(data)
		sha := hex.EncodeToString(sum[:])
		if !existingHashes[sha] {
			tasks = append(tasks, workItem{file: f, raw: data, sha: sha})
		}
	}

	if len(tasks) == 0 { os.Exit(10) }

	openOutputFile(dstPath)
	defer outFile.Close()
	bar = progressbar.Default(int64(len(tasks)), "🚢 "+containerName)
	jobs := make(chan workItem)
	var wg sync.WaitGroup
	for i := 0; i < cfg.Processing.Threads; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for item := range jobs {
				if item.raw == nil {
					rc, err := item.file.Open()
					if err == nil {
						item.raw, _ = io.ReadAll(rc)
						rc.Close()
						sum := sha1.Sum(item.raw)
						item.sha = hex.EncodeToString(sum[:])
					}
				}
				if item.raw != nil {
					if doc, err := parseResilient(item.raw); err == nil {
						saveToOutputWithSha(item.file.Name, containerName, item.raw, item.sha, doc)
					}
				}
				_ = bar.Add(1)
			}
		}()
	}
	for _, t := range tasks { jobs <- t }
	close(jobs)
	wg.Wait()
}

func runRescueMode() {
	files, _ := filepath.Glob(filepath.Join(cfg.Paths.WarnDir, "*fb2"))
	if len(files) == 0 { return }
	dstPath := filepath.Join(cfg.Paths.OutputDir, "rescued_items.jsonl")
	openOutputFile(dstPath)
	defer outFile.Close()
	jobs := make(chan string)
	var wg sync.WaitGroup
	for i := 0; i < cfg.Processing.Threads; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for path := range jobs {
				data, err := os.ReadFile(path)
				if err != nil { continue }
				if doc, err := parseResilient(data); err == nil {
					if saveToOutput(filepath.Base(path), "rescued", data, doc) {
						_ = os.Remove(path)
						atomic.AddInt32(&rescuedCount, 1)
					}
				}
			}
		}()
	}
	for _, f := range files { jobs <- f }
	close(jobs)
	wg.Wait()
}

func parseResilient(data []byte) (*docOut, error) {
	utf8Data := convertToUTF8(data)
	if doc, err := parseFB2(utf8Data); err == nil { return doc, nil }
	return parseWithRegex(utf8Data)
}

func convertToUTF8(data []byte) []byte {
	if len(data) < 2 { return data }
	if (data[0] == 0xFF && data[1] == 0xFE) || (data[0] == 0xFE && data[1] == 0xFF) {
		dec := unicode.UTF16(unicode.LittleEndian, unicode.UseBOM).NewDecoder()
		out, _ := dec.Bytes(data)
		return out
	}
	header := string(data[:min(len(data), 500)])
	if strings.Contains(strings.ToLower(header), "windows-1251") {
		out, _ := charmap.Windows1251.NewDecoder().Bytes(data)
		return out
	}
	return bytes.ToValidUTF8(data, []byte(" "))
}

func parseWithRegex(data []byte) (*docOut, error) {
	doc := &docOut{}
	reTitle := regexp.MustCompile(`(?is)<book-title[^>]*>(.*?)</book-title>`)
	if m := reTitle.FindSubmatch(data); len(m) > 1 { doc.Title = string(m[1]) }
	if doc.Title == "" { return nil, fmt.Errorf("regex failed") }
	return doc, nil
}

func openOutputFile(path string) {
	var err error
	outFile, err = os.OpenFile(path, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
	if err != nil {
		log.Fatalf("Critical: failed to open output file: %v", err)
	}
}

func saveToOutput(filename, container string, raw []byte, doc *docOut) bool {
	sum := sha1.Sum(raw)
	sha := hex.EncodeToString(sum[:])
	return saveToOutputWithSha(filename, container, raw, sha, doc)
}

func saveToOutputWithSha(filename, container string, raw []byte, sha string, doc *docOut) bool {
	doc.FileInfo.Container, doc.FileInfo.Filename, doc.FileInfo.Sha1, doc.FileInfo.Size = container, filename, sha, int64(len(raw))
	doc.IngestedAt = time.Now()
	action, _ := json.Marshal(map[string]map[string]any{"index": {"_index": cfg.OpenSearch.IndexName, "_id": sha}})
	data, _ := json.Marshal(doc)
	outMu.Lock()
	defer outMu.Unlock()
	_, _ = outFile.Write(append(action, '\n'))
	_, _ = outFile.Write(append(data, '\n'))
	return true
}

func parseFB2(data []byte) (*docOut, error) {
	var doc docOut
	d := xml.NewDecoder(bytes.NewReader(data))
	for {
		t, _ := d.Token()
		if t == nil { break }
		if se, ok := t.(xml.StartElement); ok && se.Name.Local == "book-title" {
			_ = d.DecodeElement(&doc.Title, &se)
		}
	}
	if doc.Title == "" { return nil, fmt.Errorf("no title") }
	return &doc, nil
}

func min(a, b int) int { if a < b { return a }; return b }

--- END_FILE: ./f2bulker/cmd/bulker/main.go ---

--- START_FILE: ./f2bulker/go.mod ---
module f2bulker

go 1.24.11

require (
	github.com/schollz/progressbar/v3 v3.19.0
	github.com/sirupsen/logrus v1.9.3
	golang.org/x/text v0.32.0
	gopkg.in/yaml.v3 v3.0.1
)

require (
	github.com/kr/pretty v0.3.1 // indirect
	github.com/mitchellh/colorstring v0.0.0-20190213212951-d06e56a500db // indirect
	github.com/rivo/uniseg v0.4.7 // indirect
	github.com/rogpeppe/go-internal v1.10.0 // indirect
	github.com/stretchr/testify v1.11.1 // indirect
	golang.org/x/sys v0.35.0 // indirect
	golang.org/x/term v0.28.0 // indirect
	gopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c // indirect
)

--- END_FILE: ./f2bulker/go.mod ---

--- START_FILE: ./f2bulker/Makefile ---
BINARY_NAME=f2bulker
INSTALL_DIR=/opt/f2bulker
BIN_PATH=$(INSTALL_DIR)/$(BINARY_NAME)
LOCAL_BIN=./bin/$(BINARY_NAME)
IS_ROOT = $(shell id -u)

.PHONY: build install clean check-root

build:
	go mod tidy
	mkdir -p bin
	go build -o $(LOCAL_BIN) ./cmd/bulker/main.go

check-root:
ifneq ($(IS_ROOT), 0)
	@echo "Error: Run 'sudo make install'"
	@exit 1
endif

install: check-root
	@if [ ! -f $(LOCAL_BIN) ]; then echo "Run 'make build' first"; exit 1; fi
	mkdir -p $(INSTALL_DIR)
	mkdir -p $(INSTALL_DIR)/data/src $(INSTALL_DIR)/data/out $(INSTALL_DIR)/data/warn
	cp $(LOCAL_BIN) $(INSTALL_DIR)/
	cp ./config.yaml $(INSTALL_DIR)/
	cp ./scripts/scan_zips.sh $(INSTALL_DIR)/
	chmod +x $(BIN_PATH)
	chmod +x $(INSTALL_DIR)/scan_zips.sh
	@echo "Installed to $(INSTALL_DIR)"
	@echo "Link: sudo ln -sf $(BIN_PATH) /usr/local/bin/$(BINARY_NAME)"

clean:
	rm -rf bin

--- END_FILE: ./f2bulker/Makefile ---

--- START_FILE: ./f2bulker/README.md ---
# f2bulker: Высокопроизводительный индексатор FB2 в OpenSearch

## 1. Спецификация требований (ISO 29148)

Данный раздел формализует требования к системе, обеспечивая их проверяемость и соответствие техническим целям проекта.

### 1.1 Функциональные требования (Functional Requirements)
* **FR-1: Извлечение из ZIP.** Система должна открывать ZIP-архивы и извлекать файлы формата `.fb2`.
* **FR-2: Парсинг метаданных.** Программа должна извлекать название книги и список авторов из структуры FB2.
* **FR-3: Отказоустойчивость.** При ошибках XML-парсинга система должна применять поиск через регулярные выражения.
* **FR-4: Формат Bulk API.** Вывод должен формироваться в формате JSONL, пригодном для Bulk API OpenSearch, включая строку метаданных индекса и строку документа.
* **FR-5: Дедупликация.** Система должна рассчитывать SHA1-хеш каждого файла и пропускать уже обработанные объекты на основе анализа выходного файла.
* **FR-6: Режим Fast-skip.** При установленном флаге `-fast` система должна мгновенно пропускать контейнер, если соответствующий ему `.jsonl` файл существует и не пуст.
* **FR-7: Управление через CLI.** Программа должна поддерживать флаги `-config`, `-container`, `-rescan`, `-verbose`, `-fast`.
* **FR-8: Интеграция со скриптами.** Программа должна возвращать код завершения `10` при пропуске обработанного контейнера для корректной работы внешних планировщиков.

### 1.2 Нефункциональные требования (Performance & Quality)
* **PR-1: Параллелизм.** Обработка должна распределяться между потоками (горутинами) согласно параметру `Threads` в конфигурации.
* **PR-2: Оптимизация Discovery.** Для новых контейнеров этап подготовки задач не должен включать чтение содержимого файлов в основном потоке.
* **PR-3: Эффективность памяти.** Содержимое файлов должно очищаться из RAM сразу после записи в выходной файл.
* **PR-4: Поддержка кодировок.** Система должна корректно обрабатывать UTF-8, UTF-16 и Windows-1251.

---

## 2. Документ технической реализации

### 2.1 Архитектура системы
Программа построена на модели **Concurrent Worker Pool** (Пул параллельных воркеров).



#### Компоненты потока управления:
1.  **Главный поток (Producer):** Сканирует архивы и формирует очередь задач.
2.  **Канал задач (`jobs`):** Буферизированный канал для передачи структур `workItem`.
3.  **Воркеры (Consumers):** Набор из N горутин, выполняющих параллельное чтение, хеширование и парсинг.
4.  **Синхронизатор:** `sync.WaitGroup` для контроля завершения всех процессов перед выходом.

### 2.2 Пошаговая передача управления
1.  **`main` → `processSingleZip`:** Инициализация параметров конкретного контейнера.
2.  **Проверка Fast-skip:** Если флаг `-fast` активен, управление через `os.Stat` проверяет наличие файла. При успехе — немедленный выход через `os.Exit(10)`.
3.  **Discovery (Оптимизированный):** * Если база хешей пуста (новый контейнер), основной поток лишь заполняет список `tasks` ссылками на `zip.File`, минуя вызовы `f.Open` и `io.ReadAll`.
    * Это устраняет "зависание" программы перед появлением прогресс-бара.
4.  **Развертывание воркеров:** Основной поток передает задачи в канал. Управление внутри воркера реализует **Lazy Loading**: если данные файла отсутствуют (`item.raw == nil`), воркер сам инициирует чтение и расчет SHA1 параллельно с другими воркерами.
5.  **Завершение:** После закрытия канала воркеры завершают работу, и управление возвращается в `main` для перехода к следующему ZIP-архиву.

### 2.3 Жизненный цикл переменных
* **`item.raw` ([]byte):** Данные файла. Память выделяется либо в Discovery, либо в воркере. Ссылка на массив байтов обнуляется сразу после вызова `saveToOutputWithSha`, что позволяет Garbage Collector (GC) освобождать память итеративно.
* **`existingHashes` (map):** Карта хешей. Загружается один раз в начале обработки ZIP для дедупликации. При ее отсутствии активируется режим ускоренного Discovery.
* **`err`:** Все переменные ошибок проходят аудит; при критических сбоях (например, невозможность открыть файл вывода) программа завершается через `log.Fatalf`.

### 2.4 Матрица состояний (Аудит логики `-fast`)

| Режим `-fast` | Состояние контейнера | Логика | Результат |
| :--- | :--- | :--- | :--- |
| **Установлен** | **Обработан** | `os.Stat` находит файл | Мгновенный выход `Exit(10)`. |
| **Установлен** | **Не обработан** | `os.Stat` возвращает ошибку | Быстрый Discovery -> Параллельное хеширование. |
| **Не установлен** | **Обработан** | Сравнение счетчиков файлов | Выход `Exit(10)`, если количество совпадает. |
| **Не установлен** | **Не обработан** | База хешей пуста | Быстрый Discovery -> Параллельное хеширование. |

---

## 3. Инструкции по эксплуатации

### Сборка
```bash
make build

--- END_FILE: ./f2bulker/README.md ---

--- START_FILE: ./f2bulker/backlog.md ---
# Ebusta Project Backlog

## Ingesting (f2bulker)
- [ ] **Issue #1**: Ошибка парсинга UTF-16 (BOM ÿþ). Файл `547782.fb2` падает с `XML syntax error: invalid UTF-8`. Необходимо доработать `charsetReader` для корректной десериализации UTF-16 Little Endian. [cite: 440-442]
- [ ] **Feature**: Поддержка группировки в DSL (скобки). [cite: 141]

## System
- [ ] **Auth**: Интеграция Auth-Manager в Orchestrator. [cite: 219-220]
- [ ] **OS**: Переход с мока `books.json` на реальные поисковые шаблоны OpenSearch. [cite: 221]

--- END_FILE: ./f2bulker/backlog.md ---

--- START_FILE: ./README.md ---
# Ebusta 📚

Микросервисная поисковая система для архивов Flibusta. Позволяет выполнять быстрый поиск по миллионам записей через OpenSearch, используя собственный DSL (Domain Specific Language).

## 🏗 Архитектура системы

Система состоит из нескольких независимых сервисов, взаимодействующих по gRPC:

* **Web-Adapter (The Door)**: Принимает внешние HTTP-запросы и передает их в оркестратор.
* **Orchestrator**: Координирует работу всех сервисов, управляет Trace-ID.
* **Message-Converter**: Парсит строку запроса в AST-дерево.
* **Processor**: Обрабатывает бизнес-логику и выбирает стратегию поиска.
* **Datamanager**: Слой данных, работающий с OpenSearch.
* **Auth-Manager**: Проверяет права доступа и управляет whitelist.
* **Ebusta-CLI**: Интерактивная оболочка для работы с системой.



## 🚦 Карта портов

| Сервис            | Порт (gRPC) | Функции                          |
|:------------------|:------------|:---------------------------------|
| Datamanager       | `:50051`    | Слой данных (OpenSearch)         |
| Message-Converter | `:50052`    | Парсер (AST)                     |
| Processor         | `:50053`    | Логика и выбор шаблонов          |
| Orchestrator      | `:50054`    | Координация                      |
| Auth-Manager      | `:50055`    | Безопасность (Whitelist)         |
| Web-Adapter       | `:8080`     | HTTP-вход (REST)                 |
| Metrics           | `:9091`     | Prometheus метрики (Datamanager) |

## 🚀 Быстрый старт

### Сборка и запуск
Требуется установленный Go 1.21+ и Protoc.

```bash
make build   # Генерация Proto и компиляция всех сервисов
make run     # Запуск всей системы в фоновом режиме


--- END_FILE: ./README.md ---

--- START_FILE: ./lisp-converter/server.lisp ---
(ql:quickload '(:cl-protobufs :grpc) :silent t)

;; 1. Загружаем сгенерированные определения
(load "/home/serge/projects/ebusta/lisp-converter/search.lisp")

(defpackage :ebusta.service
  (:use :cl)
  (:local-nicknames (#:pb #:cl-protobufs.ebusta.library.v1)
                    (#:grpc #:grpc)))

(in-package :ebusta.service)

;; --- Логика конвертации ---
(defun dsl-to-pb (dsl)
  (let ((query (make-instance 'pb:search-query)))
    (cond
      ((member (car dsl) '(:and :or))
       (let ((l-node (make-instance 'pb:logical-node)))
         (setf (pb:logical-node.op l-node) (if (eq (car dsl) :and) 1 2))
         (dolist (sub (cdr dsl))
           (push (dsl-to-pb sub) (pb:logical-node.nodes l-node)))
         (setf (pb:search-query.logical query) l-node)))
      ((eq (car dsl) :field)
       (let ((f-node (make-instance 'pb:filter-node)))
         (setf (pb:filter-node.field f-node) (getf dsl :field)
               (pb:filter-node.value f-node) (getf dsl :val)
               (pb:filter-node.operator f-node) 1)
         (setf (pb:search-query.filter query) f-node))))
    query))

;; --- Реализация метода сервера ---
;; Мы добавляем метод к обобщенной функции, которую создал cl-protobufs.
;; Имя пакета RPC формируется автоматически: <package-name>-rpc
(in-package :cl-protobufs.ebusta.library.v1-rpc)

(defmethod convert ((request cl-protobufs.ebusta.library.v1:convert-request) rpc)
  (declare (ignore rpc))
  (format t "Request received: ~S~%" request)
  (let* ((raw (cl-protobufs.ebusta.library.v1:convert-request.raw-query request))
         (dsl (read-from-string raw)))
    (format t "Parsed DSL: ~S~%" dsl)
    (ebusta.service::dsl-to-pb dsl)))

(in-package :ebusta.service)

;; --- Запуск ---
(defun start-service ()
  (grpc:init-grpc)
  (format t "=== EBusta Lisp Service starting on port 50052 ===~%")
  ;; qitab/grpc умеет сам находить методы по имени сервиса
  (grpc:run-grpc-proto-server 
   "0.0.0.0:50052" 
   'pb:message-converter
   :num-threads 2))

(start-service)

--- END_FILE: ./lisp-converter/server.lisp ---

--- START_FILE: ./lisp-converter/converter.lisp ---
(ql:quickload '(:cl-protobufs :cl-base64))

(defpackage :ebusta.app
  (:use :cl :cl-protobufs)
  (:export :run-test))

(in-package :ebusta.app)

;; --- 1. СХЕМА (NATIVE) ---
(eval-when (:compile-toplevel :load-toplevel :execute)
  (define-schema libraryv1
    (:package "libraryv1")))

(define-message filter-node ()
  (:schema libraryv1)
  (field :index 1 :type string :kind :optional)
  (value :index 2 :type string :kind :optional)
  (operator :index 3 :type int32 :kind :optional))

(define-message logical-node ()
  (:schema libraryv1)
  (op :index 1 :type int32 :kind :optional) ;; 1 = AND, 2 = OR
  (nodes :index 2 :type filter-node :kind :repeated))

(define-message search-query ()
  (:schema libraryv1)
  (filter :index 1 :type filter-node :kind :optional)
  (logical :index 2 :type logical-node :kind :optional))

;; --- 2. ПАРСЕР ---
(defun to-pb (dsl)
  (let ((query (make-instance 'search-query)))
    (cond 
      ((member (car dsl) '(:and :or))
       (let ((l-node (make-instance 'logical-node :op (if (eq (car dsl) :and) 1 2))))
         (dolist (sub (cdr dsl))
           (push (make-instance 'filter-node
                                :field (getf sub :field)
                                :value (getf sub :val)
                                :operator 1)
                 (logical-node.nodes l-node)))
         (setf (search-query.logical query) l-node)))
      ((eq (car dsl) :field)
       (setf (search-query.filter query)
             (make-instance 'filter-node
                            :field (getf dsl :field)
                            :value (getf dsl :val)
                            :operator 1))))
    query))

;; --- 3. ТЕСТОВЫЙ ЗАПУСК ---
(defun run-test ()
  (format t "~%--- [ CONVERTER START ] ---~%")
  (let* ((dsl '(:and (:field "author" :val "Bulgakov") 
                     (:field "title" :val "Master")))
         (pb-obj (to-pb dsl)))
    (format t "DSL input: ~A~%" dsl)
    (format t "Protobuf Text Format:~%~%")
    (print-text-format pb-obj :stream t)
    (format t "~%--- [ CONVERTER SUCCESS ] ---~%")))

(run-test)

--- END_FILE: ./lisp-converter/converter.lisp ---

--- START_FILE: ./lisp-converter/dsl-client.lisp ---
(defpackage #:dsl-client
  (:use #:cl)
  (:local-nicknames (#:pb #:cl-protobufs.ebusta.library.v1)
                    (#:pb-rpc #:cl-protobufs.ebusta.library.v1-rpc)
                    (#:grpc #:grpc)))

(in-package #:dsl-client)

(defun run ()
  (grpc:init-grpc)
  ;; Тот самый запрос: И (title="Lisp") ИЛИ (author="Serge" | author="Reva")
  (let ((dsl-string "(:and (:field \"title\" \"Lisp\") (:or (:field \"author\" \"Serge\") (:field \"author\" \"Reva\")))"))
    
    (format t ">>> Sending DSL: ~A~%" dsl-string)
    
    (grpc:with-insecure-channel (channel "localhost:50052")
      (let* ((request (pb:make-convert-request :raw-query dsl-string))
             ;; Вызываем метод Convert
             (response (pb-rpc:call-convert channel request)))
        
        (format t ">>> SERVER RESPONSE:~%")
        (format t "~S~%" response)
        
        ;; Дополнительная проверка структуры (для наглядности)
        (let ((logical (pb:search-query.logical response)))
          (when logical
            (format t "Root is LOGICAL node (Op: ~A)~%" (pb:logical-node.op logical))
            (format t "Children count: ~A~%" (length (pb:logical-node.nodes logical))))))))

  (grpc:shutdown-grpc)
  (sb-ext:exit))

(run)

--- END_FILE: ./lisp-converter/dsl-client.lisp ---

--- START_FILE: ./lisp-converter/search.proto ---
syntax = "proto3";

package ebusta.library.v1;

message FilterNode {
  string field = 1;
  string value = 2;
  int32 operator = 3;
}

message LogicalNode {
  int32 op = 1; 
  repeated SearchQuery nodes = 2;
}

message SearchQuery {
  oneof query {
    FilterNode filter = 1;
    LogicalNode logical = 2;
  }
  string canonical_form = 3;
  string request_id = 4; // UR 4.2
}

message ConvertRequest {
  string raw_query = 1;
}

service MessageConverter {
  rpc Convert(ConvertRequest) returns (SearchQuery);
}

--- END_FILE: ./lisp-converter/search.proto ---

--- START_FILE: ./lisp-converter/ebusta-search.asd ---
(defsystem "ebusta-search"
  :defsystem-depends-on (:cl-protobufs.asdf)
  :depends-on (:cl-protobufs :grpc)
  :components ((:protobuf-source-file "search")))

--- END_FILE: ./lisp-converter/ebusta-search.asd ---

--- START_FILE: ./lisp-converter/example-server.lisp ---
(defpackage #:example-server
  (:use #:cl)
  (:local-nicknames (#:pb #:cl-protobufs.lisp.grpc.integration-testing)
                    (#:pb-rpc #:cl-protobufs.lisp.grpc.integration-testing-rpc)
                    (#:grpc #:grpc)))

(in-package #:example-server)

;; Используем полное имя метода из RPC пакета, чтобы не заходить в него
(defmethod pb-rpc:say-hello ((request pb:hello-request) rpc)
  (declare (ignore rpc))
  (let ((name (pb:hello-request.name request)))
    (format t ">>> SERVER: Received request for name: ~A~%" name)
    (pb:make-hello-reply
     :message (concatenate 'string "Hello " name " (via ASDF Build)"))))

(defun run ()
  (grpc:init-grpc)
  (format t "=== Server listening on :50051 ===~%")
  (grpc:run-grpc-proto-server
   "0.0.0.0:50051"
   'pb:greeter
   :num-threads 1))

(run)

--- END_FILE: ./lisp-converter/example-server.lisp ---

--- START_FILE: ./lisp-converter/main.lisp ---
(ql:quickload '(:cl-protobufs :cl-base64))

(load "/home/serge/projects/ebusta/lisp-converter/search.lisp")

(defpackage :ebusta.converter
  (:use :cl)
  (:local-nicknames (#:pb #:cl-protobufs.ebusta.library.v1)))

(in-package :ebusta.converter)

(defun dsl-to-pb (dsl)
  (let ((request (make-instance 'pb:search-request)))
    (cond
      ((member (car dsl) '(:and :or))
       (let ((l-node (make-instance 'pb:logical-node)))
         (setf (pb:logical-node.op l-node) (if (eq (car dsl) :and) 1 2))
         (dolist (sub (cdr dsl))
           (push (dsl-to-pb sub) (pb:logical-node.nodes l-node)))
         (setf (pb:search-request.logical request) l-node)))
      ((eq (car dsl) :field)
       (let ((f-node (make-instance 'pb:filter-node)))
         (setf (pb:filter-node.field f-node) (getf dsl :field)
               (pb:filter-node.value f-node) (getf dsl :val)
               (pb:filter-node.operator f-node) 1)
         (setf (pb:search-request.filter request) f-node))))
    request))

(defun run-system-uuencode (pb-obj)
  (let* ((octets (cl-protobufs:serialize-to-bytes pb-obj))
         (b64 (cl-base64:usb8-array-to-base64-string octets)))
    ;; Вызываем системную утилиту через shell
    (uiop:run-program (format nil "echo ~A | base64 -d | uuencode query.bin" b64)
                      :output t)))

;; ТЕСТ
(format t "~%--- STARTING RECURSIVE TEST ---~%")
(let* ((complex-dsl '(:and (:field "author" :val "Bulgakov") 
                           (:or (:field "title" :val "Master") 
                                (:field "title" :val "Margarita"))))
       (pb-obj (dsl-to-pb complex-dsl)))
  (format t "~%--- UUENCODE OUTPUT ---~%")
  (run-system-uuencode pb-obj)
  (format t "~%--- SUCCESS ---~%"))

--- END_FILE: ./lisp-converter/main.lisp ---

--- START_FILE: ./lisp-converter/parser.lisp ---
(defpackage :ebusta.parser
  (:use :cl)
  (:export :to-pb))

(in-package :ebusta.parser)

(defun to-pb (dsl)
  (let ((query (make-instance 'cl-protobufs.libraryv1:search-query)))
    (cond 
      ;; Если это AND/OR
      ((member (car dsl) '(:and :or))
       (let ((l-node (make-instance 'cl-protobufs.libraryv1:logical-node
                                    :op (if (eq (car dsl) :and) 1 2))))
         (dolist (sub (cdr dsl))
           (let ((f-node (make-instance 'cl-protobufs.libraryv1:filter-node
                                        :field (getf sub :field)
                                        :value (getf sub :val)
                                        :operator 1)))
             (push f-node (cl-protobufs.libraryv1:logical-node.nodes l-node))))
         (setf (cl-protobufs.libraryv1:search-query.logical query) l-node)))
      
      ;; Если это просто поле
      ((eq (car dsl) :field)
       (setf (cl-protobufs.libraryv1:search-query.filter query)
             (make-instance 'cl-protobufs.libraryv1:filter-node
                            :field (getf dsl :field)
                            :value (getf dsl :val)
                            :operator 1))))
    query))

--- END_FILE: ./lisp-converter/parser.lisp ---

--- START_FILE: ./lisp-converter/helloworld.asd ---
(defsystem "helloworld"
  :defsystem-depends-on (:cl-protobufs.asdf)
  :depends-on (:cl-protobufs :grpc)
  :components ((:protobuf-source-file "helloworld")))

--- END_FILE: ./lisp-converter/helloworld.asd ---

--- START_FILE: ./lisp-converter/debug_registry.lisp ---
(ql:quickload '(:cl-protobufs :grpc) :silent t)
(load "/home/serge/projects/ebusta/lisp-converter/search.lisp")

(format t "~%--- Проверка поиска сервиса ---~%")
(let* ((sym 'cl-protobufs.ebusta.library.v1:message-converter)
       (sd (cl-protobufs:find-service-descriptor sym))
       (s (cl-protobufs.implementation:find-service sym)))
  (format t "Символ: ~A~%" sym)
  (format t "Service Descriptor: ~A~%" sd)
  (format t "Service Object: ~A~%" s)
  
  (when sd
    (format t "Методы через Descriptor: ~A~%" 
            (ignore-errors (cl-protobufs:proto-methods sd))))
  (when s
    (format t "Методы через Service: ~A~%" 
            (ignore-errors (cl-protobufs:proto-methods s)))))
(finish-output)

--- END_FILE: ./lisp-converter/debug_registry.lisp ---

--- START_FILE: ./lisp-converter/example-client.lisp ---
(defpackage #:example-client
  (:use #:cl)
  (:local-nicknames (#:pb #:cl-protobufs.lisp.grpc.integration-testing)
                    (#:pb-rpc #:cl-protobufs.lisp.grpc.integration-testing-rpc)
                    (#:grpc #:grpc)))

(in-package #:example-client)

(defun run ()
  (grpc:init-grpc)
  (grpc:with-insecure-channel (channel "localhost:50051")
    (format t "Sending request...~%")
    (let* ((request (pb:make-hello-request :name "Admin"))
           (response (pb-rpc:call-say-hello channel request)))
      (format t "RESPONSE: ~A~%" (pb:hello-reply.message response))))
  (grpc:shutdown-grpc)
  (sb-ext:exit))

(run)

--- END_FILE: ./lisp-converter/example-client.lisp ---

--- START_FILE: ./lisp-converter/schema.lisp ---
(ql:quickload :cl-protobufs)

(defpackage :ebusta.schema
  (:use :cl :cl-protobufs))

(in-package :ebusta.schema)

(cl-protobufs:define-schema libraryv1
    (:package "libraryv1"))

(cl-protobufs:define-message filter-node ()
  (:schema libraryv1)
  (field :index 1 :type string :kind :optional)
  (value :index 2 :type string :kind :optional)
  (operator :index 3 :type int32 :kind :optional))

;; Добавляем узел для AND/OR
(cl-protobufs:define-message logical-node ()
  (:schema libraryv1)
  (op :index 1 :type int32 :kind :optional) ;; 1 - AND, 2 - OR
  (nodes :index 2 :type filter-node :kind :repeated))

(cl-protobufs:define-message search-query ()
  (:schema libraryv1)
  (filter :index 1 :type filter-node :kind :optional)
  (logical :index 2 :type logical-node :kind :optional))

--- END_FILE: ./lisp-converter/schema.lisp ---

--- START_FILE: ./lisp-converter/search.lisp ---
;;; search.proto.lisp
;;;
;;; Generated by the protocol buffer compiler. DO NOT EDIT!

(cl:in-package #:common-lisp-user)

#+sbcl
(cl:progn
 (cl:eval-when (:compile-toplevel) (sb-ext:restrict-compiler-policy 'cl:debug 0 1))
 (cl:declaim (cl:optimize (sb-c:store-coverage-data 0))
  (sb-ext:muffle-conditions sb-kernel:redefinition-with-defun)))

(cl:eval-when (:compile-toplevel :load-toplevel :execute)
  (cl:unless (cl:find-package "CL-PROTOBUFS.EBUSTA.LIBRARY.V1")
    (cl:defpackage "CL-PROTOBUFS.EBUSTA.LIBRARY.V1" (:use)
                   (:local-nicknames (#:pi #:cl-protobufs.implementation)))))

(cl:eval-when (:compile-toplevel :load-toplevel :execute)
  (cl:unless (cl:find-package "CL-PROTOBUFS.EBUSTA.LIBRARY.V1-RPC")
    (cl:defpackage "CL-PROTOBUFS.EBUSTA.LIBRARY.V1-RPC" (:use)
                   (:local-nicknames (#:pi #:cl-protobufs.implementation)))))

(cl:in-package "CL-PROTOBUFS.EBUSTA.LIBRARY.V1")

(cl:eval-when (:compile-toplevel :load-toplevel :execute)
(pi:define-schema 'search
    :syntax :proto3

    :package "ebusta.library.v1")
)


;;; Top-Level messages

(pi:define-message convert-request
    ()
  ;; Fields
  (raw-query
   :index 1 :type cl:string :kind :scalar :label (:optional) :field-presence :implicit :json-name "rawQuery"))

(pi:define-message filter-node
    ()
  ;; Fields
  (field
   :index 1 :type cl:string :kind :scalar :label (:optional) :field-presence :implicit :json-name "field")
  (value
   :index 2 :type cl:string :kind :scalar :label (:optional) :field-presence :implicit :json-name "value")
  (operator
   :index 3 :type cl-protobufs:int32 :kind :scalar :label (:optional) :field-presence :implicit :json-name "operator"))

(pi:define-message logical-node
    ()
  ;; Fields
  (op
   :index 1 :type cl-protobufs:int32 :kind :scalar :label (:optional) :field-presence :implicit :json-name "op")
  (nodes
   :index 2 :type search-query :kind :message :label (:repeated :list) :field-presence :implicit :json-name "nodes"))

(pi:define-message search-query
    ()
  ;; Fields
  (pi:define-oneof query ()
    (filter
     :index 1 :type filter-node :kind :message :label (:optional) :field-presence :explicit :json-name "filter")
    (logical
     :index 2 :type logical-node :kind :message :label (:optional) :field-presence :explicit :json-name "logical")))

;;; Services
(pi:define-service message-converter
    (:source-location #P"search.proto")
  (convert (
    convert-request =>
    search-query)))

(cl:eval-when (:compile-toplevel :load-toplevel :execute)
(pi:add-file-descriptor #P"search.proto" 'search)
)

(cl:export '(convert-request
field
filter
filter-node
logical
logical-node
message-converter
nodes
op
operator
raw-query
search
search-query
value))

(cl:in-package "CL-PROTOBUFS.EBUSTA.LIBRARY.V1-RPC")

(cl:export '(call-convert
convert))

--- END_FILE: ./lisp-converter/search.lisp ---

--- START_FILE: ./lisp-converter/dsl-service.lisp ---
(eval-when (:compile-toplevel :load-toplevel :execute)
  (ql:quickload '(:cl-ppcre :grpc :cl-protobufs :bordeaux-threads) :silent t))

(defpackage #:ebusta-service
  (:use #:cl)
  (:export #:start #:stop #:parse-raw-to-sexp #:parse-sexp-to-ast #:build-binary)
  (:local-nicknames (#:pb #:cl-protobufs.ebusta.library.v1)
                    (#:pb-rpc #:cl-protobufs.ebusta.library.v1-rpc)
                    (#:grpc #:grpc)
                    (#:re #:cl-ppcre)
                    (#:bt #:bordeaux-threads)))

(in-package #:ebusta-service)

;; Глобальная переменная для управления логами
(defvar *verbose* nil)

;;; --- 1. ЛЕКСИКА И ПРИОРИТЕТЫ (CORE) ---

(defun get-priority (op)
  "Определяет приоритет операторов согласно UR 3.3 (NOT > AND > OR)."
  (cond ((string-equal op "NOT") 3)
        ((string-equal op "AND") 2)
        ((string-equal op "OR") 1)
        (t 0)))

(defun tokenize (str)
  "Разбивает строку на токены, учитывая кавычки и префиксы (UR 2.1)."
  (re:all-matches-as-strings "(\"[^\"]+\"|[a-zA-Z0-9_]+:|AND|OR|NOT|\\(|\\)|/|\\S+)" str))

;;; --- 2. СБОРКА ДЕРЕВА (RPN -> S-EXP) ---

(defun build-tree-from-rpn (rpn)
  "Превращает постфиксный список (A B AND) в S-выражение (:AND A B)."
  (let (stack)
    (dolist (token rpn (car stack))
      (if (and (listp token) (eq (car token) :field))
          (push token stack)
          (let ((op (string-upcase (string token))))
            (cond 
              ((string= op "NOT") 
               (push `(:not ,(pop stack)) stack))
              ((member op '("AND" "OR") :test #'string=)
               (let* ((right (pop stack))
                      (left (pop stack))
                      (key (if (string= op "AND") :and :or)))
                 (push `(,key ,left ,right) stack)))))))))

;;; --- 3. ОБРАБОТКА ПОЛЕЙ (SCOPING) ---

(defun make-field-node (field val-raw)
  "Создает узел поля, проверяя наличие регулярного выражения (UR 2.2)."
  (let* ((val (string-trim " \"" val-raw))
         (is-regex (re:scan "^/.*/$" val)))
    `(:field ,field ,(if is-regex (string-trim "/" val) val) ,@(when is-regex '(:op :regex)))))

(defun process-field (token rest-tokens-var)
  "Извлекает значение поля до ближайшего оператора или скобки."
  (let* ((pos (position #\: token))
         (field (subseq token 0 pos))
         (val-part (subseq token (1+ pos))))
    (if (string/= "" val-part)
        (values (make-field-node field val-part) rest-tokens-var)
        (let (collected)
          (loop while (and (car rest-tokens-var) 
                           (zerop (get-priority (car rest-tokens-var))) 
                           (not (member (car rest-tokens-var) '("(" ")") :test #'string-equal)))
                do (push (pop rest-tokens-var) collected))
          (values (make-field-node field (format nil "~{~A~^ ~}" (nreverse collected)))
                  rest-tokens-var)))))

;;; --- 4. SHUNTING-YARD ENGINE ---

(defun parse-raw-to-sexp (str)
  "Главный цикл трансформации инфиксного запроса в дерево приоритетов."
  (let ((token-list (tokenize str))
        (output nil)
        (stack nil))
    (loop while token-list do
      (let ((token (pop token-list)))
        (cond
          ((> (get-priority token) 0)
           (loop while (and stack 
                            (> (get-priority (car stack)) 0)
                            (>= (get-priority (car stack)) (get-priority token)))
                 do (push (pop stack) output))
           (push token stack))
          ((string= token "(") (push token stack))
          ((string= token ")")
           (loop while (and stack (string/= (car stack) "(")) 
                 do (push (pop stack) output))
           (pop stack))
          ((find #\: token)
           (multiple-value-bind (node remaining) (process-field token token-list)
             (push node output)
             (setf token-list remaining)))
          (t (push (make-field-node "any" token) output)))))
    (loop while stack do (push (pop stack) output))
    (build-tree-from-rpn (nreverse output))))

;;; --- 5. AST BUILDER ---

(defun parse-sexp-to-ast (sexp &key request-id canonical-form)
  (let ((query (pb:make-search-query)))
    (when (and sexp (listp sexp))
      (let ((head (car sexp)))
        (cond
          ((member head '(:and :or))
           (let ((node (pb:make-logical-node :op (if (eq head :and) 1 2))))
             (setf (pb:logical-node.nodes node) 
                   (mapcar (lambda (s) (parse-sexp-to-ast s)) (cdr sexp)))
             (setf (pb:search-query.logical query) node)))
          ((eq head :not)
           (let ((node (pb:make-logical-node :op 3)))
             (setf (pb:logical-node.nodes node) (list (parse-sexp-to-ast (second sexp))))
             (setf (pb:search-query.logical query) node)))
          ((eq head :field)
           (let ((node (pb:make-filter-node :field (second sexp) :value (third sexp)
                                            :operator (if (eq (getf (cdddr sexp) :op) :regex) 6 1))))
             (setf (pb:search-query.filter query) node))))))
    (when request-id (setf (pb:search-query.request-id query) request-id))
    (when canonical-form (setf (pb:search-query.canonical-form query) canonical-form))
    query))

;;; --- 6. gRPC INTERFACE ---

(defmethod pb-rpc:convert ((request pb:convert-request) rpc)
  (declare (ignore rpc))
  (let* ((raw (pb:convert-request.raw-query request))
         (request-id (format nil "req-~A" (get-universal-time))))
    (handler-case
        (let* ((sexp (parse-raw-to-sexp raw))
               (ast (parse-sexp-to-ast sexp 
                                      :request-id request-id 
                                      :canonical-form (format nil "~S" sexp))))
          ;; ВЫВОД ТОЛЬКО ПРИ ФЛАГЕ VERBOSE
          (when *verbose*
            (format t "[~A] Raw: ~A~%" request-id raw)
            (format t "[~A] S-Exp: ~S~%" request-id sexp)
            (finish-output))
          ast)
      (error (e)
        (format t "[ERR ~A] ~A~%" request-id e)
        (finish-output)
        (pb:make-search-query :request-id request-id)))))

(defun start (&key (port 50052) (workers 8) (verbose nil))
  (setf *verbose* verbose)
  (grpc:init-grpc)
  (format t "=== EBusta DSL Engine V19 [Port ~A, Workers ~A, Verbose ~A] ===~%" 
          port workers *verbose*)
  (finish-output)
  (grpc:run-grpc-proto-server (format nil "0.0.0.0:~A" port) 'pb:message-converter)
  (loop (sleep 1)))

(defun build-binary ()
  "Сборка с разбором аргументов командной строки."
  #+sbcl
  (sb-ext:save-lisp-and-die "dsl-converter"
                            :executable t
                            :toplevel (lambda ()
                                        (let ((args sb-ext:*posix-argv*))
                                          (start :port 50052 
                                                 :workers 8
                                                 :verbose (or (member "-v" args :test #'string=)
                                                              (member "--verbose" args :test #'string=)))))))

--- END_FILE: ./lisp-converter/dsl-service.lisp ---

--- START_FILE: ./lisp-converter/helloworld.proto ---
// Copyright 2021 Google LLC
//
// Use of this source code is governed by an MIT-style
// license that can be found in the LICENSE file or at
// https://opensource.org/licenses/MIT.

syntax = "proto3";

package lisp.grpc.integration_testing;

message HelloRequest {
  optional string name = 1;
  optional int32 num_responses = 2;
}

message HelloReply {
  optional string message = 1;
}

service Greeter {
  // Receives a HelloRequest and response with a HelloReply.
  rpc SayHello(HelloRequest) returns (HelloReply) {}
  // Receive a HelloRequest requesting some number of responses in num_responses
  // and response with a HelloReply num_responses times.
  rpc SayHelloServerStream(HelloRequest) returns (stream HelloReply) {}
  // Receive a number of requests and concatenate the name field of each
  // HelloRequest. Return the final string in HelloReply.
  rpc SayHelloClientStream(stream HelloRequest) returns (HelloReply) {}
  // Receive a number of HelloRequest requesting some number of responses in num_responses.
  // Respond to each HelloRequest with a HelloReply num_responses times.
  rpc SayHelloBidirectionalStream(stream HelloRequest) returns (stream HelloReply) {}
}

--- END_FILE: ./lisp-converter/helloworld.proto ---

--- START_FILE: ./lisp-converter/inspect_grpc.lisp ---
(ql:quickload '(:cl-protobufs :grpc) :silent t)
(load "/home/serge/projects/ebusta/lisp-converter/search.lisp")

(format t "~%=== 1. ПРОВЕРКА ЭКСПОРТОВ ПАКЕТА GRPC ===~%")
(let ((symbols '()))
  (do-external-symbols (s :grpc) (push s symbols))
  (format t "External symbols in GRPC: ~{~A~^, ~}~%" (sort symbols #'string<)))

(format t "~%=== 2. ГЛУБОКАЯ ИНСПЕКЦИЯ СЕРВИСА ===~%")
(let* ((sym 'cl-protobufs.ebusta.library.v1:message-converter)
       (sd (cl-protobufs:find-service-descriptor sym)))
  (if sd
      (progn
        (format t "Descriptor found: ~S~%" sd)
        (describe sd)
        (let ((methods (ignore-errors (cl-protobufs:proto-methods sd))))
          (format t "~%Methods list: ~S~%" methods)
          (dolist (m methods)
            (format t "~%--- Инспекция объекта метода ---~%")
            (describe m))))
      (format t "Descriptor NOT found.~%")))
(finish-output)

--- END_FILE: ./lisp-converter/inspect_grpc.lisp ---

--- START_FILE: ./errors.yaml ---
# Сообщения для пользователя ("Дятла")
user_errors:
  invalid_command: "🥚 Слушай, дятел, я не понял твою команду. Попробуй 'get ID' или просто текст поиска."
  empty_payload: "🥚 Дятел, ты забыл ввести текст после команды!"

# Сообщения при сбоях системы ("Сорян, братан")
system_errors:
  converter_down: "🛠 Сорян, братан, у нас конвертер приуныл. Скоро починим."
  processor_error: "🛠 Сорян, братан, труба забилась. Мы уже вызвали сантехников."
  data_layer_down: "📉 Сорян, братан, библиотека закрыта на ремонт. Попробуй позже."
  generic_error: "🧨 Сорян, братан, что-то пошло совсем не так. RequestID: %s"

--- END_FILE: ./errors.yaml ---

--- START_FILE: ./backlog.md ---

## DSL Parser Metrics Integration
- [ ] Интегрировать `cl-prometheus` и `hunchentoot` в `dsl-service.lisp`.
- [ ] Реализовать HTTP-эндпоинт `/metrics` на порту `50053`.
- [ ] Добавить счетчики `dsl_requests_total` и `dsl_errors_total`.
- [ ] Добавить гистограмму `dsl_parse_duration_seconds` (бакеты от 0.1ms до 10ms).
- [ ] Добавить Gauge для мониторинга SBCL heap и активных воркеров.
- [ ] Обеспечить изоляцию: сбой сервера метрик не должен аффектить gRPC.

--- END_FILE: ./backlog.md ---

--- START_FILE: ./doc/GRPC_API_REFERENCE.md ---
# GRPC API Reference: Доступные сервисы и методы

В данном документе перечислены все gRPC методы, зарегистрированные в системе EBusta, их пути для вызова и структуры сообщений.

---

## 1. Сервис: MessageConverter (Основной)
**Описание:** Трансляция поисковых запросов из Lisp DSL в Protobuf-структуры.
**Прото-файл:** `lisp-converter/search.proto`
**Пакет:** `ebusta.library.v1`

### Метод: `Convert`
* **Полный путь:** `ebusta.library.v1.MessageConverter/Convert`
* **Request:** `ConvertRequest` (поле `raw_query` типа string)
* **Response:** `SearchQuery` (рекурсивное дерево)
* **Пример вызова:**
  ```bash
  grpcurl -plaintext -d '{"raw_query": "(:field \"title\" \"Lisp\")"}' localhost:50052 ebusta.library.v1.MessageConverter/Convert
2. Сервис: Greeter (Тестовый)
Описание: Используется для Smoke-тестов инфраструктуры. Прото-файл: lisp-converter/helloworld.proto Пакет: cl_protobufs.lisp.grpc.integration_testing

Метод: SayHello
Полный путь: cl_protobufs.lisp.grpc.integration_testing.Greeter/SayHello

Request: HelloRequest (поле name)

Response: HelloReply (поле message)

Пример вызова:

Bash

grpcurl -plaintext -d '{"name": "Admin"}' localhost:50051 cl_protobufs.lisp.grpc.integration_testing.Greeter/SayHello
3. Обнаруженные в системе типы (Internal Types)
Ниже перечислены основные структуры, используемые в SearchQuery:

LogicalNode
Используется для группировки условий.

op: 1 (AND), 2 (OR)

nodes: Список (repeated) объектов SearchQuery.

FilterNode
Конечный фильтр для базы данных.

field: Имя поля (title, author, series, etc.)

value: Значение для поиска.

operator: Тип сравнения (по умолчанию 1 = EQ).

4. Интроспекция (Как найти новые методы)
Если в будущем будут добавлены новые .proto файлы, список методов можно получить через grpcurl, если сервер поддерживает Reflection (или передав путь к файлу):

Bash

# Список сервисов
grpcurl -plaintext -import-path ./lisp-converter -proto ./lisp-converter/search.proto list

# Детальное описание метода
grpcurl -plaintext -import-path ./lisp-converter -proto ./lisp-converter/search.proto describe ebusta.library.v1.MessageConverter/Convert

--- END_FILE: ./doc/GRPC_API_REFERENCE.md ---

--- START_FILE: ./doc/parser.md ---
;;; ===========================================================================
;;; ЯДРО ПАРСЕРА MERCURY (DSL -> S-Expression)
;;; Реализация алгоритма Shunting-yard для UR 1.1 - UR 3.3
;;; ===========================================================================

;; 1. ЛЕКСЕР (TOKENIZER)
;; Разрезает строку на атомы. Правила регулярки:
;; - \"[^\"]+\"    : строки в кавычках (UR 2.1)
;; - [a-zA-Z0-9]+: : префиксы полей (например, author:)
;; - AND|OR|NOT    : логические операторы
;; - \(|\)         : скобки для группировки
;; - /             : маркер регулярных выражений (UR 2.2)
;; - \S+           : любые другие непробельные символы
(defun tokenize (str)
  (cl-ppcre:all-matches-as-strings "(\"[^\"]+\"|[a-zA-Z0-9_]+:|AND|OR|NOT|\\(|\\)|/|\\S+)" str))

;; 2. ТАБЛИЦА ПРИОРИТЕТОВ (PRECEDENCE)
;; Определяет порядок выполнения операций согласно UR 3.3.
;; Чем выше число, тем быстрее оператор "заберет" себе операнды.
(defun get-priority (op)
  (cond ((string-equal op "NOT") 3) ; Самый высокий приоритет
        ((string-equal op "AND") 2)
        ((string-equal op "OR") 1)  ; Самый низкий приоритет
        (t 0)))                     ; Не является оператором

;; 3. СБОРКА ДЕРЕВА ИЗ ПОСТФИКСНОЙ ЗАПИСИ (RPN BUILDER)
;; На вход идет список типа (A B AND). На выходе (:AND A B).
(defun build-tree-from-rpn (rpn)
  (let (stack)
    (dolist (token rpn (car stack)) ; В конце в стеке останется один корень дерева
      (if (and (listp token) (eq (car token) :field))
          (push token stack) ; Если это уже узел данных, просто кладем в стек
          (let ((op (string-upcase (string token))))
            (cond 
              ;; Унарный NOT: берет один аргумент из стека
              ((string= op "NOT") 
               (push `(:not ,(pop stack)) stack))
              ;; Бинарные AND/OR: берут два аргумента (правый и левый)
              ((member op '("AND" "OR") :test #'string=)
               (let* ((right (pop stack))
                      (left (pop stack))
                      (key (if (string= op "AND") :and :or)))
                 (push `(,key ,left ,right) stack)))))))))

;; 4. ОБРАБОТКА ПОЛЕЙ И ЗНАЧЕНИЙ (FIELD SCOPING)
;; Логика разделения "поле:значение". Учитывает UR 2.1 (жадность).
(defun process-field (token rest)
  (let* ((pos (position #\: token))
         (field (subseq token 0 pos))      ; Берем всё до двоеточия (author)
         (val-part (subseq token (1+ pos)))) ; Хвост сразу после двоеточия
    (if (string/= "" val-part)
        ;; Случай "field:value" (без пробела)
        (values (make-field-node field val-part) rest)
        ;; Случай "field: value1 value2" — собираем всё до ближайшего оператора
        (let (collected)
          (loop while (and (car rest) 
                           (zerop (get-priority (car rest))) 
                           (not (member (car rest) '("(" ")") :test #'string-equal)))
                do (push (pop rest) collected))
          (values (make-field-node field (format nil "~{~A~^ ~}" (nreverse collected))) 
                  rest)))))

;; 5. ШИНТИНГ-ЯРД (ГЛАВНЫЙ АЛГОРИТМ)
;; Превращает инфиксную запись (A AND B) в постфиксную (A B AND)
(defun parse-raw-to-sexp (str)
  (let ((token-list (tokenize str)) (output nil) (stack nil))
    (loop while token-list do
      (let ((token (pop token-list)))
        (cond 
          ;; Если это оператор (AND/OR/NOT)
          ((> (get-priority token) 0)
           ;; Выталкиваем из стека в выход те операторы, у которых приоритет выше или равен текущему
           (loop while (and stack (> (get-priority (car stack)) 0) 
                            (>= (get-priority (car stack)) (get-priority token)))
                 do (push (pop stack) output))
           (push token stack))
          
          ;; Скобки: управляем вложенностью
          ((string= token "(") (push token stack))
          ((string= token ")")
           ;; При закрывающей скобке выталкиваем всё до ближайшей открывающей
           (loop while (and stack (string/= (car stack) "(")) do (push (pop stack) output))
           (pop stack)) ; Удаляем саму "(" из стека
          
          ;; Поля: если в токене есть двоеточие — это начало Scope-фильтра
          ((find #\: token)
           (multiple-value-bind (node remaining) (process-field token token-list)
             (push node output) 
             (setf token-list remaining))) ; Обновляем список токенов после захвата значения
          
          ;; Обычные слова: трактуются как поиск по всем полям (UR 1.1)
          (t (push (make-field-node "any" token) output)))))
    
    ;; Выталкиваем остатки из стека в выход и строим финальное дерево
    (build-tree-from-rpn (nreverse (append output stack)))))

--- END_FILE: ./doc/parser.md ---

--- START_FILE: ./doc/requirements.md ---
# Спецификация требований системы "Eboost-Library" (v2.1)

## 1. Основание проекта (Project Foundation)

### 1.1. Описание проблемы
Владельцы больших личных коллекций электронных книг сталкиваются с проблемой "мертвого груза": книги хранятся локально, но доступ к ним извне (с телефона, в дороге, для друзей) ограничен. Существующие решения либо слишком тяжеловесны, либо привязаны к одному интерфейсу. 

### 1.2. Концепция (Scope)
Необходима система-посредник, которая абстрагирует хранилище и поиск через единый внутренний протокол, предоставляя доступ через разные каналы коммуникации (Telegram, IRC, CLI) с сохранением контекста пользователя.

---

## 2. Бизнес-требования (Business Requirements)

| ID | Наименование | Описание |
| :--- | :--- | :--- |
| **BR-1** | Мультиканальность | Единая точка входа через разные интерфейсы (TG, IRC, CLI). |
| **BR-2** | Скорость поиска | Time-to-Content не более 3 секунд. |
| **BR-3** | Изоляция логики | Добавление новых фронтов без изменения Core-компонентов. |
| **BR-4** | Управляемый доступ | Ограничение доступа только для доверенного круга лиц. |
| **BR-5** | Поддержка форматов | Обработка и выдача разных расширений (EPUB, PDF, FB2). |
| **BR-6** | Континуитет сессий | Сохранение состояния поиска и навигации (пагинации). |
| **BR-7** | Масштабируемость | Стабильная работа при объеме базы до 1 000 000 книг. |
| **BR-8** | Автономность | Работа с локальными файлами без внешних зависимостей. |

---

## 3. Требования заинтересованных сторон (Stakeholder Requirements)

### 3.1. Группа: Поиск и навигация
* **UR-1: Поиск по атрибутам.** Пользователь должен иметь возможность найти книгу по автору, названию или серии.
    * *Трассировка:* [BR-1, BR-7, BR-2]
* **UR-2: Просмотр результатов.** Пользователь должен иметь возможность листать страницы выдачи (пагинация) без повторного ввода запроса.
    * *Трассировка:* [BR-6]
* **UR-3: Уточнение формата.** При выборе книги система должна предлагать список доступных для неё форматов.
    * *Трассировка:* [BR-5]

### 3.2. Группа: Получение контента
* **UR-4: Прямая доставка (TG).** В Telegram файл должен приходить документом (до определенного лимита размера).
    * *Трассировка:* [BR-1, BR-8]
* **UR-5: Ссылочная доставка (IRC/CLI).** В текстовых интерфейсах пользователь должен получать временную ссылку на скачивание.
    * *Трассировка:* [BR-1, BR-8]

### 3.3. Группа: Доступ и интерфейс
* **UR-6: Прозрачная авторизация.** Доступ предоставляется автоматически на основе ID платформы (UID Telegram, Host IRC).
    * *Трассировка:* [BR-4]
* **UR-7: Унификация команд.** Командный синтаксис должен быть единообразным для всех адаптеров.
    * *Трассировка:* [BR-1, BR-3]

### 3.4. Группа: Администрирование
* **UR-8: Управление белыми списками.** Владелец должен иметь возможность оперативно менять список разрешенных ID.
    * *Трассировка:* [BR-4]

---

## 4. Глоссарий
* **UnifiedMessage** — внутренний формат структуры данных, в который преобразуются все входящие запросы.
* **Whitelist** — список идентификаторов пользователей, имеющих доступ к системе.
* **OpenSearch** — основной движок полнотекстового поиска.

--- END_FILE: ./doc/requirements.md ---

--- START_FILE: ./doc/DSL_METRICS_REQUIREMENTS.md ---
# DSL_METRICS_REQUIREMENTS.md

## 1. Цель
Обеспечить полную наблюдаемость (Observability) процесса парсинга DSL, выявить узкие места в производительности и отслеживать ошибки разбора в разрезе типов запросов.

## 2. Технический стек
* **Библиотека**: `prometheus.lisp` (cl-prometheus).
* **Экспозитор**: Встроенный HTTP-сервер на отдельном потоке (Hunchentoot).
* **Порт**: `50053` (эндпоинт `/metrics`).
* **Формат**: OpenMetrics / Prometheus text format.

## 3. Перечень метрик (SRE Golden Signals)

### 3.1. Трафик и Ошибки (Counters)
| Название метрики | Тип | Описание | Метки (Labels) |
| :--- | :--- | :--- | :--- |
| `dsl_requests_total` | Counter | Общее кол-во запросов | `status` (ok, error) |
| `dsl_errors_total` | Counter | Кол-во ошибок разбора | `error_type` (syntax, timeout, internal) |

### 3.2. Производительность (Histograms)
| Название метрики | Тип | Описание | Buckets |
| :--- | :--- | :--- | :--- |
| `dsl_parse_duration_seconds` | Histogram | Время обработки одного запроса | `.0001, .0005, .001, .002, .005, .01` |

### 3.3. Ресурсы (Gauges)
| Название метрики | Тип | Описание |
| :--- | :--- | :--- |
| `dsl_active_workers` | Gauge | Кол-во потоков, занятых парсингом в данный момент |
| `dsl_memory_usage_bytes` | Gauge | Текущий объем памяти, занятый Lisp-кучей (SBCL heap) |

## 4. Требования к реализации
1. **Thread Safety**: Изменение счетчиков метрик не должно приводить к блокировкам основного потока (использовать атомарные операции).
2. **Isolation**: Сбой в подсистеме метрик (например, зависание HTTP-порта) не должен влиять на работу gRPC.
3. **Efficiency**: Обновление метрик должно занимать менее **1%** от общего времени парсинга.



--- END_FILE: ./doc/DSL_METRICS_REQUIREMENTS.md ---

--- START_FILE: ./doc/architecture-IN.md ---
cat << 'EOF' > ebusta_arch_spec.md
# Техническая спецификация: Архитектура Ebusta (Orchestration Model)

**Дата:** 05.01.2026
**Статус:** Утверждено
**Модель взаимодействия:** Централизованная оркестрация (Orchestration)

## 1. Обзор архитектуры
Система строится на базе центрального компонента (**Orchestrator**), который координирует работу «тонких» адаптеров, парсера DSL и сервиса данных на удаленном хосте Mercury.

### Ключевые узлы:
1. **Adapters (The Door)**: SSH/BBS, Telegram, Web. Принимают ввод, передают его в Core, получают результат и рендерят его.
2. **Orchestrator (Core)**: Логический центр. Управляет жизненным циклом запроса.
3. **Parser**: Библиотека для конвертации строки в `libraryv1.SearchQuery`.
4. **Data Manager (Mercury Proxy)**: gRPC-сервис, транслирующий запросы в OpenSearch (Docker на Mercury).

## 2. Спецификация UnifiedMessage
`UnifiedMessage` является единым транспортным контейнером внутри системы.

```protobuf
message UnifiedMessage {
    string request_id = 1;
    
    // Метаданные источника для обратной маршрутизации
    message Context {
        string client_id = 1;
        enum SourceType {
            BBS = 0;
            TELEGRAM = 1;
            WEB = 2;
        }
        SourceType source = 2;
    }
    Context context = 2;

    // Полезная нагрузка (Payload)
    oneof content {
        libraryv1.SearchQuery query = 3;  // Структурированный запрос
        SearchResult result = 4;          // Результаты из OpenSearch
        string error = 5;                 // Описание ошибки
    }
}

--- END_FILE: ./doc/architecture-IN.md ---

--- START_FILE: ./doc/architecture.md ---
# Архитектура системы "Eboost-Library" (v2.0)

## 1. Описание проблемы
[cite_start]Владельцы больших личных коллекций электронных книг часто сталкиваются с проблемой "мертвого груза": книги хранятся локально, но доступ к ним извне (с телефона, в дороге, для друзей) ограничен или неудобен[cite: 1, 3]. Существующие решения либо слишком тяжеловесны, либо привязаны к одному интерфейсу. [cite_start]Необходима система, которая абстрагирует хранилище и поиск, предоставляя единый доступ через разные каналы коммуникации с сохранением контекста пользователя[cite: 3, 39].

## 2. Предметная область (DDD Contexts)
Согласно принципам Domain-Driven Design, система разделена на следующие ограниченные контексты:
* [cite_start]**Interaction (Взаимодействие):** Трансформация специфичных протоколов (Telegram, IRC, CLI) в единый бизнес-язык системы `UnifiedMessage`[cite: 4, 14].
* [cite_start]**Identity & Access (Доступ):** Идентификация пользователей, проверка прав по Bot Token или белым спискам[cite: 6].
* [cite_start]**Library Core (Ядро):** Оркестрация процессов разбора команд, навигации и формирования ответов[cite: 14, 15].
* [cite_start]**Catalog (Каталог):** Полнотекстовый поиск и управление метаданными книг в OpenSearch[cite: 19, 21].
* [cite_start]**Delivery (Доставка):** Извлечение файлов из хранилища и предоставление ссылок или бинарных данных[cite: 25, 27].

## 3. Компоненты системы

### Слой адаптеров (Front-end)
* [cite_start]**TelegramAdapter:** Реализует интерфейс бота, обрабатывает Webhook/Long Polling[cite: 4].
* [cite_start]**IrcAdapter:** Микросервис-клиент для подключения к IRC-серверам и каналам[cite: 6, 7].
* [cite_start]**CliAdapter:** Интерфейс командной строки (Linux CLI) для удаленного обращения к ядру[cite: 10, 11].
* [cite_start]**Translator (New):** Компонент внутри адаптеров или перед процессором, преобразующий `RawPayload` в `UnifiedMessage`[cite: 30].

### Слой управления и состояния
* **Auth-Manager (New):** Проверяет UserID на наличие в Allow-листах или внешних провайдерах (Keycloak).
* **Session-Manager (New):** Прокси к **Redis** для хранения состояния поиска и текущего положения пользователя в каталоге.
* [cite_start]**Config-Manager:** Централизованный сервис для хранения лимитов, шаблонов ответов и локализации[cite: 22, 23].

### Слой бизнес-логики (Core)
* [cite_start]**Processor:** Центральный сервис, выполняющий разбор команд (/book, /author) и координирующий другие службы[cite: 14, 15, 17].

### Слой данных и хранилища
* [cite_start]**Data-Manager:** Прокси-сервис для построения запросов к **OpenSearch**[cite: 19, 21].
* [cite_start]**Book-Fetcher:** Сервис выдачи файлов по ключу из локального или объектного хранилища[cite: 25, 26, 28].

## 4. Потоки данных

### Поиск книги
1.  [cite_start]**Адаптер** (TG/IRC/CLI) принимает ввод и через **Translator** создает `UnifiedMessage`[cite: 30].
2.  **Auth-Manager** подтверждает права пользователя.
3.  [cite_start]**Processor** запрашивает метаданные у **Data-Manager**[cite: 31].
4.  **Processor** сохраняет ID результатов в **Session-Manager** (Redis) для поддержки пагинации.
5.  [cite_start]Формируется ответ и возвращается пользователю через соответствующий адаптер[cite: 32, 33].

### Получение файла
1.  [cite_start]Пользователь выбирает книгу и формат[cite: 34].
2.  [cite_start]**Processor** запрашивает файл или ссылку у **Book-Fetcher**[cite: 35, 36].
3.  [cite_start]**Book-Fetcher** обращается к **Book Storage** и возвращает результат[cite: 37, 38].

## 5. Структура проекта (Go Layout)
```text
.
├── cmd/                # Точки входа (main.go) для каждого адаптера
├── internal/           # Приватный код приложения
│   ├── domain/         # Чистые структуры (Book, User, UnifiedMessage)
│   ├── processor/      # Ядро (бизнес-сценарии)
│   ├── auth/           # Проверка прав и доступ
│   ├── session/        # Интеграция с Redis
│   ├── translator/     # Логика маппинга сообщений
│   ├── storage/        # Клиенты OpenSearch (Data-Manager) и FS (Fetcher)
│   └── config/         # Config-Manager и загрузка .env/yaml
├── pkg/                # Публичные библиотеки
├── api/                # Протоколы обмена (gRPC/Proto или OpenAPI)
└── deployments/        # Docker-compose и манифесты

--- END_FILE: ./doc/architecture.md ---

--- START_FILE: ./doc/RUNBOOK_GRPC.md ---
# RUNBOOK: Инфраструктура gRPC и DSL Конвертера (Common Lisp)

Этот документ является основным техническим руководством по работе с Lisp-сервисами в проекте **EBusta**.

---

## 1. Архитектура и компоненты

Система построена на базе `cl-protobufs` и обертки над C++ gRPC core.

### Файловая структура
* `grpc/`: Подмодуль с Lisp-биндингами gRPC. Содержит `grpc.so` и макросы для определения серверов.
* `lisp-converter/search.proto`: Контракт Protobuf. Определяет сообщения `SearchQuery`, `LogicalNode` (AND/OR) и `FilterNode`.
* `lisp-converter/dsl-service.lisp`: Серверная логика. Содержит рекурсивный парсер S-выражений.
* `lisp-converter/dsl-client.lisp`: Тестовый клиент для верификации сложных запросов.

---

## 2. Спецификация DSL (S-Expressions)

Конвертер преобразует Lisp-синтаксис в строго типизированные Protobuf-объекты:

| DSL Пример | Тип Node | Protobuf структура |
| :--- | :--- | :--- |
| `(:field "title" "Lisp")` | **Filter** | `field: "title", value: "Lisp", op: 1` |
| `(:and ... ...)` | **Logical** | `op: 1 (AND), nodes: [...]` |
| `(:or ... ...)` | **Logical** | `op: 2 (OR), nodes: [...]` |

**Пример сложного запроса:**
`(:and (:field "title" "Lisp") (:or (:field "author" "Serge") (:field "author" "Reva")))`

---

## 3. Инструкции по запуску

### А. Уровень: Example (SayHello)
Проверка базовой связности (порт `50051`).

1.  **Сервер:** `bash ~/projects/ebusta/lisp-converter/run_example_server.sh`
2.  **Клиент (Lisp):** `bash ~/projects/ebusta/lisp-converter/run_example_client.sh`
3.  **Клиент (grpcurl):**
    ```bash
    ~/projects/ebusta/lisp-converter/grpcurl -plaintext \
        -import-path ~/projects/ebusta/lisp-converter/ \
        -proto ~/projects/ebusta/lisp-converter/helloworld.proto \
        -d '{"name": "Admin"}' localhost:50051 \
        cl_protobufs.lisp.grpc.integration_testing.Greeter/SayHello
    ```

### Б. Уровень: Production (DSL Converter)
Основной сервис трансляции (порт `50052`).

1.  **Сервер:** `bash ~/projects/ebusta/lisp-converter/run_dsl_server.sh`
2.  **Клиент (Lisp):** `bash ~/projects/ebusta/lisp-converter/run_dsl_client.sh`
3.  **Клиент (grpcurl):**
    ```bash
    ~/projects/ebusta/lisp-converter/grpcurl -plaintext \
        -import-path ~/projects/ebusta/lisp-converter/ \
        -proto ~/projects/ebusta/lisp-converter/search.proto \
        -d '{"raw_query": "(:and (:field \"title\" \"Lisp\") (:field \"author\" \"Serge\"))"}' \
        localhost:50052 ebusta.library.v1.MessageConverter/Convert
    ```

---

## 4. SRE: Диагностика и устранение неисправностей

### Порты и процессы
Если сервер не запускается (Address already in use):
* `fuser -k 50051/tcp` (для Example)
* `fuser -k 50052/tcp` (для DSL)

### Пути и зависимости (ASDF)
Серверы полагаются на `asdf:*central-registry*`. Если возникает ошибка `Failed to find TRUENAME`, проверьте, что в скриптах запуска указан верный путь к подмодулю `grpc`:
`~/projects/ebusta/grpc/`

### Пакеты и символы
Если при вызове метода возникает `TYPE-ERROR ... is not of type GRPC::METHOD-DETAILS`:
1.  Проверьте полное имя сервиса в логах сервера.
2.  Убедитесь, что `grpcurl` использует верный путь: `ebusta.library.v1.MessageConverter/Convert`.

### Использование grpcurl
Всегда указывайте `-import-path`, иначе `grpcurl` не сможет найти зависимости в `.proto` файлах при использовании абсолютных путей.

---

## 5. Обновление протоколов
При изменении `.proto` файлов необходимо:
1.  Перезапустить сервер (ASDF автоматически пересоберет `.lisp` файлы из `.proto`).
2.  Если добавились новые поля, обновить функцию `parse-dsl` в `dsl-service.lisp`.

--- END_FILE: ./doc/RUNBOOK_GRPC.md ---

--- START_FILE: ./doc/DSL_INPUT_OUTPUT_SPEC.md ---
# Спецификация входных и выходных данных DSL-парсера

## 1. Входные данные (Input)
Входом является текстовая строка поискового запроса в формате DSL. Поддерживаются:
* **Логические операторы**: `AND`, `OR`, `NOT` (регистрозависимые).
* **Группировка**: Круглые скобки `(...)`.
* **Поля (Scoped Search)**: `field:value` или `field:"multi word value"`.
* **Регулярные выражения**: `/pattern/`.
* **Полнотекстовый поиск**: Слова без указания поля (автоматически получают поле `any`).

**Пример сложного входа:**
`author:"Стивен Кинг" AND (title:Куджо OR tags:/horror/)`

---

## 2. Промежуточное представление (S-Expression)
Внутри ядра на Common Lisp строка преобразуется в дерево (S-expression). Это формат, используемый для отладки и внутренней логики трансляции.

**Результат трансформации:**
```lisp
(:AND 
  (:FIELD "author" "Стивен Кинг") 
  (:OR 
    (:FIELD "title" "Куджо") 
    (:FIELD "tags" "horror" :OP :REGEX)))
3. Выходные данные (gRPC / Protobuf)
Финальный выход сервиса — это бинарный объект Protobuf. Ниже представлено JSON-представление этого объекта, которое получает клиент.

Пример команды для получения выхода:
Bash

~/projects/ebusta/lisp-converter/grpcurl -plaintext \
    -import-path ~/projects/ebusta/lisp-converter \
    -proto ~/projects/ebusta/lisp-converter/search.proto \
    -d '{"raw_query": "author:\"Стивен Кинг\" AND (title:Куджо OR tags:/horror/)"}' \
    localhost:50052 ebusta.library.v1.MessageConverter/Convert
Структура ответа (JSON View):
JSON

{
  "requestId": "req-1737898956",
  "logical": {
    "op": "AND",
    "nodes": [
      {
        "filter": {
          "field": "author",
          "value": "Стивен Кинг",
          "operator": "EQUALS"
        }
      },
      {
        "logical": {
          "op": "OR",
          "nodes": [
            {
              "filter": {
                "field": "title",
                "value": "Куджо",
                "operator": "EQUALS"
              }
            },
            {
              "filter": {
                "field": "tags",
                "value": "horror",
                "operator": "REGEX"
              }
            }
          ]
        }
      }
    ]
  },
  "canonicalForm": "(:AND (:FIELD \"author\" \"Стивен Кинг\") (:OR (:FIELD \"title\" \"Куджо\") (:FIELD \"tags\" \"horror\" :OP :REGEX)))"
}
4. Заметки для SRE
request_id: Генерируется сервером для трассировки запроса через все компоненты системы.

canonical_form: Строковое представление нормализованного дерева. Идеально подходит для использования в качестве ключа кэширования (Redis/In-memory).

operator: Перечисление (Enum), которое жестко задает тип поиска (EQUALS, REGEX и т.д.), избавляя нижележащие сервисы от необходимости повторного анализа строки. EOF

--- END_FILE: ./doc/DSL_INPUT_OUTPUT_SPEC.md ---

--- START_FILE: ./doc/ARCHITECTURE.md ---
# Ebusta: Система поиска и доставки контента

## Архитектура системы (Pipeline)

Система построена на принципах микросервисной архитектуры с использованием gRPC для межсервисного взаимодействия. Весь путь сообщения от пользователя до данных разделен на изолированные этапы.

### Схема потока данных (Data Flow)
`User Input -> Adapter -> MessageConverter -> Processor -> Data-Manager`

---

## Компоненты системы

### 1. Adapters (Входные шлюзы)
**Пример:** `cmd/web-adapter`
- **Функция:** Прием сырых данных из внешних интерфейсов (HTTP, TG, IRC).
- **Ответственность:** Только транспортный уровень. Преобразует внешние запросы в gRPC-вызов `MessageConverter.Convert`.

### 2. MessageConverter (Семантический анализатор)
**Путь:** `cmd/message-converter`
- **Функция:** Парсинг и нормализация.
- **Задача:** Извлекает "Намерение" (Intent) и очищенные данные (Payload).
- **UnifiedMessage:** Объект, который гарантирует, что `Processor` получит стандартизированные данные независимо от источника.

### 3. Processor (Бизнес-логика / Оркестратор)
**Путь:** `cmd/processor`
- **Функция:** Маршрутизация и принятие решений.
- **Логика:**
    - Если `Intent == "search"`, запрашивает данные у `Data-Manager`.
    - Если `Intent == "download"`, инициирует процесс загрузки.

### 4. Data-Manager (Слой данных)
**Путь:** `cmd/data-manager`
- **Функция:** Интерфейс к поисковому движку (OpenSearch).
- **Задача:** Выполнение поисковых запросов и возврат списка объектов `Book`.

---

## Технологический стек
- **Язык:** Go (Golang)
- **Связь:** gRPC (Protocol Buffers v3)
- **Логирование:** Logrus
- **Сборка:** Makefile

## Порты и адреса (Service Map)
| Сервис            | Порт   | Протокол |
|-------------------|--------|----------|
| Data-Manager      | :50051 | gRPC     |
| MessageConverter  | :50052 | gRPC     |
| Processor         | :50053 | gRPC     |
| Web-Adapter       | :8080  | HTTP     |

## Управление проектом
- `make run` — Запуск всего пайплайна в фоне.
- `make stop` — Безопасная остановка всех сервисов (через fuser и pkill).
- `make proto` — Генерация кода из .proto файлов.

--- END_FILE: ./doc/ARCHITECTURE.md ---

--- START_FILE: ./doc/DSL_REQUIREMENTS.md ---
# Specification: Ebusta Search DSL (v1.1)

## 1. Goal
Предоставление человекочитаемого языка запросов для поиска книг, который транслируется в структурированное дерево (AST) для поискового движка Mercury.

## 2. Lexical Atoms (Лексика)
- **Action**: `get`, `find`, `list`, `read` (зарезервированы)
- **Field Prefixes**: `title:`, `author:`, `author_id:`, `desc:`
- **Logic Operators**: `AND`, `OR` (регистронезависимые)
- **Unary Operators**: `NOT`
- **Pattern**: `/regex/` (строка, обернутая в косую черту)
- **Literal**: `"exact phrase"`, `simple_word`, `101`

## 3. Функциональные требования

### UR 1: Базовый поиск
- **UR 1.1 (Default Search)**: Любой ввод без префикса (например, `Unix`) должен интерпретироваться как поиск по всем полям (`field: any`).
- **UR 1.2 (Case Insensitivity)**: Поиск по умолчанию нечувствителен к регистру.

### UR 2: Целевой поиск (Scoping)
- **UR 2.1 (Field Limiting)**: Использование префикса `field:` ограничивает поиск конкретным мета-полем.
- **UR 2.2 (Regex)**: Если значение обернуто в `/ /`, система должна использовать регулярные выражения (Operator: `OP_REGEX`).

### UR 3: Сложная логика (Boolean)
- **UR 3.1 (Combination)**: Поддержка операторов `AND` и `OR` для объединения условий.
- **UR 3.2 (Negation)**: Поддержка оператора `NOT` для исключения результатов из выдачи.
- **UR 3.3 (Precedence)**: Приоритет операторов: `NOT` > `AND` > `OR`.

### UR 4: Обратная связь (Feedback)
- **UR 4.1 (Explanation)**: Каждый ответ системы должен содержать поле `meta.canonical_form`, отображающее дерево разбора запроса для верификации пользователем.
- **UR 4.2 (Request Tracing)**: Каждому запросу присваивается `request_id`, который пробрасывается через всю цепочку (Adapter -> Converter -> Processor -> Mercury).

## 4. Примеры валидных запросов
- `author:Кинг AND NOT title:Куджо`
- `title:/^Unix.*/ OR desc:linux`
- `101` (трактуется как поиск ID или любой поиск по "101")

--- END_FILE: ./doc/DSL_REQUIREMENTS.md ---

--- START_FILE: ./doc/REQUIREMENTS.md ---
# Software Requirements Specification (SRS) - Ebusta Pipeline

Данный документ определяет технические требования к каждому компоненту конвейера обработки сообщений системы Ebusta.

---

## 1. Web-Adapter (The Gateway)
**Роль:** Транспортный шлюз для внешних HTTP-запросов.

* **SR-1.1 (Interface):** Должен обеспечивать эндпоинт `GET /input?msg=...` для приема сырых данных.
* **SR-1.2 (Sanity Check):** Должен возвращать `HTTP 400 Bad Request`, если параметр `msg` пуст или отсутствует.
* **SR-1.3 (Source Identification):** Обязан при вызове следующего звена передавать метку `source: "web"`.
* **SR-1.4 (Logic Isolation):** **Запрещено** выполнять парсинг текста, поиск подстрок или любую бизнес-логику.
* **SR-1.5 (Error Handling):** Должен транслировать gRPC-статусы ошибок в соответствующие HTTP-коды (например, `Unavailable` -> `503 Service Unavailable`).

---

## 2. MessageConverter (The Semantic Brain)
**Роль:** Семантический разбор и нормализация сообщения.

* **SR-2.1 (Normalization):** Должен выполнять очистку входной строки (удаление лишних пробелов в начале/конце).
* **SR-2.2 (Intent Recognition):** Должен определять тип намерения (`Intent`) на основе командных префиксов:
    * `get ` или `download ` -> `intent: "download"`
    * Остальное -> `intent: "search"`
* **SR-2.3 (Payload Extraction):** Должен возвращать в поле `Payload` только содержательную часть, очищенную от командных префиксов.
* **SR-2.4 (Stateless):** Должен быть полностью "без состояния" (stateless) — результат парсинга зависит только от входной строки.
* **SR-2.5 (Robustness):** Должен корректно обрабатывать пустые строки после удаления префиксов, возвращая ошибку или дефолтный интент.

---

## 3. Processor (The Orchestrator)
**Роль:** Центр принятия решений и маршрутизации.

* **SR-3.1 (Routing):** Обязан выполнять маршрутизацию запроса строго на основе поля `Intent` из `UnifiedMessage`.
* **SR-3.2 (Service Coordination):**
    * При `search`: Вызывает `Data-Manager.Search()`.
    * При `download`: (Будущее) Вызывает `Download-Manager`.
* **SR-3.3 (Data Aggregation):** Должен упаковывать ответы от нижестоящих сервисов в единую структуру `ActionResponse`.
* **SR-3.4 (Resilience):** Должен использовать механизмы `Context Timeout` (не более 5 секунд на запрос) при обращении к другим сервисам.
* **SR-3.5 (Enrichment):** Имеет право добавлять метаданные к ответу (например, время обработки или статус выполнения).

---

## 4. Data-Manager (The Storage Interface)
**Роль:** Изолированный слой доступа к данным.

* **SR-4.1 (Contract Compliance):** Должен принимать только структурированные объекты `SearchRequest`.
* **SR-4.2 (Zero Context):** **Запрещено** иметь информацию об источниках запроса (TG/Web) или командах пользователя.
* **SR-4.3 (Data Consistency):** Должен возвращать консистентный список объектов `Book`, даже если найден только один результат.
* **SR-4.4 (Performance):** Должен обеспечивать быстрый поиск по индексу; в случае мока — имитировать задержку сети.
* **SR-4.5 (Safety):** Должен ограничивать максимальное количество возвращаемых записей (не более 50 за один запрос) для защиты памяти системы.

---

## Общие системные требования (Cross-Cutting)
1. **Communication:** Все межсервисное взаимодействие осуществляется исключительно через gRPC.
2. **Observability:** Каждый сервис обязан логировать факт получения запроса и результат его обработки через `logrus`.
3. **Graceful Shutdown:** Все компоненты должны корректно завершать работу по сигналу `SIGTERM`, закрывая активные соединения.

## 5. UnifiedMessage (The Internal Protocol)
**Роль:** Единый стандарт данных внутри системы.

* **SR-5.1 (Neutrality):** Объект не должен содержать специфичных для мессенджеров полей (например, `chat_id` или `irc_channel`). Вся метаинформация должна быть нормализована.
* **SR-5.2 (Intent Categorization):** Поле `Intent` должно быть строго типизировано (строка или enum), определяющее дальнейший путь сообщения:
    * `search` — запрос на поиск информации.
    * `download` — запрос на получение файла.
    * `help` — запрос системной справки.
    * `meta` — запрос статистики или информации о сервисе.
* **SR-5.3 (Payload Integrity):** Поле `Payload` обязано содержать только очищенные данные, готовые для передачи в поисковой движок без дополнительной обработки.
* **SR-5.4 (Traceability):** (Будущее) Должен содержать `CorrelationID` для отслеживания пути конкретного запроса через логи всех микросервисов.
* **SR-5.5 (Context Enrichment):** Должен включать поле `Source` (откуда пришел запрос), чтобы `Processor` мог принимать решение о лимитах (например, для Web-клиентов лимиты жестче, чем для CLI).

--- END_FILE: ./doc/REQUIREMENTS.md ---

--- START_FILE: ./doc/components.md ---
Компонент,Роль,Описание,Входящие (In),Исходящие (Out)
Web-Adapter,API Gateway,"Точка входа. Принимает HTTP-запросы, генерирует Trace-ID и управляет цепочкой вызовов.",HTTP :8080 (/input?msg=...),"gRPC -> Message-Converter, gRPC -> Processor"
Message-Converter,DSL Parser,Превращает сырой текст в структурированное дерево (AST). Использует internal/parser.,gRPC :50052 (Convert),Нет
Processor,Orchestrator,"Ядро системы. Реализует логику AST Walker: получает дерево, запрашивает данные и фильтрует их.",gRPC :50053 (HandleCommand),gRPC -> Data-Manager (GetData)
Data-Manager,Data Provider,Хранилище. Загружает books.json и отдает сырой список книг для дальнейшей фильтрации.,gRPC :50051 (GetData),Файловая система (books.json)
CLI,UI Client,Интерактивная консоль пользователя с поддержкой истории команд (readline).,User Input,HTTP -> Web-Adapter
Client,Debug Tool,Утилита для прямой проверки доступности Data-Manager в обход шлюзов.,Manual Run,gRPC -> Data-Manager

--- END_FILE: ./doc/components.md ---
