=== EBusta Full Project Context: Tue Jan 27 06:34:51 PM MSK 2026 ===

--- SECTION: GIT DIFF (LAST 1 HOUR) ---
diff --git a/Makefile b/Makefile
index 77968f5..9d9ea2d 100644
--- a/Makefile
+++ b/Makefile
@@ -1,34 +1,65 @@
 LISP_DIR=$(shell pwd)/lisp-converter
-GRPC_DIR=$(shell pwd)/grpc
 GEN_DIR=grpc/gen/go
 
-.PHONY: build-bin start-all stop-all test-compliance proto restart-all
+# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ—Ä—Ç–æ–≤
+WEB_PORT=50080
+ORCH_PORT=50053
+DSL_PORT=50052
+DATA_PORT=50051
+
+.PHONY: build-all stop-all start-all restart-all test-compliance test-e2e proto
 
 proto:
 	@mkdir -p $(GEN_DIR)
 	protoc --proto_path=lisp-converter \
-		--go_out=$(GEN_DIR) --go_opt=paths=source_relative \
-		--go-grpc_out=$(GEN_DIR) --go-grpc_opt=paths=source_relative \
+		--go_out=$(GEN_DIR) \
+		--go_opt=Msearch.proto=ebusta/$(GEN_DIR) \
+		--go_opt=paths=source_relative \
+		--go-grpc_out=$(GEN_DIR) \
+		--go-grpc_opt=Msearch.proto=ebusta/$(GEN_DIR) \
+		--go-grpc_opt=paths=source_relative \
 		lisp-converter/search.proto
 	@go mod tidy
 
-build-bin:
-	@echo "Building DSL-Converter binary..."
-	sbcl --noinform \
-		--eval '(push (truename "$(LISP_DIR)/") asdf:*central-registry*)' \
+build-all: proto
+	@echo "Building DSL-Converter..."
+	sbcl --noinform --eval '(push (truename "$(LISP_DIR)/") asdf:*central-registry*)' \
 		--eval '(ql:quickload :ebusta-search :silent t)' \
 		--load "$(LISP_DIR)/dsl-service.lisp" \
-		--eval '(ebusta-service:build-binary)' \
-		--quit
+		--eval '(ebusta-service:build-binary)' --quit
+	@echo "Building Go Stack..."
+	go build -o datamanager ./cmd/datamanager
+	go build -o orchestrator ./cmd/orchestrator
+	go build -o web-adapter ./cmd/web-adapter
 
 stop-all:
-	-pkill -f dsl-converter || true
+	@-pkill -f dsl-converter || true
+	@-pkill -f orchestrator || true
+	@-pkill -f datamanager || true
+	@-pkill -f web-adapter || true
 
-start-all: stop-all
-	./dsl-converter > dsl.log 2>&1 &
+start-all:
+	@echo "Starting Full Stack..."
+	./datamanager -port $(DATA_PORT) >> data.log 2>&1 &
+	./dsl-converter >> dsl.log 2>&1 &
 	@sleep 2
+	./orchestrator -port $(ORCH_PORT) >> orch.log 2>&1 &
+	@sleep 1
+	./web-adapter -port $(WEB_PORT) >> web.log 2>&1 &
+	@sleep 1
+	@echo "--- Service Status ---"
+	@grep "===" data.log | tail -n 1 || echo "[DATAMANAGER] No banner"
+	@grep "===" dsl.log | tail -n 1 || echo "[DSL-CONVERTER] No banner"
+	@grep "===" orch.log | tail -n 1 || echo "[ORCHESTRATOR] No banner"
+	@grep "===" web.log | tail -n 1 || echo "[WEB-ADAPTER] No banner"
+	@echo "----------------------"
 
 test-compliance:
 	@go run tests/compliance_runner.go
 
-restart-all: stop-all build-bin start-all
+test-e2e:
+	@echo "=== Running E2E Test (HTTP :$(WEB_PORT)/input) ==="
+	@# –ü—Ä–æ—Å—Ç–æ –≤—ã–≤–æ–¥–∏–º –æ—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞ –±–µ–∑ jq
+	@curl -v -X POST --data-urlencode "msg=author:\"–°—Ç–∏–≤–µ–Ω –ö–∏–Ω–≥\"" http://localhost:$(WEB_PORT)/input
+
+restart-all: stop-all build-all start-all
diff --git a/cmd/datamanager/main.go b/cmd/datamanager/main.go
index 0673379..8813880 100644
--- a/cmd/datamanager/main.go
+++ b/cmd/datamanager/main.go
@@ -113,6 +113,7 @@ func (s *storageServer) SearchBooks(ctx context.Context, req *libraryv1.SearchRe
 }
 
 func main() {
+	log.Println("=== [DATAMANAGER] Starting on :50051 ===")
 	viper.SetConfigName("ebusta")
 	viper.SetConfigType("yaml")
 	viper.AddConfigPath(".")
diff --git a/cmd/orchestrator/main.go b/cmd/orchestrator/main.go
index a161fb6..a6f1eab 100644
--- a/cmd/orchestrator/main.go
+++ b/cmd/orchestrator/main.go
@@ -5,38 +5,65 @@ import (
 	"log"
 	"net"
 
-	"ebusta/api/proto/v1"
 	"google.golang.org/grpc"
 	"google.golang.org/grpc/credentials/insecure"
+
+	libraryv1 "ebusta/api/proto/v1"
+	dsl "ebusta/grpc/gen/go"
 )
 
 type orchestratorServer struct {
 	libraryv1.UnimplementedOrchestratorServiceServer
-	processorClient libraryv1.ProcessorServiceClient
+	dslClient dsl.MessageConverterClient
 }
 
 func (s *orchestratorServer) Search(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
 	log.Printf("üéº Orchestrator received: %s", req.Query)
-	return s.processorClient.Process(ctx, req)
+	
+	// 1. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ Lisp DSL —Å–µ—Ä–≤–∏—Å
+	log.Printf("üéº Orchestrator -> DSL (Convert)...")
+	dslResp, err := s.dslClient.Convert(ctx, &dsl.ConvertRequest{
+		RawQuery: req.Query,
+	})
+	
+	if err != nil {
+		log.Printf("‚ùå DSL Error: %v", err)
+		// –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É –∫–ª–∏–µ–Ω—Ç—É, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø—Ä–æ–±–ª–µ–º—É
+		return nil, err
+	}
+
+	log.Printf("‚úÖ DSL Parsed: Canonical=%s, ID=%s", dslResp.CanonicalForm, dslResp.RequestId)
+
+	// 2. –ó–¥–µ—Å—å –≤ –±—É–¥—É—â–µ–º –±—É–¥–µ—Ç –≤—ã–∑–æ–≤ DataManager
+	// –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ", –Ω–æ —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º, —á—Ç–æ –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ—à–µ–ª
+	return &libraryv1.SearchResponse{
+		Books: []*libraryv1.Book{},
+		Total: 0,
+		Status: "ok",
+	}, nil
 }
 
 func main() {
-	// Orchestrator -> Processor
-	conn, err := grpc.Dial("localhost:50053", grpc.WithTransportCredentials(insecure.NewCredentials()))
+	log.Println("=== [ORCHESTRATOR] Starting on :50053 ===")
+
+	// –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Lisp DSL (50052)
+	conn, err := grpc.Dial("localhost:50052", grpc.WithTransportCredentials(insecure.NewCredentials()))
 	if err != nil {
-		log.Fatalf("failed to connect to processor: %v", err)
+		log.Fatalf("failed to connect to dsl: %v", err)
 	}
-
-	lis, err := net.Listen("tcp", ":50054")
+	
+	lis, err := net.Listen("tcp", ":50053")
 	if err != nil {
 		log.Fatalf("failed to listen: %v", err)
 	}
 
 	s := grpc.NewServer()
 	libraryv1.RegisterOrchestratorServiceServer(s, &orchestratorServer{
-		processorClient: libraryv1.NewProcessorServiceClient(conn),
+		dslClient: dsl.NewMessageConverterClient(conn),
 	})
 
-	log.Println("üéº Orchestrator started on :50054")
-	s.Serve(lis)
+	log.Println("üéº Orchestrator service registered")
+	if err := s.Serve(lis); err != nil {
+		log.Fatalf("failed to serve: %v", err)
+	}
 }
diff --git a/cmd/web-adapter/main.go b/cmd/web-adapter/main.go
index b946108..a96d484 100644
--- a/cmd/web-adapter/main.go
+++ b/cmd/web-adapter/main.go
@@ -5,8 +5,6 @@ import (
 	"fmt"
 	"log"
 	"net/http"
-	"os"
-	"strings"
 	"time"
 
 	"ebusta/api/proto/v1"
@@ -15,11 +13,8 @@ import (
 )
 
 func main() {
-	// 1. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Orchestrator (–ø–æ—Ä—Ç 50054)
-	orchHost := os.Getenv("ORCHESTRATOR_HOST")
-	if orchHost == "" {
-		orchHost = "localhost:50054"
-	}
+	log.Println("=== [WEB-ADAPTER] Starting on :50080 ===")
+	orchHost := "localhost:50053"
 
 	conn, err := grpc.Dial(orchHost, grpc.WithTransportCredentials(insecure.NewCredentials()))
 	if err != nil {
@@ -27,15 +22,14 @@ func main() {
 	}
 	defer conn.Close()
 
-	// –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 1: –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–º—è –∫–ª–∏–µ–Ω—Ç–∞ (OrchestratorServiceClient)
 	client := libraryv1.NewOrchestratorServiceClient(conn)
 
 	http.HandleFunc("/input", func(w http.ResponseWriter, r *http.Request) {
-		query := r.URL.Query().Get("msg")
+		query := r.FormValue("msg")
 		if query == "" {
-			query = r.URL.Query().Get("q")
+			query = r.FormValue("q")
 		}
-		
+
 		if query == "" {
 			http.Error(w, "Please provide 'msg' parameter", http.StatusBadRequest)
 			return
@@ -46,7 +40,6 @@ func main() {
 		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
 		defer cancel()
 
-		// –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 2: –ò—Å–ø–æ–ª—å–∑—É–µ–º SearchRequest –∏ –º–µ—Ç–æ–¥ Search
 		resp, err := client.Search(ctx, &libraryv1.SearchRequest{
 			Query: query,
 		})
@@ -56,29 +49,20 @@ func main() {
 			return
 		}
 
-		// –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
 		w.Header().Set("Content-Type", "text/plain; charset=utf-8")
-		
 		if len(resp.Books) == 0 {
 			fmt.Fprintf(w, "No books found for: %s\n", query)
 			return
 		}
 
 		fmt.Fprintf(w, "Found %d books:\n", len(resp.Books))
-		fmt.Fprintln(w, strings.Repeat("-", 40))
 		for _, b := range resp.Books {
-			authors := strings.Join(b.Authors, ", ")
-			fmt.Fprintf(w, "[%s] %s ‚Äî %s\n", b.Id, b.Title, authors)
+			fmt.Fprintf(w, "[%s] %s\n", b.Id, b.Title)
 		}
 	})
 
-	port := os.Getenv("PORT")
-	if port == "" {
-		port = "8080"
-	}
-
-	log.Printf("üåç Web Adapter started on :%s", port)
-	if err := http.ListenAndServe(":"+port, nil); err != nil {
+	log.Printf("üåç Web Adapter started on :50080")
+	if err := http.ListenAndServe(":50080", nil); err != nil {
 		log.Fatalf("failed to serve: %v", err)
 	}
 }
diff --git a/doc/DSL_REQUIREMENTS.md b/doc/DSL_REQUIREMENTS.md
index 8b47ce9..53152e1 100644
--- a/doc/DSL_REQUIREMENTS.md
+++ b/doc/DSL_REQUIREMENTS.md
@@ -5,7 +5,7 @@
 
 ## 2. Lexical Atoms (–õ–µ–∫—Å–∏–∫–∞)
 - **Action**: `get`, `find`, `list`, `read` (–∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω—ã)
-- **Field Prefixes**: `title:`, `author:`, `author_id:`, `desc:`
+- **Field Prefixes**: `title:`, `author:`, `author_id:`, `desc:`, `id:`,`containder:`,`filename:`
 - **Logic Operators**: `AND`, `OR` (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ)
 - **Unary Operators**: `NOT`
 - **Pattern**: `/regex/` (—Å—Ç—Ä–æ–∫–∞, –æ–±–µ—Ä–Ω—É—Ç–∞—è –≤ –∫–æ—Å—É—é —á–µ—Ä—Ç—É)
diff --git a/grpc b/grpc
--- a/grpc
+++ b/grpc
@@ -1 +1 @@
-Subproject commit 6c11552be627f182a70e09bb0fb43f13d1b6ec84
+Subproject commit 6c11552be627f182a70e09bb0fb43f13d1b6ec84-dirty
diff --git a/lisp-converter/ebusta-search.asd b/lisp-converter/ebusta-search.asd
index 53af474..5596245 100644
--- a/lisp-converter/ebusta-search.asd
+++ b/lisp-converter/ebusta-search.asd
@@ -1,4 +1,4 @@
 (defsystem "ebusta-search"
   :defsystem-depends-on (:cl-protobufs.asdf)
-  :depends-on (:cl-protobufs :grpc)
+  :depends-on (:cl-protobufs :grpc :esrap)
   :components ((:protobuf-source-file "search")))
diff --git a/lisp-converter/parser.lisp b/lisp-converter/parser.lisp
index 26ebb31..1bdc443 100644
--- a/lisp-converter/parser.lisp
+++ b/lisp-converter/parser.lisp
@@ -1,29 +1,69 @@
-(defpackage :ebusta.parser
-  (:use :cl)
-  (:export :to-pb))
-
-(in-package :ebusta.parser)
-
-(defun to-pb (dsl)
-  (let ((query (make-instance 'cl-protobufs.libraryv1:search-query)))
-    (cond 
-      ;; –ï—Å–ª–∏ —ç—Ç–æ AND/OR
-      ((member (car dsl) '(:and :or))
-       (let ((l-node (make-instance 'cl-protobufs.libraryv1:logical-node
-                                    :op (if (eq (car dsl) :and) 1 2))))
-         (dolist (sub (cdr dsl))
-           (let ((f-node (make-instance 'cl-protobufs.libraryv1:filter-node
-                                        :field (getf sub :field)
-                                        :value (getf sub :val)
-                                        :operator 1)))
-             (push f-node (cl-protobufs.libraryv1:logical-node.nodes l-node))))
-         (setf (cl-protobufs.libraryv1:search-query.logical query) l-node)))
-      
-      ;; –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –ø–æ–ª–µ
-      ((eq (car dsl) :field)
-       (setf (cl-protobufs.libraryv1:search-query.filter query)
-             (make-instance 'cl-protobufs.libraryv1:filter-node
-                            :field (getf dsl :field)
-                            :value (getf dsl :val)
-                            :operator 1))))
-    query))
+(defpackage #:ebusta-parser
+  (:use #:cl #:esrap)
+  (:export #:parse-query))
+
+(in-package #:ebusta-parser)
+
+;; --- –¢–æ–∫–µ–Ω—ã ---
+
+(defrule whitespace (+ (or #\space #\tab #\newline))
+  (:constant nil))
+
+(defrule colon #\:
+  (:constant nil))
+
+;; –°–ª–æ–≤–æ: –ª—é–±—ã–µ —Å–∏–º–≤–æ–ª—ã, –∫—Ä–æ–º–µ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
+(defrule word (+ (not (or #\space #\tab #\newline #\: #\( #\) #\" #\& #\|)))
+  (:text t))
+
+(defrule quoted-string (and #\" (* (not #\")) #\")
+  (:destructure (q1 text q2)
+    (declare (ignore q1 q2))
+    (text text)))
+
+(defrule value (or quoted-string word))
+(defrule key word)
+
+;; --- –í—ã—Ä–∞–∂–µ–Ω–∏—è ---
+
+;; –ü–æ–ª–µ: author:King -> (:field "author" "King")
+(defrule field-expression (and key colon value)
+  (:destructure (k c v)
+    (declare (ignore c))
+    (list :field k v)))
+
+;; –û–ø–µ—Ä–∞—Ç–æ—Ä—ã (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ)
+(defrule op-and (and (? whitespace) (or "AND" "and" "&") (? whitespace))
+  (:constant :and))
+
+(defrule op-or (and (? whitespace) (or "OR" "or" "|") (? whitespace))
+  (:constant :or))
+
+;; –†–µ–∫—É—Ä—Å–∏—è
+(defrule paren-expression (and (? whitespace) #\( expression #\) (? whitespace))
+  (:destructure (w1 p1 e p2 w2)
+    (declare (ignore w1 p1 p2 w2))
+    e))
+
+(defrule term (or paren-expression field-expression))
+
+;; AND (–≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
+(defrule and-expression (and term (* (and op-and term)))
+  (:destructure (head tail)
+    (if (null tail)
+        head
+        (cons :and (cons head (mapcar #'second tail))))))
+
+;; OR (–Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
+(defrule or-expression (and and-expression (* (and op-or and-expression)))
+  (:destructure (head tail)
+    (if (null tail)
+        head
+        (cons :or (cons head (mapcar #'second tail))))))
+
+;; –ö–æ—Ä–Ω–µ–≤–æ–µ –ø—Ä–∞–≤–∏–ª–æ
+(defrule expression or-expression)
+
+(defun parse-query (input)
+  "–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É –∑–∞–ø—Ä–æ—Å–∞ –≤ DSL S-–≤—ã—Ä–∞–∂–µ–Ω–∏–µ"
+  (parse 'expression input))
diff --git a/lisp-converter/run_dsl_server.sh b/lisp-converter/run_dsl_server.sh
index d573262..2d3a964 100755
--- a/lisp-converter/run_dsl_server.sh
+++ b/lisp-converter/run_dsl_server.sh
@@ -1,15 +1,17 @@
 #!/bin/bash
-export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/projects/ebusta/grpc
+GRPC_PATH="$HOME/projects/ebusta/grpc"
+export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$GRPC_PATH
 
-# –û—á–∏—â–∞–µ–º –ø–æ—Ä—Ç
+# –£–±–∏–≤–∞–µ–º —Å—Ç–∞—Ä—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã
 fuser -k 50052/tcp >/dev/null 2>&1 || true
 
-echo "üöÄ –ó–∞–ø—É—Å–∫–∞—é EBusta DSL Server (Fix Runtime Options)..."
+echo "üöÄ –ó–∞–ø—É—Å–∫–∞—é EBusta DSL Server (Parser + Converter)..."
 
-# –ü–†–ê–í–ò–õ–û: –†–∞–Ω—Ç–∞–π–º-–æ–ø—Ü–∏–∏ (–ø–∞–º—è—Ç—å) –î–û –æ–ø—Ü–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (eval)
-sbcl --dynamic-space-size 1024 --noinform --non-interactive \
-     --eval "(push (truename \"~/projects/ebusta/grpc/\") asdf:*central-registry*)" \
-     --eval "(push (truename \"~/projects/ebusta/lisp-converter/\") asdf:*central-registry*)" \
-     --eval "(ql:quickload '(:cl-ppcre :ebusta-search) :silent t)" \
-     --load "$HOME/projects/ebusta/lisp-converter/dsl-service.lisp" \
-     --eval "(ebusta-service:start :port 50052)"
+sbcl --noinform \
+     --eval "(push (truename \"$GRPC_PATH/\") asdf:*central-registry*)" \
+     --eval '(push (truename "~/projects/ebusta/lisp-converter/") asdf:*central-registry*)' \
+     --eval '(ql:quickload :esrap :silent t)' \
+     --eval '(ql:quickload :cl-protobufs :silent t)' \
+     --eval '(ql:quickload :grpc :silent t)' \
+     --eval '(ql:quickload :ebusta-search :silent t)' \
+     --load "$HOME/projects/ebusta/lisp-converter/dsl-service.lisp"
diff --git a/lisp-converter/search.proto b/lisp-converter/search.proto
index 234c89c..f13677b 100644
--- a/lisp-converter/search.proto
+++ b/lisp-converter/search.proto
@@ -1,6 +1,7 @@
 syntax = "proto3";
 
 package ebusta.library.v1;
+option go_package = "ebusta/grpc/gen/go;dsl";
 
 message FilterNode {
   string field = 1;
@@ -9,7 +10,7 @@ message FilterNode {
 }
 
 message LogicalNode {
-  int32 op = 1; 
+  int32 op = 1;
   repeated SearchQuery nodes = 2;
 }
 
@@ -19,7 +20,7 @@ message SearchQuery {
     LogicalNode logical = 2;
   }
   string canonical_form = 3;
-  string request_id = 4; // UR 4.2
+  string request_id = 4;
 }
 
 message ConvertRequest {
diff --git a/lisp-converter/server.lisp b/lisp-converter/server.lisp
index 55d1313..44274d7 100644
--- a/lisp-converter/server.lisp
+++ b/lisp-converter/server.lisp
@@ -1,56 +1,44 @@
 (ql:quickload '(:cl-protobufs :grpc) :silent t)
 
-;; 1. –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
-(load "/home/serge/projects/ebusta/lisp-converter/search.lisp")
-
+;; –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—à –ø–∞–∫–µ—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É Lisp (CL)
 (defpackage :ebusta.service
   (:use :cl)
   (:local-nicknames (#:pb #:cl-protobufs.ebusta.library.v1)
+                    (#:pb-rpc #:cl-protobufs.ebusta.library.v1-rpc)
                     (#:grpc #:grpc)))
 
+;; –í—Ö–æ–¥–∏–º –≤ –Ω–µ–≥–æ. –¢–£–¢ –ï–°–¢–¨ LISP.
 (in-package :ebusta.service)
 
-;; --- –õ–æ–≥–∏–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ ---
+;; --- –õ–æ–≥–∏–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (S-expressions -> Protobuf) ---
 (defun dsl-to-pb (dsl)
-  (let ((query (make-instance 'pb:search-query)))
+  (let ((query (pb:make-search-query)))
     (cond
+      ;; –û–±—Ä–∞–±–æ—Ç–∫–∞ AND / OR
       ((member (car dsl) '(:and :or))
-       (let ((l-node (make-instance 'pb:logical-node)))
+       (let ((l-node (pb:make-logical-node)))
          (setf (pb:logical-node.op l-node) (if (eq (car dsl) :and) 1 2))
          (dolist (sub (cdr dsl))
            (push (dsl-to-pb sub) (pb:logical-node.nodes l-node)))
          (setf (pb:search-query.logical query) l-node)))
+      
+      ;; –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª–µ–π (:field "name" "val")
       ((eq (car dsl) :field)
-       (let ((f-node (make-instance 'pb:filter-node)))
-         (setf (pb:filter-node.field f-node) (getf dsl :field)
-               (pb:filter-node.value f-node) (getf dsl :val)
-               (pb:filter-node.operator f-node) 1)
+       (let ((f-node (pb:make-filter-node)))
+         (setf (pb:filter-node.field f-node) (second dsl)
+               (pb:filter-node.value f-node) (third dsl)
+               (pb:filter-node.operator 1)) ;; 1 = EQUALS
          (setf (pb:search-query.filter query) f-node))))
     query))
 
-;; --- –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç–æ–¥–∞ —Å–µ—Ä–≤–µ—Ä–∞ ---
-;; –ú—ã –¥–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–æ–¥ –∫ –æ–±–æ–±—â–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—É—é —Å–æ–∑–¥–∞–ª cl-protobufs.
-;; –ò–º—è –ø–∞–∫–µ—Ç–∞ RPC —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: <package-name>-rpc
-(in-package :cl-protobufs.ebusta.library.v1-rpc)
-
-(defmethod convert ((request cl-protobufs.ebusta.library.v1:convert-request) rpc)
+;; --- –†–µ–∞–ª–∏–∑–∞—Ü–∏—è gRPC –º–µ—Ç–æ–¥–∞ ---
+;; –ú—ã –Ω–∞—Ö–æ–¥–∏–º—Å—è –≤ ebusta.service, –Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–æ–¥ –¥–ª—è –ß–£–ñ–û–ì–û –ø–∞–∫–µ—Ç–∞ pb-rpc.
+;; –≠—Ç–æ –ª–µ–≥–∞–ª—å–Ω–æ –∏ –∏–º–µ–Ω–Ω–æ —Ç–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–ª–æ.
+(defmethod pb-rpc:convert ((request pb:convert-request) rpc)
   (declare (ignore rpc))
-  (format t "Request received: ~S~%" request)
-  (let* ((raw (cl-protobufs.ebusta.library.v1:convert-request.raw-query request))
+  (let* ((raw (pb:convert-request.raw-query request))
+         ;; –ß–∏—Ç–∞–µ–º —Å—Ç—Ä–æ–∫—É –∫–∞–∫ Lisp-–∫–æ–¥ (–¥–ª—è —Ç–µ—Å—Ç–∞ (:and ...))
          (dsl (read-from-string raw)))
+    (format t "Request received: ~S~%" raw)
     (format t "Parsed DSL: ~S~%" dsl)
-    (ebusta.service::dsl-to-pb dsl)))
-
-(in-package :ebusta.service)
-
-;; --- –ó–∞–ø—É—Å–∫ ---
-(defun start-service ()
-  (grpc:init-grpc)
-  (format t "=== EBusta Lisp Service starting on port 50052 ===~%")
-  ;; qitab/grpc —É–º–µ–µ—Ç —Å–∞–º –Ω–∞—Ö–æ–¥–∏—Ç—å –º–µ—Ç–æ–¥—ã –ø–æ –∏–º–µ–Ω–∏ —Å–µ—Ä–≤–∏—Å–∞
-  (grpc:run-grpc-proto-server 
-   "0.0.0.0:50052" 
-   'pb:message-converter
-   :num-threads 2))
-
-(start-service)
+    (dsl-to-pb dsl)))
diff --git a/send_full_context.sh b/send_full_context.sh
index 236214e..669e269 100755
--- a/send_full_context.sh
+++ b/send_full_context.sh
@@ -5,7 +5,7 @@ TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
 OUTPUT_FILE="ebusta_full_context_${TIMESTAMP}.txt"
 REMOTE_DEST="reva@mars:/home/reva/to_chat"
 
-echo "üìÇ –°–æ–±–∏—Ä–∞—é –ü–û–õ–ù–´–ô –∫–æ–Ω—Ç–µ–∫—Å—Ç (Go + Lisp + C++ + Proto) –≤ $OUTPUT_FILE..."
+echo "üìÇ –°–æ–±–∏—Ä–∞—é –ü–û–õ–ù–´–ô –∫–æ–Ω—Ç–µ–∫—Å—Ç (Go + Lisp + Proto), –∏—Å–∫–ª—é—á–∞—è –º—É—Å–æ—Ä..."
 
 # –û—á–∏—â–∞–µ–º —Ñ–∞–π–ª –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º
 echo "=== EBusta Full Project Context: $(date) ===" > "$OUTPUT_FILE"
@@ -21,7 +21,11 @@ fi
 echo "--- END SECTION: GIT DIFF ---" >> "$OUTPUT_FILE"
 
 # 2. –°–æ–±–∏—Ä–∞–µ–º –∏—Å—Ö–æ–¥–Ω–∏–∫–∏
-# –û–±—ä–µ–¥–∏–Ω–µ–Ω—ã —Ñ–∏–ª—å—Ç—Ä—ã –∏–∑ ebusta (go, yaml, json...) –∏ grpc (lisp, cc, asd...)
+# –ò—Å–∫–ª—é—á–∞–µ–º:
+# - ./bin (–±–∏–Ω–∞—Ä–Ω–∏–∫–∏)
+# - ./old (—Å—Ç–∞—Ä—ã–π –∫–æ–¥)
+# - ./grpc (—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥, –æ–Ω –æ—á–µ–Ω—å –æ–±—ä–µ–º–Ω—ã–π)
+# - .git, –ª–æ–≥–∏ –∏ –ø—Ä–æ—á–∏–π —à—É–º
 find . -type f \
     \( -name "*.go" \
        -o -name "*.yaml" \
@@ -37,6 +41,8 @@ find . -type f \
     -not -path "./bin/*" \
     -not -path "*/data/*" \
     -not -path "./.git/*" \
+    -not -path "*/old/*" \
+    -not -path "./grpc/*" \
     -not -path "*/uploader.log" \
     -not -path "*.log" \
     -not -path "*_context_*.txt" | while read -r file; do
--- END SECTION: GIT DIFF ---

--- START_FILE: ./quicklisp.lisp ---
;;;;
;;;; This is quicklisp.lisp, the quickstart file for Quicklisp. To use
;;;; it, start Lisp, then (load "quicklisp.lisp")
;;;;
;;;; Quicklisp is beta software and comes with no warranty of any kind.
;;;;
;;;; For more information about the Quicklisp beta, see:
;;;;
;;;;    http://www.quicklisp.org/beta/
;;;;
;;;; If you have any questions or comments about Quicklisp, please
;;;; contact:
;;;;
;;;;    Zach Beane <zach@quicklisp.org>
;;;;

(cl:in-package #:cl-user)
(cl:defpackage #:qlqs-user
  (:use #:cl))
(cl:in-package #:qlqs-user)

(defpackage #:qlqs-info
  (:export #:*version*))

(defvar qlqs-info:*version* "2015-01-28")

(defpackage #:qlqs-impl
  (:use #:cl)
  (:export #:*implementation*)
  (:export #:definterface
           #:defimplementation)
  (:export #:lisp
           #:abcl
           #:allegro
           #:ccl
           #:clasp
           #:clisp
           #:cmucl
           #:cormanlisp
           #:ecl
           #:gcl
           #:lispworks
	   #:mkcl
           #:scl
           #:sbcl))

(defpackage #:qlqs-impl-util
  (:use #:cl #:qlqs-impl)
  (:export #:call-with-quiet-compilation))

(defpackage #:qlqs-network
  (:use #:cl #:qlqs-impl)
  (:export #:open-connection
           #:write-octets
           #:read-octets
           #:close-connection
           #:with-connection))

(defpackage #:qlqs-progress
  (:use #:cl)
  (:export #:make-progress-bar
           #:start-display
           #:update-progress
           #:finish-display))

(defpackage #:qlqs-http
  (:use #:cl #:qlqs-network #:qlqs-progress)
  (:export #:fetch
           #:*proxy-url*
           #:*maximum-redirects*
           #:*default-url-defaults*))

(defpackage #:qlqs-minitar
  (:use #:cl)
  (:export #:unpack-tarball))

(defpackage #:quicklisp-quickstart
  (:use #:cl #:qlqs-impl #:qlqs-impl-util #:qlqs-http #:qlqs-minitar)
  (:export #:install
           #:help
           #:*proxy-url*
           #:*asdf-url*
           #:*quicklisp-tar-url*
           #:*setup-url*
           #:*help-message*
           #:*after-load-message*
           #:*after-initial-setup-message*))


;;;
;;; Defining implementation-specific packages and functionality
;;;

(in-package #:qlqs-impl)

(eval-when (:compile-toplevel :load-toplevel :execute)
  (defun error-unimplemented (&rest args)
    (declare (ignore args))
    (error "Not implemented")))

(defmacro neuter-package (name)
  `(eval-when (:compile-toplevel :load-toplevel :execute)
     (let ((definition (fdefinition 'error-unimplemented)))
       (do-external-symbols (symbol ,(string name))
         (unless (fboundp symbol)
           (setf (fdefinition symbol) definition))))))

(eval-when (:compile-toplevel :load-toplevel :execute)
  (defun feature-expression-passes-p (expression)
    (cond ((keywordp expression)
           (member expression *features*))
          ((consp expression)
           (case (first expression)
             (or
              (some 'feature-expression-passes-p (rest expression)))
             (and
              (every 'feature-expression-passes-p (rest expression)))))
          (t (error "Unrecognized feature expression -- ~S" expression)))))


(defmacro define-implementation-package (feature package-name &rest options)
  (let* ((output-options '((:use)
                           (:export #:lisp)))
         (prep (cdr (assoc :prep options)))
         (class-option (cdr (assoc :class options)))
         (class (first class-option))
         (superclasses (rest class-option))
         (import-options '())
         (effectivep (feature-expression-passes-p feature)))
    (dolist (option options)
      (ecase (first option)
        ((:prep :class))
        ((:import-from
          :import)
         (push option import-options))
        ((:export
          :shadow
          :intern
          :documentation)
         (push option output-options))
        ((:reexport-from)
         (push (cons :export (cddr option)) output-options)
         (push (cons :import-from (cdr option)) import-options))))
    `(eval-when (:compile-toplevel :load-toplevel :execute)
       ,@(when effectivep
               prep)
       (defclass ,class ,superclasses ())
       (defpackage ,package-name ,@output-options
                   ,@(when effectivep
                           import-options))
       ,@(when effectivep
               `((setf *implementation* (make-instance ',class))))
       ,@(unless effectivep
                 `((neuter-package ,package-name))))))

(defmacro definterface (name lambda-list &body options)
  (let* ((forbidden (intersection lambda-list lambda-list-keywords))
         (gf-options (remove :implementation options :key #'first))
         (implementations (set-difference options gf-options)))
    (when forbidden
      (error "~S not allowed in definterface lambda list" forbidden))
    (flet ((method-option (class body)
             `(:method ((*implementation* ,class) ,@lambda-list)
                ,@body)))
      (let ((generic-name (intern (format nil "%~A" name))))
        `(eval-when (:compile-toplevel :load-toplevel :execute)
           (defgeneric ,generic-name (lisp ,@lambda-list)
             ,@gf-options
             ,@(mapcar (lambda (implementation)
                         (destructuring-bind (class &rest body)
                             (rest implementation)
                           (method-option class body)))
                       implementations))
           (defun ,name ,lambda-list
             (,generic-name *implementation* ,@lambda-list)))))))

(defmacro defimplementation (name-and-options
                             lambda-list &body body)
  (destructuring-bind (name &key (for t) qualifier)
      (if (consp name-and-options)
          name-and-options
          (list name-and-options))
    (unless for
      (error "You must specify an implementation name."))
    (let ((generic-name (find-symbol (format nil "%~A" name))))
      (unless (and generic-name
                   (fboundp generic-name))
        (error "~S does not name an implementation function" name))
      `(defmethod ,generic-name
           ,@(when qualifier (list qualifier))
         ,(list* `(*implementation* ,for) lambda-list) ,@body))))


;;; Bootstrap implementations

(defvar *implementation* nil)
(defclass lisp () ())


;;; Allegro Common Lisp

(define-implementation-package :allegro #:qlqs-allegro
  (:documentation
   "Allegro Common Lisp - http://www.franz.com/products/allegrocl/")
  (:class allegro)
  (:reexport-from #:socket
                  #:make-socket)
  (:reexport-from #:excl
                  #:read-vector))


;;; Armed Bear Common Lisp

(define-implementation-package :abcl #:qlqs-abcl
  (:documentation
   "Armed Bear Common Lisp - http://common-lisp.net/project/armedbear/")
  (:class abcl)
  (:reexport-from #:system
                  #:make-socket
                  #:get-socket-stream))

;;; Clozure CL

(define-implementation-package :ccl #:qlqs-ccl
  (:documentation
   "Clozure Common Lisp - http://www.clozure.com/clozurecl.html")
  (:class ccl)
  (:reexport-from #:ccl
                  #:make-socket))


;;; CLASP

(define-implementation-package :clasp #:qlqs-clasp
  (:documentation "CLASP - http://github.com/drmeister/clasp")
  (:class clasp)
  (:prep
   (require 'sockets))
  (:intern #:host-network-address)
  (:reexport-from #:sb-bsd-sockets
                  #:get-host-by-name
                  #:host-ent-address
                  #:socket-connect
                  #:socket-make-stream
                  #:inet-socket))


;;; GNU CLISP

(define-implementation-package :clisp #:qlqs-clisp
  (:documentation "GNU CLISP - http://clisp.cons.org/")
  (:class clisp)
  (:reexport-from #:socket
                  #:socket-connect)
  (:reexport-from #:ext
                  #:read-byte-sequence))


;;; CMUCL

(define-implementation-package :cmu #:qlqs-cmucl
  (:documentation "CMU Common Lisp - http://www.cons.org/cmucl/")
  (:class cmucl)
  (:reexport-from #:ext
                  #:*gc-verbose*)
  (:reexport-from #:system
                  #:make-fd-stream)
  (:reexport-from #:extensions
                  #:connect-to-inet-socket))

(defvar qlqs-cmucl:*gc-verbose* nil)


;;; Scieneer CL

(define-implementation-package :scl #:qlqs-scl
  (:documentation "Scieneer Common Lisp - http://www.scieneer.com/scl/")
  (:class scl)
  (:reexport-from #:system
                  #:make-fd-stream)
  (:reexport-from #:extensions
                  #:connect-to-inet-socket))

;;; ECL

(define-implementation-package :ecl #:qlqs-ecl
  (:documentation "ECL - http://ecls.sourceforge.net/")
  (:class ecl)
  (:prep
   (require 'sockets))
  (:intern #:host-network-address)
  (:reexport-from #:sb-bsd-sockets
                  #:get-host-by-name
                  #:host-ent-address
                  #:socket-connect
                  #:socket-make-stream
                  #:inet-socket))


;;; LispWorks

(define-implementation-package :lispworks #:qlqs-lispworks
  (:documentation "LispWorks - http://www.lispworks.com/")
  (:class lispworks)
  (:prep
   (require "comm"))
  (:reexport-from #:comm
                  #:open-tcp-stream
                  #:get-host-entry))


;;; SBCL

(define-implementation-package :sbcl #:qlqs-sbcl
  (:class sbcl)
  (:documentation
   "Steel Bank Common Lisp - http://www.sbcl.org/")
  (:prep
   (require 'sb-bsd-sockets))
  (:intern #:host-network-address)
  (:reexport-from #:sb-ext
                  #:compiler-note)
  (:reexport-from #:sb-bsd-sockets
                  #:get-host-by-name
                  #:inet-socket
                  #:host-ent-address
                  #:socket-connect
                  #:socket-make-stream))

;;; MKCL

(define-implementation-package :mkcl #:qlqs-mkcl
  (:class mkcl)
  (:documentation
   "ManKai Common Lisp - http://common-lisp.net/project/mkcl/")
  (:prep
   (require 'sockets))
  (:intern #:host-network-address)
  (:reexport-from #:sb-bsd-sockets
                  #:get-host-by-name
                  #:inet-socket
                  #:host-ent-address
                  #:socket-connect
                  #:socket-make-stream))

;;;
;;; Utility function
;;;

(in-package #:qlqs-impl-util)

(definterface call-with-quiet-compilation (fun)
  (:implementation t
    (let ((*load-verbose* nil)
          (*compile-verbose* nil)
          (*load-print* nil)
          (*compile-print* nil))
      (handler-bind ((warning #'muffle-warning))
        (funcall fun)))))

(defimplementation (call-with-quiet-compilation :for sbcl :qualifier :around)
    (fun)
  (declare (ignorable fun))
  (handler-bind ((qlqs-sbcl:compiler-note #'muffle-warning))
    (call-next-method)))

(defimplementation (call-with-quiet-compilation :for cmucl :qualifier :around)
    (fun)
  (declare (ignorable fun))
  (let ((qlqs-cmucl:*gc-verbose* nil))
    (call-next-method)))


;;;
;;; Low-level networking implementations
;;;

(in-package #:qlqs-network)

(definterface host-address (host)
  (:implementation t
    host)
  (:implementation mkcl
    (qlqs-mkcl:host-ent-address (qlqs-mkcl:get-host-by-name host)))
  (:implementation sbcl
    (qlqs-sbcl:host-ent-address (qlqs-sbcl:get-host-by-name host))))

(definterface open-connection (host port)
  (:implementation t
    (declare (ignorable host port))
    (error "Sorry, quicklisp in implementation ~S is not supported yet."
           (lisp-implementation-type)))
  (:implementation allegro
    (qlqs-allegro:make-socket :remote-host host
                             :remote-port port))
  (:implementation abcl
    (let ((socket (qlqs-abcl:make-socket host port)))
      (qlqs-abcl:get-socket-stream socket :element-type '(unsigned-byte 8))))
  (:implementation ccl
    (qlqs-ccl:make-socket :remote-host host
                         :remote-port port))
  (:implementation clasp
    (let* ((endpoint (qlqs-clasp:host-ent-address
                      (qlqs-clasp:get-host-by-name host)))
           (socket (make-instance 'qlqs-clasp:inet-socket
                                  :protocol :tcp
                                  :type :stream)))
      (qlqs-clasp:socket-connect socket endpoint port)
      (qlqs-clasp:socket-make-stream socket
                                  :element-type '(unsigned-byte 8)
                                  :input t
                                  :output t
                                  :buffering :full)))
  (:implementation clisp
    (qlqs-clisp:socket-connect port host :element-type '(unsigned-byte 8)))
  (:implementation cmucl
    (let ((fd (qlqs-cmucl:connect-to-inet-socket host port)))
      (qlqs-cmucl:make-fd-stream fd
                                :element-type '(unsigned-byte 8)
                                :binary-stream-p t
                                :input t
                                :output t)))
  (:implementation scl
    (let ((fd (qlqs-scl:connect-to-inet-socket host port)))
      (qlqs-scl:make-fd-stream fd
			       :element-type '(unsigned-byte 8)
			       :input t
			       :output t)))
  (:implementation ecl
    (let* ((endpoint (qlqs-ecl:host-ent-address
                      (qlqs-ecl:get-host-by-name host)))
           (socket (make-instance 'qlqs-ecl:inet-socket
                                  :protocol :tcp
                                  :type :stream)))
      (qlqs-ecl:socket-connect socket endpoint port)
      (qlqs-ecl:socket-make-stream socket
                                  :element-type '(unsigned-byte 8)
                                  :input t
                                  :output t
                                  :buffering :full)))
  (:implementation lispworks
    (qlqs-lispworks:open-tcp-stream host port
                                   :direction :io
                                   :errorp t
                                   :read-timeout nil
                                   :element-type '(unsigned-byte 8)
                                   :timeout 5))
  (:implementation mkcl
    (let* ((endpoint (qlqs-mkcl:host-ent-address
                      (qlqs-mkcl:get-host-by-name host)))
           (socket (make-instance 'qlqs-mkcl:inet-socket
                                  :protocol :tcp
                                  :type :stream)))
      (qlqs-mkcl:socket-connect socket endpoint port)
      (qlqs-mkcl:socket-make-stream socket
                                   :element-type '(unsigned-byte 8)
                                   :input t
                                   :output t
                                   :buffering :full)))
  (:implementation sbcl
    (let* ((endpoint (qlqs-sbcl:host-ent-address
                      (qlqs-sbcl:get-host-by-name host)))
           (socket (make-instance 'qlqs-sbcl:inet-socket
                                  :protocol :tcp
                                  :type :stream)))
      (qlqs-sbcl:socket-connect socket endpoint port)
      (qlqs-sbcl:socket-make-stream socket
                                   :element-type '(unsigned-byte 8)
                                   :input t
                                   :output t
                                   :buffering :full))))

(definterface read-octets (buffer connection)
  (:implementation t
    (read-sequence buffer connection))
  (:implementation allegro
    (qlqs-allegro:read-vector buffer connection))
  (:implementation clisp
    (qlqs-clisp:read-byte-sequence buffer connection
                                  :no-hang nil
                                  :interactive t)))

(definterface write-octets (buffer connection)
  (:implementation t
    (write-sequence buffer connection)
    (finish-output connection)))

(definterface close-connection (connection)
  (:implementation t
    (ignore-errors (close connection))))

(definterface call-with-connection (host port fun)
  (:implementation t
    (let (connection)
      (unwind-protect
           (progn
             (setf connection (open-connection host port))
             (funcall fun connection))
        (when connection
          (close connection))))))

(defmacro with-connection ((connection host port) &body body)
  `(call-with-connection ,host ,port (lambda (,connection) ,@body)))


;;;
;;; A text progress bar
;;;

(in-package #:qlqs-progress)

(defclass progress-bar ()
  ((start-time
    :initarg :start-time
    :accessor start-time)
   (end-time
    :initarg :end-time
    :accessor end-time)
   (progress-character
    :initarg :progress-character
    :accessor progress-character)
   (character-count
    :initarg :character-count
    :accessor character-count
    :documentation "How many characters wide is the progress bar?")
   (characters-so-far
    :initarg :characters-so-far
    :accessor characters-so-far)
   (update-interval
    :initarg :update-interval
    :accessor update-interval
    :documentation "Update the progress bar display after this many
    internal-time units.")
   (last-update-time
    :initarg :last-update-time
    :accessor last-update-time
    :documentation "The display was last updated at this time.")
   (total
    :initarg :total
    :accessor total
    :documentation "The total number of units tracked by this progress bar.")
   (progress
    :initarg :progress
    :accessor progress
    :documentation "How far in the progress are we?")
   (pending
    :initarg :pending
    :accessor pending
    :documentation "How many raw units should be tracked in the next
    display update?"))
  (:default-initargs
   :progress-character #\=
   :character-count 50
   :characters-so-far 0
   :update-interval (floor internal-time-units-per-second 4)
   :last-update-time 0
   :total 0
   :progress 0
   :pending 0))

(defgeneric start-display (progress-bar))
(defgeneric update-progress (progress-bar unit-count))
(defgeneric update-display (progress-bar))
(defgeneric finish-display (progress-bar))
(defgeneric elapsed-time (progress-bar))
(defgeneric units-per-second (progress-bar))

(defmethod start-display (progress-bar)
  (setf (last-update-time progress-bar) (get-internal-real-time))
  (setf (start-time progress-bar) (get-internal-real-time))
  (fresh-line)
  (finish-output))

(defmethod update-display (progress-bar)
  (incf (progress progress-bar) (pending progress-bar))
  (setf (pending progress-bar) 0)
  (setf (last-update-time progress-bar) (get-internal-real-time))
  (let* ((showable (floor (character-count progress-bar)
                          (/ (total progress-bar) (progress progress-bar))))
         (needed (- showable (characters-so-far progress-bar))))
    (setf (characters-so-far progress-bar) showable)
    (dotimes (i needed)
      (write-char (progress-character progress-bar)))
    (finish-output)))

(defmethod update-progress (progress-bar unit-count)
  (incf (pending progress-bar) unit-count)
  (let ((now (get-internal-real-time)))
    (when (< (update-interval progress-bar)
             (- now (last-update-time progress-bar)))
      (update-display progress-bar))))

(defmethod finish-display (progress-bar)
  (update-display progress-bar)
  (setf (end-time progress-bar) (get-internal-real-time))
  (terpri)
  (format t "~:D bytes in ~$ seconds (~$KB/sec)"
          (total progress-bar)
          (elapsed-time progress-bar)
          (/  (units-per-second progress-bar) 1024))
  (finish-output))

(defmethod elapsed-time (progress-bar)
  (/ (- (end-time progress-bar) (start-time progress-bar))
     internal-time-units-per-second))

(defmethod units-per-second (progress-bar)
  (if (plusp (elapsed-time progress-bar))
      (/ (total progress-bar) (elapsed-time progress-bar))
      0))

(defun kb/sec (progress-bar)
  (/ (units-per-second progress-bar) 1024))



(defparameter *uncertain-progress-chars* "?")

(defclass uncertain-size-progress-bar (progress-bar)
  ((progress-char-index
    :initarg :progress-char-index
    :accessor progress-char-index)
   (units-per-char
    :initarg :units-per-char
    :accessor units-per-char))
  (:default-initargs
   :total 0
   :progress-char-index 0
   :units-per-char (floor (expt 1024 2) 50)))

(defmethod update-progress :after ((progress-bar uncertain-size-progress-bar)
                            unit-count)
  (incf (total progress-bar) unit-count))

(defmethod progress-character ((progress-bar uncertain-size-progress-bar))
  (let ((index (progress-char-index progress-bar)))
    (prog1
        (char *uncertain-progress-chars* index)
      (setf (progress-char-index progress-bar)
            (mod (1+ index) (length *uncertain-progress-chars*))))))

(defmethod update-display ((progress-bar uncertain-size-progress-bar))
  (setf (last-update-time progress-bar) (get-internal-real-time))
  (multiple-value-bind (chars pend)
      (floor (pending progress-bar) (units-per-char progress-bar))
    (setf (pending progress-bar) pend)
    (dotimes (i chars)
      (write-char (progress-character progress-bar))
      (incf (characters-so-far progress-bar))
      (when (<= (character-count progress-bar)
                (characters-so-far progress-bar))
        (terpri)
        (setf (characters-so-far progress-bar) 0)
        (finish-output)))
    (finish-output)))

(defun make-progress-bar (total)
  (if (or (not total) (zerop total))
      (make-instance 'uncertain-size-progress-bar)
      (make-instance 'progress-bar :total total)))

;;;
;;; A simple HTTP client
;;;

(in-package #:qlqs-http)

;;; Octet data

(deftype octet ()
  '(unsigned-byte 8))

(defun make-octet-vector (size)
  (make-array size :element-type 'octet
              :initial-element 0))

(defun octet-vector (&rest octets)
  (make-array (length octets) :element-type 'octet
              :initial-contents octets))

;;; ASCII characters as integers

(defun acode (char)
  (cond ((eql char :cr)
         13)
        ((eql char :lf)
         10)
        (t
         (let ((code (char-code char)))
           (if (<= 0 code 127)
               code
               (error "Character ~S is not in the ASCII character set"
                      char))))))

(defvar *whitespace*
  (list (acode #\Space) (acode #\Tab) (acode :cr) (acode :lf)))

(defun whitep (code)
  (member code *whitespace*))

(defun ascii-vector (string)
  (let ((vector (make-octet-vector (length string))))
    (loop for char across string
          for code = (char-code char)
          for i from 0
          if (< 127 code) do
          (error "Invalid character for ASCII -- ~A" char)
          else
          do (setf (aref vector i) code))
    vector))

(defun ascii-subseq (vector start end)
  "Return a subseq of octet-specialized VECTOR as a string."
  (let ((string (make-string (- end start))))
    (loop for i from 0
          for j from start below end
          do (setf (char string i) (code-char (aref vector j))))
    string))

(defun ascii-downcase (code)
  (if (<= 65 code 90)
      (+ code 32)
      code))

(defun ascii-equal (a b)
  (eql (ascii-downcase a) (ascii-downcase b)))

(defmacro acase (value &body cases)
  (flet ((convert-case-keys (keys)
           (mapcar (lambda (key)
                     (etypecase key
                       (integer key)
                       (character (char-code key))
                       (symbol
                        (ecase key
                          (:cr 13)
                          (:lf 10)
                          ((t) t)))))
                   (if (consp keys) keys (list keys)))))
    `(case ,value
       ,@(mapcar (lambda (case)
                   (destructuring-bind (keys &rest body)
                       case
                     `(,(if (eql keys t)
                            t
                            (convert-case-keys keys))
                        ,@body)))
                 cases))))

;;; Pattern matching (for finding headers)

(defclass matcher ()
  ((pattern
    :initarg :pattern
    :reader pattern)
   (pos
    :initform 0
    :accessor match-pos)
   (matchedp
    :initform nil
    :accessor matchedp)))

(defun reset-match (matcher)
  (setf (match-pos matcher) 0
        (matchedp matcher) nil))

(define-condition match-failure (error) ())

(defun match (matcher input &key (start 0) end error)
  (let ((i start)
        (end (or end (length input)))
        (match-end (length (pattern matcher))))
    (with-slots (pattern pos)
        matcher
      (loop
       (cond ((= pos match-end)
              (let ((match-start (- i pos)))
                (setf pos 0)
                (setf (matchedp matcher) t)
                (return (values match-start (+ match-start match-end)))))
             ((= i end)
              (return nil))
             ((= (aref pattern pos)
                 (aref input i))
              (incf i)
              (incf pos))
             (t
              (if error
                  (error 'match-failure)
                  (if (zerop pos)
                      (incf i)
                      (setf pos 0)))))))))

(defun ascii-matcher (string)
  (make-instance 'matcher
                 :pattern (ascii-vector string)))

(defun octet-matcher (&rest octets)
  (make-instance 'matcher
                 :pattern (apply 'octet-vector octets)))

(defun acode-matcher (&rest codes)
  (make-instance 'matcher
                 :pattern (make-array (length codes)
                                      :element-type 'octet
                                      :initial-contents
                                      (mapcar 'acode codes))))


;;; "Connection Buffers" are a kind of callback-driven,
;;; pattern-matching chunky stream. Callbacks can be called for a
;;; certain number of octets or until one or more patterns are seen in
;;; the input. cbufs automatically refill themselves from a
;;; connection as needed.

(defvar *cbuf-buffer-size* 8192)

(define-condition end-of-data (error) ())

(defclass cbuf ()
  ((data
    :initarg :data
    :accessor data)
   (connection
    :initarg :connection
    :accessor connection)
   (start
    :initarg :start
    :accessor start)
   (end
    :initarg :end
    :accessor end)
   (eofp
    :initarg :eofp
    :accessor eofp))
  (:default-initargs
   :data (make-octet-vector *cbuf-buffer-size*)
   :connection nil
   :start 0
   :end 0
   :eofp nil)
  (:documentation "A CBUF is a connection buffer that keeps track of
  incoming data from a connection. Several functions make it easy to
  treat a CBUF as a kind of chunky, callback-driven stream."))

(define-condition cbuf-progress ()
  ((size
    :initarg :size
    :accessor cbuf-progress-size
    :initform 0)))

(defun call-processor (fun cbuf start end)
  (signal 'cbuf-progress :size (- end start))
  (funcall fun (data cbuf) start end))

(defun make-cbuf (connection)
  (make-instance 'cbuf :connection connection))

(defun make-stream-writer (stream)
  "Create a callback for writing data to STREAM."
  (lambda (data start end)
    (write-sequence data stream :start start :end end)))

(defgeneric size (cbuf)
  (:method ((cbuf cbuf))
    (- (end cbuf) (start cbuf))))

(defgeneric emptyp (cbuf)
  (:method ((cbuf cbuf))
    (zerop (size cbuf))))

(defgeneric refill (cbuf)
  (:method ((cbuf cbuf))
    (when (eofp cbuf)
      (error 'end-of-data))
    (setf (start cbuf) 0)
    (setf (end cbuf)
          (read-octets (data cbuf)
                       (connection cbuf)))
    (cond ((emptyp cbuf)
           (setf (eofp cbuf) t)
           (error 'end-of-data))
          (t (size cbuf)))))

(defun process-all (fun cbuf)
  (unless (emptyp cbuf)
    (call-processor fun cbuf (start cbuf) (end cbuf))))

(defun multi-cmatch (matchers cbuf)
  (let (start end)
    (dolist (matcher matchers (values start end))
      (multiple-value-bind (s e)
          (match matcher (data cbuf)
                 :start (start cbuf)
                 :end (end cbuf))
        (when (and s (or (null start) (< s start)))
          (setf start s
                end e))))))

(defun cmatch (matcher cbuf)
  (if (consp matcher)
      (multi-cmatch matcher cbuf)
      (match matcher (data cbuf) :start (start cbuf) :end (end cbuf))))

(defun call-until-end (fun cbuf)
  (handler-case
      (loop
       (process-all fun cbuf)
       (refill cbuf))
    (end-of-data ()
      (return-from call-until-end))))

(defun show-cbuf (context cbuf)
  (format t "cbuf: ~A ~D - ~D~%" context (start cbuf) (end cbuf)))

(defun call-for-n-octets (n fun cbuf)
  (let ((remaining n))
    (loop
     (when (<= remaining (size cbuf))
       (let ((end (+ (start cbuf) remaining)))
         (call-processor fun cbuf (start cbuf) end)
         (setf (start cbuf) end)
         (return)))
     (process-all fun cbuf)
     (decf remaining (size cbuf))
     (refill cbuf))))

(defun call-until-matching (matcher fun cbuf)
  (loop
   (multiple-value-bind (start end)
       (cmatch matcher cbuf)
     (when start
       (call-processor fun cbuf (start cbuf) end)
       (setf (start cbuf) end)
       (return)))
   (process-all fun cbuf)
   (refill cbuf)))

(defun ignore-data (data start end)
  (declare (ignore data start end)))

(defun skip-until-matching (matcher cbuf)
  (call-until-matching matcher 'ignore-data cbuf))


;;; Creating HTTP requests as octet buffers

(defclass octet-sink ()
  ((storage
    :initarg :storage
    :accessor storage))
  (:default-initargs
   :storage (make-array 1024 :element-type 'octet
                        :fill-pointer 0
                        :adjustable t))
  (:documentation "A simple stream-like target for collecting
  octets."))

(defun add-octet (octet sink)
  (vector-push-extend octet (storage sink)))

(defun add-octets (octets sink &key (start 0) end)
  (setf end (or end (length octets)))
  (loop for i from start below end
        do (add-octet (aref octets i) sink)))

(defun add-string (string sink)
  (loop for char across string
        for code = (char-code char)
        do (add-octet code sink)))

(defun add-strings (sink &rest strings)
  (mapc (lambda (string) (add-string string sink)) strings))

(defun add-newline (sink)
  (add-octet 13 sink)
  (add-octet 10 sink))

(defun sink-buffer (sink)
  (subseq (storage sink) 0))

(defvar *proxy-url* nil)

(defun full-proxy-path (host port path)
  (format nil "~:[http~;https~]://~A~:[:~D~;~*~]~A"
                       (= port 443)
                       host
                       (or (= port 80)
                           (= port 443))
                       port
                       path))

(defun make-request-buffer (host port path &key (method "GET"))
  (setf method (string method))
  (when *proxy-url*
    (setf path (full-proxy-path host port path)))
  (let ((sink (make-instance 'octet-sink)))
    (flet ((add-line (&rest strings)
             (apply #'add-strings sink strings)
             (add-newline sink)))
      (add-line method " " path " HTTP/1.1")
      (add-line "Host: " host (if (= port 80) ""
                                  (format nil ":~D" port)))
      (add-line "Connection: close")
      ;; FIXME: get this version string from somewhere else.
      (add-line "User-Agent: quicklisp-bootstrap/"
                qlqs-info:*version*)
      (add-newline sink)
      (sink-buffer sink))))

(defun sink-until-matching (matcher cbuf)
  (let ((sink (make-instance 'octet-sink)))
    (call-until-matching
     matcher
     (lambda (buffer start end)
       (add-octets buffer sink :start start :end end))
     cbuf)
    (sink-buffer sink)))


;;; HTTP headers

(defclass header ()
  ((data
    :initarg :data
    :accessor data)
   (status
    :initarg :status
    :accessor status)
   (name-starts
    :initarg :name-starts
    :accessor name-starts)
   (name-ends
    :initarg :name-ends
    :accessor name-ends)
   (value-starts
    :initarg :value-starts
    :accessor value-starts)
   (value-ends
    :initarg :value-ends
    :accessor value-ends)))

(defmethod print-object ((header header) stream)
  (print-unreadable-object (header stream :type t)
    (prin1 (status header) stream)))

(defun matches-at (pattern target pos)
  (= (mismatch pattern target :start2 pos) (length pattern)))

(defun header-value-indexes (field-name header)
  (loop with data = (data header)
        with pattern = (ascii-vector (string-downcase field-name))
        for start across (name-starts header)
        for i from 0
        when (matches-at pattern data start)
        return (values (aref (value-starts header) i)
                       (aref (value-ends header) i))))

(defun ascii-header-value (field-name header)
  (multiple-value-bind (start end)
      (header-value-indexes field-name header)
    (when start
      (ascii-subseq (data header) start end))))

(defun all-field-names (header)
  (map 'list
       (lambda (start end)
         (ascii-subseq (data header) start end))
       (name-starts header)
       (name-ends header)))

(defun headers-alist (header)
  (mapcar (lambda (name)
            (cons name (ascii-header-value name header)))
          (all-field-names header)))

(defmethod describe-object :after ((header header) stream)
  (format stream "~&Decoded headers:~%  ~S~%" (headers-alist header)))

(defun content-length (header)
  (let ((field-value (ascii-header-value "content-length" header)))
    (when field-value
      (let ((value (ignore-errors (parse-integer field-value))))
        (or value
            (error "Content-Length header field value is not a number -- ~A"
                   field-value))))))

(defun chunkedp (header)
  (string= (ascii-header-value "transfer-encoding" header) "chunked"))

(defun location (header)
  (ascii-header-value "location" header))

(defun status-code (vector)
  (let* ((space (position (acode #\Space) vector))
         (c1 (- (aref vector (incf space)) 48))
         (c2 (- (aref vector (incf space)) 48))
         (c3 (- (aref vector (incf space)) 48)))
    (+ (* c1 100)
       (* c2  10)
       (* c3   1))))

(defun force-downcase-field-names (header)
  (loop with data = (data header)
        for start across (name-starts header)
        for end across (name-ends header)
        do (loop for i from start below end
                 for code = (aref data i)
                 do (setf (aref data i) (ascii-downcase code)))))

(defun skip-white-forward (pos vector)
  (position-if-not 'whitep vector :start pos))

(defun skip-white-backward (pos vector)
  (let ((nonwhite (position-if-not 'whitep vector :end pos :from-end t)))
    (if nonwhite
        (1+ nonwhite)
        pos)))

(defun contract-field-value-indexes (header)
  "Header field values exclude leading and trailing whitespace; adjust
the indexes in the header accordingly."
  (loop with starts = (value-starts header)
        with ends = (value-ends header)
        with data = (data header)
        for i from 0
        for start across starts
        for end across ends
        do
        (setf (aref starts i) (skip-white-forward start data))
        (setf (aref ends i) (skip-white-backward end data))))

(defun next-line-pos (vector)
  (let ((pos 0))
    (labels ((finish (&optional (i pos))
               (return-from next-line-pos i))
             (after-cr (code)
               (acase code
                 (:lf (finish pos))
                 (t (finish (1- pos)))))
             (pending (code)
               (acase code
                 (:cr #'after-cr)
                 (:lf (finish pos))
                 (t #'pending))))
      (let ((state #'pending))
        (loop
         (setf state (funcall state (aref vector pos)))
         (incf pos))))))

(defun make-hvector ()
  (make-array 16 :fill-pointer 0 :adjustable t))

(defun process-header (vector)
  "Create a HEADER instance from the octet data in VECTOR."
  (let* ((name-starts (make-hvector))
         (name-ends (make-hvector))
         (value-starts (make-hvector))
         (value-ends (make-hvector))
         (header (make-instance 'header
                                :data vector
                                :status 999
                                :name-starts name-starts
                                :name-ends name-ends
                                :value-starts value-starts
                                :value-ends value-ends))
         (mark nil)
         (pos (next-line-pos vector)))
    (unless pos
      (error "Unable to process HTTP header"))
    (setf (status header) (status-code vector))
    (labels ((save (value vector)
               (vector-push-extend value vector))
             (mark ()
               (setf mark pos))
             (clear-mark ()
               (setf mark nil))
             (finish ()
               (if mark
                   (save mark value-ends)
                   (save pos value-ends))
              (force-downcase-field-names header)
              (contract-field-value-indexes header)
              (return-from process-header header))
             (in-new-line (code)
               (acase code
                 ((#\Tab #\Space) (setf mark nil) #'in-value)
                 (t
                  (when mark
                    (save mark value-ends))
                  (clear-mark)
                  (save pos name-starts)
                  (in-name code))))
             (after-cr (code)
               (acase code
                 (:lf #'in-new-line)
                 (t (in-new-line code))))
             (pending-value (code)
               (acase code
                 ((#\Tab #\Space) #'pending-value)
                 (:cr #'after-cr)
                 (:lf #'in-new-line)
                 (t (save pos value-starts) #'in-value)))
             (in-name (code)
               (acase code
                 (#\:
                  (save pos name-ends)
                  (save (1+ pos) value-starts)
                  #'in-value)
                 ((:cr :lf)
                  (finish))
                 ((#\Tab #\Space)
                  (error "Unexpected whitespace in header field name"))
                 (t
                  (unless (<= 0 code 127)
                    (error "Unexpected non-ASCII header field name"))
                  #'in-name)))
             (in-value (code)
               (acase code
                 (:lf (mark) #'in-new-line)
                 (:cr (mark) #'after-cr)
                 (t #'in-value))))
      (let ((state #'in-new-line))
        (loop
         (incf pos)
         (when (<= (length vector) pos)
           (error "No header found in response"))
         (setf state (funcall state (aref vector pos))))))))


;;; HTTP URL parsing

(defclass url ()
  ((hostname
    :initarg :hostname
    :accessor hostname
    :initform nil)
   (port
    :initarg :port
    :accessor port
    :initform 80)
   (path
    :initarg :path
    :accessor path
    :initform "/")))

(defun parse-urlstring (urlstring)
  (setf urlstring (string-trim " " urlstring))
  (let* ((pos (mismatch urlstring "http://" :test 'char-equal))
         (mark pos)
         (url (make-instance 'url)))
    (labels ((save ()
               (subseq urlstring mark pos))
             (mark ()
               (setf mark pos))
             (finish ()
               (return-from parse-urlstring url))
             (hostname-char-p (char)
               (position char "ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_."
                         :test 'char-equal))
             (at-start (char)
               (case char
                 (#\/
                  (setf (port url) nil)
                  (mark)
                  #'in-path)
                 (t
                  #'in-host)))
             (in-host (char)
               (case char
                 ((#\/ :end)
                  (setf (hostname url) (save))
                  (mark)
                  #'in-path)
                 (#\:
                  (setf (hostname url) (save))
                  (mark)
                  #'in-port)
                 (t
                  (unless (hostname-char-p char)
                    (error "~S is not a valid URL" urlstring))
                  #'in-host)))
             (in-port (char)
               (case char
                 ((#\/ :end)
                  (setf (port url)
                        (parse-integer urlstring
                                       :start (1+ mark)
                                       :end pos))
                  (mark)
                  #'in-path)
                 (t
                  (unless (digit-char-p char)
                    (error "Bad port in URL ~S" urlstring))
                  #'in-port)))
             (in-path (char)
               (case char
                 ((#\# :end)
                  (setf (path url) (save))
                  (finish)))
               #'in-path))
      (let ((state #'at-start))
        (loop
         (when (<= (length urlstring) pos)
           (funcall state :end)
           (finish))
         (setf state (funcall state (aref urlstring pos)))
         (incf pos))))))

(defun url (thing)
  (if (stringp thing)
      (parse-urlstring thing)
      thing))

(defgeneric request-buffer (method url)
  (:method (method url)
    (setf url (url url))
    (make-request-buffer (hostname url) (port url) (path url)
                         :method method)))

(defun urlstring (url)
  (format nil "~@[http://~A~]~@[:~D~]~A"
          (hostname url)
          (and (/= 80 (port url)) (port url))
          (path url)))

(defmethod print-object ((url url) stream)
  (print-unreadable-object (url stream :type t)
    (prin1 (urlstring url) stream)))

(defun merge-urls (url1 url2)
  (setf url1 (url url1))
  (setf url2 (url url2))
  (make-instance 'url
                 :hostname (or (hostname url1)
                               (hostname url2))
                 :port (or (port url1)
                           (port url2))
                 :path (or (path url1)
                           (path url2))))


;;; Requesting an URL and saving it to a file

(defparameter *maximum-redirects* 10)
(defvar *default-url-defaults* (url "http://src.quicklisp.org/"))

(defun read-http-header (cbuf)
  (let ((header-data (sink-until-matching (list (acode-matcher :lf :lf)
                                                (acode-matcher :cr :cr)
                                                (acode-matcher :cr :lf :cr :lf))
                                 cbuf)))
    (process-header header-data)))

(defun read-chunk-header (cbuf)
  (let* ((header-data (sink-until-matching (acode-matcher :cr :lf) cbuf))
         (end (or (position (acode :cr) header-data)
                  (position (acode #\;) header-data))))
    (values (parse-integer (ascii-subseq header-data 0 end) :radix 16))))

(defun save-chunk-response (stream cbuf)
  "For a chunked response, read all chunks and write them to STREAM."
  (let ((fun (make-stream-writer stream))
        (matcher (acode-matcher :cr :lf)))
    (loop
     (let ((chunk-size (read-chunk-header cbuf)))
       (when (zerop chunk-size)
         (return))
       (call-for-n-octets chunk-size fun cbuf)
       (skip-until-matching matcher cbuf)))))

(defun save-response (file header cbuf)
  (with-open-file (stream file
                          :direction :output
                          :if-exists :supersede
                          :element-type 'octet)
    (let ((content-length (content-length header)))
      (cond ((chunkedp header)
             (save-chunk-response stream cbuf))
            (content-length
             (call-for-n-octets content-length
                                (make-stream-writer stream)
                                cbuf))
            (t
             (call-until-end (make-stream-writer stream) cbuf))))))

(defun call-with-progress-bar (size fun)
  (let ((progress-bar (make-progress-bar size)))
    (start-display progress-bar)
    (flet ((update (condition)
             (update-progress progress-bar
                              (cbuf-progress-size condition))))
      (handler-bind ((cbuf-progress #'update))
        (funcall fun)))
    (finish-display progress-bar)))

(defun fetch (url file &key (follow-redirects t) quietly
              (maximum-redirects *maximum-redirects*))
  "Request URL and write the body of the response to FILE."
  (setf url (merge-urls url *default-url-defaults*))
  (setf file (merge-pathnames file))
  (let ((redirect-count 0)
        (original-url url)
        (connect-url (or (url *proxy-url*) url))
        (stream (if quietly
                    (make-broadcast-stream)
                    *trace-output*)))
    (loop
     (when (<= maximum-redirects redirect-count)
       (error "Too many redirects for ~A" original-url))
     (with-connection (connection (hostname connect-url) (port connect-url))
       (let ((cbuf (make-instance 'cbuf :connection connection))
             (request (request-buffer "GET" url)))
         (write-octets request connection)
         (let ((header (read-http-header cbuf)))
           (loop while (= (status header) 100)
                 do (setf header (read-http-header cbuf)))
           (cond ((= (status header) 200)
                  (let ((size (content-length header)))
                    (format stream "~&; Fetching ~A~%" url)
                    (if (and (numberp size)
                             (plusp size))
                        (format stream "; ~$KB~%" (/ size 1024))
                        (format stream "; Unknown size~%"))
                    (if quietly
                        (save-response file header cbuf)
                        (call-with-progress-bar (content-length header)
                                                (lambda ()
                                                  (save-response file header cbuf))))))
                 ((not (<= 300 (status header) 399))
                  (error "Unexpected status for ~A: ~A"
                         url (status header))))
           (if (and follow-redirects (<= 300 (status header) 399))
               (let ((new-urlstring (ascii-header-value "location" header)))
                 (when (not new-urlstring)
                   (error "Redirect code ~D received, but no Location: header"
                          (status header)))
                 (incf redirect-count)
                 (setf url (merge-urls new-urlstring
                                       url))
                 (format stream "~&; Redirecting to ~A~%" url))
               (return (values header (and file (probe-file file)))))))))))


;;; A primitive tar unpacker

(in-package #:qlqs-minitar)

(defun make-block-buffer ()
  (make-array 512 :element-type '(unsigned-byte 8) :initial-element 0))

(defun skip-n-blocks (n stream)
  (let ((block (make-block-buffer)))
    (dotimes (i n)
      (read-sequence block stream))))

(defun ascii-subseq (vector start end)
  (let ((string (make-string (- end start))))
    (loop for i from 0
          for j from start below end
          do (setf (char string i) (code-char (aref vector j))))
    string))

(defun block-asciiz-string (block start length)
  (let* ((end (+ start length))
         (eos (or (position 0 block :start start :end end)
                            end)))
    (ascii-subseq block start eos)))

(defun prefix (header)
  (when (plusp (aref header 345))
    (block-asciiz-string header 345 155)))

(defun name (header)
  (block-asciiz-string header 0 100))

(defun payload-size (header)
  (values (parse-integer (block-asciiz-string header 124 12) :radix 8)))

(defun nth-block (n file)
  (with-open-file (stream file :element-type '(unsigned-byte 8))
    (let ((block (make-block-buffer)))
      (skip-n-blocks (1- n) stream)
      (read-sequence block stream)
      block)))

(defun payload-type (code)
  (case code
    (0 :file)
    (48 :file)
    (53 :directory)
    (t :unsupported)))

(defun full-path (header)
  (let ((prefix (prefix header))
        (name (name header)))
    (if prefix
        (format nil "~A/~A" prefix name)
        name)))

(defun save-file (file size stream)
  (multiple-value-bind (full-blocks partial)
      (truncate size 512)
    (ensure-directories-exist file)
    (with-open-file (outstream file
                     :direction :output
                     :if-exists :supersede
                     :element-type '(unsigned-byte 8))
      (let ((block (make-block-buffer)))
        (dotimes (i full-blocks)
          (read-sequence block stream)
          (write-sequence block outstream))
        (when (plusp partial)
          (read-sequence block stream)
          (write-sequence block outstream :end partial))))))

(defun unpack-tarball (tarfile &key (directory *default-pathname-defaults*))
  (let ((block (make-block-buffer)))
    (with-open-file (stream tarfile :element-type '(unsigned-byte 8))
      (loop
       (let ((size (read-sequence block stream)))
         (when (zerop size)
           (return))
         (unless (= size 512)
           (error "Bad size on tarfile"))
         (when (every #'zerop block)
           (return))
         (let* ((payload-code (aref block 156))
                (payload-type (payload-type payload-code))
                (tar-path (full-path block))
                (full-path (merge-pathnames tar-path directory))
                (payload-size (payload-size block)))
         (case payload-type
           (:file
            (save-file full-path payload-size stream))
           (:directory
            (ensure-directories-exist full-path))
           (t
            (warn "Unknown tar block payload code -- ~D" payload-code)
            (skip-n-blocks (ceiling (payload-size block) 512) stream)))))))))

(defun contents (tarfile)
  (let ((block (make-block-buffer))
        (result '()))
    (with-open-file (stream tarfile :element-type '(unsigned-byte 8))
      (loop
        (let ((size (read-sequence block stream)))
          (when (zerop size)
            (return (nreverse result)))
          (unless (= size 512)
            (error "Bad size on tarfile"))
          (when (every #'zerop block)
            (return (nreverse result)))
          (let* ((payload-type (payload-type (aref block 156)))
                 (tar-path (full-path block))
                 (payload-size (payload-size block)))
            (skip-n-blocks (ceiling payload-size 512) stream)
            (case payload-type
              (:file
               (push tar-path result))
              (:directory
               (push tar-path result)))))))))


;;;
;;; The actual bootstrapping work
;;;

(in-package #:quicklisp-quickstart)

(defvar *home*
  (merge-pathnames (make-pathname :directory '(:relative "quicklisp"))
                   (user-homedir-pathname)))

(defun qmerge (pathname)
  (merge-pathnames pathname *home*))

(defun renaming-fetch (url file)
  (let ((tmpfile (qmerge "tmp/fetch.dat")))
    (fetch url tmpfile)
    (rename-file tmpfile file)))

(defvar *quickstart-parameters* nil
  "This plist is populated with parameters that may carry over to the
  initial configuration of the client, e.g. :proxy-url
  or :initial-dist-url")

(defvar *quicklisp-hostname* "beta.quicklisp.org")

(defvar *client-info-url*
  (format nil "http://~A/client/quicklisp.sexp"
          *quicklisp-hostname*))

(defclass client-info ()
  ((setup-url
    :reader setup-url
    :initarg :setup-url)
   (asdf-url
    :reader asdf-url
    :initarg :asdf-url)
   (client-tar-url
    :reader client-tar-url
    :initarg :client-tar-url)
   (version
    :reader version
    :initarg :version)
   (plist
    :reader plist
    :initarg :plist)
   (source-file
    :reader source-file
    :initarg :source-file)))

(defmethod print-object ((client-info client-info) stream)
  (print-unreadable-object (client-info stream :type t)
    (prin1 (version client-info) stream)))

(defun safely-read (stream)
  (let ((*read-eval* nil))
    (read stream)))

(defun fetch-client-info-plist (url)
  "Fetch and return the client info data at URL."
  (let ((local-client-info-file (qmerge "tmp/client-info.sexp")))
    (ensure-directories-exist local-client-info-file)
    (renaming-fetch url local-client-info-file)
    (with-open-file (stream local-client-info-file)
      (list* :source-file local-client-info-file
             (safely-read stream)))))

(defun fetch-client-info (url)
  (let ((plist (fetch-client-info-plist url)))
    (destructuring-bind (&key setup asdf client-tar version
                              source-file
                              &allow-other-keys)
        plist
      (unless (and setup asdf client-tar version)
        (error "Invalid data from client info URL -- ~A" url))
      (make-instance 'client-info
                     :setup-url (getf setup :url)
                     :asdf-url (getf asdf :url)
                     :client-tar-url (getf client-tar :url)
                     :version version
                     :plist plist
                     :source-file source-file))))

(defun client-info-url-from-version (version)
  (format nil "http://~A/client/~A/client-info.sexp"
          *quicklisp-hostname*
          version))

(defun distinfo-url-from-version (version)
  (format nil "http://~A/dist/~A/distinfo.txt"
          *quicklisp-hostname*
          version))

(defvar *help-message*
  (format nil "~&~%  ==== quicklisp quickstart install help ====~%~%    ~
               quicklisp-quickstart:install can take the following ~
               optional arguments:~%~%      ~
                 :path \"/path/to/installation/\"~%~%      ~
                 :proxy \"http://your.proxy:port/\"~%~%      ~
                 :client-url <url>~%~%      ~
                 :client-version <version>~%~%      ~
                 :dist-url <url>~%~%      ~
                 :dist-version <version>~%~%"))

(defvar *after-load-message*
  (format nil "~&~%  ==== quicklisp quickstart ~A loaded ====~%~%    ~
               To continue with installation, evaluate: (quicklisp-quickstart:install)~%~%    ~
               For installation options, evaluate: (quicklisp-quickstart:help)~%~%"
          qlqs-info:*version*))

(defvar *after-initial-setup-message*
  (with-output-to-string (*standard-output*)
    (format t "~&~%  ==== quicklisp installed ====~%~%")
    (format t "    To load a system, use: (ql:quickload \"system-name\")~%~%")
    (format t "    To find systems, use: (ql:system-apropos \"term\")~%~%")
    (format t "    To load Quicklisp every time you start Lisp, use: (ql:add-to-init-file)~%~%")
    (format t "    For more information, see http://www.quicklisp.org/beta/~%~%")))

(defun initial-install (&key (client-url *client-info-url*) dist-url)
  (setf *quickstart-parameters*
        (list :proxy-url *proxy-url*
              :initial-dist-url dist-url))
  (ensure-directories-exist (qmerge "tmp/"))
  (let ((client-info (fetch-client-info client-url))
        (tmptar (qmerge "tmp/quicklisp.tar"))
        (setup (qmerge "setup.lisp"))
        (asdf (qmerge "asdf.lisp")))
    (renaming-fetch (client-tar-url client-info) tmptar)
    (unpack-tarball tmptar :directory (qmerge "./"))
    (renaming-fetch (setup-url client-info) setup)
    (renaming-fetch (asdf-url client-info) asdf)
    (rename-file (source-file client-info) (qmerge "client-info.sexp"))
    (load setup :verbose nil :print nil)
    (write-string *after-initial-setup-message*)
    (finish-output)))

(defun help ()
  (write-string *help-message*)
  t)

(defun non-empty-file-namestring (pathname)
  (let ((string (file-namestring pathname)))
    (unless (or (null string)
                (equal string ""))
      string)))

(defun install (&key ((:path *home*) *home*)
                  ((:proxy *proxy-url*) *proxy-url*)
                  client-url
                  client-version
                  dist-url
                  dist-version)
  (setf *home* (merge-pathnames *home* (truename *default-pathname-defaults*)))
  (let ((name (non-empty-file-namestring *home*)))
    (when name
      (warn "Making ~A part of the install pathname directory"
            name)
      ;; This corrects a pathname like "/foo/bar" to "/foo/bar/" and
      ;; "foo" to "foo/"
      (setf *home*
            (make-pathname :defaults *home*
                           :directory (append (pathname-directory *home*)
                                              (list name))))))
  (let ((setup-file (qmerge "setup.lisp")))
    (when (probe-file setup-file)
      (multiple-value-bind (result proceed)
          (with-simple-restart (load-setup "Load ~S" setup-file)
            (error "Quicklisp has already been installed. Load ~S instead."
                   setup-file))
        (declare (ignore result))
        (when proceed
          (return-from install (load setup-file))))))
  (if (find-package '#:ql)
      (progn
        (write-line "!!! Quicklisp has already been set up. !!!")
        (write-string *after-initial-setup-message*)
        t)
      (call-with-quiet-compilation
       (lambda ()
         (let ((client-url (or client-url
                               (and client-version
                                    (client-info-url-from-version client-version))
                               *client-info-url*))
               ;; It's ok for dist-url to be nil; there's a default in
               ;; the client
               (dist-url (or dist-url
                             (and dist-version
                                  (distinfo-url-from-version dist-version)))))
           (initial-install :client-url client-url
                            :dist-url dist-url))))))

(write-string *after-load-message*)

;;; End of quicklisp.lisp

--- END_FILE: ./quicklisp.lisp ---

--- START_FILE: ./internal/parser/parser_test.go ---
package parser

import (
	"ebusta/api/proto/v1"
	"testing"
)

func TestParser(t *testing.T) {
	tests := []struct {
		name     string
		input    string
		validate func(*testing.T, *libraryv1.SearchQuery)
	}{
		{
			name:  "Simple Any Search",
			input: "Unix",
			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
				f := q.GetFilter()
				if f == nil || f.Field != "any" || f.Value != "Unix" {
					t.Errorf("Expected any:Unix, got %+v", f)
				}
			},
		},
		{
			name:  "Field Search",
			input: "author:–ö–∏–Ω–≥",
			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
				f := q.GetFilter()
				if f == nil || f.Field != "author" || f.Value != "–ö–∏–Ω–≥" {
					t.Errorf("Expected author:–ö–∏–Ω–≥, got %+v", f)
				}
			},
		},
		{
			name:  "Logical AND",
			input: "author:–ö–∏–Ω–≥ AND title:–û–Ω–æ",
			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
				l := q.GetLogical()
				if l == nil || l.Op != libraryv1.LogicalOp_AND || len(l.Nodes) != 2 {
					t.Errorf("Expected AND with 2 nodes, got %+v", l)
				}
			},
		},
		{
			name:  "Negation NOT",
			input: "NOT title:–ö—É–¥–∂–æ",
			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
				n := q.GetNegation()
				if n == nil {
					t.Fatalf("Expected negation node, got nil")
				}
				f := n.Node.GetFilter()
				if f.Field != "title" || f.Value != "–ö—É–¥–∂–æ" {
					t.Errorf("Expected NOT title:–ö—É–¥–∂–æ, got %s:%s", f.Field, f.Value)
				}
			},
		},
		{
			name:  "Regex Detection",
			input: "title:/^Unix.*/",
			validate: func(t *testing.T, q *libraryv1.SearchQuery) {
				f := q.GetFilter()
				if f.Operator != libraryv1.Operator_OP_REGEX {
					t.Errorf("Expected REGEX operator, got %v", f.Operator)
				}
			},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			p := NewParser(tt.input)
			query := p.Parse()
			tt.validate(t, query)
		})
	}
}

--- END_FILE: ./internal/parser/parser_test.go ---

--- START_FILE: ./internal/parser/lexer.go ---
package parser

import (
	"strings"
)

// ==========================================
// LEXER DEFINITIONS
// ==========================================

type TokenType int

const (
	TOKEN_EOF TokenType = iota
	TOKEN_ERROR
	TOKEN_IDENT     // author, title, –ö–∏–Ω–≥
	TOKEN_STRING    // "–°—Ç–∏–≤–µ–Ω –ö–∏–Ω–≥"
	TOKEN_COLON     // :
	TOKEN_AND       // AND
	TOKEN_OR        // OR
	TOKEN_NOT       // NOT, -
	TOKEN_LPAREN    // (
	TOKEN_RPAREN    // )
	TOKEN_EQUALS    // =
	TOKEN_CONTAINS  // ~
)

type Token struct {
	Type  TokenType
	Value string
	Pos   int
}

type Lexer struct {
	input  string
	pos    int
	start  int
	width  int
	tokens []Token
}

// newLexer —Å–æ–∑–¥–∞–µ—Ç –ª–µ–∫—Å–µ—Ä (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ parser.go)
func newLexer(input string) *Lexer {
	return &Lexer{input: input}
}

// NextToken –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ parser.go)
func (l *Lexer) NextToken() Token {
	l.skipWhitespace()
	if l.pos >= len(l.input) {
		return Token{Type: TOKEN_EOF}
	}

	ch := l.input[l.pos]

	switch {
	case isLetter(ch):
		return l.scanIdentifier()
	case ch == '"':
		return l.scanString()
	case ch == ':':
		l.pos++
		return Token{Type: TOKEN_COLON, Value: ":"}
	case ch == '(':
		l.pos++
		return Token{Type: TOKEN_LPAREN, Value: "("}
	case ch == ')':
		l.pos++
		return Token{Type: TOKEN_RPAREN, Value: ")"}
	case ch == '-': // –ú–∏–Ω—É—Å –∫–∞–∫ NOT
		l.pos++
		return Token{Type: TOKEN_NOT, Value: "-"}
	case ch == '=':
		l.pos++
		return Token{Type: TOKEN_EQUALS, Value: "="}
	case ch == '~':
		l.pos++
		return Token{Type: TOKEN_CONTAINS, Value: "~"}
	}

	return Token{Type: TOKEN_ERROR, Value: string(ch)}
}

func (l *Lexer) skipWhitespace() {
	for l.pos < len(l.input) && (l.input[l.pos] == ' ' || l.input[l.pos] == '\t') {
		l.pos++
	}
}

func (l *Lexer) scanIdentifier() Token {
	start := l.pos
	for l.pos < len(l.input) && isLetter(l.input[l.pos]) {
		l.pos++
	}
	lit := l.input[start:l.pos]
	
	switch strings.ToUpper(lit) {
	case "AND":
		return Token{Type: TOKEN_AND, Value: lit}
	case "OR":
		return Token{Type: TOKEN_OR, Value: lit}
	case "NOT":
		return Token{Type: TOKEN_NOT, Value: lit}
	}
	return Token{Type: TOKEN_IDENT, Value: lit}
}

func (l *Lexer) scanString() Token {
	l.pos++ // skip opening quote
	start := l.pos
	for l.pos < len(l.input) && l.input[l.pos] != '"' {
		l.pos++
	}
	lit := l.input[start:l.pos]
	if l.pos < len(l.input) {
		l.pos++ // skip closing quote
	}
	return Token{Type: TOKEN_STRING, Value: lit}
}

func isLetter(ch byte) bool {
	return (ch >= 'a' && ch <= 'z') || (ch >= 'A' && ch <= 'Z') || (ch >= '0' && ch <= '9') || ch > 127 || ch == '_' || ch == '.'
}

--- END_FILE: ./internal/parser/lexer.go ---

--- START_FILE: ./internal/parser/parser.go ---
package parser

import (
	"fmt"
	"ebusta/api/proto/v1"
)

// ==========================================
// PUBLIC API
// ==========================================

// Parse - —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞. –°–æ–∑–¥–∞–µ—Ç –ª–µ–∫—Å–µ—Ä –∏ –ø–∞—Ä—Å–µ—Ä.
func Parse(input string) *libraryv1.SearchQuery {
	l := newLexer(input)
	p := newParser(l)
	return p.parseSearchQuery()
}

// ==========================================
// PARSER LOGIC
// ==========================================

type Parser struct {
	l       *Lexer
	curTok  Token
	peekTok Token
}

func newParser(l *Lexer) *Parser {
	p := &Parser{l: l}
	p.nextToken()
	p.nextToken()
	return p
}

func (p *Parser) nextToken() {
	p.curTok = p.peekTok
	p.peekTok = p.l.NextToken()
}

// Expression -> Term { OR Term }
func (p *Parser) parseSearchQuery() *libraryv1.SearchQuery {
	if p.curTok.Type == TOKEN_EOF {
		return nil
	}
	return p.parseExpression()
}

func (p *Parser) parseExpression() *libraryv1.SearchQuery {
	left := p.parseTerm()

	for p.curTok.Type == TOKEN_OR {
		p.nextToken() // eat OR
		right := p.parseTerm()
		left = &libraryv1.SearchQuery{
			Node: &libraryv1.SearchQuery_Logical{
				Logical: &libraryv1.LogicalNode{
					Op:    libraryv1.LogicalOp_OR,
					Nodes: []*libraryv1.SearchQuery{left, right},
				},
			},
		}
	}
	return left
}

// Term -> Factor { AND Factor }
func (p *Parser) parseTerm() *libraryv1.SearchQuery {
	left := p.parseFactor()

	for p.curTok.Type == TOKEN_AND {
		p.nextToken() // eat AND
		right := p.parseFactor()
		left = &libraryv1.SearchQuery{
			Node: &libraryv1.SearchQuery_Logical{
				Logical: &libraryv1.LogicalNode{
					Op:    libraryv1.LogicalOp_AND,
					Nodes: []*libraryv1.SearchQuery{left, right},
				},
			},
		}
	}
	return left
}

// Factor -> ( Expr ) | NOT Factor | Filter
func (p *Parser) parseFactor() *libraryv1.SearchQuery {
	switch p.curTok.Type {
	case TOKEN_LPAREN:
		p.nextToken() // eat (
		exp := p.parseExpression()
		if p.curTok.Type != TOKEN_RPAREN {
			fmt.Println("Error: expected )") 
		}
		p.nextToken() // eat )
		return exp

	case TOKEN_NOT:
		p.nextToken() // eat NOT
		right := p.parseFactor()
		return &libraryv1.SearchQuery{
			Node: &libraryv1.SearchQuery_Negation{
				Negation: &libraryv1.NotNode{
					Node: right,
				},
			},
		}
	
	default:
		return p.parseFilter()
	}
}

// Filter -> IDENT [OP] VALUE
func (p *Parser) parseFilter() *libraryv1.SearchQuery {
	if p.curTok.Type == TOKEN_IDENT && (p.peekTok.Type == TOKEN_COLON || p.peekTok.Type == TOKEN_EQUALS || p.peekTok.Type == TOKEN_CONTAINS) {
		field := p.curTok.Value
		p.nextToken() // eat field
		
		var op libraryv1.Operator
		switch p.curTok.Type {
		case TOKEN_COLON:    op = libraryv1.Operator_OP_CONTAINS
		case TOKEN_EQUALS:   op = libraryv1.Operator_OP_EQUALS
		case TOKEN_CONTAINS: op = libraryv1.Operator_OP_CONTAINS
		}
		
		p.nextToken() // eat op
		
		value := p.curTok.Value
		p.nextToken() // eat value

		return &libraryv1.SearchQuery{
			Node: &libraryv1.SearchQuery_Filter{
				Filter: &libraryv1.FilterNode{
					Field:    field,
					Value:    value,
					Operator: op,
				},
			},
		}
	}

	// Implicit "any" search
	val := p.curTok.Value
	p.nextToken()
	
	return &libraryv1.SearchQuery{
		Node: &libraryv1.SearchQuery_Filter{
			Filter: &libraryv1.FilterNode{
				Field:    "any",
				Value:    val,
				Operator: libraryv1.Operator_OP_CONTAINS,
			},
		},
	}
}

--- END_FILE: ./internal/parser/parser.go ---

--- START_FILE: ./internal/logger/logger.go ---
package logger

import (
	"context"
	"time"
	"github.com/sirupsen/logrus"
)

type ctxKey string
const RequestIDKey ctxKey = "requestId"

func init() {
	logrus.SetFormatter(&logrus.TextFormatter{
		FullTimestamp:   true,
		TimestampFormat: "15:04:05",
		ForceColors:     true,
		DisableColors:   false,
	})
}

func For(ctx context.Context) *logrus.Entry {
	id, ok := ctx.Value(RequestIDKey).(string)
	if !ok {
		return logrus.NewEntry(logrus.StandardLogger())
	}
	return logrus.WithField("request_id", id)
}

func ContextWithID(ctx context.Context, id string) context.Context {
	return context.WithValue(ctx, RequestIDKey, id)
}

func Track(ctx context.Context, msg string) func() {
	start := time.Now()
	return func() {
		dur := time.Since(start)
		entry := For(ctx).WithField("duration", dur.String())
		
		if dur > 500*time.Millisecond {
			entry.Warnf("%s completed (SLOW)", msg)
		} else {
			entry.Infof("%s completed", msg)
		}
	}
}

--- END_FILE: ./internal/logger/logger.go ---

--- START_FILE: ./internal/metrics/metrics.go ---
package metrics

import (
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promauto"
)

var (
	HttpRequestsTotal = promauto.NewCounterVec(prometheus.CounterOpts{
		Name: "ebusta_gateway_requests_total",
		Help: "Total number of HTTP requests to gateway",
	}, []string{"method", "path", "status"})

	HttpRequestDuration = promauto.NewHistogramVec(prometheus.HistogramOpts{
		Name:    "ebusta_gateway_request_duration_seconds",
		Help:    "Duration of HTTP requests in seconds",
		Buckets: prometheus.DefBuckets,
	}, []string{"path"})
)

--- END_FILE: ./internal/metrics/metrics.go ---

--- START_FILE: ./internal/storage/datamanager/config/config.go ---
package config

import (
	"time"
	"github.com/kelseyhightower/envconfig"
)

type Config struct {
	BindAddr    string        `env:"BIND_ADDR" default:":8082"`
	OSScheme    string        `env:"OS_SCHEME" default:"http"`
	OSHost      string        `env:"OS_HOST" default:"mercury"`
	OSPort      string        `env:"OS_PORT" default:"9200"`
	OSIndex     string        `env:"OS_INDEX" default:"ebusta"`
	ESUser      string        `env:"ES_USER"`
	ESPass      string        `env:"ES_PASS"`
	HTTPTimeout time.Duration `env:"HTTP_TIMEOUT" default:"5s"`
	LogJSON     bool          `env:"LOG_JSON" default:"false"`
	LogLevel    string        `env:"LOG_LEVEL" default:"INFO"`
	LogPath     string        `env:"LOG_PATH"` // Default is empty, logs to stdout
}

func (c *Config) Validate() error {
	if c.BindAddr == "" {
		return ErrInvalid("bind address is required")
	}
	if c.OSHost == "" || c.OSPort == "" || c.OSIndex == "" {
		return ErrInvalid("OS_HOST/OS_PORT/OS_INDEX are required")
	}
	return nil
}

type invalidErr string
func (e invalidErr) Error() string { return string(e) }
func ErrInvalid(msg string) error { return invalidErr(msg) }

func Load() (Config, error) {
	var cfg Config
	if err := envconfig.Process("", &cfg); err != nil {
		return cfg, err
	}
	return cfg, cfg.Validate()
}

--- END_FILE: ./internal/storage/datamanager/config/config.go ---

--- START_FILE: ./internal/storage/datamanager/delivery/grpc.go ---
package delivery

import (
	"context"
	"ebusta/api/proto/v1"
	"ebusta/internal/logger"
)

type DataManagerServer struct {
	libraryv1.UnimplementedLibraryServiceServer
}

// –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ú–µ—Ç–æ–¥ –¥–æ–ª–∂–µ–Ω –Ω–∞–∑—ã–≤–∞—Ç—å—Å—è SearchBooks, —á—Ç–æ–±—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É
func (s *DataManagerServer) SearchBooks(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
	// –ï—Å–ª–∏ –ª–æ–≥–≥–µ—Ä –µ—â–µ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–Ω—Ç –∏–ª–∏ –∑–∞–≥–ª—É—à–∫—É
	if logger.For(ctx) != nil {
		defer logger.Track(ctx, "Storage: DB Search Operation")()
	}

	// –ú–æ–∫–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∞
	books := []*libraryv1.Book{
		{
			Id:      "101",
			Title:   "The Art of Unix Programming",
			Authors: []string{"Eric S. Raymond"},
		},
	}

	return &libraryv1.SearchResponse{
		Books: books,
		Total: int32(len(books)),
	}, nil
}

func (s *DataManagerServer) GetAuthors(ctx context.Context, req *libraryv1.ListRequest) (*libraryv1.ListResponse, error) {
	return &libraryv1.ListResponse{Items: []string{"King", "Tolkien"}}, nil
}

--- END_FILE: ./internal/storage/datamanager/delivery/grpc.go ---

--- START_FILE: ./internal/storage/datamanager/delivery/handlers.go ---
package delivery

import (
	"ebusta/api/proto/v1"
	"encoding/json"
	"log"
)

func MapOSResponseToGrpc(body []byte) ([]*libraryv1.Book, int32) {
	// Total –≤—ã–Ω–æ—Å–∏–º –≤ interface{}, —Ç–∞–∫ –∫–∞–∫ OS –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –∏ —á–∏—Å–ª–æ, –∏ –æ–±—ä–µ–∫—Ç
	var raw struct {
		Hits struct {
			Total interface{} `json:"total"`
			Hits  []struct {
				ID     string `json:"_id"`
				Source struct {
					Title   string   `json:"title"`
					Authors []string `json:"authors"`
				} `json:"_source"`
			} `json:"hits"`
		} `json:"hits"`
	}

	if err := json.Unmarshal(body, &raw); err != nil {
		log.Printf("‚ùå DataManager Parsing Error: %v", err)
		return nil, 0
	}

	var totalValue int32
	// –ì–∏–±–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ Total (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–±—ä–µ–∫—Ç–∞ –∏ —á–∏—Å–ª–∞)
	switch v := raw.Hits.Total.(type) {
	case float64:
		totalValue = int32(v)
	case map[string]interface{}:
		if val, ok := v["value"].(float64); ok {
			totalValue = int32(val)
		}
	}

	var books []*libraryv1.Book
	for _, h := range raw.Hits.Hits {
		// –ó–∞—â–∏—Ç–∞ –æ—Ç –ø—É—Å—Ç—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤
		authors := h.Source.Authors
		if authors == nil {
			authors = []string{"Unknown"}
		}
		
		books = append(books, &libraryv1.Book{
			Id:      h.ID,
			Title:   h.Source.Title,
			Authors: authors,
		})
	}

	// –ï—Å–ª–∏ —Ö–∏—Ç—ã –µ—Å—Ç—å, –∞ total 0 (–±—ã–≤–∞–µ—Ç –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö OS)
	if totalValue == 0 && len(books) > 0 {
		totalValue = int32(len(books))
	}

	return books, totalValue
}

--- END_FILE: ./internal/storage/datamanager/delivery/handlers.go ---

--- START_FILE: ./internal/storage/datamanager/shaping/shaping.go ---
package shaping

import (
	"encoding/json"
	"fmt"
)

// --- Search shaping ---
type searchHit struct {
	Source struct {
		Title   string   `json:"title"`
		Authors []string `json:"authors"`
		FileInfo struct {
			Container string `json:"container"`
			Filename  string `json:"filename"`
		} `json:"fileInfo"`
	} `json:"_source"`
}
type searchResp struct {
	Hits struct {
		Total struct{ Value int `json:"value"` } `json:"total"`
		Hits  []searchHit `json:"hits"`
	} `json:"hits"`
}

// ShapeSearch flattens OpenSearch hits into a smaller payload.
func ShapeSearch(data []byte, from, size int) ([]byte, error) {
	var r searchResp
	if err := json.Unmarshal(data, &r); err != nil {
		return nil, fmt.Errorf("decode hits: %w", err)
	}
	type item struct {
		Title    string   `json:"title"`
		Authors  []string `json:"authors"`
		Download string   `json:"download,omitempty"`
	}
	out := struct {
		Total    int    `json:"total"`
		From     int    `json:"from"`
		Size     int    `json:"size"`
		NextFrom int    `json:"next_from"`
		Items    []item `json:"items"`
	}{
		Total:    r.Hits.Total.Value,
		From:     from,
		Size:     size,
		NextFrom: from + size,
		Items:    make([]item, 0, len(r.Hits.Hits)), // ensure [] not null
	}
	for _, h := range r.Hits.Hits {
		dl := ""
		if h.Source.FileInfo.Container != "" && h.Source.FileInfo.Filename != "" {
			dl = h.Source.FileInfo.Container + "/" + h.Source.FileInfo.Filename
		}
		out.Items = append(out.Items, item{
			Title:    h.Source.Title,
			Authors:  h.Source.Authors,
			Download: dl,
		})
	}
	return json.MarshalIndent(out, "", "  ")
}

// --- Composite/aggregation shaping (best-effort generic) ---
type composite struct {
	AfterKey any `json:"after_key"`
	Buckets  any `json:"buckets"`
}
type aggResp struct {
	Aggregations map[string]composite `json:"aggregations"`
}

func ShapeComposite(data []byte) ([]byte, error) {
	var r aggResp
	if err := json.Unmarshal(data, &r); err != nil {
		return nil, fmt.Errorf("decode aggregations: %w", err)
	}
	if len(r.Aggregations) == 0 {
		// pass-through
		return data, nil
	}
	// pick first aggregation
	for name, c := range r.Aggregations {
		out := map[string]any{
			"name":       name,
			"buckets":    c.Buckets,
			"after_key":  c.AfterKey,
		}
		return json.MarshalIndent(out, "", "  ")
	}
	return data, nil
}

--- END_FILE: ./internal/storage/datamanager/shaping/shaping.go ---

--- START_FILE: ./internal/storage/datamanager/shaping/shaping_test.go ---
package shaping

import "testing"

func TestShapeSearch(t *testing.T) {
	jsonIn := []byte(`{"hits":{"total":{"value":2},"hits":[{"_source":{"title":"A","authors":["X"],"fileInfo":{"container":"c","filename":"a.fb2"}}},{"_source":{"title":"B","authors":["Y"],"fileInfo":{"container":"d","filename":"b.fb2"}}}]}}`)
	out, err := ShapeSearch(jsonIn, 0, 10)
	if err != nil { t.Fatalf("unexpected error: %v", err) }
	mustContain(t, string(out), `"total": 2`)
	mustContain(t, string(out), `"items": [`)
	mustContain(t, string(out), `"download": "c/a.fb2"`)
}

func mustContain(t *testing.T, s, sub string) {
	t.Helper()
	if !contains(s, sub) { t.Fatalf("expected substring %q in %s", sub, s) }
}

func contains(s, sub string) bool { return len(s) >= len(sub) && (s == sub || (len(sub) > 0 && (stringIndex(s, sub) >= 0))) }
func stringIndex(s, sub string) int {
	for i := 0; i+len(sub) <= len(s); i++ {
		if s[i:i+len(sub)] == sub { return i }
	}
	return -1
}

--- END_FILE: ./internal/storage/datamanager/shaping/shaping_test.go ---

--- START_FILE: ./internal/storage/datamanager/proxy/proxy.go ---
package proxy

import (
	"bytes"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"sync"
	"time"

	"github.com/sirupsen/logrus"

	"ebusta/internal/storage/datamanager/config"
)

type Proxy struct {
	cfg     config.Config
	client  *http.Client
	logger  *logrus.Logger
	baseURL string
	once    sync.Once
}

func New(cfg config.Config, logger *logrus.Logger) *Proxy {
	return &Proxy{
		cfg:    cfg,
		logger: logger,
		client: newHTTPClient(cfg),
	}
}

func newHTTPClient(cfg config.Config) *http.Client {
	t := &http.Transport{
		MaxIdleConns:        100,
		IdleConnTimeout:     90 * time.Second,
		DisableCompression:  false,
		ForceAttemptHTTP2:   true,
	}
	return &http.Client{Transport: t, Timeout: cfg.HTTPTimeout}
}

func (p *Proxy) BaseURL() string {
	p.once.Do(func() {
		p.baseURL = fmt.Sprintf("%s://%s:%s/%s/_search/template", p.cfg.OSScheme, p.cfg.OSHost, p.cfg.OSPort, p.cfg.OSIndex)
	})
	return p.baseURL
}

// Structured error envelope
type ErrorEnvelope struct {
	Error ErrorBody `json:"error"`
}
type ErrorBody struct {
	Code    string      `json:"code"`
	Message string      `json:"message"`
	Details interface{} `json:"details,omitempty"`
}

func WriteError(w http.ResponseWriter, status int, code, message string, details interface{}) {
	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(status)
	_ = json.NewEncoder(w).Encode(ErrorEnvelope{
		Error: ErrorBody{Code: code, Message: message, Details: details},
	})
}

// DoTemplate executes a stored template by id with params.
func (p *Proxy) DoTemplate(ctx context.Context, id string, params map[string]any) ([]byte, int, error) {
	body := map[string]any{
		"id":     id,
		"params": params,
	}
	
	// This now only logs if LOG_LEVEL=DEBUG
	if p.logger.IsLevelEnabled(logrus.DebugLevel) {
		p.logger.WithFields(logrus.Fields{
			"template": id,
			"params":   params,
		}).Debug("os.request") // Changed from Info to Debug
	}
	
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, 0, fmt.Errorf("marshal body: %w", err)
	}

	req, err := http.NewRequestWithContext(ctx, http.MethodPost, p.BaseURL(), bytes.NewReader(buf))
	if err != nil {
		return nil, 0, fmt.Errorf("failed to create request: %w", err)
	}
	req.Header.Set("Content-Type", "application/json")
	if p.cfg.ESUser != "" || p.cfg.ESPass != "" {
		req.SetBasicAuth(p.cfg.ESUser, p.cfg.ESPass)
	}

	res, err := p.client.Do(req)
	if err != nil {
		return nil, 0, fmt.Errorf("upstream do: %w", err)
	}
	defer res.Body.Close()

	data, _ := io.ReadAll(res.Body)
	
	// This now only logs if LOG_LEVEL=DEBUG
	if p.logger.IsLevelEnabled(logrus.DebugLevel) {
		p.logger.WithFields(logrus.Fields{
			"template": id,
			"status": res.StatusCode,
			"response_body": string(data),
		}).Debug("os.response")
	}
	
	return data, res.StatusCode, nil
}

// DecodeAfter supports raw JSON or base64(JSON).
func DecodeAfter(s string) (any, error) {
	if s == "" {
		return nil, nil
	}
	// try raw JSON first
	var v any
	if json.Unmarshal([]byte(s), &v) == nil {
		return v, nil
	}
	// try base64
	b, err := base64.StdEncoding.DecodeString(s)
	if err != nil {
		return nil, fmt.Errorf("invalid after (not json or base64): %w", err)
	}
	if err := json.Unmarshal(b, &v); err != nil {
		return nil, fmt.Errorf("invalid after (bad json): %w", err)
	}
	return v, nil
}

--- END_FILE: ./internal/storage/datamanager/proxy/proxy.go ---

--- START_FILE: ./internal/middleware/logging.go ---
package middleware

import (
	"net/http"
	"time"

	"github.com/sirupsen/logrus"
)

// RequestLogger logs incoming requests at the INFO level.
func RequestLogger(log *logrus.Logger) func(http.Handler) http.Handler {
	return func(next http.Handler) http.Handler {
		return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
			start := time.Now()
			
			// Serve the request
			next.ServeHTTP(w, r)
			
			// Log the request
			log.WithFields(logrus.Fields{
				"method": r.Method,
				"path":   r.URL.Path,
//				"query":  r.URL.RawQuery,
				"query":  r.URL.Query(),
				"remote": r.RemoteAddr,
				"agent":  r.UserAgent(),
				"took":   time.Since(start),
			}).Info("http.request")
		})
	}
}

--- END_FILE: ./internal/middleware/logging.go ---

--- START_FILE: ./internal/middleware/middleware.go ---
package middleware

import (
	"net/http"
	"strings"
)

// CORS allows basic CORS for browser apps.
func CORS(next http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Access-Control-Allow-Origin", "*")
		w.Header().Set("Access-Control-Allow-Methods", "GET,POST,OPTIONS")
		w.Header().Set("Access-Control-Allow-Headers", "Content-Type,Authorization")
		if strings.ToUpper(r.Method) == "OPTIONS" {
			w.WriteHeader(http.StatusNoContent)
			return
		}
		next.ServeHTTP(w, r)
	})
}

--- END_FILE: ./internal/middleware/middleware.go ---

--- START_FILE: ./tests/compliance_runner.go ---
package main

import (
	"context"
	"fmt"
	"log"
	"time"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
	pb "ebusta/grpc/gen/go" 
)

func findFilter(resp *pb.SearchQuery, field string) *pb.FilterNode {
	if f := resp.GetFilter(); f != nil && f.Field == field {
		return f
	}
	if l := resp.GetLogical(); l != nil {
		for _, node := range l.Nodes {
			if f := findFilter(node, field); f != nil {
				return f
			}
		}
	}
	return nil
}

func main() {
	conn, err := grpc.Dial("localhost:50052", grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil { log.Fatalf("Conn failed: %v", err) }
	defer conn.Close()
	client := pb.NewMessageConverterClient(conn)

	tests := []struct {
		name, query, expF, expV string
	}{
		{"UR 1.1 (Numeric ID)", "101", "id", "101"},
		{"UR 1.1 (Default any)", "linux", "any", "linux"},
		{"UR 2.1 (Quoted Author)", "author:\"–°—Ç–∏–≤–µ–Ω –ö–∏–Ω–≥\"", "author", "–°—Ç–∏–≤–µ–Ω –ö–∏–Ω–≥"},
		{"UR 2.1 (Greedy Author)", "author:–°—Ç–∏–≤–µ–Ω –ö–∏–Ω–≥ AND year:2026", "author", "–°—Ç–∏–≤–µ–Ω –ö–∏–Ω–≥"},
	}

	fmt.Println("=== Running Native Go Compliance Tests ===")
	for _, tc := range tests {
		fmt.Printf("[TEST] %-25s... ", tc.name)
		ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
		resp, err := client.Convert(ctx, &pb.ConvertRequest{RawQuery: tc.query})
		cancel()

		if err != nil { fmt.Printf("‚ùå RPC ERROR: %v\n", err); continue }

		f := findFilter(resp, tc.expF)
		if f != nil && f.Value == tc.expV {
			fmt.Println("‚úÖ PASSED")
		} else if f == nil {
			fmt.Printf("‚ùå FAILED (Field %s not found)\n", tc.expF)
		} else {
			fmt.Printf("‚ùå FAILED (Got value '%s', Expected '%s')\n", f.Value, tc.expV)
		}
	}
}

--- END_FILE: ./tests/compliance_runner.go ---

--- START_FILE: ./ebusta.yaml ---
datamanager:
  opensearch_url: "http://cloud-1:9200"
  index_name: "flibusta_merged_index"
  debug: true

orchestrator:
  storage_addr: "localhost:50051"
  processor_addr: "localhost:50053"

web:
  port: 8080

--- END_FILE: ./ebusta.yaml ---

--- START_FILE: ./api/proto/v1/library_simple.proto ---
syntax = "proto2";

package libraryv1;

message FilterNode {
  optional string field = 1;
  optional string value = 2;
  optional int32 operator = 3;
}

message LogicalNode {
  repeated SearchQuery nodes = 1;
}

message NotNode {
  optional SearchQuery node = 1;
}

message SearchQuery {
  optional FilterNode filter = 1;
  optional LogicalNode logical = 2;
  optional NotNode negation = 3;
}

--- END_FILE: ./api/proto/v1/library_simple.proto ---

--- START_FILE: ./api/proto/v1/auth.proto ---
syntax = "proto3";

package libraryv1;

option go_package = "ebusta/api/proto/v1;libraryv1";

service AuthService {
  // –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
  rpc CheckAccess (AccessRequest) returns (AccessResponse);
}

message AccessRequest {
  string user_id = 1;      // ID (–Ω–∞–ø—Ä–∏–º–µ—Ä, Telegram UID –∏–ª–∏ –Ω–∏–∫ –≤ BBS)
  string platform = 2;     // –ò—Å—Ç–æ—á–Ω–∏–∫ (web, telegram, cli, bbs)
  string trace_id = 3;     // –î–ª—è —Å–∫–≤–æ–∑–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
}

message AccessResponse {
  bool allowed = 1;        // –†–∞–∑—Ä–µ—à–µ–Ω –ª–∏ –≤—Ö–æ–¥
  string reason = 2;       // –ü—Ä–∏—á–∏–Ω–∞ –æ—Ç–∫–∞–∑–∞
  string user_role = 3;    // –†–æ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (admin, family, guest)
}

--- END_FILE: ./api/proto/v1/auth.proto ---

--- START_FILE: ./api/proto/v1/library_grpc.pb.go ---
// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
// versions:
// - protoc-gen-go-grpc v1.6.0
// - protoc             v3.21.12
// source: api/proto/v1/library.proto

package libraryv1

import (
	context "context"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.64.0 or later.
const _ = grpc.SupportPackageIsVersion9

const (
	OrchestratorService_Search_FullMethodName = "/libraryv1.OrchestratorService/Search"
)

// OrchestratorServiceClient is the client API for OrchestratorService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type OrchestratorServiceClient interface {
	Search(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
}

type orchestratorServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewOrchestratorServiceClient(cc grpc.ClientConnInterface) OrchestratorServiceClient {
	return &orchestratorServiceClient{cc}
}

func (c *orchestratorServiceClient) Search(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(SearchResponse)
	err := c.cc.Invoke(ctx, OrchestratorService_Search_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// OrchestratorServiceServer is the server API for OrchestratorService service.
// All implementations must embed UnimplementedOrchestratorServiceServer
// for forward compatibility.
type OrchestratorServiceServer interface {
	Search(context.Context, *SearchRequest) (*SearchResponse, error)
	mustEmbedUnimplementedOrchestratorServiceServer()
}

// UnimplementedOrchestratorServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedOrchestratorServiceServer struct{}

func (UnimplementedOrchestratorServiceServer) Search(context.Context, *SearchRequest) (*SearchResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method Search not implemented")
}
func (UnimplementedOrchestratorServiceServer) mustEmbedUnimplementedOrchestratorServiceServer() {}
func (UnimplementedOrchestratorServiceServer) testEmbeddedByValue()                             {}

// UnsafeOrchestratorServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to OrchestratorServiceServer will
// result in compilation errors.
type UnsafeOrchestratorServiceServer interface {
	mustEmbedUnimplementedOrchestratorServiceServer()
}

func RegisterOrchestratorServiceServer(s grpc.ServiceRegistrar, srv OrchestratorServiceServer) {
	// If the following call panics, it indicates UnimplementedOrchestratorServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&OrchestratorService_ServiceDesc, srv)
}

func _OrchestratorService_Search_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SearchRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(OrchestratorServiceServer).Search(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: OrchestratorService_Search_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(OrchestratorServiceServer).Search(ctx, req.(*SearchRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// OrchestratorService_ServiceDesc is the grpc.ServiceDesc for OrchestratorService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var OrchestratorService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "libraryv1.OrchestratorService",
	HandlerType: (*OrchestratorServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Search",
			Handler:    _OrchestratorService_Search_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "api/proto/v1/library.proto",
}

const (
	ProcessorService_Process_FullMethodName = "/libraryv1.ProcessorService/Process"
)

// ProcessorServiceClient is the client API for ProcessorService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type ProcessorServiceClient interface {
	Process(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
}

type processorServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewProcessorServiceClient(cc grpc.ClientConnInterface) ProcessorServiceClient {
	return &processorServiceClient{cc}
}

func (c *processorServiceClient) Process(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(SearchResponse)
	err := c.cc.Invoke(ctx, ProcessorService_Process_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// ProcessorServiceServer is the server API for ProcessorService service.
// All implementations must embed UnimplementedProcessorServiceServer
// for forward compatibility.
type ProcessorServiceServer interface {
	Process(context.Context, *SearchRequest) (*SearchResponse, error)
	mustEmbedUnimplementedProcessorServiceServer()
}

// UnimplementedProcessorServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedProcessorServiceServer struct{}

func (UnimplementedProcessorServiceServer) Process(context.Context, *SearchRequest) (*SearchResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method Process not implemented")
}
func (UnimplementedProcessorServiceServer) mustEmbedUnimplementedProcessorServiceServer() {}
func (UnimplementedProcessorServiceServer) testEmbeddedByValue()                          {}

// UnsafeProcessorServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to ProcessorServiceServer will
// result in compilation errors.
type UnsafeProcessorServiceServer interface {
	mustEmbedUnimplementedProcessorServiceServer()
}

func RegisterProcessorServiceServer(s grpc.ServiceRegistrar, srv ProcessorServiceServer) {
	// If the following call panics, it indicates UnimplementedProcessorServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&ProcessorService_ServiceDesc, srv)
}

func _ProcessorService_Process_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SearchRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ProcessorServiceServer).Process(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: ProcessorService_Process_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ProcessorServiceServer).Process(ctx, req.(*SearchRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// ProcessorService_ServiceDesc is the grpc.ServiceDesc for ProcessorService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var ProcessorService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "libraryv1.ProcessorService",
	HandlerType: (*ProcessorServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Process",
			Handler:    _ProcessorService_Process_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "api/proto/v1/library.proto",
}

const (
	StorageService_SearchBooks_FullMethodName = "/libraryv1.StorageService/SearchBooks"
)

// StorageServiceClient is the client API for StorageService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type StorageServiceClient interface {
	SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
}

type storageServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewStorageServiceClient(cc grpc.ClientConnInterface) StorageServiceClient {
	return &storageServiceClient{cc}
}

func (c *storageServiceClient) SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(SearchResponse)
	err := c.cc.Invoke(ctx, StorageService_SearchBooks_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// StorageServiceServer is the server API for StorageService service.
// All implementations must embed UnimplementedStorageServiceServer
// for forward compatibility.
type StorageServiceServer interface {
	SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error)
	mustEmbedUnimplementedStorageServiceServer()
}

// UnimplementedStorageServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedStorageServiceServer struct{}

func (UnimplementedStorageServiceServer) SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method SearchBooks not implemented")
}
func (UnimplementedStorageServiceServer) mustEmbedUnimplementedStorageServiceServer() {}
func (UnimplementedStorageServiceServer) testEmbeddedByValue()                        {}

// UnsafeStorageServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to StorageServiceServer will
// result in compilation errors.
type UnsafeStorageServiceServer interface {
	mustEmbedUnimplementedStorageServiceServer()
}

func RegisterStorageServiceServer(s grpc.ServiceRegistrar, srv StorageServiceServer) {
	// If the following call panics, it indicates UnimplementedStorageServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&StorageService_ServiceDesc, srv)
}

func _StorageService_SearchBooks_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SearchRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(StorageServiceServer).SearchBooks(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: StorageService_SearchBooks_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(StorageServiceServer).SearchBooks(ctx, req.(*SearchRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// StorageService_ServiceDesc is the grpc.ServiceDesc for StorageService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var StorageService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "libraryv1.StorageService",
	HandlerType: (*StorageServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "SearchBooks",
			Handler:    _StorageService_SearchBooks_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "api/proto/v1/library.proto",
}

const (
	AuthService_CheckAccess_FullMethodName = "/libraryv1.AuthService/CheckAccess"
)

// AuthServiceClient is the client API for AuthService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type AuthServiceClient interface {
	CheckAccess(ctx context.Context, in *AccessRequest, opts ...grpc.CallOption) (*AccessResponse, error)
}

type authServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewAuthServiceClient(cc grpc.ClientConnInterface) AuthServiceClient {
	return &authServiceClient{cc}
}

func (c *authServiceClient) CheckAccess(ctx context.Context, in *AccessRequest, opts ...grpc.CallOption) (*AccessResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(AccessResponse)
	err := c.cc.Invoke(ctx, AuthService_CheckAccess_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// AuthServiceServer is the server API for AuthService service.
// All implementations must embed UnimplementedAuthServiceServer
// for forward compatibility.
type AuthServiceServer interface {
	CheckAccess(context.Context, *AccessRequest) (*AccessResponse, error)
	mustEmbedUnimplementedAuthServiceServer()
}

// UnimplementedAuthServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedAuthServiceServer struct{}

func (UnimplementedAuthServiceServer) CheckAccess(context.Context, *AccessRequest) (*AccessResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method CheckAccess not implemented")
}
func (UnimplementedAuthServiceServer) mustEmbedUnimplementedAuthServiceServer() {}
func (UnimplementedAuthServiceServer) testEmbeddedByValue()                     {}

// UnsafeAuthServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to AuthServiceServer will
// result in compilation errors.
type UnsafeAuthServiceServer interface {
	mustEmbedUnimplementedAuthServiceServer()
}

func RegisterAuthServiceServer(s grpc.ServiceRegistrar, srv AuthServiceServer) {
	// If the following call panics, it indicates UnimplementedAuthServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&AuthService_ServiceDesc, srv)
}

func _AuthService_CheckAccess_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(AccessRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(AuthServiceServer).CheckAccess(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: AuthService_CheckAccess_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(AuthServiceServer).CheckAccess(ctx, req.(*AccessRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// AuthService_ServiceDesc is the grpc.ServiceDesc for AuthService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var AuthService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "libraryv1.AuthService",
	HandlerType: (*AuthServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "CheckAccess",
			Handler:    _AuthService_CheckAccess_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "api/proto/v1/library.proto",
}

const (
	MessageConverterService_Convert_FullMethodName = "/libraryv1.MessageConverterService/Convert"
)

// MessageConverterServiceClient is the client API for MessageConverterService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type MessageConverterServiceClient interface {
	Convert(ctx context.Context, in *RawInput, opts ...grpc.CallOption) (*UnmarshaledMessage, error)
}

type messageConverterServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewMessageConverterServiceClient(cc grpc.ClientConnInterface) MessageConverterServiceClient {
	return &messageConverterServiceClient{cc}
}

func (c *messageConverterServiceClient) Convert(ctx context.Context, in *RawInput, opts ...grpc.CallOption) (*UnmarshaledMessage, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(UnmarshaledMessage)
	err := c.cc.Invoke(ctx, MessageConverterService_Convert_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// MessageConverterServiceServer is the server API for MessageConverterService service.
// All implementations must embed UnimplementedMessageConverterServiceServer
// for forward compatibility.
type MessageConverterServiceServer interface {
	Convert(context.Context, *RawInput) (*UnmarshaledMessage, error)
	mustEmbedUnimplementedMessageConverterServiceServer()
}

// UnimplementedMessageConverterServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedMessageConverterServiceServer struct{}

func (UnimplementedMessageConverterServiceServer) Convert(context.Context, *RawInput) (*UnmarshaledMessage, error) {
	return nil, status.Error(codes.Unimplemented, "method Convert not implemented")
}
func (UnimplementedMessageConverterServiceServer) mustEmbedUnimplementedMessageConverterServiceServer() {
}
func (UnimplementedMessageConverterServiceServer) testEmbeddedByValue() {}

// UnsafeMessageConverterServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to MessageConverterServiceServer will
// result in compilation errors.
type UnsafeMessageConverterServiceServer interface {
	mustEmbedUnimplementedMessageConverterServiceServer()
}

func RegisterMessageConverterServiceServer(s grpc.ServiceRegistrar, srv MessageConverterServiceServer) {
	// If the following call panics, it indicates UnimplementedMessageConverterServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&MessageConverterService_ServiceDesc, srv)
}

func _MessageConverterService_Convert_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(RawInput)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(MessageConverterServiceServer).Convert(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: MessageConverterService_Convert_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(MessageConverterServiceServer).Convert(ctx, req.(*RawInput))
	}
	return interceptor(ctx, in, info, handler)
}

// MessageConverterService_ServiceDesc is the grpc.ServiceDesc for MessageConverterService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var MessageConverterService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "libraryv1.MessageConverterService",
	HandlerType: (*MessageConverterServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Convert",
			Handler:    _MessageConverterService_Convert_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "api/proto/v1/library.proto",
}

const (
	LibraryService_SearchBooks_FullMethodName = "/libraryv1.LibraryService/SearchBooks"
	LibraryService_GetAuthors_FullMethodName  = "/libraryv1.LibraryService/GetAuthors"
)

// LibraryServiceClient is the client API for LibraryService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
//
// Legacy
type LibraryServiceClient interface {
	SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error)
	GetAuthors(ctx context.Context, in *ListRequest, opts ...grpc.CallOption) (*ListResponse, error)
}

type libraryServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewLibraryServiceClient(cc grpc.ClientConnInterface) LibraryServiceClient {
	return &libraryServiceClient{cc}
}

func (c *libraryServiceClient) SearchBooks(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(SearchResponse)
	err := c.cc.Invoke(ctx, LibraryService_SearchBooks_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *libraryServiceClient) GetAuthors(ctx context.Context, in *ListRequest, opts ...grpc.CallOption) (*ListResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(ListResponse)
	err := c.cc.Invoke(ctx, LibraryService_GetAuthors_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// LibraryServiceServer is the server API for LibraryService service.
// All implementations must embed UnimplementedLibraryServiceServer
// for forward compatibility.
//
// Legacy
type LibraryServiceServer interface {
	SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error)
	GetAuthors(context.Context, *ListRequest) (*ListResponse, error)
	mustEmbedUnimplementedLibraryServiceServer()
}

// UnimplementedLibraryServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedLibraryServiceServer struct{}

func (UnimplementedLibraryServiceServer) SearchBooks(context.Context, *SearchRequest) (*SearchResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method SearchBooks not implemented")
}
func (UnimplementedLibraryServiceServer) GetAuthors(context.Context, *ListRequest) (*ListResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method GetAuthors not implemented")
}
func (UnimplementedLibraryServiceServer) mustEmbedUnimplementedLibraryServiceServer() {}
func (UnimplementedLibraryServiceServer) testEmbeddedByValue()                        {}

// UnsafeLibraryServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to LibraryServiceServer will
// result in compilation errors.
type UnsafeLibraryServiceServer interface {
	mustEmbedUnimplementedLibraryServiceServer()
}

func RegisterLibraryServiceServer(s grpc.ServiceRegistrar, srv LibraryServiceServer) {
	// If the following call panics, it indicates UnimplementedLibraryServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&LibraryService_ServiceDesc, srv)
}

func _LibraryService_SearchBooks_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SearchRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(LibraryServiceServer).SearchBooks(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: LibraryService_SearchBooks_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(LibraryServiceServer).SearchBooks(ctx, req.(*SearchRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _LibraryService_GetAuthors_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ListRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(LibraryServiceServer).GetAuthors(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: LibraryService_GetAuthors_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(LibraryServiceServer).GetAuthors(ctx, req.(*ListRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// LibraryService_ServiceDesc is the grpc.ServiceDesc for LibraryService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var LibraryService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "libraryv1.LibraryService",
	HandlerType: (*LibraryServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "SearchBooks",
			Handler:    _LibraryService_SearchBooks_Handler,
		},
		{
			MethodName: "GetAuthors",
			Handler:    _LibraryService_GetAuthors_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "api/proto/v1/library.proto",
}

--- END_FILE: ./api/proto/v1/library_grpc.pb.go ---

--- START_FILE: ./api/proto/v1/lisp_library.proto ---
syntax = "proto3";
package libraryv1;

message FilterNode {
  string field = 1;
  string value = 2;
  int32 operator = 3;
}

message LogicalNode {
  repeated SearchQuery nodes = 1;
}

message NotNode {
  SearchQuery node = 1;
}

message SearchQuery {
  FilterNode filter = 1;
  LogicalNode logical = 2;
  NotNode negation = 3;
}

--- END_FILE: ./api/proto/v1/lisp_library.proto ---

--- START_FILE: ./api/proto/v1/library.pb.go ---
// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v3.21.12
// source: api/proto/v1/library.proto

package libraryv1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type LogicalOp int32

const (
	LogicalOp_AND LogicalOp = 0
	LogicalOp_OR  LogicalOp = 1
	LogicalOp_NOT LogicalOp = 2
)

// Enum value maps for LogicalOp.
var (
	LogicalOp_name = map[int32]string{
		0: "AND",
		1: "OR",
		2: "NOT",
	}
	LogicalOp_value = map[string]int32{
		"AND": 0,
		"OR":  1,
		"NOT": 2,
	}
)

func (x LogicalOp) Enum() *LogicalOp {
	p := new(LogicalOp)
	*p = x
	return p
}

func (x LogicalOp) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (LogicalOp) Descriptor() protoreflect.EnumDescriptor {
	return file_api_proto_v1_library_proto_enumTypes[0].Descriptor()
}

func (LogicalOp) Type() protoreflect.EnumType {
	return &file_api_proto_v1_library_proto_enumTypes[0]
}

func (x LogicalOp) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use LogicalOp.Descriptor instead.
func (LogicalOp) EnumDescriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{0}
}

type Operator int32

const (
	Operator_OP_EQUALS   Operator = 0
	Operator_OP_CONTAINS Operator = 1
	Operator_OP_REGEX    Operator = 2
)

// Enum value maps for Operator.
var (
	Operator_name = map[int32]string{
		0: "OP_EQUALS",
		1: "OP_CONTAINS",
		2: "OP_REGEX",
	}
	Operator_value = map[string]int32{
		"OP_EQUALS":   0,
		"OP_CONTAINS": 1,
		"OP_REGEX":    2,
	}
)

func (x Operator) Enum() *Operator {
	p := new(Operator)
	*p = x
	return p
}

func (x Operator) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Operator) Descriptor() protoreflect.EnumDescriptor {
	return file_api_proto_v1_library_proto_enumTypes[1].Descriptor()
}

func (Operator) Type() protoreflect.EnumType {
	return &file_api_proto_v1_library_proto_enumTypes[1]
}

func (x Operator) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Operator.Descriptor instead.
func (Operator) EnumDescriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{1}
}

type SearchRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Query         string                 `protobuf:"bytes,1,opt,name=query,proto3" json:"query,omitempty"`
	TemplateId    string                 `protobuf:"bytes,2,opt,name=template_id,json=templateId,proto3" json:"template_id,omitempty"`
	Limit         int32                  `protobuf:"varint,3,opt,name=limit,proto3" json:"limit,omitempty"`
	Offset        int32                  `protobuf:"varint,4,opt,name=offset,proto3" json:"offset,omitempty"`
	TraceId       string                 `protobuf:"bytes,5,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SearchRequest) Reset() {
	*x = SearchRequest{}
	mi := &file_api_proto_v1_library_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SearchRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SearchRequest) ProtoMessage() {}

func (x *SearchRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SearchRequest.ProtoReflect.Descriptor instead.
func (*SearchRequest) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{0}
}

func (x *SearchRequest) GetQuery() string {
	if x != nil {
		return x.Query
	}
	return ""
}

func (x *SearchRequest) GetTemplateId() string {
	if x != nil {
		return x.TemplateId
	}
	return ""
}

func (x *SearchRequest) GetLimit() int32 {
	if x != nil {
		return x.Limit
	}
	return 0
}

func (x *SearchRequest) GetOffset() int32 {
	if x != nil {
		return x.Offset
	}
	return 0
}

func (x *SearchRequest) GetTraceId() string {
	if x != nil {
		return x.TraceId
	}
	return ""
}

type SearchResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Status        string                 `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
	Total         int32                  `protobuf:"varint,2,opt,name=total,proto3" json:"total,omitempty"`
	Books         []*Book                `protobuf:"bytes,3,rep,name=books,proto3" json:"books,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SearchResponse) Reset() {
	*x = SearchResponse{}
	mi := &file_api_proto_v1_library_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SearchResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SearchResponse) ProtoMessage() {}

func (x *SearchResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SearchResponse.ProtoReflect.Descriptor instead.
func (*SearchResponse) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{1}
}

func (x *SearchResponse) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *SearchResponse) GetTotal() int32 {
	if x != nil {
		return x.Total
	}
	return 0
}

func (x *SearchResponse) GetBooks() []*Book {
	if x != nil {
		return x.Books
	}
	return nil
}

type Book struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	Title         string                 `protobuf:"bytes,2,opt,name=title,proto3" json:"title,omitempty"`
	Authors       []string               `protobuf:"bytes,3,rep,name=authors,proto3" json:"authors,omitempty"`
	Container     string                 `protobuf:"bytes,4,opt,name=container,proto3" json:"container,omitempty"`
	Filename      string                 `protobuf:"bytes,5,opt,name=filename,proto3" json:"filename,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Book) Reset() {
	*x = Book{}
	mi := &file_api_proto_v1_library_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Book) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Book) ProtoMessage() {}

func (x *Book) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Book.ProtoReflect.Descriptor instead.
func (*Book) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{2}
}

func (x *Book) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *Book) GetTitle() string {
	if x != nil {
		return x.Title
	}
	return ""
}

func (x *Book) GetAuthors() []string {
	if x != nil {
		return x.Authors
	}
	return nil
}

func (x *Book) GetContainer() string {
	if x != nil {
		return x.Container
	}
	return ""
}

func (x *Book) GetFilename() string {
	if x != nil {
		return x.Filename
	}
	return ""
}

type ListRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Query         string                 `protobuf:"bytes,1,opt,name=query,proto3" json:"query,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListRequest) Reset() {
	*x = ListRequest{}
	mi := &file_api_proto_v1_library_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListRequest) ProtoMessage() {}

func (x *ListRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListRequest.ProtoReflect.Descriptor instead.
func (*ListRequest) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{3}
}

func (x *ListRequest) GetQuery() string {
	if x != nil {
		return x.Query
	}
	return ""
}

type ListResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Items         []string               `protobuf:"bytes,1,rep,name=items,proto3" json:"items,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListResponse) Reset() {
	*x = ListResponse{}
	mi := &file_api_proto_v1_library_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListResponse) ProtoMessage() {}

func (x *ListResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListResponse.ProtoReflect.Descriptor instead.
func (*ListResponse) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{4}
}

func (x *ListResponse) GetItems() []string {
	if x != nil {
		return x.Items
	}
	return nil
}

type AccessRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	UserId        string                 `protobuf:"bytes,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`
	Platform      string                 `protobuf:"bytes,2,opt,name=platform,proto3" json:"platform,omitempty"`
	TraceId       string                 `protobuf:"bytes,3,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AccessRequest) Reset() {
	*x = AccessRequest{}
	mi := &file_api_proto_v1_library_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AccessRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AccessRequest) ProtoMessage() {}

func (x *AccessRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AccessRequest.ProtoReflect.Descriptor instead.
func (*AccessRequest) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{5}
}

func (x *AccessRequest) GetUserId() string {
	if x != nil {
		return x.UserId
	}
	return ""
}

func (x *AccessRequest) GetPlatform() string {
	if x != nil {
		return x.Platform
	}
	return ""
}

func (x *AccessRequest) GetTraceId() string {
	if x != nil {
		return x.TraceId
	}
	return ""
}

type AccessResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Allowed       bool                   `protobuf:"varint,1,opt,name=allowed,proto3" json:"allowed,omitempty"`
	Reason        string                 `protobuf:"bytes,2,opt,name=reason,proto3" json:"reason,omitempty"`
	UserRole      string                 `protobuf:"bytes,3,opt,name=user_role,json=userRole,proto3" json:"user_role,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AccessResponse) Reset() {
	*x = AccessResponse{}
	mi := &file_api_proto_v1_library_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AccessResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AccessResponse) ProtoMessage() {}

func (x *AccessResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AccessResponse.ProtoReflect.Descriptor instead.
func (*AccessResponse) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{6}
}

func (x *AccessResponse) GetAllowed() bool {
	if x != nil {
		return x.Allowed
	}
	return false
}

func (x *AccessResponse) GetReason() string {
	if x != nil {
		return x.Reason
	}
	return ""
}

func (x *AccessResponse) GetUserRole() string {
	if x != nil {
		return x.UserRole
	}
	return ""
}

type RawInput struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–æ –≤ 'data', —á—Ç–æ–±—ã –ø–æ—è–≤–∏–ª—Å—è –º–µ—Ç–æ–¥ GetData(), –∫–æ—Ç–æ—Ä—ã–π –∂–¥–µ—Ç message-converter
	Data          string `protobuf:"bytes,1,opt,name=data,proto3" json:"data,omitempty"`
	TraceId       string `protobuf:"bytes,2,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RawInput) Reset() {
	*x = RawInput{}
	mi := &file_api_proto_v1_library_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RawInput) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RawInput) ProtoMessage() {}

func (x *RawInput) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RawInput.ProtoReflect.Descriptor instead.
func (*RawInput) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{7}
}

func (x *RawInput) GetData() string {
	if x != nil {
		return x.Data
	}
	return ""
}

func (x *RawInput) GetTraceId() string {
	if x != nil {
		return x.TraceId
	}
	return ""
}

type MessageMeta struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	TraceId       string                 `protobuf:"bytes,1,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
	CanonicalForm string                 `protobuf:"bytes,2,opt,name=canonical_form,json=canonicalForm,proto3" json:"canonical_form,omitempty"`
	Platform      string                 `protobuf:"bytes,3,opt,name=platform,proto3" json:"platform,omitempty"`
	UserId        string                 `protobuf:"bytes,4,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`
	// –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –¥–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ–ª–µ, –∫–æ—Ç–æ—Ä–æ–µ —Ç—Ä–µ–±—É–µ—Ç message-converter
	AstPlan       string `protobuf:"bytes,5,opt,name=ast_plan,json=astPlan,proto3" json:"ast_plan,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MessageMeta) Reset() {
	*x = MessageMeta{}
	mi := &file_api_proto_v1_library_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MessageMeta) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MessageMeta) ProtoMessage() {}

func (x *MessageMeta) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MessageMeta.ProtoReflect.Descriptor instead.
func (*MessageMeta) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{8}
}

func (x *MessageMeta) GetTraceId() string {
	if x != nil {
		return x.TraceId
	}
	return ""
}

func (x *MessageMeta) GetCanonicalForm() string {
	if x != nil {
		return x.CanonicalForm
	}
	return ""
}

func (x *MessageMeta) GetPlatform() string {
	if x != nil {
		return x.Platform
	}
	return ""
}

func (x *MessageMeta) GetUserId() string {
	if x != nil {
		return x.UserId
	}
	return ""
}

func (x *MessageMeta) GetAstPlan() string {
	if x != nil {
		return x.AstPlan
	}
	return ""
}

type UnmarshaledMessage struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Meta          *MessageMeta           `protobuf:"bytes,1,opt,name=meta,proto3" json:"meta,omitempty"`
	Query         *SearchQuery           `protobuf:"bytes,2,opt,name=query,proto3" json:"query,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UnmarshaledMessage) Reset() {
	*x = UnmarshaledMessage{}
	mi := &file_api_proto_v1_library_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UnmarshaledMessage) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UnmarshaledMessage) ProtoMessage() {}

func (x *UnmarshaledMessage) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UnmarshaledMessage.ProtoReflect.Descriptor instead.
func (*UnmarshaledMessage) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{9}
}

func (x *UnmarshaledMessage) GetMeta() *MessageMeta {
	if x != nil {
		return x.Meta
	}
	return nil
}

func (x *UnmarshaledMessage) GetQuery() *SearchQuery {
	if x != nil {
		return x.Query
	}
	return nil
}

type Response struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Status        string                 `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
	Books         []*Book                `protobuf:"bytes,2,rep,name=books,proto3" json:"books,omitempty"`
	Meta          *ResponseMeta          `protobuf:"bytes,3,opt,name=meta,proto3" json:"meta,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Response) Reset() {
	*x = Response{}
	mi := &file_api_proto_v1_library_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Response) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Response) ProtoMessage() {}

func (x *Response) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Response.ProtoReflect.Descriptor instead.
func (*Response) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{10}
}

func (x *Response) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *Response) GetBooks() []*Book {
	if x != nil {
		return x.Books
	}
	return nil
}

func (x *Response) GetMeta() *ResponseMeta {
	if x != nil {
		return x.Meta
	}
	return nil
}

type ResponseMeta struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	TraceId       string                 `protobuf:"bytes,1,opt,name=trace_id,json=traceId,proto3" json:"trace_id,omitempty"`
	CanonicalForm string                 `protobuf:"bytes,2,opt,name=canonical_form,json=canonicalForm,proto3" json:"canonical_form,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ResponseMeta) Reset() {
	*x = ResponseMeta{}
	mi := &file_api_proto_v1_library_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ResponseMeta) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ResponseMeta) ProtoMessage() {}

func (x *ResponseMeta) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ResponseMeta.ProtoReflect.Descriptor instead.
func (*ResponseMeta) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{11}
}

func (x *ResponseMeta) GetTraceId() string {
	if x != nil {
		return x.TraceId
	}
	return ""
}

func (x *ResponseMeta) GetCanonicalForm() string {
	if x != nil {
		return x.CanonicalForm
	}
	return ""
}

type SearchQuery struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Node:
	//
	//	*SearchQuery_Filter
	//	*SearchQuery_Logical
	//	*SearchQuery_Negation
	Node          isSearchQuery_Node `protobuf_oneof:"node"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SearchQuery) Reset() {
	*x = SearchQuery{}
	mi := &file_api_proto_v1_library_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SearchQuery) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SearchQuery) ProtoMessage() {}

func (x *SearchQuery) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SearchQuery.ProtoReflect.Descriptor instead.
func (*SearchQuery) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{12}
}

func (x *SearchQuery) GetNode() isSearchQuery_Node {
	if x != nil {
		return x.Node
	}
	return nil
}

func (x *SearchQuery) GetFilter() *FilterNode {
	if x != nil {
		if x, ok := x.Node.(*SearchQuery_Filter); ok {
			return x.Filter
		}
	}
	return nil
}

func (x *SearchQuery) GetLogical() *LogicalNode {
	if x != nil {
		if x, ok := x.Node.(*SearchQuery_Logical); ok {
			return x.Logical
		}
	}
	return nil
}

func (x *SearchQuery) GetNegation() *NotNode {
	if x != nil {
		if x, ok := x.Node.(*SearchQuery_Negation); ok {
			return x.Negation
		}
	}
	return nil
}

type isSearchQuery_Node interface {
	isSearchQuery_Node()
}

type SearchQuery_Filter struct {
	Filter *FilterNode `protobuf:"bytes,1,opt,name=filter,proto3,oneof"`
}

type SearchQuery_Logical struct {
	Logical *LogicalNode `protobuf:"bytes,2,opt,name=logical,proto3,oneof"`
}

type SearchQuery_Negation struct {
	Negation *NotNode `protobuf:"bytes,3,opt,name=negation,proto3,oneof"`
}

func (*SearchQuery_Filter) isSearchQuery_Node() {}

func (*SearchQuery_Logical) isSearchQuery_Node() {}

func (*SearchQuery_Negation) isSearchQuery_Node() {}

type FilterNode struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Field         string                 `protobuf:"bytes,1,opt,name=field,proto3" json:"field,omitempty"`
	Value         string                 `protobuf:"bytes,2,opt,name=value,proto3" json:"value,omitempty"`
	Operator      Operator               `protobuf:"varint,3,opt,name=operator,proto3,enum=libraryv1.Operator" json:"operator,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FilterNode) Reset() {
	*x = FilterNode{}
	mi := &file_api_proto_v1_library_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FilterNode) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FilterNode) ProtoMessage() {}

func (x *FilterNode) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FilterNode.ProtoReflect.Descriptor instead.
func (*FilterNode) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{13}
}

func (x *FilterNode) GetField() string {
	if x != nil {
		return x.Field
	}
	return ""
}

func (x *FilterNode) GetValue() string {
	if x != nil {
		return x.Value
	}
	return ""
}

func (x *FilterNode) GetOperator() Operator {
	if x != nil {
		return x.Operator
	}
	return Operator_OP_EQUALS
}

type LogicalNode struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Op            LogicalOp              `protobuf:"varint,1,opt,name=op,proto3,enum=libraryv1.LogicalOp" json:"op,omitempty"`
	Nodes         []*SearchQuery         `protobuf:"bytes,2,rep,name=nodes,proto3" json:"nodes,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LogicalNode) Reset() {
	*x = LogicalNode{}
	mi := &file_api_proto_v1_library_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LogicalNode) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LogicalNode) ProtoMessage() {}

func (x *LogicalNode) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LogicalNode.ProtoReflect.Descriptor instead.
func (*LogicalNode) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{14}
}

func (x *LogicalNode) GetOp() LogicalOp {
	if x != nil {
		return x.Op
	}
	return LogicalOp_AND
}

func (x *LogicalNode) GetNodes() []*SearchQuery {
	if x != nil {
		return x.Nodes
	}
	return nil
}

type NotNode struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// –í–∞–∂–Ω–æ: –∏–º—è –ø–æ–ª—è 'node' –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–µ 'Node' –≤ Go —Å—Ç—Ä—É–∫—Ç—É—Ä–µ, —á—Ç–æ –Ω—É–∂–Ω–æ –ø–∞—Ä—Å–µ—Ä—É
	Node          *SearchQuery `protobuf:"bytes,1,opt,name=node,proto3" json:"node,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *NotNode) Reset() {
	*x = NotNode{}
	mi := &file_api_proto_v1_library_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *NotNode) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*NotNode) ProtoMessage() {}

func (x *NotNode) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_v1_library_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use NotNode.ProtoReflect.Descriptor instead.
func (*NotNode) Descriptor() ([]byte, []int) {
	return file_api_proto_v1_library_proto_rawDescGZIP(), []int{15}
}

func (x *NotNode) GetNode() *SearchQuery {
	if x != nil {
		return x.Node
	}
	return nil
}

var File_api_proto_v1_library_proto protoreflect.FileDescriptor

const file_api_proto_v1_library_proto_rawDesc = "" +
	"\n" +
	"\x1aapi/proto/v1/library.proto\x12\tlibraryv1\"\x8f\x01\n" +
	"\rSearchRequest\x12\x14\n" +
	"\x05query\x18\x01 \x01(\tR\x05query\x12\x1f\n" +
	"\vtemplate_id\x18\x02 \x01(\tR\n" +
	"templateId\x12\x14\n" +
	"\x05limit\x18\x03 \x01(\x05R\x05limit\x12\x16\n" +
	"\x06offset\x18\x04 \x01(\x05R\x06offset\x12\x19\n" +
	"\btrace_id\x18\x05 \x01(\tR\atraceId\"e\n" +
	"\x0eSearchResponse\x12\x16\n" +
	"\x06status\x18\x01 \x01(\tR\x06status\x12\x14\n" +
	"\x05total\x18\x02 \x01(\x05R\x05total\x12%\n" +
	"\x05books\x18\x03 \x03(\v2\x0f.libraryv1.BookR\x05books\"\x80\x01\n" +
	"\x04Book\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12\x14\n" +
	"\x05title\x18\x02 \x01(\tR\x05title\x12\x18\n" +
	"\aauthors\x18\x03 \x03(\tR\aauthors\x12\x1c\n" +
	"\tcontainer\x18\x04 \x01(\tR\tcontainer\x12\x1a\n" +
	"\bfilename\x18\x05 \x01(\tR\bfilename\"#\n" +
	"\vListRequest\x12\x14\n" +
	"\x05query\x18\x01 \x01(\tR\x05query\"$\n" +
	"\fListResponse\x12\x14\n" +
	"\x05items\x18\x01 \x03(\tR\x05items\"_\n" +
	"\rAccessRequest\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\tR\x06userId\x12\x1a\n" +
	"\bplatform\x18\x02 \x01(\tR\bplatform\x12\x19\n" +
	"\btrace_id\x18\x03 \x01(\tR\atraceId\"_\n" +
	"\x0eAccessResponse\x12\x18\n" +
	"\aallowed\x18\x01 \x01(\bR\aallowed\x12\x16\n" +
	"\x06reason\x18\x02 \x01(\tR\x06reason\x12\x1b\n" +
	"\tuser_role\x18\x03 \x01(\tR\buserRole\"9\n" +
	"\bRawInput\x12\x12\n" +
	"\x04data\x18\x01 \x01(\tR\x04data\x12\x19\n" +
	"\btrace_id\x18\x02 \x01(\tR\atraceId\"\x9f\x01\n" +
	"\vMessageMeta\x12\x19\n" +
	"\btrace_id\x18\x01 \x01(\tR\atraceId\x12%\n" +
	"\x0ecanonical_form\x18\x02 \x01(\tR\rcanonicalForm\x12\x1a\n" +
	"\bplatform\x18\x03 \x01(\tR\bplatform\x12\x17\n" +
	"\auser_id\x18\x04 \x01(\tR\x06userId\x12\x19\n" +
	"\bast_plan\x18\x05 \x01(\tR\aastPlan\"n\n" +
	"\x12UnmarshaledMessage\x12*\n" +
	"\x04meta\x18\x01 \x01(\v2\x16.libraryv1.MessageMetaR\x04meta\x12,\n" +
	"\x05query\x18\x02 \x01(\v2\x16.libraryv1.SearchQueryR\x05query\"v\n" +
	"\bResponse\x12\x16\n" +
	"\x06status\x18\x01 \x01(\tR\x06status\x12%\n" +
	"\x05books\x18\x02 \x03(\v2\x0f.libraryv1.BookR\x05books\x12+\n" +
	"\x04meta\x18\x03 \x01(\v2\x17.libraryv1.ResponseMetaR\x04meta\"P\n" +
	"\fResponseMeta\x12\x19\n" +
	"\btrace_id\x18\x01 \x01(\tR\atraceId\x12%\n" +
	"\x0ecanonical_form\x18\x02 \x01(\tR\rcanonicalForm\"\xac\x01\n" +
	"\vSearchQuery\x12/\n" +
	"\x06filter\x18\x01 \x01(\v2\x15.libraryv1.FilterNodeH\x00R\x06filter\x122\n" +
	"\alogical\x18\x02 \x01(\v2\x16.libraryv1.LogicalNodeH\x00R\alogical\x120\n" +
	"\bnegation\x18\x03 \x01(\v2\x12.libraryv1.NotNodeH\x00R\bnegationB\x06\n" +
	"\x04node\"i\n" +
	"\n" +
	"FilterNode\x12\x14\n" +
	"\x05field\x18\x01 \x01(\tR\x05field\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value\x12/\n" +
	"\boperator\x18\x03 \x01(\x0e2\x13.libraryv1.OperatorR\boperator\"a\n" +
	"\vLogicalNode\x12$\n" +
	"\x02op\x18\x01 \x01(\x0e2\x14.libraryv1.LogicalOpR\x02op\x12,\n" +
	"\x05nodes\x18\x02 \x03(\v2\x16.libraryv1.SearchQueryR\x05nodes\"5\n" +
	"\aNotNode\x12*\n" +
	"\x04node\x18\x01 \x01(\v2\x16.libraryv1.SearchQueryR\x04node*%\n" +
	"\tLogicalOp\x12\a\n" +
	"\x03AND\x10\x00\x12\x06\n" +
	"\x02OR\x10\x01\x12\a\n" +
	"\x03NOT\x10\x02*8\n" +
	"\bOperator\x12\r\n" +
	"\tOP_EQUALS\x10\x00\x12\x0f\n" +
	"\vOP_CONTAINS\x10\x01\x12\f\n" +
	"\bOP_REGEX\x10\x022T\n" +
	"\x13OrchestratorService\x12=\n" +
	"\x06Search\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse2R\n" +
	"\x10ProcessorService\x12>\n" +
	"\aProcess\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse2T\n" +
	"\x0eStorageService\x12B\n" +
	"\vSearchBooks\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse2Q\n" +
	"\vAuthService\x12B\n" +
	"\vCheckAccess\x12\x18.libraryv1.AccessRequest\x1a\x19.libraryv1.AccessResponse2X\n" +
	"\x17MessageConverterService\x12=\n" +
	"\aConvert\x12\x13.libraryv1.RawInput\x1a\x1d.libraryv1.UnmarshaledMessage2\x93\x01\n" +
	"\x0eLibraryService\x12B\n" +
	"\vSearchBooks\x12\x18.libraryv1.SearchRequest\x1a\x19.libraryv1.SearchResponse\x12=\n" +
	"\n" +
	"GetAuthors\x12\x16.libraryv1.ListRequest\x1a\x17.libraryv1.ListResponseB\x1fZ\x1debusta/api/proto/v1;libraryv1b\x06proto3"

var (
	file_api_proto_v1_library_proto_rawDescOnce sync.Once
	file_api_proto_v1_library_proto_rawDescData []byte
)

func file_api_proto_v1_library_proto_rawDescGZIP() []byte {
	file_api_proto_v1_library_proto_rawDescOnce.Do(func() {
		file_api_proto_v1_library_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_api_proto_v1_library_proto_rawDesc), len(file_api_proto_v1_library_proto_rawDesc)))
	})
	return file_api_proto_v1_library_proto_rawDescData
}

var file_api_proto_v1_library_proto_enumTypes = make([]protoimpl.EnumInfo, 2)
var file_api_proto_v1_library_proto_msgTypes = make([]protoimpl.MessageInfo, 16)
var file_api_proto_v1_library_proto_goTypes = []any{
	(LogicalOp)(0),             // 0: libraryv1.LogicalOp
	(Operator)(0),              // 1: libraryv1.Operator
	(*SearchRequest)(nil),      // 2: libraryv1.SearchRequest
	(*SearchResponse)(nil),     // 3: libraryv1.SearchResponse
	(*Book)(nil),               // 4: libraryv1.Book
	(*ListRequest)(nil),        // 5: libraryv1.ListRequest
	(*ListResponse)(nil),       // 6: libraryv1.ListResponse
	(*AccessRequest)(nil),      // 7: libraryv1.AccessRequest
	(*AccessResponse)(nil),     // 8: libraryv1.AccessResponse
	(*RawInput)(nil),           // 9: libraryv1.RawInput
	(*MessageMeta)(nil),        // 10: libraryv1.MessageMeta
	(*UnmarshaledMessage)(nil), // 11: libraryv1.UnmarshaledMessage
	(*Response)(nil),           // 12: libraryv1.Response
	(*ResponseMeta)(nil),       // 13: libraryv1.ResponseMeta
	(*SearchQuery)(nil),        // 14: libraryv1.SearchQuery
	(*FilterNode)(nil),         // 15: libraryv1.FilterNode
	(*LogicalNode)(nil),        // 16: libraryv1.LogicalNode
	(*NotNode)(nil),            // 17: libraryv1.NotNode
}
var file_api_proto_v1_library_proto_depIdxs = []int32{
	4,  // 0: libraryv1.SearchResponse.books:type_name -> libraryv1.Book
	10, // 1: libraryv1.UnmarshaledMessage.meta:type_name -> libraryv1.MessageMeta
	14, // 2: libraryv1.UnmarshaledMessage.query:type_name -> libraryv1.SearchQuery
	4,  // 3: libraryv1.Response.books:type_name -> libraryv1.Book
	13, // 4: libraryv1.Response.meta:type_name -> libraryv1.ResponseMeta
	15, // 5: libraryv1.SearchQuery.filter:type_name -> libraryv1.FilterNode
	16, // 6: libraryv1.SearchQuery.logical:type_name -> libraryv1.LogicalNode
	17, // 7: libraryv1.SearchQuery.negation:type_name -> libraryv1.NotNode
	1,  // 8: libraryv1.FilterNode.operator:type_name -> libraryv1.Operator
	0,  // 9: libraryv1.LogicalNode.op:type_name -> libraryv1.LogicalOp
	14, // 10: libraryv1.LogicalNode.nodes:type_name -> libraryv1.SearchQuery
	14, // 11: libraryv1.NotNode.node:type_name -> libraryv1.SearchQuery
	2,  // 12: libraryv1.OrchestratorService.Search:input_type -> libraryv1.SearchRequest
	2,  // 13: libraryv1.ProcessorService.Process:input_type -> libraryv1.SearchRequest
	2,  // 14: libraryv1.StorageService.SearchBooks:input_type -> libraryv1.SearchRequest
	7,  // 15: libraryv1.AuthService.CheckAccess:input_type -> libraryv1.AccessRequest
	9,  // 16: libraryv1.MessageConverterService.Convert:input_type -> libraryv1.RawInput
	2,  // 17: libraryv1.LibraryService.SearchBooks:input_type -> libraryv1.SearchRequest
	5,  // 18: libraryv1.LibraryService.GetAuthors:input_type -> libraryv1.ListRequest
	3,  // 19: libraryv1.OrchestratorService.Search:output_type -> libraryv1.SearchResponse
	3,  // 20: libraryv1.ProcessorService.Process:output_type -> libraryv1.SearchResponse
	3,  // 21: libraryv1.StorageService.SearchBooks:output_type -> libraryv1.SearchResponse
	8,  // 22: libraryv1.AuthService.CheckAccess:output_type -> libraryv1.AccessResponse
	11, // 23: libraryv1.MessageConverterService.Convert:output_type -> libraryv1.UnmarshaledMessage
	3,  // 24: libraryv1.LibraryService.SearchBooks:output_type -> libraryv1.SearchResponse
	6,  // 25: libraryv1.LibraryService.GetAuthors:output_type -> libraryv1.ListResponse
	19, // [19:26] is the sub-list for method output_type
	12, // [12:19] is the sub-list for method input_type
	12, // [12:12] is the sub-list for extension type_name
	12, // [12:12] is the sub-list for extension extendee
	0,  // [0:12] is the sub-list for field type_name
}

func init() { file_api_proto_v1_library_proto_init() }
func file_api_proto_v1_library_proto_init() {
	if File_api_proto_v1_library_proto != nil {
		return
	}
	file_api_proto_v1_library_proto_msgTypes[12].OneofWrappers = []any{
		(*SearchQuery_Filter)(nil),
		(*SearchQuery_Logical)(nil),
		(*SearchQuery_Negation)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_api_proto_v1_library_proto_rawDesc), len(file_api_proto_v1_library_proto_rawDesc)),
			NumEnums:      2,
			NumMessages:   16,
			NumExtensions: 0,
			NumServices:   6,
		},
		GoTypes:           file_api_proto_v1_library_proto_goTypes,
		DependencyIndexes: file_api_proto_v1_library_proto_depIdxs,
		EnumInfos:         file_api_proto_v1_library_proto_enumTypes,
		MessageInfos:      file_api_proto_v1_library_proto_msgTypes,
	}.Build()
	File_api_proto_v1_library_proto = out.File
	file_api_proto_v1_library_proto_goTypes = nil
	file_api_proto_v1_library_proto_depIdxs = nil
}

--- END_FILE: ./api/proto/v1/library.pb.go ---

--- START_FILE: ./api/proto/v1/library.proto ---
syntax = "proto3";

package libraryv1;

option go_package = "ebusta/api/proto/v1;libraryv1";

// ==========================================
// 1. SERVICES
// ==========================================

service OrchestratorService {
  rpc Search (SearchRequest) returns (SearchResponse);
}

service ProcessorService {
  rpc Process (SearchRequest) returns (SearchResponse);
}

service StorageService {
  rpc SearchBooks (SearchRequest) returns (SearchResponse);
}

service AuthService {
  rpc CheckAccess (AccessRequest) returns (AccessResponse);
}

service MessageConverterService {
  rpc Convert (RawInput) returns (UnmarshaledMessage);
}

// Legacy
service LibraryService {
  rpc SearchBooks (SearchRequest) returns (SearchResponse);
  rpc GetAuthors (ListRequest) returns (ListResponse);
}

// ==========================================
// 2. MESSAGES
// ==========================================

message SearchRequest {
  string query = 1;
  string template_id = 2;
  int32 limit = 3;
  int32 offset = 4;
  string trace_id = 5;
}

message SearchResponse {
  string status = 1;
  int32 total = 2;
  repeated Book books = 3;
}

message Book {
  string id = 1;
  string title = 2;
  repeated string authors = 3;
  string container = 4;
  string filename = 5;
}

message ListRequest {
  string query = 1;
}

message ListResponse {
  repeated string items = 1;
}

// --- AUTH ---

message AccessRequest {
  string user_id = 1;
  string platform = 2;
  string trace_id = 3;
}

message AccessResponse {
  bool allowed = 1;
  string reason = 2;
  string user_role = 3;
}

// ==========================================
// 3. CONVERTER & AST (Fixed for existing code)
// ==========================================

message RawInput {
  // –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–æ –≤ 'data', —á—Ç–æ–±—ã –ø–æ—è–≤–∏–ª—Å—è –º–µ—Ç–æ–¥ GetData(), –∫–æ—Ç–æ—Ä—ã–π –∂–¥–µ—Ç message-converter
  string data = 1; 
  string trace_id = 2;
}

message MessageMeta {
  string trace_id = 1;
  string canonical_form = 2;
  string platform = 3;
  string user_id = 4;
  // –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –¥–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ–ª–µ, –∫–æ—Ç–æ—Ä–æ–µ —Ç—Ä–µ–±—É–µ—Ç message-converter
  string ast_plan = 5; 
}

message UnmarshaledMessage {
  MessageMeta meta = 1;
  SearchQuery query = 2;
}

message Response {
  string status = 1;
  repeated Book books = 2;
  ResponseMeta meta = 3;
}

message ResponseMeta {
  string trace_id = 1;
  string canonical_form = 2;
}

// --- AST NODES (Strictly for parser.go) ---

enum LogicalOp {
  AND = 0;
  OR = 1;
  NOT = 2;
}

enum Operator {
  OP_EQUALS = 0;
  OP_CONTAINS = 1;
  OP_REGEX = 2;
}

message SearchQuery {
  oneof node {
    FilterNode filter = 1;
    LogicalNode logical = 2;
    NotNode negation = 3;
  }
}

message FilterNode {
  string field = 1;
  string value = 2;
  Operator operator = 3;
}

message LogicalNode {
  LogicalOp op = 1;
  repeated SearchQuery nodes = 2;
}

message NotNode {
  // –í–∞–∂–Ω–æ: –∏–º—è –ø–æ–ª—è 'node' –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–µ 'Node' –≤ Go —Å—Ç—Ä—É–∫—Ç—É—Ä–µ, —á—Ç–æ –Ω—É–∂–Ω–æ –ø–∞—Ä—Å–µ—Ä—É
  SearchQuery node = 1; 
}

--- END_FILE: ./api/proto/v1/library.proto ---

--- START_FILE: ./opensearch/templates/fl_author_id.json ---
{
  "script": {
    "lang": "mustache",
    "source": {
      "query": { "term": { "authors.kw": "{{query}}" } },
      "size": "{{size}}{{^size}}50{{/size}}"
    }
  }
}

--- END_FILE: ./opensearch/templates/fl_author_id.json ---

--- START_FILE: ./opensearch/templates/fl_authors_all.json ---
{
  "script": {
    "lang": "mustache",
    "source": "{\n  \"size\": 0,\n  \"aggs\": {\n    \"authors\": {\n      \"composite\": {\n        \"size\": {{size}},\n        \"sources\": [ { \"a\": { \"terms\": { \"field\": \"authors.kw\" } } } ]{{#after}},\n        \"after\": {{after}}{{/after}}\n      }\n    }\n  }\n}\n"
  }
}


--- END_FILE: ./opensearch/templates/fl_authors_all.json ---

--- START_FILE: ./opensearch/templates/fl_author_fuzzy.json ---
{
  "script": {
    "lang": "mustache",
    "source": {
      "query": {
        "match": {
          "authors": {
            "query": "{{author}}",
            "operator": "and"
          }
        }
      },
      "size": "{{size}}",
      "from": "{{from}}",
      "_source": ["title", "authors", "fileInfo.container", "fileInfo.filename"],
      "track_total_hits": false
    }
  }
}

--- END_FILE: ./opensearch/templates/fl_author_fuzzy.json ---

--- START_FILE: ./opensearch/templates/fl_author_exact.json ---
{
  "script": {
    "lang": "mustache",
    "source": {
      "query": { "term": { "authors.kw": "{{author}}" } },
      "collapse": { "field": "title.kw", "inner_hits": { "name": "best", "size": 1, "sort": [{"fileInfo.size": "desc"}] } },
      "size": "{{size}}{{^size}}20{{/size}}"
    }
  }
}

--- END_FILE: ./opensearch/templates/fl_author_exact.json ---

--- START_FILE: ./opensearch/templates/fl_container_lookup.json ---
{
  "script": {
    "lang": "mustache",
    "source": {
      "query": { "term": { "fileInfo.container": "{{query}}" } },
      "size": "{{size}}{{^size}}50{{/size}}"
    }
  }
}

--- END_FILE: ./opensearch/templates/fl_container_lookup.json ---

--- START_FILE: ./opensearch/templates/fl_names_token_prefix.json ---
{
  "script": {
    "lang": "mustache",
    "source": "{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        { \"multi_match\": { \"query\": \"{{query}}\", \"type\": \"phrase_prefix\", \"fields\": [\"authors^3\",\"title^1\"] } },\n        { \"match\": { \"authors.prefix\": { \"query\": \"{{query}}\", \"boost\": 4 } } },\n        { \"match\": { \"title.prefix\":   { \"query\": \"{{query}}\", \"boost\": 2 } } }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"size\": {{size}},\n  \"from\": {{from}},\n  \"sort\": [{ \"title.kw\": { \"order\": \"asc\" } }],\n  \"track_total_hits\": false,\n  \"_source\": [\"title\",\"authors\",\"fileInfo.container\",\"fileInfo.filename\"],\n  \"highlight\": { \"fields\": { \"authors\": {}, \"title\": {} } }\n}"
  }
}
--- END_FILE: ./opensearch/templates/fl_names_token_prefix.json ---

--- START_FILE: ./opensearch/templates/fl_title_match.json ---
{
  "script": {
    "lang": "mustache",
    "source": {
      "query": {
        "match": {
          "title": {
            "query": "{{query}}",
            "operator": "and"
          }
        }
      },
      "from": "{{from}}",
      "size": "{{size}}"
    }
  }
}

--- END_FILE: ./opensearch/templates/fl_title_match.json ---

--- START_FILE: ./opensearch/templates/fl_id_lookup.json ---
{
  "script": {
    "lang": "mustache",
    "source": {
      "query": { "term": { "_id": "{{query}}" } }
    }
  }
}

--- END_FILE: ./opensearch/templates/fl_id_lookup.json ---

--- START_FILE: ./opensearch/templates/fl_filename_lookup.json ---
{
  "script": {
    "lang": "mustache",
    "source": {
      "query": {
        "wildcard": { "fileInfo.filename": "*{{query}}*" }
      },
      "size": "{{size}}{{^size}}20{{/size}}"
    }
  }
}

--- END_FILE: ./opensearch/templates/fl_filename_lookup.json ---

--- START_FILE: ./opensearch/templates/fl_title_substring.json ---
{
  "script": {
    "lang": "mustache",
    "source": "{\n  \"from\": 0,\n  \"size\": {{size}},\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"*{{query}}*\",\n      \"fields\": [\"title.kw\", \"authors.kw\"],\n      \"analyze_wildcard\": true,\n      \"default_operator\": \"and\"\n    }\n  },\n  \"_source\": [\"title\", \"authors\", \"year\", \"fileInfo.container\", \"fileInfo.filename\"]\n}\n"
  }
}


--- END_FILE: ./opensearch/templates/fl_title_substring.json ---

--- START_FILE: ./opensearch/templates/fl_title_prefix.json ---
{
  "script": {
    "lang": "mustache",
    "source": "{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        { \"match\": { \"title.prefix\": { \"query\": \"{{query}}\", \"boost\": 5 } } },\n        { \"match_phrase_prefix\": { \"title\": { \"query\": \"{{query}}\", \"boost\": 2 } } },\n        { \"term\": { \"title.kw\": { \"value\": \"{{query}}\", \"boost\": 20 } } }\n      ],\n      \"minimum_should_match\": 1\n    }\n  },\n  \"size\": {{size}},\n  \"from\": {{from}},\n  \"sort\": [{ \"title.kw\": { \"order\": \"asc\" } }],\n  \"track_total_hits\": false,\n  \"_source\": [\"title\",\"authors\",\"fileInfo.container\",\"fileInfo.filename\"],\n  \"highlight\": { \"fields\": { \"title\": {} } }\n}"
  }
}
--- END_FILE: ./opensearch/templates/fl_title_prefix.json ---

--- START_FILE: ./opensearch/templates/fl_mixed_search.json ---
{
  "script": {
    "lang": "mustache",
    "source": {
      "query": {
        "multi_match": {
          "query": "{{query}}",
          "fields": ["title^3", "authors", "annotation"],
          "type": "best_fields",
          "fuzziness": "AUTO"
        }
      },
      "collapse": {
        "field": "title.kw",
        "inner_hits": { "name": "best", "size": 1, "sort": [{"fileInfo.size": "desc"}] }
      },
      "from": "{{from}}{{^from}}0{{/from}}",
      "size": "{{size}}{{^size}}10{{/size}}"
    }
  }
}

--- END_FILE: ./opensearch/templates/fl_mixed_search.json ---

--- START_FILE: ./opensearch/templates/fl_titles_all.json ---
{
  "script": {
    "lang": "mustache",
    "source": "{\n  \"size\": 0,\n  \"aggs\": {\n    \"titles\": {\n      \"composite\": {\n        \"size\": {{size}},\n        \"sources\": [ { \"t\": { \"terms\": { \"field\": \"title.kw\" } } } ]{{#after}},\n        \"after\": {{after}}{{/after}}\n      }\n    }\n  }\n}\n"
  }
}


--- END_FILE: ./opensearch/templates/fl_titles_all.json ---

--- START_FILE: ./opensearch/templates/fl_desc_match.json ---
{
  "script": {
    "lang": "mustache",
    "source": {
      "query": {
        "match": {
          "annotation": { "query": "{{query}}", "fuzziness": "AUTO" }
        }
      },
      "size": "{{size}}{{^size}}10{{/size}}",
      "from": "{{from}}{{^from}}0{{/from}}",
      "_source": ["title", "authors", "annotation"]
    }
  }
}

--- END_FILE: ./opensearch/templates/fl_desc_match.json ---

--- START_FILE: ./opensearch/flibusta_merged_index.fixed.json ---
{
  "settings": {
    "index": {
      "number_of_shards": 1,
      "number_of_replicas": 1,
      "refresh_interval": "1s"
    },
    "analysis": {
      "filter": {
        "ru_stop": {
          "type": "stop",
          "stopwords": "_russian_"
        },
        "ru_stemmer": {
          "type": "stemmer",
          "language": "russian"
        },
        "en_stop": {
          "type": "stop",
          "stopwords": "_english_"
        },
        "en_stemmer": {
          "type": "stemmer",
          "language": "english"
        },
        "shingle_2_3": {
          "type": "shingle",
          "min_shingle_size": 2,
          "max_shingle_size": 3
        }
      },
      "char_filter": {
        "quotes": {
          "type": "mapping",
          "mappings": [
            "‚Äú=>\"",
            "‚Äù=>\"",
            "‚Äò=>'",
            "‚Äô=>'"
          ]
        }
      },
      "normalizer": {
        "lc_ascii": {
          "type": "custom",
          "filter": [
            "lowercase",
            "asciifolding"
          ]
        }
      },
      "analyzer": {
        "mixed_text": {
          "type": "custom",
          "tokenizer": "standard",
          "char_filter": [
            "quotes"
          ],
          "filter": [
            "lowercase",
            "ru_stop",
            "ru_stemmer",
            "en_stop",
            "en_stemmer"
          ]
        },
        "autocomplete": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase"
          ]
        },
        "autocomplete_edge": {
          "type": "custom",
          "tokenizer": "edge_ngram_tokenizer",
          "filter": [
            "lowercase"
          ]
        },
        "shingled": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "shingle_2_3"
          ]
        }
      },
      "tokenizer": {
        "edge_ngram_tokenizer": {
          "type": "edge_ngram",
          "min_gram": 2,
          "max_gram": 20,
          "token_chars": [
            "letter",
            "digit"
          ]
        }
      }
    }
  },
  "mappings": {
    "dynamic": "strict",
    "properties": {
      "id": {
        "type": "keyword"
      },
      "docId": {
        "type": "keyword"
      },
      "source": {
        "type": "keyword"
      },
      "ingestedAt": {
        "type": "date"
      },
      "title": {
        "type": "text",
        "analyzer": "mixed_text",
        "fields": {
          "kw": {
            "type": "keyword",
            "normalizer": "lc_ascii"
          },
          "ac": {
            "type": "text",
            "analyzer": "autocomplete_edge",
            "search_analyzer": "autocomplete"
          },
          "sh": {
            "type": "text",
            "analyzer": "shingled"
          }
        }
      },
      "authors": {
        "type": "text",
        "analyzer": "mixed_text",
        "fields": {
          "kw": {
            "type": "keyword",
            "normalizer": "lc_ascii"
          },
          "ac": {
            "type": "text",
            "analyzer": "autocomplete_edge",
            "search_analyzer": "autocomplete"
          }
        }
      },
      "genres": {
        "type": "keyword",
        "normalizer": "lc_ascii"
      },
      "languages": {
        "type": "keyword",
        "normalizer": "lc_ascii"
      },
      "year": {
        "type": "integer"
      },
      "annotation": {
        "type": "text",
        "analyzer": "mixed_text"
      },
      "sequences": {
        "type": "nested",
        "properties": {
          "name": {
            "type": "text",
            "analyzer": "mixed_text",
            "fields": {
              "kw": {
                "type": "keyword",
                "normalizer": "lc_ascii"
              },
              "ac": {
                "type": "text",
                "analyzer": "autocomplete_edge",
                "search_analyzer": "autocomplete"
              }
            }
          },
          "number": {
            "type": "float"
          }
        }
      },
      "fileInfo": {
        "type": "object",
        "properties": {
          "container": {
            "type": "keyword"
          },
          "filename": {
            "type": "keyword"
          },
          "size": {
            "type": "long"
          },
          "sha1": {
            "type": "keyword"
          }
        }
      },
      "suggest_title": {
        "type": "completion"
      },
      "suggest_author": {
        "type": "completion"
      }
    }
  }
}
--- END_FILE: ./opensearch/flibusta_merged_index.fixed.json ---

--- START_FILE: ./opensearch/os-setup-config.yaml ---
opensearch:
  url: "http://cloud-1:9200"
  index_name: "flibusta_merged_index"

paths:
  index_file: "./flibusta_merged_index.fixed.json"
  templates_dir: "./templates"

logging:
  log_path: "os-setup.log"

--- END_FILE: ./opensearch/os-setup-config.yaml ---

--- START_FILE: ./cmd/datamanager/main.go ---
package main

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net"
	"net/http"
	"os"

	"ebusta/api/proto/v1"
	"github.com/spf13/viper"
	"google.golang.org/grpc"
)

type storageServer struct {
	libraryv1.UnimplementedStorageServiceServer
	osBaseURL string
	indexName string
	debug     bool
}

func (s *storageServer) SearchBooks(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
	templateID := req.TemplateId
	if templateID == "" {
		templateID = "fl_mixed_search"
	}
	
	var paramName string
	switch templateID {
	case "fl_author_exact", "fl_author_fuzzy":
		paramName = "author"
	case "fl_title_substring", "fl_titles_all":
		paramName = "query"
	default:
		paramName = "query"
	}

	osReqBody := map[string]interface{}{
		"id": templateID,
		"params": map[string]interface{}{
			paramName: req.Query,
			"from":    0,
			"size":    req.Limit,
		},
	}
	
	if val, ok := osReqBody["params"].(map[string]interface{})["size"].(int32); ok && val == 0 {
		osReqBody["params"].(map[string]interface{})["size"] = 10
	}

	jsonData, _ := json.Marshal(osReqBody)
	targetURL := fmt.Sprintf("%s/%s/_search/template", s.osBaseURL, s.indexName)
	log.Printf("üì§ [OS-REQ] URL: %s | BODY: %s", targetURL, string(jsonData))

	resp, err := http.Post(targetURL, "application/json", bytes.NewBuffer(jsonData))
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	body, _ := io.ReadAll(resp.Body)
	
	// –ì–ò–ë–ö–ò–ô –ü–ê–†–°–ò–ù–ì: Total –º–æ–∂–µ—Ç –±—ã—Ç—å —á–∏—Å–ª–æ–º, –æ–±—ä–µ–∫—Ç–æ–º –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å
	var osRaw struct {
		Hits struct {
			Total interface{} `json:"total"`
			Hits  []struct {
				Source struct {
					Title   string   `json:"title"`
					Authors []string `json:"authors"`
				} `json:"_source"`
				ID string `json:"_id"`
			} `json:"hits"`
		} `json:"hits"`
	}

	if err := json.Unmarshal(body, &osRaw); err != nil {
		log.Printf("‚ùå Storage parse error: %v", err)
		return &libraryv1.SearchResponse{Status: "error"}, nil
	}

	var totalValue int32
	switch v := osRaw.Hits.Total.(type) {
	case float64:
		totalValue = int32(v)
	case map[string]interface{}:
		if val, ok := v["value"].(float64); ok {
			totalValue = int32(val)
		}
	}

	res := &libraryv1.SearchResponse{}
	for _, hit := range osRaw.Hits.Hits {
		res.Books = append(res.Books, &libraryv1.Book{
			Id:      hit.ID,
			Title:   hit.Source.Title,
			Authors: hit.Source.Authors,
		})
	}

	// FALLBACK: –ï—Å–ª–∏ —Ö–∏—Ç—ã –µ—Å—Ç—å, –∞ total 0 –∏–ª–∏ –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–∏–ª—Å—è
	if totalValue == 0 && len(res.Books) > 0 {
		totalValue = int32(len(res.Books))
	}
	res.Total = totalValue

	log.Printf("üì• [OS-RESP] Found: %d books", totalValue)
	return res, nil
}

func main() {
	log.Println("=== [DATAMANAGER] Starting on :50051 ===")
	viper.SetConfigName("ebusta")
	viper.SetConfigType("yaml")
	viper.AddConfigPath(".")
	viper.ReadInConfig()

	osBaseURL := viper.GetString("datamanager.opensearch_url")
	indexName := viper.GetString("datamanager.index_name")
	debug := os.Getenv("DEBUG") != ""

	lis, err := net.Listen("tcp", ":50051")
	if err != nil { log.Fatalf("failed to listen: %v", err) }

	s := grpc.NewServer()
	libraryv1.RegisterStorageServiceServer(s, &storageServer{
		osBaseURL: osBaseURL,
		indexName: indexName,
		debug:     debug,
	})

	log.Println("üíæ DataManager (Storage) started on :50051")
	s.Serve(lis)
}

--- END_FILE: ./cmd/datamanager/main.go ---

--- START_FILE: ./cmd/bulker/main.go ---
package main

import (
	"archive/zip"
	"bufio"
	"bytes"
	"crypto/sha1"
	"encoding/hex"
	"encoding/json"
	"encoding/xml"
	"flag"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"github.com/schollz/progressbar/v3"
	"github.com/sirupsen/logrus"
	"golang.org/x/text/encoding/charmap"
	"golang.org/x/text/encoding/unicode"
	"gopkg.in/yaml.v3"
)

type Config struct {
	OpenSearch struct {
		IndexName string `yaml:"index_name"`
	} `yaml:"opensearch"`
	Paths struct {
		WarnDir   string `yaml:"warn_dir"`
		OutputDir string `yaml:"output_dir"`
		SourceDir string `yaml:"source_dir"`
	} `yaml:"paths"`
	Processing struct {
		Threads int `yaml:"threads"`
	} `yaml:"processing"`
}

type docOut struct {
	Title      string    `json:"title"`
	Authors    []string  `json:"authors,omitempty"`
	IngestedAt time.Time `json:"ingestedAt"`
	FileInfo   struct {
		Container string `json:"container"`
		Filename  string `json:"filename"`
		Sha1      string `json:"sha1"`
		Size      int64  `json:"size"`
	} `json:"fileInfo"`
}

var (
	cfg          Config
	log          = logrus.New()
	outFile      *os.File
	outMu        sync.Mutex
	bar          *progressbar.ProgressBar
	rescuedCount int32
	// –§–ª–∞–≥–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
	flagRescan  *bool
	flagVerbose *bool
)

func main() {
	configPath := flag.String("config", "./config.yaml", "Path to config file")
	container := flag.String("container", "", "Process only this specific ZIP from source_dir")
	rescue := flag.Bool("rescue", false, "Rescue mode")
	flagRescan = flag.Bool("rescan", false, "Force rescan all files ignoring existing output")
	flagVerbose = flag.Bool("verbose", false, "Detailed check by hashing every file")
	flag.Parse()

	cFile, err := os.ReadFile(*configPath)
	if err != nil {
		fmt.Printf("Error: Cannot read config file at %s\n", *configPath)
		os.Exit(1)
	}
	_ = yaml.Unmarshal(cFile, &cfg)

	log.SetFormatter(&logrus.TextFormatter{FullTimestamp: true, ForceColors: true})
	_ = os.MkdirAll(cfg.Paths.OutputDir, 0755)

	if *rescue {
		runRescueMode()
		fmt.Printf("\nüèÅ Rescue Finished. Successfully processed: %d files.\n", atomic.LoadInt32(&rescuedCount))
	} else if *container != "" {
		fullPath := filepath.Join(cfg.Paths.SourceDir, *container)
		dstPath := filepath.Join(cfg.Paths.OutputDir, *container+".jsonl")
		processSingleZip(fullPath, dstPath)
	} else {
		archives, _ := filepath.Glob(filepath.Join(cfg.Paths.SourceDir, "*.zip"))
		for _, zipPath := range archives {
			dstPath := filepath.Join(cfg.Paths.OutputDir, filepath.Base(zipPath)+".jsonl")
			processSingleZip(zipPath, dstPath)
		}
	}
}

// –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–∞: —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å
func normalizeJSONL(path string) (int, error) {
	baseName := filepath.Base(path)
	log.Infof("[%s] Normalization started: scanning for unique IDs...", baseName)

	f, err := os.Open(path)
	if err != nil {
		return 0, err
	}
	defer f.Close()

	tmpPath := path + ".tmp"
	tmpFile, err := os.Create(tmpPath)
	if err != nil {
		return 0, err
	}
	defer tmpFile.Close()

	hashes := make(map[string]bool)
	scanner := bufio.NewScanner(f)
	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
	count := 0

	for scanner.Scan() {
		line1 := scanner.Text()
		if strings.Contains(line1, `"_index"`) {
			match := re.FindStringSubmatch(line1)
			if len(match) > 1 {
				id := match[1]
				if scanner.Scan() {
					line2 := scanner.Text()
					if !hashes[id] {
						hashes[id] = true
						_, _ = tmpFile.WriteString(line1 + "\n")
						_, _ = tmpFile.WriteString(line2 + "\n")
						count++
					}
				}
			}
		}
	}

	log.Infof("[%s] Writing normalized file to disk (%d unique records)...", baseName, count)

	f.Close()
	tmpFile.Close()

	if err := os.Rename(tmpPath, path); err != nil {
		return 0, err
	}

	log.Infof("[%s] Normalization finished successfully.", baseName)
	return count, nil
}

func countExistingDocs(path string) int {
	count := 0
	f, err := os.Open(path)
	if err != nil { return 0 }
	defer f.Close()
	scanner := bufio.NewScanner(f)
	for scanner.Scan() {
		if strings.Contains(scanner.Text(), `"_index"`) { count++ }
	}
	return count
}

func loadExistingHashes(path string) map[string]bool {
	hashes := make(map[string]bool)
	f, err := os.Open(path)
	if err != nil { return hashes }
	defer f.Close()
	scanner := bufio.NewScanner(f)
	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
	for scanner.Scan() {
		line := scanner.Text()
		if strings.Contains(line, `"_index"`) {
			match := re.FindStringSubmatch(line)
			if len(match) > 1 { hashes[match[1]] = true }
		}
	}
	return hashes
}

func processSingleZip(zipPath, dstPath string) {
	containerName := filepath.Base(zipPath)
	z, err := zip.OpenReader(zipPath)
	if err != nil {
		log.Errorf("Failed to open zip %s: %v", zipPath, err)
		return
	}
	defer z.Close()

	zipFb2Count := 0
	for _, f := range z.File {
		if strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { zipFb2Count++ }
	}

	// 1. –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
	if !*flagRescan && !*flagVerbose {
		jsonlDocCount := countExistingDocs(dstPath)
		if jsonlDocCount > 0 {
			if zipFb2Count == jsonlDocCount {
				log.Infof("[%s] Quick check: counts match (%d). Skipping container.", containerName, zipFb2Count)
				z.Close()
				os.Exit(10)
			} else {
				log.Infof("[%s] Count mismatch (ZIP: %d, JSONL: %d). Starting normalization...", containerName, zipFb2Count, jsonlDocCount)
				
				newCount, err := normalizeJSONL(dstPath)
				
				// –ù–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
				log.Infof("[%s] New check after normalization: count is %d.", containerName, newCount)
				
				if err == nil {
					if newCount == zipFb2Count {
						log.Infof("[%s] Result: Counts match! Skipping container.", containerName)
						z.Close()
						os.Exit(10)
					} else {
						log.Infof("[%s] Result: Still mismatch. Proceeding to detailed check.", containerName)
					}
				} else {
					log.Errorf("[%s] Normalization failed: %v. Proceeding to detailed check.", containerName, err)
				}
			}
		}
	}

	existingHashes := make(map[string]bool)
	if !*flagRescan {
		existingHashes = loadExistingHashes(dstPath)
		if len(existingHashes) > 0 && *flagVerbose {
			log.Infof("[%s] Found %d already processed documents.", containerName, len(existingHashes))
		}
	}

	type workItem struct {
		file *zip.File
		raw  []byte
		sha  string
	}
	var tasks []workItem

	for _, f := range z.File {
		if !strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { continue }
		rc, err := f.Open()
		if err != nil {
			log.Errorf("Read error %s: %v", f.Name, err)
			continue
		}
		raw, _ := io.ReadAll(rc)
		rc.Close()
		sum := sha1.Sum(raw)
		sha := hex.EncodeToString(sum[:])
		if existingHashes[sha] {
			if *flagVerbose { log.Infof("Skipping %s (already exists in output)", f.Name) }
			continue
		}
		tasks = append(tasks, workItem{file: f, raw: raw, sha: sha})
	}

	if len(tasks) == 0 {
		log.Infof("Container %s is fully processed. Nothing new.", containerName)
		z.Close()
		os.Exit(10)
	}

	openOutputFile(dstPath)
	defer outFile.Close()
	bar = progressbar.Default(int64(len(tasks)), "üö¢ "+containerName)
	jobs := make(chan workItem)
	var wg sync.WaitGroup
	for i := 0; i < cfg.Processing.Threads; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for item := range jobs {
				doc, err := parseResilient(item.raw)
				if err != nil {
					log.Errorf("FAILED: %s | %v", item.file.Name, err)
					saveToWarn(item.file.Name, item.raw, err)
				} else {
					saveToOutputWithSha(item.file.Name, containerName, item.raw, item.sha, doc)
				}
				_ = bar.Add(1)
			}
		}()
	}
	for _, task := range tasks { jobs <- task }
	close(jobs)
	wg.Wait()
}

func runRescueMode() {
	files, _ := filepath.Glob(filepath.Join(cfg.Paths.WarnDir, "*fb2"))
	if len(files) == 0 { return }
	dstPath := filepath.Join(cfg.Paths.OutputDir, "rescued_items.jsonl")
	openOutputFile(dstPath)
	defer outFile.Close()
	bar = progressbar.Default(int64(len(files)), "ü©π Rescuing")
	jobs := make(chan string)
	var wg sync.WaitGroup
	for i := 0; i < cfg.Processing.Threads; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for path := range jobs {
				data, err := os.ReadFile(path)
				if err != nil || len(data) == 0 {
					_ = os.Remove(path)
					_ = os.Remove(path + ".log")
					_ = bar.Add(1)
					continue
				}
				doc, err := parseResilient(data)
				if err == nil {
					if saveToOutput(filepath.Base(path), "rescued", data, doc) {
						_ = os.Remove(path)
						_ = os.Remove(path + ".log")
						atomic.AddInt32(&rescuedCount, 1)
					}
				} else { log.Errorf("FAILED: %s | %v", filepath.Base(path), err) }
				_ = bar.Add(1)
			}
		}()
	}
	for _, f := range files { jobs <- f }
	close(jobs)
	wg.Wait()
}

func parseResilient(data []byte) (*docOut, error) {
	if len(data) == 0 { return nil, fmt.Errorf("empty file") }
	utf8Data := convertToUTF8(data)
	doc, err := parseFB2(utf8Data)
	if err == nil { return doc, nil }
	return parseWithRegex(utf8Data)
}

func convertToUTF8(data []byte) []byte {
	if len(data) < 2 { return data }
	if (data[0] == 0xFF && data[1] == 0xFE) || (data[0] == 0xFE && data[1] == 0xFF) {
		dec := unicode.UTF16(unicode.LittleEndian, unicode.UseBOM).NewDecoder()
		out, _ := dec.Bytes(data)
		return out
	}
	if len(data) > 10 && data[1] == 0 && data[3] == 0 {
		dec := unicode.UTF16(unicode.LittleEndian, unicode.IgnoreBOM).NewDecoder()
		out, _ := dec.Bytes(data)
		return out
	}
	header := string(data[:min(len(data), 500)])
	if strings.Contains(strings.ToLower(header), "windows-1251") {
		out, _ := charmap.Windows1251.NewDecoder().Bytes(data)
		return out
	}
	return bytes.ToValidUTF8(data, []byte(" "))
}

func parseWithRegex(data []byte) (*docOut, error) {
	doc := &docOut{}
	reTitle := regexp.MustCompile(`(?is)<book-title[^>]*>(.*?)</book-title>`)
	if m := reTitle.FindSubmatch(data); len(m) > 1 { doc.Title = strings.TrimSpace(string(m[1])) }
	reAuthor := regexp.MustCompile(`(?is)<author[^>]*>(.*?)</author>`)
	reFirst := regexp.MustCompile(`(?is)<first-name[^>]*>(.*?)</first-name>`)
	reLast := regexp.MustCompile(`(?is)<last-name[^>]*>(.*?)</last-name>`)
	authors := reAuthor.FindAllSubmatch(data, -1)
	for _, a := range authors {
		fn, ln := reFirst.FindSubmatch(a[1]), reLast.FindSubmatch(a[1])
		name := ""
		if len(fn) > 1 { name += string(fn[1]) + " " }
		if len(ln) > 1 { name += string(ln[1]) }
		if name = strings.TrimSpace(name); name != "" { doc.Authors = append(doc.Authors, name) }
	}
	if doc.Title == "" { return nil, fmt.Errorf("regex failed") }
	return doc, nil
}

func openOutputFile(path string) {
	var err error
	outFile, err = os.OpenFile(path, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
	if err != nil { log.Fatal(err) }
}

func saveToOutput(filename, container string, raw []byte, doc *docOut) bool {
	sum := sha1.Sum(raw)
	sha := hex.EncodeToString(sum[:])
	return saveToOutputWithSha(filename, container, raw, sha, doc)
}

func saveToOutputWithSha(filename, container string, raw []byte, sha string, doc *docOut) bool {
	doc.FileInfo.Container, doc.FileInfo.Filename, doc.FileInfo.Sha1, doc.FileInfo.Size = container, filename, sha, int64(len(raw))
	doc.IngestedAt = time.Now()
	action, _ := json.Marshal(map[string]map[string]any{"index": {"_index": cfg.OpenSearch.IndexName, "_id": sha}})
	data, _ := json.Marshal(doc)
	outMu.Lock()
	defer outMu.Unlock()
	_, _ = outFile.Write(append(action, '\n'))
	_, _ = outFile.Write(append(data, '\n'))
	return true
}

func saveToWarn(filename string, data []byte, err error) {
	_ = os.WriteFile(filepath.Join(cfg.Paths.WarnDir, filename), data, 0644)
	_ = os.WriteFile(filepath.Join(cfg.Paths.WarnDir, filename+".log"), []byte(err.Error()), 0644)
}

func parseFB2(data []byte) (*docOut, error) {
	d := xml.NewDecoder(bytes.NewReader(data))
	d.CharsetReader = func(charset string, input io.Reader) (io.Reader, error) { return input, nil }
	d.Strict = false
	var doc docOut
	var inTitle bool
	for {
		t, err := d.Token()
		if err != nil || t == nil { break }
		switch se := t.(type) {
		case xml.StartElement:
			if se.Name.Local == "title-info" { inTitle = true }
			if se.Name.Local == "book-title" && inTitle { _ = d.DecodeElement(&doc.Title, &se) }
			if se.Name.Local == "author" && inTitle {
				var a struct { First string `xml:"first-name"`; Last string `xml:"last-name"` }
				_ = d.DecodeElement(&a, &se)
				if n := strings.TrimSpace(a.First + " " + a.Last); n != "" { doc.Authors = append(doc.Authors, n) }
			}
		case xml.EndElement:
			if se.Name.Local == "title-info" { inTitle = false }
		}
	}
	if doc.Title == "" { return nil, fmt.Errorf("xml: no title") }
	return &doc, nil
}

func min(a, b int) int { if a < b { return a }; return b }

--- END_FILE: ./cmd/bulker/main.go ---

--- START_FILE: ./cmd/processor/main.go ---
package main

import (
	"context"
	"log"
	"net"
	"strings"

	"ebusta/api/proto/v1"
	"google.golang.org/grpc"
)

type processorServer struct {
	libraryv1.UnimplementedProcessorServiceServer
	storage libraryv1.StorageServiceClient
}

func (s *processorServer) Process(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
	fullQuery := req.Query
	qLower := strings.ToLower(fullQuery)
	log.Printf("üß† Processor: Handling '%s'", fullQuery)

	// 1. –°–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (AND/OR)
	if strings.Contains(qLower, " and ") || strings.Contains(qLower, " or ") {
		cleanQuery := fullQuery
		for _, prefix := range []string{"author:", "title:", "Author:", "Title:"} {
			cleanQuery = strings.ReplaceAll(cleanQuery, prefix, "")
		}
		log.Printf("üß† Processor: Complex query cleaned: '%s'", cleanQuery)
		return s.storage.SearchBooks(ctx, &libraryv1.SearchRequest{
			Query:      strings.TrimSpace(cleanQuery),
			TemplateId: "fl_mixed_search",
			Limit:      req.Limit,
			TraceId:    req.TraceId,
		})
	}

	// 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ title: (–ö–∞—Å–∫–∞–¥–Ω—ã–π –ø–æ–∏—Å–∫)
	if strings.HasPrefix(qLower, "title:") {
		cleanTitle := strings.TrimSpace(strings.TrimPrefix(fullQuery, "title:"))
		
		// –ü–æ–ø—ã—Ç–∫–∞ 1: –°—Ç—Ä–æ–≥–∏–π substring
		subReq := &libraryv1.SearchRequest{
			Query:      cleanTitle,
			TemplateId: "fl_title_substring",
			Limit:      req.Limit,
			TraceId:    req.TraceId,
		}
		resp, err := s.storage.SearchBooks(ctx, subReq)
		
		if err == nil && resp.Total > 0 {
			return resp, nil
		}

		// –ü–æ–ø—ã—Ç–∫–∞ 2: –£–º–Ω—ã–π Match (–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ä–∞–∑–±–µ—Ä–µ—Ç—Å—è —Å —Ä–µ–≥–∏—Å—Ç—Ä–æ–º)
		log.Printf("‚ö†Ô∏è Substring search found 0, switching to fl_title_match for: %s", cleanTitle)
		subReq.TemplateId = "fl_title_match"
		return s.storage.SearchBooks(ctx, subReq)
	}

	// 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ author: (—É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞)
	if strings.HasPrefix(qLower, "author:") {
		cleanAuthor := strings.TrimSpace(strings.TrimPrefix(fullQuery, "author:"))
		subReq := &libraryv1.SearchRequest{
			Query:      cleanAuthor,
			TemplateId: "fl_author_exact",
			Limit:      req.Limit,
			TraceId:    req.TraceId,
		}
		resp, err := s.storage.SearchBooks(ctx, subReq)
		if err == nil && resp.Total > 0 {
			return resp, nil
		}
		log.Printf("‚ö†Ô∏è Switching to fuzzy for: %s", cleanAuthor)
		subReq.TemplateId = "fl_author_fuzzy"
		return s.storage.SearchBooks(ctx, subReq)
	}

	return s.storage.SearchBooks(ctx, req)
}

func main() {
	lis, err := net.Listen("tcp", ":50053")
	if err != nil { log.Fatal(err) }
	conn, err := grpc.Dial("localhost:50051", grpc.WithInsecure())
	if err != nil { log.Fatal(err) }
	defer conn.Close()
	s := grpc.NewServer()
	libraryv1.RegisterProcessorServiceServer(s, &processorServer{storage: libraryv1.NewStorageServiceClient(conn)})
	log.Println("üß† Ebusta Processor started on :50053")
	s.Serve(lis)
}

--- END_FILE: ./cmd/processor/main.go ---

--- START_FILE: ./cmd/cli/main.go ---
package main

import (
	"context"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"strings"
	"time"

	"ebusta/api/proto/v1"
	"github.com/peterh/liner"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
)

var (
	debugMode   bool
	historyPath = filepath.Join(os.TempDir(), ".ebusta_history")
)

func main() {
	if os.Getenv("DEBUG") != "" {
		debugMode = true
		log.Println("üêû DEBUG MODE: ENABLED")
	}

	conn, err := grpc.Dial("localhost:50054", grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		log.Fatalf("‚ùå Failed to connect to Orchestrator: %v", err)
	}
	defer conn.Close()

	client := libraryv1.NewOrchestratorServiceClient(conn)

	if len(os.Args) > 1 {
		query := strings.Join(os.Args[1:], " ")
		runSearch(client, query)
	} else {
		runInteractiveLoop(client)
	}
}

func runInteractiveLoop(client libraryv1.OrchestratorServiceClient) {
	line := liner.NewLiner()
	defer line.Close()

	line.SetCtrlCAborts(true)

	// –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏–∑ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
	if f, err := os.Open(historyPath); err == nil {
		line.ReadHistory(f)
		f.Close()
	}

	fmt.Println("üöÄ Ebusta CLI Interactive Mode (with History Support)")
	fmt.Println("Use UP/DOWN arrows for history. Type 'exit' to stop.")
	fmt.Println("---------------------------------")

	for {
		if text, err := line.Prompt("ebusta> "); err == nil {
			text = strings.TrimSpace(text)
			if text == "" {
				continue
			}
			if text == "exit" || text == "quit" {
				fmt.Println("Bye!")
				break
			}

			// –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
			line.AppendHistory(text)
			runSearch(client, text)

			// –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ –≤–≤–æ–¥–∞
			if f, err := os.Create(historyPath); err == nil {
				line.WriteHistory(f)
				f.Close()
			}
		} else if err == liner.ErrPromptAborted {
			fmt.Println("Aborted")
			break
		} else {
			log.Print("Error reading line: ", err)
			break
		}
	}
}

func runSearch(client libraryv1.OrchestratorServiceClient, query string) {
	if debugMode {
		log.Printf("üì° Sending query: '%s'", query)
	}

	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	resp, err := client.Search(ctx, &libraryv1.SearchRequest{
		Query:   query,
		TraceId: "cli-user",
	})

	if err != nil {
		log.Printf("‚ùå Error: %v", err)
		return
	}

	if resp.Total == 0 && len(resp.Books) == 0 {
		fmt.Println("No results found.")
		return
	}

	fmt.Printf("%-40s | %-40s | %s\n", "ID", "Title", "Authors")
	fmt.Println(strings.Repeat("-", 100))

	for _, b := range resp.Books {
		fmt.Printf("%-40s | %-40s | %s\n", 
			b.Id, 
			truncate(b.Title, 38), 
			truncate(strings.Join(b.Authors, ", "), 30),
		)
	}
}

func truncate(s string, max int) string {
	runes := []rune(s)
	if len(runes) > max {
		return string(runes[:max]) + "..."
	}
	return s
}

--- END_FILE: ./cmd/cli/main.go ---

--- START_FILE: ./cmd/client/main.go ---
package main

import (
	"context"
	"log"
	"time"

	"ebusta/api/proto/v1" // –£–±–µ–¥–∏—Å—å, —á—Ç–æ –º–æ–¥—É–ª—å –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è —Ç–∞–∫ –∂–µ, –∫–∞–∫ –≤ go.mod
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
)

func main() {
	// –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É Data-Manager
	conn, err := grpc.Dial("localhost:50051", grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		log.Fatalf("did not connect: %v", err)
	}
	defer conn.Close()

	c := libraryv1.NewLibraryServiceClient(conn)

	ctx, cancel := context.WithTimeout(context.Background(), time.Second)
	defer cancel()

	log.Println("--- Ebusta gRPC Client: Sending Search Request ---")
	
	// –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 1: –ú–µ—Ç–æ–¥ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è SearchBooks
	r, err := c.SearchBooks(ctx, &libraryv1.SearchRequest{
		Query: "Flibusta rules",
		Limit: 5,
	})
	if err != nil {
		log.Fatalf("could not search: %v", err)
	}

	// –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 2: –ò—Å–ø–æ–ª—å–∑—É–µ–º GetTotal() –≤–º–µ—Å—Ç–æ GetTotalFound()
	log.Printf("Response from server: Found %d books", r.GetTotal())
	
	for _, book := range r.GetBooks() {
		log.Printf("-> Book: [%s] %s (Authors: %v)", book.GetId(), book.GetTitle(), book.GetAuthors())
	}
}

--- END_FILE: ./cmd/client/main.go ---

--- START_FILE: ./cmd/web-adapter/main.go ---
package main

import (
	"context"
	"fmt"
	"log"
	"net/http"
	"time"

	"ebusta/api/proto/v1"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
)

func main() {
	log.Println("=== [WEB-ADAPTER] Starting on :50080 ===")
	orchHost := "localhost:50053"

	conn, err := grpc.Dial(orchHost, grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		log.Fatalf("did not connect: %v", err)
	}
	defer conn.Close()

	client := libraryv1.NewOrchestratorServiceClient(conn)

	http.HandleFunc("/input", func(w http.ResponseWriter, r *http.Request) {
		query := r.FormValue("msg")
		if query == "" {
			query = r.FormValue("q")
		}

		if query == "" {
			http.Error(w, "Please provide 'msg' parameter", http.StatusBadRequest)
			return
		}

		log.Printf("üåç Web Adapter received: %s", query)

		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
		defer cancel()

		resp, err := client.Search(ctx, &libraryv1.SearchRequest{
			Query: query,
		})

		if err != nil {
			http.Error(w, fmt.Sprintf("Error calling Orchestrator: %v", err), http.StatusInternalServerError)
			return
		}

		w.Header().Set("Content-Type", "text/plain; charset=utf-8")
		if len(resp.Books) == 0 {
			fmt.Fprintf(w, "No books found for: %s\n", query)
			return
		}

		fmt.Fprintf(w, "Found %d books:\n", len(resp.Books))
		for _, b := range resp.Books {
			fmt.Fprintf(w, "[%s] %s\n", b.Id, b.Title)
		}
	})

	log.Printf("üåç Web Adapter started on :50080")
	if err := http.ListenAndServe(":50080", nil); err != nil {
		log.Fatalf("failed to serve: %v", err)
	}
}

--- END_FILE: ./cmd/web-adapter/main.go ---

--- START_FILE: ./cmd/auth-manager/whitelist.yaml ---
users:
  - id: "serge_dev_cli"
    platform: "cli"
    role: "admin"
  - id: "12345678"
    platform: "telegram"
    role: "family"

--- END_FILE: ./cmd/auth-manager/whitelist.yaml ---

--- START_FILE: ./cmd/auth-manager/main.go ---
package main

import (
	"context"
	"log"
	"net"
	"os"

	"ebusta/api/proto/v1"
	"google.golang.org/grpc"
	"gopkg.in/yaml.v3"
)

type UserEntry struct {
	ID       string `yaml:"id"`
	Platform string `yaml:"platform"`
	Role     string `yaml:"role"`
}

type Whitelist struct {
	Users []UserEntry `yaml:"users"`
}

type authServer struct {
	libraryv1.UnimplementedAuthServiceServer
	whitelist Whitelist
}

func (s *authServer) CheckAccess(ctx context.Context, req *libraryv1.AccessRequest) (*libraryv1.AccessResponse, error) {
	log.Printf("[%s] Auth check: user=%s platform=%s", req.TraceId, req.UserId, req.Platform)

	for _, u := range s.whitelist.Users {
		if u.ID == req.UserId && u.Platform == req.Platform {
			return &libraryv1.AccessResponse{
				Allowed:  true,
				UserRole: u.Role,
			}, nil
		}
	}

	return &libraryv1.AccessResponse{
		Allowed: false,
		Reason:  "Access denied: user not in whitelist for this platform",
	}, nil
}

func main() {
	data, err := os.ReadFile("cmd/auth-manager/whitelist.yaml")
	if err != nil {
		log.Fatalf("Failed to read whitelist: %v", err)
	}

	var wl Whitelist
	if err := yaml.Unmarshal(data, &wl); err != nil {
		log.Fatalf("Failed to parse whitelist: %v", err)
	}

	lis, err := net.Listen("tcp", ":50055")
	if err != nil {
		log.Fatalf("failed to listen: %v", err)
	}

	s := grpc.NewServer()
	libraryv1.RegisterAuthServiceServer(s, &authServer{whitelist: wl})

	log.Println("üõ°  Auth-Manager started on :50055")
	if err := s.Serve(lis); err != nil {
		log.Fatalf("failed to serve: %v", err)
	}
}

--- END_FILE: ./cmd/auth-manager/main.go ---

--- START_FILE: ./cmd/orchestrator/main.go ---
package main

import (
	"context"
	"log"
	"net"

	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"

	libraryv1 "ebusta/api/proto/v1"
	dsl "ebusta/grpc/gen/go"
)

type orchestratorServer struct {
	libraryv1.UnimplementedOrchestratorServiceServer
	dslClient dsl.MessageConverterClient
}

func (s *orchestratorServer) Search(ctx context.Context, req *libraryv1.SearchRequest) (*libraryv1.SearchResponse, error) {
	log.Printf("üéº Orchestrator received: %s", req.Query)
	
	// 1. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ Lisp DSL —Å–µ—Ä–≤–∏—Å
	log.Printf("üéº Orchestrator -> DSL (Convert)...")
	dslResp, err := s.dslClient.Convert(ctx, &dsl.ConvertRequest{
		RawQuery: req.Query,
	})
	
	if err != nil {
		log.Printf("‚ùå DSL Error: %v", err)
		// –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É –∫–ª–∏–µ–Ω—Ç—É, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø—Ä–æ–±–ª–µ–º—É
		return nil, err
	}

	log.Printf("‚úÖ DSL Parsed: Canonical=%s, ID=%s", dslResp.CanonicalForm, dslResp.RequestId)

	// 2. –ó–¥–µ—Å—å –≤ –±—É–¥—É—â–µ–º –±—É–¥–µ—Ç –≤—ã–∑–æ–≤ DataManager
	// –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ", –Ω–æ —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º, —á—Ç–æ –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ—à–µ–ª
	return &libraryv1.SearchResponse{
		Books: []*libraryv1.Book{},
		Total: 0,
		Status: "ok",
	}, nil
}

func main() {
	log.Println("=== [ORCHESTRATOR] Starting on :50053 ===")

	// –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Lisp DSL (50052)
	conn, err := grpc.Dial("localhost:50052", grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		log.Fatalf("failed to connect to dsl: %v", err)
	}
	
	lis, err := net.Listen("tcp", ":50053")
	if err != nil {
		log.Fatalf("failed to listen: %v", err)
	}

	s := grpc.NewServer()
	libraryv1.RegisterOrchestratorServiceServer(s, &orchestratorServer{
		dslClient: dsl.NewMessageConverterClient(conn),
	})

	log.Println("üéº Orchestrator service registered")
	if err := s.Serve(lis); err != nil {
		log.Fatalf("failed to serve: %v", err)
	}
}

--- END_FILE: ./cmd/orchestrator/main.go ---

--- START_FILE: ./cmd/diagnose/main.go ---
package main

import (
	"context"
	"fmt"
	"log"
	"net/http"
	"time"

	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"

	libraryv1 "ebusta/api/proto/v1"
	dsl "ebusta/grpc/gen/go"
)

func main() {
	fmt.Println("üîç === STARTING COMPONENT DIAGNOSTICS ===")
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	// 1. TEST DSL (LISP)
	fmt.Println("\n[1] Testing Lisp DSL Service (:50052)...")
	checkDSL(ctx)

	// 2. TEST ORCHESTRATOR
	fmt.Println("\n[2] Testing Orchestrator (:50053)...")
	checkOrchestrator(ctx)

	// 3. TEST WEB ADAPTER
	fmt.Println("\n[3] Testing Web Adapter (:50080)...")
	checkWeb()

	fmt.Println("\nüèÅ === DIAGNOSTICS COMPLETE ===")
}

func checkDSL(ctx context.Context) {
	conn, err := grpc.Dial("localhost:50052", grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		log.Printf("‚ùå Failed to connect to DSL: %v", err)
		return
	}
	defer conn.Close()

	client := dsl.NewMessageConverterClient(conn)
	req := &dsl.ConvertRequest{RawQuery: "author:\"King\""}
	resp, err := client.Convert(ctx, req)
	if err != nil {
		log.Printf("‚ùå DSL Convert failed: %v", err)
		return
	}
	fmt.Printf("‚úÖ PASS. Canonical: '%s', RequestID: '%s'\n", resp.CanonicalForm, resp.RequestId)
}

func checkOrchestrator(ctx context.Context) {
	conn, err := grpc.Dial("localhost:50053", grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		log.Printf("‚ùå Failed to connect to Orchestrator: %v", err)
		return
	}
	defer conn.Close()

	client := libraryv1.NewOrchestratorServiceClient(conn)
	resp, err := client.Search(ctx, &libraryv1.SearchRequest{Query: "author:\"King\""})
	if err != nil {
		log.Printf("‚ùå Orchestrator Search failed: %v", err)
		return
	}
	fmt.Printf("‚úÖ PASS. Status: '%s', Books Found: %d\n", resp.Status, len(resp.Books))
	if len(resp.Books) == 0 {
		fmt.Println("   (Note: 0 books is expected if DataManager is not connected yet)")
	}
}

func checkWeb() {
	url := "http://localhost:50080/input?msg=author:King"
	resp, err := http.Get(url)
	if err != nil {
		log.Printf("‚ùå Web Adapter failed: %v", err)
		return
	}
	defer resp.Body.Close()
	
	if resp.StatusCode == 200 {
		fmt.Printf("‚úÖ PASS. HTTP Status: %d\n", resp.StatusCode)
	} else {
		fmt.Printf("‚ö†Ô∏è WARNING. HTTP Status: %d\n", resp.StatusCode)
	}
}

--- END_FILE: ./cmd/diagnose/main.go ---

--- START_FILE: ./cmd/message-converter/main.go ---
package main

import (
	"context"
	"fmt"
	"log"
	"net"

	"ebusta/api/proto/v1"
	"ebusta/internal/parser"
	"google.golang.org/grpc"
)

type server struct {
	libraryv1.UnimplementedMessageConverterServiceServer
}

func (s *server) Convert(ctx context.Context, req *libraryv1.RawInput) (*libraryv1.UnmarshaledMessage, error) {
	log.Printf("üîÑ Converter parsing: %s", req.Data)

	// –¢–µ–ø–µ—Ä—å —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ internal/parser/parser.go
	queryAst := parser.Parse(req.Data)

	return &libraryv1.UnmarshaledMessage{
		Meta: &libraryv1.MessageMeta{
			TraceId:       req.TraceId,
			CanonicalForm: req.Data,
			// –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É AST –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è –ª–æ–≥–æ–≤/–æ—Ç–ª–∞–¥–∫–∏
			AstPlan:       fmt.Sprintf("%v", queryAst),
		},
		Query: queryAst,
	}, nil
}

func main() {
	lis, err := net.Listen("tcp", ":50052")
	if err != nil {
		log.Fatalf("failed to listen: %v", err)
	}

	s := grpc.NewServer()
	libraryv1.RegisterMessageConverterServiceServer(s, &server{})

	log.Println("üîÑ MessageConverter started on :50052")
	if err := s.Serve(lis); err != nil {
		log.Fatalf("failed to serve: %v", err)
	}
}

--- END_FILE: ./cmd/message-converter/main.go ---

--- START_FILE: ./backlog-parser.md ---
–¶–µ–ª—å: –ü–µ—Ä–µ–≤–æ–¥ Processor –Ω–∞ –ø–æ–ª–Ω—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É Ebusta Search DSL v1.1 —á–µ—Ä–µ–∑ –æ–±—Ö–æ–¥ –¥–µ—Ä–µ–≤–∞ SearchQuery.
+3

1. –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
–ò–∑–º–µ–Ω–∏—Ç—å –ª–æ–≥–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ cmd/processor/main.go , —á—Ç–æ–±—ã —Å–µ—Ä–≤–∏—Å –∏–∑–≤–ª–µ–∫–∞–ª –ø–æ–ª–µ query —Ç–∏–ø–∞ SearchQuery –∏–∑ –≤—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è UnmarshaledMessage.
+4

–û–±–µ—Å–ø–µ—á–∏—Ç—å –ø–µ—Ä–µ–¥–∞—á—É —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ SearchQuery –æ—Ç Message-Converter –∫ Processor —á–µ—Ä–µ–∑ gRPC.
+3

2. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ AST Walker
–†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –æ–±—Ö–æ–¥–∞ –¥–µ—Ä–µ–≤–∞ SearchQuery –≤ internal/processor.
+2

–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —É–∑–ª–∞ LogicalNode –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ AND –∏ OR.
+1

–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —É–∑–ª–∞ NotNode –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏–Ω–≤–µ—Ä—Å–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ (negation).
+1

3. –ú–∞–ø–ø–∏–Ω–≥ —É–∑–ª–æ–≤ –Ω–∞ —à–∞–±–ª–æ–Ω—ã OpenSearch
–ó–∞–º–µ–Ω–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É strings.HasPrefix(queryLower, "author:") –Ω–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ FilterNode —Å –ø–æ–ª–µ–º field: "author".
+1

–ü—Ä–∏–≤—è–∑–∞—Ç—å FilterNode  –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º —à–∞–±–ª–æ–Ω–∞–º –¥–∞–Ω–Ω—ã—Ö:


field: "author" -> fl_author_exact / fl_author_fuzzy.


field: "title" -> fl_title_substring / fl_title_prefix.


field: "any" -> fl_mixed_search.
+1

–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É Operator:
+1


OP_REGEX -> —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è –≤ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è OpenSearch.


OP_EQUALS -> —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ.
+1

4. –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —É—Å–ª–æ–≤–∏–π
–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—é LogicalNode –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É bool query (must, should, must_not) –¥–ª—è OpenSearch.
+3

–û–±–µ—Å–ø–µ—á–∏—Ç—å —Å–æ–±–ª—é–¥–µ–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤: NOT > AND > OR.

5. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è
–î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –≤ tests/smoke_full.sh –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ü–µ–ø–æ—á–∫–∏: DSL-—Å—Ç—Ä–æ–∫–∞ -> Message-Converter (AST) -> Processor (Walker) -> Data-Manager.
+2

–í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª–µ meta.canonical_form –≤ –æ—Ç–≤–µ—Ç–µ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ —Ä–∞–∑–æ–±—Ä–∞–Ω–Ω–æ–≥–æ –¥–µ—Ä–µ–≤–∞.
+1

–ê—É–¥–∏—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏:


–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ: –ü–æ–ª—è LogicalOp, Operator –∏ SearchQuery —É–∂–µ –æ–±—ä—è–≤–ª–µ–Ω—ã –≤ api/proto/v1/library.proto.
+1


–§—É–Ω–∫—Ü–∏–∏: –ü–∞—Ä—Å–µ—Ä parser.Parse(req.Data) —É–∂–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω –≤ cmd/message-converter/main.go.


–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞: –®–∞–±–ª–æ–Ω—ã OpenSearch (fl_mixed_search, fl_author_exact –∏ –¥—Ä.) –≥–æ—Ç–æ–≤—ã –∫ –ø—Ä–∏–µ–º—É —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

--- END_FILE: ./backlog-parser.md ---

--- START_FILE: ./books.json ---
[
  {"id": "1", "title": "–û–Ω–æ", "authors": ["–°—Ç–∏–≤–µ–Ω –ö–∏–Ω–≥"]},
  {"id": "2", "title": "–°–∏—è–Ω–∏–µ", "authors": ["–°—Ç–∏–≤–µ–Ω –ö–∏–Ω–≥"]},
  {"id": "3", "title": "The Hobbit", "authors": ["J.R.R. Tolkien"]}
]

--- END_FILE: ./books.json ---

--- START_FILE: ./go.mod ---
module ebusta

go 1.24.0

toolchain go1.24.11

require (
	github.com/kelseyhightower/envconfig v1.4.0
	github.com/peterh/liner v1.2.2
	github.com/prometheus/client_golang v1.23.2
	github.com/schollz/progressbar/v3 v3.19.0
	github.com/sirupsen/logrus v1.9.3
	github.com/spf13/viper v1.21.0
	golang.org/x/text v0.31.0
	google.golang.org/grpc v1.78.0
	google.golang.org/protobuf v1.36.10
	gopkg.in/yaml.v3 v3.0.1
)

require (
	github.com/beorn7/perks v1.0.1 // indirect
	github.com/cespare/xxhash/v2 v2.3.0 // indirect
	github.com/fsnotify/fsnotify v1.9.0 // indirect
	github.com/go-viper/mapstructure/v2 v2.4.0 // indirect
	github.com/mattn/go-runewidth v0.0.16 // indirect
	github.com/mitchellh/colorstring v0.0.0-20190213212951-d06e56a500db // indirect
	github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect
	github.com/pelletier/go-toml/v2 v2.2.4 // indirect
	github.com/prometheus/client_model v0.6.2 // indirect
	github.com/prometheus/common v0.66.1 // indirect
	github.com/prometheus/procfs v0.16.1 // indirect
	github.com/rivo/uniseg v0.4.7 // indirect
	github.com/sagikazarmark/locafero v0.11.0 // indirect
	github.com/sourcegraph/conc v0.3.1-0.20240121214520-5f936abd7ae8 // indirect
	github.com/spf13/afero v1.15.0 // indirect
	github.com/spf13/cast v1.10.0 // indirect
	github.com/spf13/pflag v1.0.10 // indirect
	github.com/subosito/gotenv v1.6.0 // indirect
	go.yaml.in/yaml/v2 v2.4.2 // indirect
	go.yaml.in/yaml/v3 v3.0.4 // indirect
	golang.org/x/net v0.47.0 // indirect
	golang.org/x/sys v0.38.0 // indirect
	golang.org/x/term v0.37.0 // indirect
	google.golang.org/genproto/googleapis/rpc v0.0.0-20251029180050-ab9386a59fda // indirect
)

--- END_FILE: ./go.mod ---

--- START_FILE: ./Makefile ---
LISP_DIR=$(shell pwd)/lisp-converter
GEN_DIR=grpc/gen/go

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ—Ä—Ç–æ–≤
WEB_PORT=50080
ORCH_PORT=50053
DSL_PORT=50052
DATA_PORT=50051

.PHONY: build-all stop-all start-all restart-all test-compliance test-e2e proto

proto:
	@mkdir -p $(GEN_DIR)
	protoc --proto_path=lisp-converter \
		--go_out=$(GEN_DIR) \
		--go_opt=Msearch.proto=ebusta/$(GEN_DIR) \
		--go_opt=paths=source_relative \
		--go-grpc_out=$(GEN_DIR) \
		--go-grpc_opt=Msearch.proto=ebusta/$(GEN_DIR) \
		--go-grpc_opt=paths=source_relative \
		lisp-converter/search.proto
	@go mod tidy

build-all: proto
	@echo "Building DSL-Converter..."
	sbcl --noinform --eval '(push (truename "$(LISP_DIR)/") asdf:*central-registry*)' \
		--eval '(ql:quickload :ebusta-search :silent t)' \
		--load "$(LISP_DIR)/dsl-service.lisp" \
		--eval '(ebusta-service:build-binary)' --quit
	@echo "Building Go Stack..."
	go build -o datamanager ./cmd/datamanager
	go build -o orchestrator ./cmd/orchestrator
	go build -o web-adapter ./cmd/web-adapter

stop-all:
	@-pkill -f dsl-converter || true
	@-pkill -f orchestrator || true
	@-pkill -f datamanager || true
	@-pkill -f web-adapter || true

start-all:
	@echo "Starting Full Stack..."
	./datamanager -port $(DATA_PORT) >> data.log 2>&1 &
	./dsl-converter >> dsl.log 2>&1 &
	@sleep 2
	./orchestrator -port $(ORCH_PORT) >> orch.log 2>&1 &
	@sleep 1
	./web-adapter -port $(WEB_PORT) >> web.log 2>&1 &
	@sleep 1
	@echo "--- Service Status ---"
	@grep "===" data.log | tail -n 1 || echo "[DATAMANAGER] No banner"
	@grep "===" dsl.log | tail -n 1 || echo "[DSL-CONVERTER] No banner"
	@grep "===" orch.log | tail -n 1 || echo "[ORCHESTRATOR] No banner"
	@grep "===" web.log | tail -n 1 || echo "[WEB-ADAPTER] No banner"
	@echo "----------------------"

test-compliance:
	@go run tests/compliance_runner.go

test-e2e:
	@echo "=== Running E2E Test (HTTP :$(WEB_PORT)/input) ==="
	@# –ü—Ä–æ—Å—Ç–æ –≤—ã–≤–æ–¥–∏–º –æ—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞ –±–µ–∑ jq
	@curl -v -X POST --data-urlencode "msg=author:\"–°—Ç–∏–≤–µ–Ω –ö–∏–Ω–≥\"" http://localhost:$(WEB_PORT)/input

restart-all: stop-all build-all start-all

--- END_FILE: ./Makefile ---

--- START_FILE: ./EBusta_Search_Technical_Spec_v1.1.md ---
# –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è: –ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ Ebusta (v1.1)

## 1. –û–±–∑–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
[cite_start]–°–∏—Å—Ç–µ–º–∞ Ebusta –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω—É—é –ø–æ–∏—Å–∫–æ–≤—É—é –ø–ª–∞—Ç—Ñ–æ—Ä–º—É, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—É—é –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∏ –ø–æ–∏—Å–∫–∞ –ø–æ –∞—Ä—Ö–∏–≤–∞–º —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö –∫–Ω–∏–≥[cite: 326]. [cite_start]–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –º–µ–∂–¥—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ gRPC[cite: 409].

### –ü–æ—Ç–æ–∫–æ–≤—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä (Pipeline)
1.  [cite_start]**Web-Adapter**: –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –≤–Ω–µ—à–Ω–∏–µ HTTP-–∑–∞–ø—Ä–æ—Å—ã –∏ –ø–µ—Ä–µ–¥–∞–µ—Ç –∏—Ö –≤ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä[cite: 328, 411].
2.  [cite_start]**Orchestrator**: –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤ –∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ (`Trace-ID`)[cite: 329].
3.  [cite_start]**Message-Converter**: –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—ã—Ä—É—é —Å—Ç—Ä–æ–∫—É –∑–∞–ø—Ä–æ—Å–∞ –≤ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω–æ–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–æ–µ –¥–µ—Ä–µ–≤–æ (AST)[cite: 329, 413].
4.  [cite_start]**Processor**: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —É–∑–µ–ª –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∏, –≤—ã–±–∏—Ä–∞—é—â–∏–π —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø–æ–∏—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ AST[cite: 330, 415].
5.  [cite_start]**Data-Manager**: –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–∏—Å–∞ –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å OpenSearch[cite: 330, 417].
6.  [cite_start]**OpenSearch**: –î–≤–∏–∂–æ–∫ –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞, –≤—ã–ø–æ–ª–Ω—è—é—â–∏–π –∑–∞–ø—Ä–æ—Å—ã –ø–æ –∏–Ω–¥–µ–∫—Å—É `flibusta_merged_index`[cite: 369].



---

## 2. Ebusta Search DSL (v1.1)

[cite_start]DSL (Domain Specific Language) –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≥–∏–±–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø–æ–∏—Å–∫–∞[cite: 426].

### 2.1 –õ–µ–∫—Å–∏—á–µ—Å–∫–∏–µ –∞—Ç–æ–º—ã –∏ –ø—Ä–µ—Ñ–∏–∫—Å—ã (Scopes)
–°–∏—Å—Ç–µ–º–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –æ–±–ª–∞—Å—Ç–∏ –ø–æ–∏—Å–∫–∞:
* [cite_start]`title:` ‚Äî –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∫–Ω–∏–≥–∏[cite: 426].
* [cite_start]`author:` ‚Äî –ü–æ–∏—Å–∫ –ø–æ –∏–º–µ–Ω–∏ –∞–≤—Ç–æ—Ä–∞[cite: 426].
* [cite_start]`author_id:` ‚Äî –ü–æ–∏—Å–∫ –ø–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–º—É –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É –∞–≤—Ç–æ—Ä–∞[cite: 426].
* [cite_start]`desc:` ‚Äî –ü–æ–∏—Å–∫ –ø–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏/–æ–ø–∏—Å–∞–Ω–∏—é[cite: 426].
* **`id:`** ‚Äî –ü–æ–∏—Å–∫ –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–ª–∏ SHA1-—Ö–µ—à—É —Ñ–∞–π–ª–∞.
* **`file:`** ‚Äî –ü–æ–∏—Å–∫ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `743373.fb2`).
* **`container:`** ‚Äî –ü–æ–∏—Å–∫ –ø–æ –∏–º–µ–Ω–∏ ZIP-–∞—Ä—Ö–∏–≤–∞.

### 2.2 –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã –∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
* [cite_start]**–û–ø–µ—Ä–∞—Ç–æ—Ä—ã**: `AND`, `OR`, `NOT` (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ)[cite: 426].
* [cite_start]**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç**: `NOT` > `AND` > `OR`[cite: 433].
* [cite_start]**–†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è**: –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤–∏–¥–∞ `/regex/`[cite: 426, 430].
* [cite_start]**–¢–æ—á–Ω—ã–µ —Ñ—Ä–∞–∑—ã**: –ü–æ–∏—Å–∫ –ø–æ —Ñ—Ä–∞–∑–µ –≤ –∫–∞–≤—ã—á–∫–∞—Ö: `"–ú–∞—Å—Ç–µ—Ä –∏ –ú–∞—Ä–≥–∞—Ä–∏—Ç–∞"`[cite: 426].

---

## 3. –í–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ: SearchQuery (AST)

[cite_start]–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö `SearchQuery` —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Protocol Buffers (`library.proto`)[cite: 173].

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–µ—Ä–µ–≤–∞:
* [cite_start]**FilterNode**: –õ–∏—Å—Ç–æ–≤–æ–π —É–∑–µ–ª, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –ø–æ–ª—è `field`, `value` –∏ `operator` (`OP_EQUALS`, `OP_CONTAINS`, `OP_REGEX`)[cite: 175].
* [cite_start]**LogicalNode**: –£–∑–µ–ª –≤–µ—Ç–≤–ª–µ–Ω–∏—è, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π –¥—Ä—É–≥–∏–µ –∑–∞–ø—Ä–æ—Å—ã —á–µ—Ä–µ–∑ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏[cite: 176].
* [cite_start]**NotNode**: –£–∑–µ–ª –∏–Ω–≤–µ—Ä—Å–∏–∏ –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞ `NOT`[cite: 174, 177].



---

## 4. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏ (OpenSearch)

### 4.1 –°—Ö–µ–º–∞ –∏–Ω–¥–µ–∫—Å–∞
[cite_start]–ò–Ω–¥–µ–∫—Å `flibusta_merged_index` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç—Ä–æ–≥–∏–π –º–∞–ø–ø–∏–Ω–≥ (`dynamic: strict`)[cite: 197].
* [cite_start]**–¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è**: –ü–æ–ª—è `title` –∏ `authors` –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä `mixed_text` –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ä—É—Å—Å–∫–æ–≥–æ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–æ–≤[cite: 198, 200].
* [cite_start]**–ü–æ–ª—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤**: –ü–æ–¥–ø–æ–ª—è `.kw` –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ —Å—Ö–ª–æ–ø—ã–≤–∞–Ω–∏—è –¥—É–±–ª–µ–π[cite: 198, 201].
* [cite_start]**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ**: –û–±—ä–µ–∫—Ç `fileInfo` —Ö—Ä–∞–Ω–∏—Ç `container`, `filename` –∏ `size`[cite: 205].

### 4.2 –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
[cite_start]–î–ª—è –±–æ—Ä—å–±—ã —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–µ—Ö–∞–Ω–∏–∑–º **Collapse** –ø–æ –ø–æ–ª—é `title.kw`[cite: 185].
* [cite_start]–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ–∏—Å–∫–∞ –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è ¬´–ª—É—á—à–∞—è¬ª –≤–µ—Ä—Å–∏—è –∫–Ω–∏–≥–∏ (—Å–µ–∫—Ü–∏—è `inner_hits` —Å –∏–º–µ–Ω–µ–º `best`), –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É —Ñ–∞–π–ª–∞ (`fileInfo.size`)[cite: 185, 186].

---

## 5. –¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞–∑–≤–∏—Ç–∏—è

### 5.1 –ê–Ω–∞–ª–∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è (Status Quo)
[cite_start]–ù–∞ —Ç–µ–∫—É—â–∏–π –º–æ–º–µ–Ω—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç **Parser** (`internal/parser`) —É—Å–ø–µ—à–Ω–æ —Ä–∞–∑–±–∏—Ä–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –≤ AST –≤ —Å–µ—Ä–≤–∏—Å–µ `Message-Converter`[cite: 244]. [cite_start]–û–¥–Ω–∞–∫–æ —Å–µ—Ä–≤–∏—Å **Processor** –≤—Å–µ –µ—â–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –ª–æ–≥–∏–∫—É —Ä–∞–∑–±–æ—Ä–∞ —Å—Ç—Ä–æ–∫ —á–µ—Ä–µ–∑ `strings.HasPrefix`[cite: 231, 233].

### 5.2 –ü–ª–∞–Ω –≤–Ω–µ–¥—Ä–µ–Ω–∏—è AST Walker
[cite_start]–¶–µ–ª—å—é —è–≤–ª—è–µ—Ç—Å—è –ø–æ–ª–Ω—ã–π –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –æ–±—Ö–æ–¥ –¥–µ—Ä–µ–≤–∞ `SearchQuery` –≤ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ[cite: 249]:
1.  [cite_start]**–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ**: –ü–µ—Ä–µ–≤–æ–¥ `cmd/processor/main.go` –Ω–∞ —Ä–∞–±–æ—Ç—É —Å –ø–æ–ª–µ–º `query` –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è `UnmarshaledMessage`[cite: 247].
2.  **–ú–∞–ø–ø–∏–Ω–≥**: –ü—Ä–∏–≤—è–∑–∫–∞ –Ω–æ–≤—ã—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ (`id`, `file`, `container`) –∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –ø–æ–ª—è–º –∏–Ω–¥–µ–∫—Å–∞ OpenSearch –≤ —à–∞–±–ª–æ–Ω–∞—Ö.
3.  [cite_start]**–õ–æ–≥–∏–∫–∞**: –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏–∏ `LogicalNode` –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É `bool query` (must, should, must_not) –¥–ª—è OpenSearch[cite: 254].
4.  [cite_start]**–í–∞–ª–∏–¥–∞—Ü–∏—è**: –û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –≤–æ–∑–≤—Ä–∞—Ç–∞ `meta.canonical_form` –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–µ—Ä–µ–≤–∞ —Ä–∞–∑–±–æ—Ä–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é[cite: 434, 467].

---
*–î–æ–∫—É–º–µ–Ω—Ç –∞–∫—Ç—É–∞–ª–µ–Ω –Ω–∞: 2026-01-25*

--- END_FILE: ./EBusta_Search_Technical_Spec_v1.1.md ---

--- START_FILE: ./f2bulker/config.yaml ---
opensearch:
  index_name: "flibusta_merged_index"
  url: "http://cloud-1:9200"

paths:
  warn_dir: "./data/warn"
  output_dir: "./data/out"
  source_dir: "/mnt/fb2/fb2.Flibusta.Net"

processing:
  threads: 4

logging:
  log_path: "f2bulker.log"

metrics:
  pushgateway_url: "http://localhost:9091"

# –ü–∞—É–∑–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö –º–µ–∂–¥—É –∞—Ä—Ö–∏–≤–∞–º–∏, —á—Ç–æ–±—ã —Å–µ—Ä–≤–µ—Ä –æ—Å—Ç—ã–ª
sleep_between_zips: 600 


uploading:
  log_path: "uploader.log"
  sleep_between_uploads: 30

--- END_FILE: ./f2bulker/config.yaml ---

--- START_FILE: ./f2bulker/cmd/bulker/main.go ---
package main

import (
	"archive/zip"
	"bufio"
	"bytes"
	"crypto/sha1"
	"encoding/hex"
	"encoding/json"
	"encoding/xml"
	"flag"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"github.com/schollz/progressbar/v3"
	"github.com/sirupsen/logrus"
	"golang.org/x/text/encoding/charmap"
	"golang.org/x/text/encoding/unicode"
	"gopkg.in/yaml.v3"
)

type Config struct {
	OpenSearch struct {
		IndexName string `yaml:"index_name"`
	} `yaml:"opensearch"`
	Paths struct {
		WarnDir   string `yaml:"warn_dir"`
		OutputDir string `yaml:"output_dir"`
		SourceDir string `yaml:"source_dir"`
	} `yaml:"paths"`
	Processing struct {
		Threads int `yaml:"threads"`
	} `yaml:"processing"`
}

type docOut struct {
	Title      string    `json:"title"`
	Authors    []string  `json:"authors,omitempty"`
	IngestedAt time.Time `json:"ingestedAt"`
	FileInfo   struct {
		Container string `json:"container"`
		Filename  string `json:"filename"`
		Sha1      string `json:"sha1"`
		Size      int64  `json:"size"`
	} `json:"fileInfo"`
}

var (
	cfg           Config
	log           = logrus.New()
	outFile       *os.File
	outMu         sync.Mutex
	bar           *progressbar.ProgressBar
	rescuedCount  int32
	flagRescan    *bool
	flagVerbose   *bool
	flagSuperFast *bool
)

func main() {
	configPath := flag.String("config", "./config.yaml", "Path to config file")
	container := flag.String("container", "", "Process specific ZIP")
	rescue := flag.Bool("rescue", false, "Rescue mode")
	flagRescan = flag.Bool("rescan", false, "Force rescan all")
	flagVerbose = flag.Bool("verbose", false, "Detailed check")
	flagSuperFast = flag.Bool("fast", false, "Ultra-fast skip if output exists")
	flag.Parse()

	cFile, err := os.ReadFile(*configPath)
	if err != nil {
		fmt.Printf("Error reading config: %v\n", err)
		os.Exit(1)
	}
	if err := yaml.Unmarshal(cFile, &cfg); err != nil {
		fmt.Printf("Error parsing YAML: %v\n", err)
		os.Exit(1)
	}

	log.SetFormatter(&logrus.TextFormatter{FullTimestamp: true, ForceColors: true})
	_ = os.MkdirAll(cfg.Paths.OutputDir, 0755)

	if *rescue {
		runRescueMode()
	} else if *container != "" {
		processSingleZip(filepath.Join(cfg.Paths.SourceDir, *container), filepath.Join(cfg.Paths.OutputDir, *container+".jsonl"))
	} else {
		archives, _ := filepath.Glob(filepath.Join(cfg.Paths.SourceDir, "*.zip"))
		for _, zipPath := range archives {
			processSingleZip(zipPath, filepath.Join(cfg.Paths.OutputDir, filepath.Base(zipPath)+".jsonl"))
		}
	}
}

func normalizeJSONL(path string) (int, error) {
	f, err := os.Open(path)
	if err != nil { return 0, err }
	defer f.Close()
	tmpPath := path + ".tmp"
	tmpFile, err := os.Create(tmpPath)
	if err != nil { return 0, err }
	defer tmpFile.Close()

	hashes := make(map[string]bool)
	scanner := bufio.NewScanner(f)
	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
	count := 0
	for scanner.Scan() {
		line1 := scanner.Text()
		if strings.Contains(line1, `"_index"`) {
			match := re.FindStringSubmatch(line1)
			if len(match) > 1 {
				id := match[1]
				if scanner.Scan() {
					line2 := scanner.Text()
					if !hashes[id] {
						hashes[id] = true
						_, _ = tmpFile.WriteString(line1 + "\n")
						_, _ = tmpFile.WriteString(line2 + "\n")
						count++
					}
				}
			}
		}
	}
	_ = os.Rename(tmpPath, path)
	return count, nil
}

func countExistingDocs(path string) int {
	count := 0
	f, err := os.Open(path)
	if err != nil { return 0 }
	defer f.Close()
	scanner := bufio.NewScanner(f)
	for scanner.Scan() {
		if strings.Contains(scanner.Text(), `"_index"`) { count++ }
	}
	return count
}

func loadExistingHashes(path string) map[string]bool {
	hashes := make(map[string]bool)
	f, err := os.Open(path)
	if err != nil { return hashes }
	defer f.Close()
	scanner := bufio.NewScanner(f)
	re := regexp.MustCompile(`"_id":"([a-fA-F0-9]+)"`)
	for scanner.Scan() {
		line := scanner.Text()
		if strings.Contains(line, `"_index"`) {
			match := re.FindStringSubmatch(line)
			if len(match) > 1 { hashes[match[1]] = true }
		}
	}
	return hashes
}

func processSingleZip(zipPath, dstPath string) {
	containerName := filepath.Base(zipPath)
	if *flagSuperFast && !*flagRescan {
		if info, err := os.Stat(dstPath); err == nil && info.Size() > 0 {
			log.Infof("[%s] Fast-skip: exists.", containerName)
			os.Exit(10)
		}
	}

	z, err := zip.OpenReader(zipPath)
	if err != nil { return }
	defer z.Close()

	fb2Count := 0
	for _, f := range z.File {
		if strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { fb2Count++ }
	}

	if !*flagRescan && !*flagVerbose {
		if jsonlCount := countExistingDocs(dstPath); jsonlCount > 0 {
			if fb2Count == jsonlCount {
				os.Exit(10)
			} else {
				newCount, _ := normalizeJSONL(dstPath)
				if newCount == fb2Count { os.Exit(10) }
			}
		}
	}

	existingHashes := make(map[string]bool)
	if !*flagRescan { existingHashes = loadExistingHashes(dstPath) }

	type workItem struct {
		file *zip.File
		raw  []byte
		sha  string
	}
	var tasks []workItem

	for _, f := range z.File {
		if !strings.HasSuffix(strings.ToLower(f.Name), ".fb2") { continue }
		
		if len(existingHashes) == 0 && !*flagRescan && !*flagVerbose {
			tasks = append(tasks, workItem{file: f})
			continue
		}

		rc, err := f.Open()
		if err != nil { continue }
		data, _ := io.ReadAll(rc)
		rc.Close()
		sum := sha1.Sum(data)
		sha := hex.EncodeToString(sum[:])
		if !existingHashes[sha] {
			tasks = append(tasks, workItem{file: f, raw: data, sha: sha})
		}
	}

	if len(tasks) == 0 { os.Exit(10) }

	openOutputFile(dstPath)
	defer outFile.Close()
	bar = progressbar.Default(int64(len(tasks)), "üö¢ "+containerName)
	jobs := make(chan workItem)
	var wg sync.WaitGroup
	for i := 0; i < cfg.Processing.Threads; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for item := range jobs {
				if item.raw == nil {
					rc, err := item.file.Open()
					if err == nil {
						item.raw, _ = io.ReadAll(rc)
						rc.Close()
						sum := sha1.Sum(item.raw)
						item.sha = hex.EncodeToString(sum[:])
					}
				}
				if item.raw != nil {
					if doc, err := parseResilient(item.raw); err == nil {
						saveToOutputWithSha(item.file.Name, containerName, item.raw, item.sha, doc)
					}
				}
				_ = bar.Add(1)
			}
		}()
	}
	for _, t := range tasks { jobs <- t }
	close(jobs)
	wg.Wait()
}

func runRescueMode() {
	files, _ := filepath.Glob(filepath.Join(cfg.Paths.WarnDir, "*fb2"))
	if len(files) == 0 { return }
	dstPath := filepath.Join(cfg.Paths.OutputDir, "rescued_items.jsonl")
	openOutputFile(dstPath)
	defer outFile.Close()
	jobs := make(chan string)
	var wg sync.WaitGroup
	for i := 0; i < cfg.Processing.Threads; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for path := range jobs {
				data, err := os.ReadFile(path)
				if err != nil { continue }
				if doc, err := parseResilient(data); err == nil {
					if saveToOutput(filepath.Base(path), "rescued", data, doc) {
						_ = os.Remove(path)
						atomic.AddInt32(&rescuedCount, 1)
					}
				}
			}
		}()
	}
	for _, f := range files { jobs <- f }
	close(jobs)
	wg.Wait()
}

func parseResilient(data []byte) (*docOut, error) {
	utf8Data := convertToUTF8(data)
	if doc, err := parseFB2(utf8Data); err == nil { return doc, nil }
	return parseWithRegex(utf8Data)
}

func convertToUTF8(data []byte) []byte {
	if len(data) < 2 { return data }
	if (data[0] == 0xFF && data[1] == 0xFE) || (data[0] == 0xFE && data[1] == 0xFF) {
		dec := unicode.UTF16(unicode.LittleEndian, unicode.UseBOM).NewDecoder()
		out, _ := dec.Bytes(data)
		return out
	}
	header := string(data[:min(len(data), 500)])
	if strings.Contains(strings.ToLower(header), "windows-1251") {
		out, _ := charmap.Windows1251.NewDecoder().Bytes(data)
		return out
	}
	return bytes.ToValidUTF8(data, []byte(" "))
}

func parseWithRegex(data []byte) (*docOut, error) {
	doc := &docOut{}
	reTitle := regexp.MustCompile(`(?is)<book-title[^>]*>(.*?)</book-title>`)
	if m := reTitle.FindSubmatch(data); len(m) > 1 { doc.Title = string(m[1]) }
	if doc.Title == "" { return nil, fmt.Errorf("regex failed") }
	return doc, nil
}

func openOutputFile(path string) {
	var err error
	outFile, err = os.OpenFile(path, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
	if err != nil {
		log.Fatalf("Critical: failed to open output file: %v", err)
	}
}

func saveToOutput(filename, container string, raw []byte, doc *docOut) bool {
	sum := sha1.Sum(raw)
	sha := hex.EncodeToString(sum[:])
	return saveToOutputWithSha(filename, container, raw, sha, doc)
}

func saveToOutputWithSha(filename, container string, raw []byte, sha string, doc *docOut) bool {
	doc.FileInfo.Container, doc.FileInfo.Filename, doc.FileInfo.Sha1, doc.FileInfo.Size = container, filename, sha, int64(len(raw))
	doc.IngestedAt = time.Now()
	action, _ := json.Marshal(map[string]map[string]any{"index": {"_index": cfg.OpenSearch.IndexName, "_id": sha}})
	data, _ := json.Marshal(doc)
	outMu.Lock()
	defer outMu.Unlock()
	_, _ = outFile.Write(append(action, '\n'))
	_, _ = outFile.Write(append(data, '\n'))
	return true
}

func parseFB2(data []byte) (*docOut, error) {
	var doc docOut
	d := xml.NewDecoder(bytes.NewReader(data))
	for {
		t, _ := d.Token()
		if t == nil { break }
		if se, ok := t.(xml.StartElement); ok && se.Name.Local == "book-title" {
			_ = d.DecodeElement(&doc.Title, &se)
		}
	}
	if doc.Title == "" { return nil, fmt.Errorf("no title") }
	return &doc, nil
}

func min(a, b int) int { if a < b { return a }; return b }

--- END_FILE: ./f2bulker/cmd/bulker/main.go ---

--- START_FILE: ./f2bulker/go.mod ---
module f2bulker

go 1.24.11

require (
	github.com/schollz/progressbar/v3 v3.19.0
	github.com/sirupsen/logrus v1.9.3
	golang.org/x/text v0.32.0
	gopkg.in/yaml.v3 v3.0.1
)

require (
	github.com/kr/pretty v0.3.1 // indirect
	github.com/mitchellh/colorstring v0.0.0-20190213212951-d06e56a500db // indirect
	github.com/rivo/uniseg v0.4.7 // indirect
	github.com/rogpeppe/go-internal v1.10.0 // indirect
	github.com/stretchr/testify v1.11.1 // indirect
	golang.org/x/sys v0.35.0 // indirect
	golang.org/x/term v0.28.0 // indirect
	gopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c // indirect
)

--- END_FILE: ./f2bulker/go.mod ---

--- START_FILE: ./f2bulker/Makefile ---
BINARY_NAME=f2bulker
INSTALL_DIR=/opt/f2bulker
BIN_PATH=$(INSTALL_DIR)/$(BINARY_NAME)
LOCAL_BIN=./bin/$(BINARY_NAME)
IS_ROOT = $(shell id -u)

.PHONY: build install clean check-root

build:
	go mod tidy
	mkdir -p bin
	go build -o $(LOCAL_BIN) ./cmd/bulker/main.go

check-root:
ifneq ($(IS_ROOT), 0)
	@echo "Error: Run 'sudo make install'"
	@exit 1
endif

install: check-root
	@if [ ! -f $(LOCAL_BIN) ]; then echo "Run 'make build' first"; exit 1; fi
	mkdir -p $(INSTALL_DIR)
	mkdir -p $(INSTALL_DIR)/data/src $(INSTALL_DIR)/data/out $(INSTALL_DIR)/data/warn
	cp $(LOCAL_BIN) $(INSTALL_DIR)/
	cp ./config.yaml $(INSTALL_DIR)/
	cp ./scripts/scan_zips.sh $(INSTALL_DIR)/
	chmod +x $(BIN_PATH)
	chmod +x $(INSTALL_DIR)/scan_zips.sh
	@echo "Installed to $(INSTALL_DIR)"
	@echo "Link: sudo ln -sf $(BIN_PATH) /usr/local/bin/$(BINARY_NAME)"

clean:
	rm -rf bin

--- END_FILE: ./f2bulker/Makefile ---

--- START_FILE: ./f2bulker/README.md ---
# f2bulker: –í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä FB2 –≤ OpenSearch

## 1. –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π (ISO 29148)

–î–∞–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª —Ñ–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–∏—Å—Ç–µ–º–µ, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –∏—Ö –ø—Ä–æ–≤–µ—Ä—è–µ–º–æ—Å—Ç—å –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º —Ü–µ–ª—è–º –ø—Ä–æ–µ–∫—Ç–∞.

### 1.1 –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (Functional Requirements)
* **FR-1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ ZIP.** –°–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ –æ—Ç–∫—Ä—ã–≤–∞—Ç—å ZIP-–∞—Ä—Ö–∏–≤—ã –∏ –∏–∑–≤–ª–µ–∫–∞—Ç—å —Ñ–∞–π–ª—ã —Ñ–æ—Ä–º–∞—Ç–∞ `.fb2`.
* **FR-2: –ü–∞—Ä—Å–∏–Ω–≥ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö.** –ü—Ä–æ–≥—Ä–∞–º–º–∞ –¥–æ–ª–∂–Ω–∞ –∏–∑–≤–ª–µ–∫–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–Ω–∏–≥–∏ –∏ —Å–ø–∏—Å–æ–∫ –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã FB2.
* **FR-3: –û—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å.** –ü—Ä–∏ –æ—à–∏–±–∫–∞—Ö XML-–ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è.
* **FR-4: –§–æ—Ä–º–∞—Ç Bulk API.** –í—ã–≤–æ–¥ –¥–æ–ª–∂–µ–Ω —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSONL, –ø—Ä–∏–≥–æ–¥–Ω–æ–º –¥–ª—è Bulk API OpenSearch, –≤–∫–ª—é—á–∞—è —Å—Ç—Ä–æ–∫—É –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–∞ –∏ —Å—Ç—Ä–æ–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–∞.
* **FR-5: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è.** –°–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—Ç—å SHA1-—Ö–µ—à –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ –∏ –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.
* **FR-6: –†–µ–∂–∏–º Fast-skip.** –ü—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–º —Ñ–ª–∞–≥–µ `-fast` —Å–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ –º–≥–Ω–æ–≤–µ–Ω–Ω–æ –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä, –µ—Å–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –µ–º—É `.jsonl` —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –Ω–µ –ø—É—Å—Ç.
* **FR-7: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ CLI.** –ü—Ä–æ–≥—Ä–∞–º–º–∞ –¥–æ–ª–∂–Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å —Ñ–ª–∞–≥–∏ `-config`, `-container`, `-rescan`, `-verbose`, `-fast`.
* **FR-8: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å–æ —Å–∫—Ä–∏–ø—Ç–∞–º–∏.** –ü—Ä–æ–≥—Ä–∞–º–º–∞ –¥–æ–ª–∂–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –∫–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è `10` –ø—Ä–∏ –ø—Ä–æ–ø—É—Å–∫–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã –≤–Ω–µ—à–Ω–∏—Ö –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–æ–≤.

### 1.2 –ù–µ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (Performance & Quality)
* **PR-1: –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º.** –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–ª–∂–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—Ç—å—Å—è –º–µ–∂–¥—É –ø–æ—Ç–æ–∫–∞–º–∏ (–≥–æ—Ä—É—Ç–∏–Ω–∞–º–∏) —Å–æ–≥–ª–∞—Å–Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—É `Threads` –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.
* **PR-2: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è Discovery.** –î–ª—è –Ω–æ–≤—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ —ç—Ç–∞–ø –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∑–∞–¥–∞—á –Ω–µ –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å —á—Ç–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ.
* **PR-3: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏.** –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤ –¥–æ–ª–∂–Ω–æ –æ—á–∏—â–∞—Ç—å—Å—è –∏–∑ RAM —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –∑–∞–ø–∏—Å–∏ –≤ –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª.
* **PR-4: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–æ–∫.** –°–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å UTF-8, UTF-16 –∏ Windows-1251.

---

## 2. –î–æ–∫—É–º–µ–Ω—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### 2.1 –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã
–ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞ –Ω–∞ –º–æ–¥–µ–ª–∏ **Concurrent Worker Pool** (–ü—É–ª –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤).



#### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–æ—Ç–æ–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è:
1.  **–ì–ª–∞–≤–Ω—ã–π –ø–æ—Ç–æ–∫ (Producer):** –°–∫–∞–Ω–∏—Ä—É–µ—Ç –∞—Ä—Ö–∏–≤—ã –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –æ—á–µ—Ä–µ–¥—å –∑–∞–¥–∞—á.
2.  **–ö–∞–Ω–∞–ª –∑–∞–¥–∞—á (`jobs`):** –ë—É—Ñ–µ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–∞–Ω–∞–ª –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä `workItem`.
3.  **–í–æ—Ä–∫–µ—Ä—ã (Consumers):** –ù–∞–±–æ—Ä –∏–∑ N –≥–æ—Ä—É—Ç–∏–Ω, –≤—ã–ø–æ–ª–Ω—è—é—â–∏—Ö –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ, —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ø–∞—Ä—Å–∏–Ω–≥.
4.  **–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ç–æ—Ä:** `sync.WaitGroup` –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –ø–µ—Ä–µ–¥ –≤—ã—Ö–æ–¥–æ–º.

### 2.2 –ü–æ—à–∞–≥–æ–≤–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
1.  **`main` ‚Üí `processSingleZip`:** –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞.
2.  **–ü—Ä–æ–≤–µ—Ä–∫–∞ Fast-skip:** –ï—Å–ª–∏ —Ñ–ª–∞–≥ `-fast` –∞–∫—Ç–∏–≤–µ–Ω, —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ `os.Stat` –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞. –ü—Ä–∏ —É—Å–ø–µ—Ö–µ ‚Äî –Ω–µ–º–µ–¥–ª–µ–Ω–Ω—ã–π –≤—ã—Ö–æ–¥ —á–µ—Ä–µ–∑ `os.Exit(10)`.
3.  **Discovery (–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π):** * –ï—Å–ª–∏ –±–∞–∑–∞ —Ö–µ—à–µ–π –ø—É—Å—Ç–∞ (–Ω–æ–≤—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä), –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ –ª–∏—à—å –∑–∞–ø–æ–ª–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ `tasks` —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ `zip.File`, –º–∏–Ω—É—è –≤—ã–∑–æ–≤—ã `f.Open` –∏ `io.ReadAll`.
    * –≠—Ç–æ —É—Å—Ç—Ä–∞–Ω—è–µ—Ç "–∑–∞–≤–∏—Å–∞–Ω–∏–µ" –ø—Ä–æ–≥—Ä–∞–º–º—ã –ø–µ—Ä–µ–¥ –ø–æ—è–≤–ª–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞.
4.  **–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –≤–æ—Ä–∫–µ—Ä–æ–≤:** –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ –ø–µ—Ä–µ–¥–∞–µ—Ç –∑–∞–¥–∞—á–∏ –≤ –∫–∞–Ω–∞–ª. –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–Ω—É—Ç—Ä–∏ –≤–æ—Ä–∫–µ—Ä–∞ —Ä–µ–∞–ª–∏–∑—É–µ—Ç **Lazy Loading**: –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç (`item.raw == nil`), –≤–æ—Ä–∫–µ—Ä —Å–∞–º –∏–Ω–∏—Ü–∏–∏—Ä—É–µ—Ç —á—Ç–µ–Ω–∏–µ –∏ —Ä–∞—Å—á–µ—Ç SHA1 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –¥—Ä—É–≥–∏–º–∏ –≤–æ—Ä–∫–µ—Ä–∞–º–∏.
5.  **–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ:** –ü–æ—Å–ª–µ –∑–∞–∫—Ä—ã—Ç–∏—è –∫–∞–Ω–∞–ª–∞ –≤–æ—Ä–∫–µ—Ä—ã –∑–∞–≤–µ—Ä—à–∞—é—Ç —Ä–∞–±–æ—Ç—É, –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤ `main` –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É ZIP-–∞—Ä—Ö–∏–≤—É.

### 2.3 –ñ–∏–∑–Ω–µ–Ω–Ω—ã–π —Ü–∏–∫–ª –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
* **`item.raw` ([]byte):** –î–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª–∞. –ü–∞–º—è—Ç—å –≤—ã–¥–µ–ª—è–µ—Ç—Å—è –ª–∏–±–æ –≤ Discovery, –ª–∏–±–æ –≤ –≤–æ—Ä–∫–µ—Ä–µ. –°—Å—ã–ª–∫–∞ –Ω–∞ –º–∞—Å—Å–∏–≤ –±–∞–π—Ç–æ–≤ –æ–±–Ω—É–ª—è–µ—Ç—Å—è —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –≤—ã–∑–æ–≤–∞ `saveToOutputWithSha`, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç Garbage Collector (GC) –æ—Å–≤–æ–±–æ–∂–¥–∞—Ç—å –ø–∞–º—è—Ç—å –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ.
* **`existingHashes` (map):** –ö–∞—Ä—Ç–∞ —Ö–µ—à–µ–π. –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –≤ –Ω–∞—á–∞–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ZIP –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏. –ü—Ä–∏ –µ–µ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç—Å—è —Ä–µ–∂–∏–º —É—Å–∫–æ—Ä–µ–Ω–Ω–æ–≥–æ Discovery.
* **`err`:** –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ—à–∏–±–æ–∫ –ø—Ä–æ—Ö–æ–¥—è—Ç –∞—É–¥–∏—Ç; –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–±–æ—è—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª –≤—ã–≤–æ–¥–∞) –ø—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ `log.Fatalf`.

### 2.4 –ú–∞—Ç—Ä–∏—Ü–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–π (–ê—É–¥–∏—Ç –ª–æ–≥–∏–∫–∏ `-fast`)

| –†–µ–∂–∏–º `-fast` | –°–æ—Å—Ç–æ—è–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ | –õ–æ–≥–∏–∫–∞ | –†–µ–∑—É–ª—å—Ç–∞—Ç |
| :--- | :--- | :--- | :--- |
| **–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω** | **–û–±—Ä–∞–±–æ—Ç–∞–Ω** | `os.Stat` –Ω–∞—Ö–æ–¥–∏—Ç —Ñ–∞–π–ª | –ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–π –≤—ã—Ö–æ–¥ `Exit(10)`. |
| **–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω** | **–ù–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω** | `os.Stat` –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—à–∏–±–∫—É | –ë—ã—Å—Ç—Ä—ã–π Discovery -> –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ. |
| **–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω** | **–û–±—Ä–∞–±–æ—Ç–∞–Ω** | –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—á–µ—Ç—á–∏–∫–æ–≤ —Ñ–∞–π–ª–æ–≤ | –í—ã—Ö–æ–¥ `Exit(10)`, –µ—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–ø–∞–¥–∞–µ—Ç. |
| **–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω** | **–ù–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω** | –ë–∞–∑–∞ —Ö–µ—à–µ–π –ø—É—Å—Ç–∞ | –ë—ã—Å—Ç—Ä—ã–π Discovery -> –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ. |

---

## 3. –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏

### –°–±–æ—Ä–∫–∞
```bash
make build

--- END_FILE: ./f2bulker/README.md ---

--- START_FILE: ./f2bulker/backlog.md ---
# Ebusta Project Backlog

## Ingesting (f2bulker)
- [ ] **Issue #1**: –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ UTF-16 (BOM √ø√æ). –§–∞–π–ª `547782.fb2` –ø–∞–¥–∞–µ—Ç —Å `XML syntax error: invalid UTF-8`. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å `charsetReader` –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ UTF-16 Little Endian. [cite: 440-442]
- [ ] **Feature**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –≤ DSL (—Å–∫–æ–±–∫–∏). [cite: 141]

## System
- [ ] **Auth**: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Auth-Manager –≤ Orchestrator. [cite: 219-220]
- [ ] **OS**: –ü–µ—Ä–µ—Ö–æ–¥ —Å –º–æ–∫–∞ `books.json` –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ —à–∞–±–ª–æ–Ω—ã OpenSearch. [cite: 221]

--- END_FILE: ./f2bulker/backlog.md ---

--- START_FILE: ./README.md ---
# Ebusta üìö

–ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–∞—è –ø–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∞—Ä—Ö–∏–≤–æ–≤ Flibusta. –ü–æ–∑–≤–æ–ª—è–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ –º–∏–ª–ª–∏–æ–Ω–∞–º –∑–∞–ø–∏—Å–µ–π —á–µ—Ä–µ–∑ OpenSearch, –∏—Å–ø–æ–ª—å–∑—É—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π DSL (Domain Specific Language).

## üèó –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã

–°–∏—Å—Ç–µ–º–∞ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤, –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö –ø–æ gRPC:

* **Web-Adapter (The Door)**: –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –≤–Ω–µ—à–Ω–∏–µ HTTP-–∑–∞–ø—Ä–æ—Å—ã –∏ –ø–µ—Ä–µ–¥–∞–µ—Ç –∏—Ö –≤ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä.
* **Orchestrator**: –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤, —É–ø—Ä–∞–≤–ª—è–µ—Ç Trace-ID.
* **Message-Converter**: –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É –∑–∞–ø—Ä–æ—Å–∞ –≤ AST-–¥–µ—Ä–µ–≤–æ.
* **Processor**: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É –∏ –≤—ã–±–∏—Ä–∞–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø–æ–∏—Å–∫–∞.
* **Datamanager**: –°–ª–æ–π –¥–∞–Ω–Ω—ã—Ö, —Ä–∞–±–æ—Ç–∞—é—â–∏–π —Å OpenSearch.
* **Auth-Manager**: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç whitelist.
* **Ebusta-CLI**: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –æ–±–æ–ª–æ—á–∫–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Å–∏—Å—Ç–µ–º–æ–π.



## üö¶ –ö–∞—Ä—Ç–∞ –ø–æ—Ä—Ç–æ–≤

| –°–µ—Ä–≤–∏—Å            | –ü–æ—Ä—Ç (gRPC) | –§—É–Ω–∫—Ü–∏–∏                          |
|:------------------|:------------|:---------------------------------|
| Datamanager       | `:50051`    | –°–ª–æ–π –¥–∞–Ω–Ω—ã—Ö (OpenSearch)         |
| Message-Converter | `:50052`    | –ü–∞—Ä—Å–µ—Ä (AST)                     |
| Processor         | `:50053`    | –õ–æ–≥–∏–∫–∞ –∏ –≤—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–æ–≤          |
| Orchestrator      | `:50054`    | –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è                      |
| Auth-Manager      | `:50055`    | –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å (Whitelist)         |
| Web-Adapter       | `:8080`     | HTTP-–≤—Ö–æ–¥ (REST)                 |
| Metrics           | `:9091`     | Prometheus –º–µ—Ç—Ä–∏–∫–∏ (Datamanager) |

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –°–±–æ—Ä–∫–∞ –∏ –∑–∞–ø—É—Å–∫
–¢—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π Go 1.21+ –∏ Protoc.

```bash
make build   # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Proto –∏ –∫–æ–º–ø–∏–ª—è—Ü–∏—è –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
make run     # –ó–∞–ø—É—Å–∫ –≤—Å–µ–π —Å–∏—Å—Ç–µ–º—ã –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ


--- END_FILE: ./README.md ---

--- START_FILE: ./lisp-converter/server.lisp ---
(ql:quickload '(:cl-protobufs :grpc) :silent t)

;; –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—à –ø–∞–∫–µ—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É Lisp (CL)
(defpackage :ebusta.service
  (:use :cl)
  (:local-nicknames (#:pb #:cl-protobufs.ebusta.library.v1)
                    (#:pb-rpc #:cl-protobufs.ebusta.library.v1-rpc)
                    (#:grpc #:grpc)))

;; –í—Ö–æ–¥–∏–º –≤ –Ω–µ–≥–æ. –¢–£–¢ –ï–°–¢–¨ LISP.
(in-package :ebusta.service)

;; --- –õ–æ–≥–∏–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (S-expressions -> Protobuf) ---
(defun dsl-to-pb (dsl)
  (let ((query (pb:make-search-query)))
    (cond
      ;; –û–±—Ä–∞–±–æ—Ç–∫–∞ AND / OR
      ((member (car dsl) '(:and :or))
       (let ((l-node (pb:make-logical-node)))
         (setf (pb:logical-node.op l-node) (if (eq (car dsl) :and) 1 2))
         (dolist (sub (cdr dsl))
           (push (dsl-to-pb sub) (pb:logical-node.nodes l-node)))
         (setf (pb:search-query.logical query) l-node)))
      
      ;; –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª–µ–π (:field "name" "val")
      ((eq (car dsl) :field)
       (let ((f-node (pb:make-filter-node)))
         (setf (pb:filter-node.field f-node) (second dsl)
               (pb:filter-node.value f-node) (third dsl)
               (pb:filter-node.operator 1)) ;; 1 = EQUALS
         (setf (pb:search-query.filter query) f-node))))
    query))

;; --- –†–µ–∞–ª–∏–∑–∞—Ü–∏—è gRPC –º–µ—Ç–æ–¥–∞ ---
;; –ú—ã –Ω–∞—Ö–æ–¥–∏–º—Å—è –≤ ebusta.service, –Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–æ–¥ –¥–ª—è –ß–£–ñ–û–ì–û –ø–∞–∫–µ—Ç–∞ pb-rpc.
;; –≠—Ç–æ –ª–µ–≥–∞–ª—å–Ω–æ –∏ –∏–º–µ–Ω–Ω–æ —Ç–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–ª–æ.
(defmethod pb-rpc:convert ((request pb:convert-request) rpc)
  (declare (ignore rpc))
  (let* ((raw (pb:convert-request.raw-query request))
         ;; –ß–∏—Ç–∞–µ–º —Å—Ç—Ä–æ–∫—É –∫–∞–∫ Lisp-–∫–æ–¥ (–¥–ª—è —Ç–µ—Å—Ç–∞ (:and ...))
         (dsl (read-from-string raw)))
    (format t "Request received: ~S~%" raw)
    (format t "Parsed DSL: ~S~%" dsl)
    (dsl-to-pb dsl)))

--- END_FILE: ./lisp-converter/server.lisp ---

--- START_FILE: ./lisp-converter/converter.lisp ---
(ql:quickload '(:cl-protobufs :cl-base64))

(defpackage :ebusta.app
  (:use :cl :cl-protobufs)
  (:export :run-test))

(in-package :ebusta.app)

;; --- 1. –°–•–ï–ú–ê (NATIVE) ---
(eval-when (:compile-toplevel :load-toplevel :execute)
  (define-schema libraryv1
    (:package "libraryv1")))

(define-message filter-node ()
  (:schema libraryv1)
  (field :index 1 :type string :kind :optional)
  (value :index 2 :type string :kind :optional)
  (operator :index 3 :type int32 :kind :optional))

(define-message logical-node ()
  (:schema libraryv1)
  (op :index 1 :type int32 :kind :optional) ;; 1 = AND, 2 = OR
  (nodes :index 2 :type filter-node :kind :repeated))

(define-message search-query ()
  (:schema libraryv1)
  (filter :index 1 :type filter-node :kind :optional)
  (logical :index 2 :type logical-node :kind :optional))

;; --- 2. –ü–ê–†–°–ï–† ---
(defun to-pb (dsl)
  (let ((query (make-instance 'search-query)))
    (cond 
      ((member (car dsl) '(:and :or))
       (let ((l-node (make-instance 'logical-node :op (if (eq (car dsl) :and) 1 2))))
         (dolist (sub (cdr dsl))
           (push (make-instance 'filter-node
                                :field (getf sub :field)
                                :value (getf sub :val)
                                :operator 1)
                 (logical-node.nodes l-node)))
         (setf (search-query.logical query) l-node)))
      ((eq (car dsl) :field)
       (setf (search-query.filter query)
             (make-instance 'filter-node
                            :field (getf dsl :field)
                            :value (getf dsl :val)
                            :operator 1))))
    query))

;; --- 3. –¢–ï–°–¢–û–í–´–ô –ó–ê–ü–£–°–ö ---
(defun run-test ()
  (format t "~%--- [ CONVERTER START ] ---~%")
  (let* ((dsl '(:and (:field "author" :val "Bulgakov") 
                     (:field "title" :val "Master")))
         (pb-obj (to-pb dsl)))
    (format t "DSL input: ~A~%" dsl)
    (format t "Protobuf Text Format:~%~%")
    (print-text-format pb-obj :stream t)
    (format t "~%--- [ CONVERTER SUCCESS ] ---~%")))

(run-test)

--- END_FILE: ./lisp-converter/converter.lisp ---

--- START_FILE: ./lisp-converter/dsl-client.lisp ---
(defpackage #:dsl-client
  (:use #:cl)
  (:local-nicknames (#:pb #:cl-protobufs.ebusta.library.v1)
                    (#:pb-rpc #:cl-protobufs.ebusta.library.v1-rpc)
                    (#:grpc #:grpc)))

(in-package #:dsl-client)

(defun run ()
  (grpc:init-grpc)
  ;; –¢–æ—Ç —Å–∞–º—ã–π –∑–∞–ø—Ä–æ—Å: –ò (title="Lisp") –ò–õ–ò (author="Serge" | author="Reva")
  (let ((dsl-string "(:and (:field \"title\" \"Lisp\") (:or (:field \"author\" \"Serge\") (:field \"author\" \"Reva\")))"))
    
    (format t ">>> Sending DSL: ~A~%" dsl-string)
    
    (grpc:with-insecure-channel (channel "localhost:50052")
      (let* ((request (pb:make-convert-request :raw-query dsl-string))
             ;; –í—ã–∑—ã–≤–∞–µ–º –º–µ—Ç–æ–¥ Convert
             (response (pb-rpc:call-convert channel request)))
        
        (format t ">>> SERVER RESPONSE:~%")
        (format t "~S~%" response)
        
        ;; –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏)
        (let ((logical (pb:search-query.logical response)))
          (when logical
            (format t "Root is LOGICAL node (Op: ~A)~%" (pb:logical-node.op logical))
            (format t "Children count: ~A~%" (length (pb:logical-node.nodes logical))))))))

  (grpc:shutdown-grpc)
  (sb-ext:exit))

(run)

--- END_FILE: ./lisp-converter/dsl-client.lisp ---

--- START_FILE: ./lisp-converter/search.proto ---
syntax = "proto3";

package ebusta.library.v1;
option go_package = "ebusta/grpc/gen/go;dsl";

message FilterNode {
  string field = 1;
  string value = 2;
  int32 operator = 3;
}

message LogicalNode {
  int32 op = 1;
  repeated SearchQuery nodes = 2;
}

message SearchQuery {
  oneof query {
    FilterNode filter = 1;
    LogicalNode logical = 2;
  }
  string canonical_form = 3;
  string request_id = 4;
}

message ConvertRequest {
  string raw_query = 1;
}

service MessageConverter {
  rpc Convert(ConvertRequest) returns (SearchQuery);
}

--- END_FILE: ./lisp-converter/search.proto ---

--- START_FILE: ./lisp-converter/ebusta-search.asd ---
(defsystem "ebusta-search"
  :defsystem-depends-on (:cl-protobufs.asdf)
  :depends-on (:cl-protobufs :grpc :esrap)
  :components ((:protobuf-source-file "search")))

--- END_FILE: ./lisp-converter/ebusta-search.asd ---

--- START_FILE: ./lisp-converter/example-server.lisp ---
(defpackage #:example-server
  (:use #:cl)
  (:local-nicknames (#:pb #:cl-protobufs.lisp.grpc.integration-testing)
                    (#:pb-rpc #:cl-protobufs.lisp.grpc.integration-testing-rpc)
                    (#:grpc #:grpc)))

(in-package #:example-server)

;; –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω–æ–µ –∏–º—è –º–µ—Ç–æ–¥–∞ –∏–∑ RPC –ø–∞–∫–µ—Ç–∞, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Ö–æ–¥–∏—Ç—å –≤ –Ω–µ–≥–æ
(defmethod pb-rpc:say-hello ((request pb:hello-request) rpc)
  (declare (ignore rpc))
  (let ((name (pb:hello-request.name request)))
    (format t ">>> SERVER: Received request for name: ~A~%" name)
    (pb:make-hello-reply
     :message (concatenate 'string "Hello " name " (via ASDF Build)"))))

(defun run ()
  (grpc:init-grpc)
  (format t "=== Server listening on :50051 ===~%")
  (grpc:run-grpc-proto-server
   "0.0.0.0:50051"
   'pb:greeter
   :num-threads 1))

(run)

--- END_FILE: ./lisp-converter/example-server.lisp ---

--- START_FILE: ./lisp-converter/main.lisp ---
(ql:quickload '(:cl-protobufs :cl-base64))

(load "/home/serge/projects/ebusta/lisp-converter/search.lisp")

(defpackage :ebusta.converter
  (:use :cl)
  (:local-nicknames (#:pb #:cl-protobufs.ebusta.library.v1)))

(in-package :ebusta.converter)

(defun dsl-to-pb (dsl)
  (let ((request (make-instance 'pb:search-request)))
    (cond
      ((member (car dsl) '(:and :or))
       (let ((l-node (make-instance 'pb:logical-node)))
         (setf (pb:logical-node.op l-node) (if (eq (car dsl) :and) 1 2))
         (dolist (sub (cdr dsl))
           (push (dsl-to-pb sub) (pb:logical-node.nodes l-node)))
         (setf (pb:search-request.logical request) l-node)))
      ((eq (car dsl) :field)
       (let ((f-node (make-instance 'pb:filter-node)))
         (setf (pb:filter-node.field f-node) (getf dsl :field)
               (pb:filter-node.value f-node) (getf dsl :val)
               (pb:filter-node.operator f-node) 1)
         (setf (pb:search-request.filter request) f-node))))
    request))

(defun run-system-uuencode (pb-obj)
  (let* ((octets (cl-protobufs:serialize-to-bytes pb-obj))
         (b64 (cl-base64:usb8-array-to-base64-string octets)))
    ;; –í—ã–∑—ã–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—É—é —É—Ç–∏–ª–∏—Ç—É —á–µ—Ä–µ–∑ shell
    (uiop:run-program (format nil "echo ~A | base64 -d | uuencode query.bin" b64)
                      :output t)))

;; –¢–ï–°–¢
(format t "~%--- STARTING RECURSIVE TEST ---~%")
(let* ((complex-dsl '(:and (:field "author" :val "Bulgakov") 
                           (:or (:field "title" :val "Master") 
                                (:field "title" :val "Margarita"))))
       (pb-obj (dsl-to-pb complex-dsl)))
  (format t "~%--- UUENCODE OUTPUT ---~%")
  (run-system-uuencode pb-obj)
  (format t "~%--- SUCCESS ---~%"))

--- END_FILE: ./lisp-converter/main.lisp ---

--- START_FILE: ./lisp-converter/parser.lisp ---
(defpackage #:ebusta-parser
  (:use #:cl #:esrap)
  (:export #:parse-query))

(in-package #:ebusta-parser)

;; --- –¢–æ–∫–µ–Ω—ã ---

(defrule whitespace (+ (or #\space #\tab #\newline))
  (:constant nil))

(defrule colon #\:
  (:constant nil))

;; –°–ª–æ–≤–æ: –ª—é–±—ã–µ —Å–∏–º–≤–æ–ª—ã, –∫—Ä–æ–º–µ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
(defrule word (+ (not (or #\space #\tab #\newline #\: #\( #\) #\" #\& #\|)))
  (:text t))

(defrule quoted-string (and #\" (* (not #\")) #\")
  (:destructure (q1 text q2)
    (declare (ignore q1 q2))
    (text text)))

(defrule value (or quoted-string word))
(defrule key word)

;; --- –í—ã—Ä–∞–∂–µ–Ω–∏—è ---

;; –ü–æ–ª–µ: author:King -> (:field "author" "King")
(defrule field-expression (and key colon value)
  (:destructure (k c v)
    (declare (ignore c))
    (list :field k v)))

;; –û–ø–µ—Ä–∞—Ç–æ—Ä—ã (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ)
(defrule op-and (and (? whitespace) (or "AND" "and" "&") (? whitespace))
  (:constant :and))

(defrule op-or (and (? whitespace) (or "OR" "or" "|") (? whitespace))
  (:constant :or))

;; –†–µ–∫—É—Ä—Å–∏—è
(defrule paren-expression (and (? whitespace) #\( expression #\) (? whitespace))
  (:destructure (w1 p1 e p2 w2)
    (declare (ignore w1 p1 p2 w2))
    e))

(defrule term (or paren-expression field-expression))

;; AND (–≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
(defrule and-expression (and term (* (and op-and term)))
  (:destructure (head tail)
    (if (null tail)
        head
        (cons :and (cons head (mapcar #'second tail))))))

;; OR (–Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
(defrule or-expression (and and-expression (* (and op-or and-expression)))
  (:destructure (head tail)
    (if (null tail)
        head
        (cons :or (cons head (mapcar #'second tail))))))

;; –ö–æ—Ä–Ω–µ–≤–æ–µ –ø—Ä–∞–≤–∏–ª–æ
(defrule expression or-expression)

(defun parse-query (input)
  "–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É –∑–∞–ø—Ä–æ—Å–∞ –≤ DSL S-–≤—ã—Ä–∞–∂–µ–Ω–∏–µ"
  (parse 'expression input))

--- END_FILE: ./lisp-converter/parser.lisp ---

--- START_FILE: ./lisp-converter/helloworld.asd ---
(defsystem "helloworld"
  :defsystem-depends-on (:cl-protobufs.asdf)
  :depends-on (:cl-protobufs :grpc)
  :components ((:protobuf-source-file "helloworld")))

--- END_FILE: ./lisp-converter/helloworld.asd ---

--- START_FILE: ./lisp-converter/debug_registry.lisp ---
(ql:quickload '(:cl-protobufs :grpc) :silent t)
(load "/home/serge/projects/ebusta/lisp-converter/search.lisp")

(format t "~%--- –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ ---~%")
(let* ((sym 'cl-protobufs.ebusta.library.v1:message-converter)
       (sd (cl-protobufs:find-service-descriptor sym))
       (s (cl-protobufs.implementation:find-service sym)))
  (format t "–°–∏–º–≤–æ–ª: ~A~%" sym)
  (format t "Service Descriptor: ~A~%" sd)
  (format t "Service Object: ~A~%" s)
  
  (when sd
    (format t "–ú–µ—Ç–æ–¥—ã —á–µ—Ä–µ–∑ Descriptor: ~A~%" 
            (ignore-errors (cl-protobufs:proto-methods sd))))
  (when s
    (format t "–ú–µ—Ç–æ–¥—ã —á–µ—Ä–µ–∑ Service: ~A~%" 
            (ignore-errors (cl-protobufs:proto-methods s)))))
(finish-output)

--- END_FILE: ./lisp-converter/debug_registry.lisp ---

--- START_FILE: ./lisp-converter/example-client.lisp ---
(defpackage #:example-client
  (:use #:cl)
  (:local-nicknames (#:pb #:cl-protobufs.lisp.grpc.integration-testing)
                    (#:pb-rpc #:cl-protobufs.lisp.grpc.integration-testing-rpc)
                    (#:grpc #:grpc)))

(in-package #:example-client)

(defun run ()
  (grpc:init-grpc)
  (grpc:with-insecure-channel (channel "localhost:50051")
    (format t "Sending request...~%")
    (let* ((request (pb:make-hello-request :name "Admin"))
           (response (pb-rpc:call-say-hello channel request)))
      (format t "RESPONSE: ~A~%" (pb:hello-reply.message response))))
  (grpc:shutdown-grpc)
  (sb-ext:exit))

(run)

--- END_FILE: ./lisp-converter/example-client.lisp ---

--- START_FILE: ./lisp-converter/schema.lisp ---
(ql:quickload :cl-protobufs)

(defpackage :ebusta.schema
  (:use :cl :cl-protobufs))

(in-package :ebusta.schema)

(cl-protobufs:define-schema libraryv1
    (:package "libraryv1"))

(cl-protobufs:define-message filter-node ()
  (:schema libraryv1)
  (field :index 1 :type string :kind :optional)
  (value :index 2 :type string :kind :optional)
  (operator :index 3 :type int32 :kind :optional))

;; –î–æ–±–∞–≤–ª—è–µ–º —É–∑–µ–ª –¥–ª—è AND/OR
(cl-protobufs:define-message logical-node ()
  (:schema libraryv1)
  (op :index 1 :type int32 :kind :optional) ;; 1 - AND, 2 - OR
  (nodes :index 2 :type filter-node :kind :repeated))

(cl-protobufs:define-message search-query ()
  (:schema libraryv1)
  (filter :index 1 :type filter-node :kind :optional)
  (logical :index 2 :type logical-node :kind :optional))

--- END_FILE: ./lisp-converter/schema.lisp ---

--- START_FILE: ./lisp-converter/search.lisp ---
;;; search.proto.lisp
;;;
;;; Generated by the protocol buffer compiler. DO NOT EDIT!

(cl:in-package #:common-lisp-user)

#+sbcl
(cl:progn
 (cl:eval-when (:compile-toplevel) (sb-ext:restrict-compiler-policy 'cl:debug 0 1))
 (cl:declaim (cl:optimize (sb-c:store-coverage-data 0))
  (sb-ext:muffle-conditions sb-kernel:redefinition-with-defun)))

(cl:eval-when (:compile-toplevel :load-toplevel :execute)
  (cl:unless (cl:find-package "CL-PROTOBUFS.EBUSTA.LIBRARY.V1")
    (cl:defpackage "CL-PROTOBUFS.EBUSTA.LIBRARY.V1" (:use)
                   (:local-nicknames (#:pi #:cl-protobufs.implementation)))))

(cl:eval-when (:compile-toplevel :load-toplevel :execute)
  (cl:unless (cl:find-package "CL-PROTOBUFS.EBUSTA.LIBRARY.V1-RPC")
    (cl:defpackage "CL-PROTOBUFS.EBUSTA.LIBRARY.V1-RPC" (:use)
                   (:local-nicknames (#:pi #:cl-protobufs.implementation)))))

(cl:in-package "CL-PROTOBUFS.EBUSTA.LIBRARY.V1")

(cl:eval-when (:compile-toplevel :load-toplevel :execute)
(pi:define-schema 'search
    :syntax :proto3

    :package "ebusta.library.v1")
)


;;; Top-Level messages

(pi:define-message convert-request
    ()
  ;; Fields
  (raw-query
   :index 1 :type cl:string :kind :scalar :label (:optional) :field-presence :implicit :json-name "rawQuery"))

(pi:define-message filter-node
    ()
  ;; Fields
  (field
   :index 1 :type cl:string :kind :scalar :label (:optional) :field-presence :implicit :json-name "field")
  (value
   :index 2 :type cl:string :kind :scalar :label (:optional) :field-presence :implicit :json-name "value")
  (operator
   :index 3 :type cl-protobufs:int32 :kind :scalar :label (:optional) :field-presence :implicit :json-name "operator"))

(pi:define-message logical-node
    ()
  ;; Fields
  (op
   :index 1 :type cl-protobufs:int32 :kind :scalar :label (:optional) :field-presence :implicit :json-name "op")
  (nodes
   :index 2 :type search-query :kind :message :label (:repeated :list) :field-presence :implicit :json-name "nodes"))

(pi:define-message search-query
    ()
  ;; Fields
  (pi:define-oneof query ()
    (filter
     :index 1 :type filter-node :kind :message :label (:optional) :field-presence :explicit :json-name "filter")
    (logical
     :index 2 :type logical-node :kind :message :label (:optional) :field-presence :explicit :json-name "logical")))

;;; Services
(pi:define-service message-converter
    (:source-location #P"search.proto")
  (convert (
    convert-request =>
    search-query)))

(cl:eval-when (:compile-toplevel :load-toplevel :execute)
(pi:add-file-descriptor #P"search.proto" 'search)
)

(cl:export '(convert-request
field
filter
filter-node
logical
logical-node
message-converter
nodes
op
operator
raw-query
search
search-query
value))

(cl:in-package "CL-PROTOBUFS.EBUSTA.LIBRARY.V1-RPC")

(cl:export '(call-convert
convert))

--- END_FILE: ./lisp-converter/search.lisp ---

--- START_FILE: ./lisp-converter/dsl-service.lisp ---
(eval-when (:compile-toplevel :load-toplevel :execute)
  (ql:quickload '(:cl-ppcre :grpc :cl-protobufs :bordeaux-threads) :silent t))

(defpackage #:ebusta-service
  (:use #:cl)
  (:export #:start #:stop #:parse-raw-to-sexp #:parse-sexp-to-ast #:build-binary))

(in-package #:ebusta-service)

(defun get-priority (op)
  (cond ((string-equal op "NOT") 3) ((string-equal op "AND") 2) ((string-equal op "OR") 1) (t 0)))

(defun tokenize (str)
  (cl-ppcre:all-matches-as-strings "(\"[^\"]+\"|[a-zA-Z0-9_]+:|AND|OR|NOT|\\(|\\)|/|\\S+)" str))

(defun numeric-p (s) (if (cl-ppcre:scan "^[0-9]+$" s) t nil))

(defun make-field-node (field val-raw)
  (let* ((val (string-trim " \"" val-raw))
         (is-regex (cl-ppcre:scan "^/.*/$" val)))
    `(:field ,field ,(if is-regex (string-trim "/" val) val) ,@(when is-regex '(:op :regex)))))

(defun process-field (token rest)
  (let* ((field (string-right-trim ":" token))
         (first (car rest)))
    (cond 
      ((and first (cl-ppcre:scan "^\".*\"$" first))
       (values (make-field-node field (car rest)) (cdr rest)))
      (t (let (coll)
           (loop while (and (car rest) 
                            (zerop (get-priority (car rest))) 
                            (not (member (car rest) '("(" ")") :test #'string-equal)))
                 do (push (pop rest) coll))
           (let ((val (if coll (format nil "~{~A~^ ~}" (nreverse coll)) "")))
             (values (make-field-node field val) rest)))))))

(defun parse-raw-to-sexp (str)
  (let ((tokens (tokenize str)) (out nil) (stack nil))
    (loop while tokens do
      (let ((tok (pop tokens)))
        (cond
          ((> (get-priority tok) 0)
           (loop while (and stack (> (get-priority (car stack)) 0) (>= (get-priority (car stack)) (get-priority tok)))
                 do (push (pop stack) out))
           (push tok stack))
          ((string= tok "(") (push tok stack))
          ((string= tok ")")
           (loop while (and stack (string/= (car stack) "(")) do (push (pop stack) out)) (pop stack))
          ((cl-ppcre:scan "^[a-zA-Z0-9_]+:$" tok)
           (multiple-value-bind (node rem) (process-field tok tokens) (push node out) (setf tokens rem)))
          (t (push (make-field-node (if (numeric-p tok) "id" "any") tok) out)))))
    (loop while stack do (push (pop stack) out))
    (let (s-eval)
      (dolist (tok (nreverse out) (car s-eval))
        (if (and (listp tok) (eq (car tok) :field)) (push tok s-eval)
            (let ((op (string-upcase (string tok))))
              (cond ((string= op "NOT") (push `(:not ,(pop s-eval)) s-eval))
                    ((member op '("AND" "OR") :test #'string=)
                     (let* ((r (pop s-eval)) (l (pop s-eval)) (k (if (string= op "AND") :and :or)))
                       (push `(,k ,l ,r) s-eval))))))))))

(defun parse-sexp-to-ast (sexp &key request-id canonical-form)
  (let ((q (cl-protobufs.ebusta.library.v1:make-search-query)))
    (when (and sexp (listp sexp))
      (let ((h (car sexp)))
        (cond
          ((member h '(:and :or))
           (let ((n (cl-protobufs.ebusta.library.v1:make-logical-node :op (if (eq h :and) 1 2))))
             (setf (cl-protobufs.ebusta.library.v1:logical-node.nodes n) (mapcar (lambda (s) (parse-sexp-to-ast s)) (cdr sexp)))
             (setf (cl-protobufs.ebusta.library.v1:search-query.logical q) n)))
          ((eq h :not)
           (let ((n (cl-protobufs.ebusta.library.v1:make-logical-node :op 3)))
             (setf (cl-protobufs.ebusta.library.v1:logical-node.nodes n) (list (parse-sexp-to-ast (second sexp))))
             (setf (cl-protobufs.ebusta.library.v1:search-query.logical q) n)))
          ((eq h :field)
           (let ((n (cl-protobufs.ebusta.library.v1:make-filter-node :field (second sexp) :value (third sexp)
                                            :operator (if (getf (cdddr sexp) :op) 6 1))))
             (setf (cl-protobufs.ebusta.library.v1:search-query.filter q) n))))))
    (if request-id (setf (cl-protobufs.ebusta.library.v1:search-query.request-id q) request-id))
    (if canonical-form (setf (cl-protobufs.ebusta.library.v1:search-query.canonical-form q) canonical-form))
    q))

(defmethod cl-protobufs.ebusta.library.v1-rpc:convert ((req cl-protobufs.ebusta.library.v1:convert-request) rpc)
  (declare (ignore rpc))
  (let* ((raw (cl-protobufs.ebusta.library.v1:convert-request.raw-query req))
         (sexp (parse-raw-to-sexp raw)))
    (parse-sexp-to-ast sexp :request-id (format nil "req-~A" (get-universal-time)) :canonical-form (format nil "~S" sexp))))

(defun start (&key (port 50052))
  (grpc:init-grpc)
  (grpc:run-grpc-proto-server (format nil "0.0.0.0:~A" port) 'cl-protobufs.ebusta.library.v1:message-converter)
  (loop (sleep 1)))

(defun build-binary ()
  #+sbcl (sb-ext:save-lisp-and-die "dsl-converter" :executable t :toplevel (lambda () 
             (setf *standard-output* *error-output*)
             (start :port 50052))))

--- END_FILE: ./lisp-converter/dsl-service.lisp ---

--- START_FILE: ./lisp-converter/helloworld.proto ---
// Copyright 2021 Google LLC
//
// Use of this source code is governed by an MIT-style
// license that can be found in the LICENSE file or at
// https://opensource.org/licenses/MIT.

syntax = "proto3";

package lisp.grpc.integration_testing;

message HelloRequest {
  optional string name = 1;
  optional int32 num_responses = 2;
}

message HelloReply {
  optional string message = 1;
}

service Greeter {
  // Receives a HelloRequest and response with a HelloReply.
  rpc SayHello(HelloRequest) returns (HelloReply) {}
  // Receive a HelloRequest requesting some number of responses in num_responses
  // and response with a HelloReply num_responses times.
  rpc SayHelloServerStream(HelloRequest) returns (stream HelloReply) {}
  // Receive a number of requests and concatenate the name field of each
  // HelloRequest. Return the final string in HelloReply.
  rpc SayHelloClientStream(stream HelloRequest) returns (HelloReply) {}
  // Receive a number of HelloRequest requesting some number of responses in num_responses.
  // Respond to each HelloRequest with a HelloReply num_responses times.
  rpc SayHelloBidirectionalStream(stream HelloRequest) returns (stream HelloReply) {}
}

--- END_FILE: ./lisp-converter/helloworld.proto ---

--- START_FILE: ./lisp-converter/inspect_grpc.lisp ---
(ql:quickload '(:cl-protobufs :grpc) :silent t)
(load "/home/serge/projects/ebusta/lisp-converter/search.lisp")

(format t "~%=== 1. –ü–†–û–í–ï–†–ö–ê –≠–ö–°–ü–û–†–¢–û–í –ü–ê–ö–ï–¢–ê GRPC ===~%")
(let ((symbols '()))
  (do-external-symbols (s :grpc) (push s symbols))
  (format t "External symbols in GRPC: ~{~A~^, ~}~%" (sort symbols #'string<)))

(format t "~%=== 2. –ì–õ–£–ë–û–ö–ê–Ø –ò–ù–°–ü–ï–ö–¶–ò–Ø –°–ï–†–í–ò–°–ê ===~%")
(let* ((sym 'cl-protobufs.ebusta.library.v1:message-converter)
       (sd (cl-protobufs:find-service-descriptor sym)))
  (if sd
      (progn
        (format t "Descriptor found: ~S~%" sd)
        (describe sd)
        (let ((methods (ignore-errors (cl-protobufs:proto-methods sd))))
          (format t "~%Methods list: ~S~%" methods)
          (dolist (m methods)
            (format t "~%--- –ò–Ω—Å–ø–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–∞ –º–µ—Ç–æ–¥–∞ ---~%")
            (describe m))))
      (format t "Descriptor NOT found.~%")))
(finish-output)

--- END_FILE: ./lisp-converter/inspect_grpc.lisp ---

--- START_FILE: ./errors.yaml ---
# –°–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ("–î—è—Ç–ª–∞")
user_errors:
  invalid_command: "ü•ö –°–ª—É—à–∞–π, –¥—è—Ç–µ–ª, —è –Ω–µ –ø–æ–Ω—è–ª —Ç–≤–æ—é –∫–æ–º–∞–Ω–¥—É. –ü–æ–ø—Ä–æ–±—É–π 'get ID' –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç –ø–æ–∏—Å–∫–∞."
  empty_payload: "ü•ö –î—è—Ç–µ–ª, —Ç—ã –∑–∞–±—ã–ª –≤–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã!"

# –°–æ–æ–±—â–µ–Ω–∏—è –ø—Ä–∏ —Å–±–æ—è—Ö —Å–∏—Å—Ç–µ–º—ã ("–°–æ—Ä—è–Ω, –±—Ä–∞—Ç–∞–Ω")
system_errors:
  converter_down: "üõ† –°–æ—Ä—è–Ω, –±—Ä–∞—Ç–∞–Ω, —É –Ω–∞—Å –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä –ø—Ä–∏—É–Ω—ã–ª. –°–∫–æ—Ä–æ –ø–æ—á–∏–Ω–∏–º."
  processor_error: "üõ† –°–æ—Ä—è–Ω, –±—Ä–∞—Ç–∞–Ω, —Ç—Ä—É–±–∞ –∑–∞–±–∏–ª–∞—Å—å. –ú—ã —É–∂–µ –≤—ã–∑–≤–∞–ª–∏ —Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫–æ–≤."
  data_layer_down: "üìâ –°–æ—Ä—è–Ω, –±—Ä–∞—Ç–∞–Ω, –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∑–∞–∫—Ä—ã—Ç–∞ –Ω–∞ —Ä–µ–º–æ–Ω—Ç. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ."
  generic_error: "üß® –°–æ—Ä—è–Ω, –±—Ä–∞—Ç–∞–Ω, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ —Å–æ–≤—Å–µ–º –Ω–µ —Ç–∞–∫. RequestID: %s"

--- END_FILE: ./errors.yaml ---

--- START_FILE: ./backlog.md ---

## DSL Parser Metrics Integration
- [ ] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å `cl-prometheus` –∏ `hunchentoot` –≤ `dsl-service.lisp`.
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å HTTP-—ç–Ω–¥–ø–æ–∏–Ω—Ç `/metrics` –Ω–∞ –ø–æ—Ä—Ç—É `50053`.
- [ ] –î–æ–±–∞–≤–∏—Ç—å —Å—á–µ—Ç—á–∏–∫–∏ `dsl_requests_total` –∏ `dsl_errors_total`.
- [ ] –î–æ–±–∞–≤–∏—Ç—å –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É `dsl_parse_duration_seconds` (–±–∞–∫–µ—Ç—ã –æ—Ç 0.1ms –¥–æ 10ms).
- [ ] –î–æ–±–∞–≤–∏—Ç—å Gauge –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ SBCL heap –∏ –∞–∫—Ç–∏–≤–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤.
- [ ] –û–±–µ—Å–ø–µ—á–∏—Ç—å –∏–∑–æ–ª—è—Ü–∏—é: —Å–±–æ–π —Å–µ—Ä–≤–µ—Ä–∞ –º–µ—Ç—Ä–∏–∫ –Ω–µ –¥–æ–ª–∂–µ–Ω –∞—Ñ—Ñ–µ–∫—Ç–∏—Ç—å gRPC.

--- END_FILE: ./backlog.md ---

--- START_FILE: ./doc/GRPC_API_REFERENCE.md ---
# GRPC API Reference: –î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã –∏ –º–µ—Ç–æ–¥—ã

–í –¥–∞–Ω–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã –≤—Å–µ gRPC –º–µ—Ç–æ–¥—ã, –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤ —Å–∏—Å—Ç–µ–º–µ EBusta, –∏—Ö –ø—É—Ç–∏ –¥–ª—è –≤—ã–∑–æ–≤–∞ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å–æ–æ–±—â–µ–Ω–∏–π.

---

## 1. –°–µ—Ä–≤–∏—Å: MessageConverter (–û—Å–Ω–æ–≤–Ω–æ–π)
**–û–ø–∏—Å–∞–Ω–∏–µ:** –¢—Ä–∞–Ω—Å–ª—è—Ü–∏—è –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ Lisp DSL –≤ Protobuf-—Å—Ç—Ä—É–∫—Ç—É—Ä—ã.
**–ü—Ä–æ—Ç–æ-—Ñ–∞–π–ª:** `lisp-converter/search.proto`
**–ü–∞–∫–µ—Ç:** `ebusta.library.v1`

### –ú–µ—Ç–æ–¥: `Convert`
* **–ü–æ–ª–Ω—ã–π –ø—É—Ç—å:** `ebusta.library.v1.MessageConverter/Convert`
* **Request:** `ConvertRequest` (–ø–æ–ª–µ `raw_query` —Ç–∏–ø–∞ string)
* **Response:** `SearchQuery` (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ –¥–µ—Ä–µ–≤–æ)
* **–ü—Ä–∏–º–µ—Ä –≤—ã–∑–æ–≤–∞:**
  ```bash
  grpcurl -plaintext -d '{"raw_query": "(:field \"title\" \"Lisp\")"}' localhost:50052 ebusta.library.v1.MessageConverter/Convert
2. –°–µ—Ä–≤–∏—Å: Greeter (–¢–µ—Å—Ç–æ–≤—ã–π)
–û–ø–∏—Å–∞–Ω–∏–µ: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è Smoke-—Ç–µ—Å—Ç–æ–≤ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã. –ü—Ä–æ—Ç–æ-—Ñ–∞–π–ª: lisp-converter/helloworld.proto –ü–∞–∫–µ—Ç: cl_protobufs.lisp.grpc.integration_testing

–ú–µ—Ç–æ–¥: SayHello
–ü–æ–ª–Ω—ã–π –ø—É—Ç—å: cl_protobufs.lisp.grpc.integration_testing.Greeter/SayHello

Request: HelloRequest (–ø–æ–ª–µ name)

Response: HelloReply (–ø–æ–ª–µ message)

–ü—Ä–∏–º–µ—Ä –≤—ã–∑–æ–≤–∞:

Bash

grpcurl -plaintext -d '{"name": "Admin"}' localhost:50051 cl_protobufs.lisp.grpc.integration_testing.Greeter/SayHello
3. –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –≤ —Å–∏—Å—Ç–µ–º–µ —Ç–∏–ø—ã (Internal Types)
–ù–∏–∂–µ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã –æ—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –≤ SearchQuery:

LogicalNode
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —É—Å–ª–æ–≤–∏–π.

op: 1 (AND), 2 (OR)

nodes: –°–ø–∏—Å–æ–∫ (repeated) –æ–±—ä–µ–∫—Ç–æ–≤ SearchQuery.

FilterNode
–ö–æ–Ω–µ—á–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.

field: –ò–º—è –ø–æ–ª—è (title, author, series, etc.)

value: –ó–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞.

operator: –¢–∏–ø —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1 = EQ).

4. –ò–Ω—Ç—Ä–æ—Å–ø–µ–∫—Ü–∏—è (–ö–∞–∫ –Ω–∞–π—Ç–∏ –Ω–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã)
–ï—Å–ª–∏ –≤ –±—É–¥—É—â–µ–º –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ .proto —Ñ–∞–π–ª—ã, —Å–ø–∏—Å–æ–∫ –º–µ—Ç–æ–¥–æ–≤ –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —á–µ—Ä–µ–∑ grpcurl, –µ—Å–ª–∏ —Å–µ—Ä–≤–µ—Ä –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Reflection (–∏–ª–∏ –ø–µ—Ä–µ–¥–∞–≤ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É):

Bash

# –°–ø–∏—Å–æ–∫ —Å–µ—Ä–≤–∏—Å–æ–≤
grpcurl -plaintext -import-path ./lisp-converter -proto ./lisp-converter/search.proto list

# –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞
grpcurl -plaintext -import-path ./lisp-converter -proto ./lisp-converter/search.proto describe ebusta.library.v1.MessageConverter/Convert

--- END_FILE: ./doc/GRPC_API_REFERENCE.md ---

--- START_FILE: ./doc/parser.md ---
;;; ===========================================================================
;;; –Ø–î–†–û –ü–ê–†–°–ï–†–ê MERCURY (DSL -> S-Expression)
;;; –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ Shunting-yard –¥–ª—è UR 1.1 - UR 3.3
;;; ===========================================================================

;; 1. –õ–ï–ö–°–ï–† (TOKENIZER)
;; –†–∞–∑—Ä–µ–∑–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –Ω–∞ –∞—Ç–æ–º—ã. –ü—Ä–∞–≤–∏–ª–∞ —Ä–µ–≥—É–ª—è—Ä–∫–∏:
;; - \"[^\"]+\"    : —Å—Ç—Ä–æ–∫–∏ –≤ –∫–∞–≤—ã—á–∫–∞—Ö (UR 2.1)
;; - [a-zA-Z0-9]+: : –ø—Ä–µ—Ñ–∏–∫—Å—ã –ø–æ–ª–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, author:)
;; - AND|OR|NOT    : –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã
;; - \(|\)         : —Å–∫–æ–±–∫–∏ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
;; - /             : –º–∞—Ä–∫–µ—Ä —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π (UR 2.2)
;; - \S+           : –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ –Ω–µ–ø—Ä–æ–±–µ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
(defun tokenize (str)
  (cl-ppcre:all-matches-as-strings "(\"[^\"]+\"|[a-zA-Z0-9_]+:|AND|OR|NOT|\\(|\\)|/|\\S+)" str))

;; 2. –¢–ê–ë–õ–ò–¶–ê –ü–†–ò–û–†–ò–¢–ï–¢–û–í (PRECEDENCE)
;; –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π —Å–æ–≥–ª–∞—Å–Ω–æ UR 3.3.
;; –ß–µ–º –≤—ã—à–µ —á–∏—Å–ª–æ, —Ç–µ–º –±—ã—Å—Ç—Ä–µ–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä "–∑–∞–±–µ—Ä–µ—Ç" —Å–µ–±–µ –æ–ø–µ—Ä–∞–Ω–¥—ã.
(defun get-priority (op)
  (cond ((string-equal op "NOT") 3) ; –°–∞–º—ã–π –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        ((string-equal op "AND") 2)
        ((string-equal op "OR") 1)  ; –°–∞–º—ã–π –Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        (t 0)))                     ; –ù–µ —è–≤–ª—è–µ—Ç—Å—è –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º

;; 3. –°–ë–û–†–ö–ê –î–ï–†–ï–í–ê –ò–ó –ü–û–°–¢–§–ò–ö–°–ù–û–ô –ó–ê–ü–ò–°–ò (RPN BUILDER)
;; –ù–∞ –≤—Ö–æ–¥ –∏–¥–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–∏–ø–∞ (A B AND). –ù–∞ –≤—ã—Ö–æ–¥–µ (:AND A B).
(defun build-tree-from-rpn (rpn)
  (let (stack)
    (dolist (token rpn (car stack)) ; –í –∫–æ–Ω—Ü–µ –≤ —Å—Ç–µ–∫–µ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –æ–¥–∏–Ω –∫–æ—Ä–µ–Ω—å –¥–µ—Ä–µ–≤–∞
      (if (and (listp token) (eq (car token) :field))
          (push token stack) ; –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ —É–∑–µ–ª –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ—Å—Ç–æ –∫–ª–∞–¥–µ–º –≤ —Å—Ç–µ–∫
          (let ((op (string-upcase (string token))))
            (cond 
              ;; –£–Ω–∞—Ä–Ω—ã–π NOT: –±–µ—Ä–µ—Ç –æ–¥–∏–Ω –∞—Ä–≥—É–º–µ–Ω—Ç –∏–∑ —Å—Ç–µ–∫–∞
              ((string= op "NOT") 
               (push `(:not ,(pop stack)) stack))
              ;; –ë–∏–Ω–∞—Ä–Ω—ã–µ AND/OR: –±–µ—Ä—É—Ç –¥–≤–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ (–ø—Ä–∞–≤—ã–π –∏ –ª–µ–≤—ã–π)
              ((member op '("AND" "OR") :test #'string=)
               (let* ((right (pop stack))
                      (left (pop stack))
                      (key (if (string= op "AND") :and :or)))
                 (push `(,key ,left ,right) stack)))))))))

;; 4. –û–ë–†–ê–ë–û–¢–ö–ê –ü–û–õ–ï–ô –ò –ó–ù–ê–ß–ï–ù–ò–ô (FIELD SCOPING)
;; –õ–æ–≥–∏–∫–∞ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è "–ø–æ–ª–µ:–∑–Ω–∞—á–µ–Ω–∏–µ". –£—á–∏—Ç—ã–≤–∞–µ—Ç UR 2.1 (–∂–∞–¥–Ω–æ—Å—Ç—å).
(defun process-field (token rest)
  (let* ((pos (position #\: token))
         (field (subseq token 0 pos))      ; –ë–µ—Ä–µ–º –≤—Å—ë –¥–æ –¥–≤–æ–µ—Ç–æ—á–∏—è (author)
         (val-part (subseq token (1+ pos)))) ; –•–≤–æ—Å—Ç —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è
    (if (string/= "" val-part)
        ;; –°–ª—É—á–∞–π "field:value" (–±–µ–∑ –ø—Ä–æ–±–µ–ª–∞)
        (values (make-field-node field val-part) rest)
        ;; –°–ª—É—á–∞–π "field: value1 value2" ‚Äî —Å–æ–±–∏—Ä–∞–µ–º –≤—Å—ë –¥–æ –±–ª–∏–∂–∞–π—à–µ–≥–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞
        (let (collected)
          (loop while (and (car rest) 
                           (zerop (get-priority (car rest))) 
                           (not (member (car rest) '("(" ")") :test #'string-equal)))
                do (push (pop rest) collected))
          (values (make-field-node field (format nil "~{~A~^ ~}" (nreverse collected))) 
                  rest)))))

;; 5. –®–ò–ù–¢–ò–ù–ì-–Ø–†–î (–ì–õ–ê–í–ù–´–ô –ê–õ–ì–û–†–ò–¢–ú)
;; –ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–∏–∫—Å–Ω—É—é –∑–∞–ø–∏—Å—å (A AND B) –≤ –ø–æ—Å—Ç—Ñ–∏–∫—Å–Ω—É—é (A B AND)
(defun parse-raw-to-sexp (str)
  (let ((token-list (tokenize str)) (output nil) (stack nil))
    (loop while token-list do
      (let ((token (pop token-list)))
        (cond 
          ;; –ï—Å–ª–∏ —ç—Ç–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä (AND/OR/NOT)
          ((> (get-priority token) 0)
           ;; –í—ã—Ç–∞–ª–∫–∏–≤–∞–µ–º –∏–∑ —Å—Ç–µ–∫–∞ –≤ –≤—ã—Ö–æ–¥ —Ç–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã, —É –∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤—ã—à–µ –∏–ª–∏ —Ä–∞–≤–µ–Ω —Ç–µ–∫—É—â–µ–º—É
           (loop while (and stack (> (get-priority (car stack)) 0) 
                            (>= (get-priority (car stack)) (get-priority token)))
                 do (push (pop stack) output))
           (push token stack))
          
          ;; –°–∫–æ–±–∫–∏: —É–ø—Ä–∞–≤–ª—è–µ–º –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å—é
          ((string= token "(") (push token stack))
          ((string= token ")")
           ;; –ü—Ä–∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–µ –≤—ã—Ç–∞–ª–∫–∏–≤–∞–µ–º –≤—Å—ë –¥–æ –±–ª–∏–∂–∞–π—à–µ–π –æ—Ç–∫—Ä—ã–≤–∞—é—â–µ–π
           (loop while (and stack (string/= (car stack) "(")) do (push (pop stack) output))
           (pop stack)) ; –£–¥–∞–ª—è–µ–º —Å–∞–º—É "(" –∏–∑ —Å—Ç–µ–∫–∞
          
          ;; –ü–æ–ª—è: –µ—Å–ª–∏ –≤ —Ç–æ–∫–µ–Ω–µ –µ—Å—Ç—å –¥–≤–æ–µ—Ç–æ—á–∏–µ ‚Äî —ç—Ç–æ –Ω–∞—á–∞–ª–æ Scope-—Ñ–∏–ª—å—Ç—Ä–∞
          ((find #\: token)
           (multiple-value-bind (node remaining) (process-field token token-list)
             (push node output) 
             (setf token-list remaining))) ; –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ—Å–ª–µ –∑–∞—Ö–≤–∞—Ç–∞ –∑–Ω–∞—á–µ–Ω–∏—è
          
          ;; –û–±—ã—á–Ω—ã–µ —Å–ª–æ–≤–∞: —Ç—Ä–∞–∫—Ç—É—é—Ç—Å—è –∫–∞–∫ –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –ø–æ–ª—è–º (UR 1.1)
          (t (push (make-field-node "any" token) output)))))
    
    ;; –í—ã—Ç–∞–ª–∫–∏–≤–∞–µ–º –æ—Å—Ç–∞—Ç–∫–∏ –∏–∑ —Å—Ç–µ–∫–∞ –≤ –≤—ã—Ö–æ–¥ –∏ —Å—Ç—Ä–æ–∏–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –¥–µ—Ä–µ–≤–æ
    (build-tree-from-rpn (nreverse (append output stack)))))

--- END_FILE: ./doc/parser.md ---

--- START_FILE: ./doc/requirements.md ---
# –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π —Å–∏—Å—Ç–µ–º—ã "Eboost-Library" (v2.1)

## 1. –û—Å–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ (Project Foundation)

### 1.1. –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
–í–ª–∞–¥–µ–ª—å—Ü—ã –±–æ–ª—å—à–∏—Ö –ª–∏—á–Ω—ã—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö –∫–Ω–∏–≥ —Å—Ç–∞–ª–∫–∏–≤–∞—é—Ç—Å—è —Å –ø—Ä–æ–±–ª–µ–º–æ–π "–º–µ—Ä—Ç–≤–æ–≥–æ –≥—Ä—É–∑–∞": –∫–Ω–∏–≥–∏ —Ö—Ä–∞–Ω—è—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ, –Ω–æ –¥–æ—Å—Ç—É–ø –∫ –Ω–∏–º –∏–∑–≤–Ω–µ (—Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞, –≤ –¥–æ—Ä–æ–≥–µ, –¥–ª—è –¥—Ä—É–∑–µ–π) –æ–≥—Ä–∞–Ω–∏—á–µ–Ω. –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ä–µ—à–µ–Ω–∏—è –ª–∏–±–æ —Å–ª–∏—à–∫–æ–º —Ç—è–∂–µ–ª–æ–≤–µ—Å–Ω—ã, –ª–∏–±–æ –ø—Ä–∏–≤—è–∑–∞–Ω—ã –∫ –æ–¥–Ω–æ–º—É –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É. 

### 1.2. –ö–æ–Ω—Ü–µ–ø—Ü–∏—è (Scope)
–ù–µ–æ–±—Ö–æ–¥–∏–º–∞ —Å–∏—Å—Ç–µ–º–∞-–ø–æ—Å—Ä–µ–¥–Ω–∏–∫, –∫–æ—Ç–æ—Ä–∞—è –∞–±—Å—Ç—Ä–∞–≥–∏—Ä—É–µ—Ç —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏ –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –µ–¥–∏–Ω—ã–π –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—è –¥–æ—Å—Ç—É–ø —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω—ã–µ –∫–∞–Ω–∞–ª—ã –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ (Telegram, IRC, CLI) —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

---

## 2. –ë–∏–∑–Ω–µ—Å-—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (Business Requirements)

| ID | –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ | –û–ø–∏—Å–∞–Ω–∏–µ |
| :--- | :--- | :--- |
| **BR-1** | –ú—É–ª—å—Ç–∏–∫–∞–Ω–∞–ª—å–Ω–æ—Å—Ç—å | –ï–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã (TG, IRC, CLI). |
| **BR-2** | –°–∫–æ—Ä–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞ | Time-to-Content –Ω–µ –±–æ–ª–µ–µ 3 —Å–µ–∫—É–Ω–¥. |
| **BR-3** | –ò–∑–æ–ª—è—Ü–∏—è –ª–æ–≥–∏–∫–∏ | –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ñ—Ä–æ–Ω—Ç–æ–≤ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è Core-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤. |
| **BR-4** | –£–ø—Ä–∞–≤–ª—è–µ–º—ã–π –¥–æ—Å—Ç—É–ø | –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è –¥–æ–≤–µ—Ä–µ–Ω–Ω–æ–≥–æ –∫—Ä—É–≥–∞ –ª–∏—Ü. |
| **BR-5** | –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–æ–≤ | –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –≤—ã–¥–∞—á–∞ —Ä–∞–∑–Ω—ã—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π (EPUB, PDF, FB2). |
| **BR-6** | –ö–æ–Ω—Ç–∏–Ω—É–∏—Ç–µ—Ç —Å–µ—Å—Å–∏–π | –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–∏—Å–∫–∞ –∏ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ (–ø–∞–≥–∏–Ω–∞—Ü–∏–∏). |
| **BR-7** | –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å | –°—Ç–∞–±–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –ø—Ä–∏ –æ–±—ä–µ–º–µ –±–∞–∑—ã –¥–æ 1 000 000 –∫–Ω–∏–≥. |
| **BR-8** | –ê–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å | –†–∞–±–æ—Ç–∞ —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏ –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π. |

---

## 3. –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç–æ—Ä–æ–Ω (Stakeholder Requirements)

### 3.1. –ì—Ä—É–ø–ø–∞: –ü–æ–∏—Å–∫ –∏ –Ω–∞–≤–∏–≥–∞—Ü–∏—è
* **UR-1: –ü–æ–∏—Å–∫ –ø–æ –∞—Ç—Ä–∏–±—É—Ç–∞–º.** –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –Ω–∞–π—Ç–∏ –∫–Ω–∏–≥—É –ø–æ –∞–≤—Ç–æ—Ä—É, –Ω–∞–∑–≤–∞–Ω–∏—é –∏–ª–∏ —Å–µ—Ä–∏–∏.
    * *–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞:* [BR-1, BR-7, BR-2]
* **UR-2: –ü—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.** –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ª–∏—Å—Ç–∞—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤—ã–¥–∞—á–∏ (–ø–∞–≥–∏–Ω–∞—Ü–∏—è) –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –≤–≤–æ–¥–∞ –∑–∞–ø—Ä–æ—Å–∞.
    * *–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞:* [BR-6]
* **UR-3: –£—Ç–æ—á–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞.** –ü—Ä–∏ –≤—ã–±–æ—Ä–µ –∫–Ω–∏–≥–∏ —Å–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ –ø—Ä–µ–¥–ª–∞–≥–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–ª—è –Ω–µ—ë —Ñ–æ—Ä–º–∞—Ç–æ–≤.
    * *–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞:* [BR-5]

### 3.2. –ì—Ä—É–ø–ø–∞: –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
* **UR-4: –ü—Ä—è–º–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞ (TG).** –í Telegram —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–º (–¥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞ —Ä–∞–∑–º–µ—Ä–∞).
    * *–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞:* [BR-1, BR-8]
* **UR-5: –°—Å—ã–ª–æ—á–Ω–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞ (IRC/CLI).** –í —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–ª–∂–µ–Ω –ø–æ–ª—É—á–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ.
    * *–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞:* [BR-1, BR-8]

### 3.3. –ì—Ä—É–ø–ø–∞: –î–æ—Å—Ç—É–ø –∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
* **UR-6: –ü—Ä–æ–∑—Ä–∞—á–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è.** –î–æ—Å—Ç—É–ø –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ ID –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã (UID Telegram, Host IRC).
    * *–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞:* [BR-4]
* **UR-7: –£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ–º–∞–Ω–¥.** –ö–æ–º–∞–Ω–¥–Ω—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º –¥–ª—è –≤—Å–µ—Ö –∞–¥–∞–ø—Ç–µ—Ä–æ–≤.
    * *–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞:* [BR-1, BR-3]

### 3.4. –ì—Ä—É–ø–ø–∞: –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ
* **UR-8: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–µ–ª—ã–º–∏ —Å–ø–∏—Å–∫–∞–º–∏.** –í–ª–∞–¥–µ–ª–µ—Ü –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ –º–µ–Ω—è—Ç—å —Å–ø–∏—Å–æ–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö ID.
    * *–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞:* [BR-4]

---

## 4. –ì–ª–æ—Å—Å–∞—Ä–∏–π
* **UnifiedMessage** ‚Äî –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö, –≤ –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤—Å–µ –≤—Ö–æ–¥—è—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã.
* **Whitelist** ‚Äî —Å–ø–∏—Å–æ–∫ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∏–º–µ—é—â–∏—Ö –¥–æ—Å—Ç—É–ø –∫ —Å–∏—Å—Ç–µ–º–µ.
* **OpenSearch** ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π –¥–≤–∏–∂–æ–∫ –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞.

--- END_FILE: ./doc/requirements.md ---

--- START_FILE: ./doc/DSL_METRICS_REQUIREMENTS.md ---
# DSL_METRICS_REQUIREMENTS.md

## 1. –¶–µ–ª—å
–û–±–µ—Å–ø–µ—á–∏—Ç—å –ø–æ–ª–Ω—É—é –Ω–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç—å (Observability) –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ DSL, –≤—ã—è–≤–∏—Ç—å —É–∑–∫–∏–µ –º–µ—Å—Ç–∞ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –æ—à–∏–±–∫–∏ —Ä–∞–∑–±–æ—Ä–∞ –≤ —Ä–∞–∑—Ä–µ–∑–µ —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤.

## 2. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫
* **–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞**: `prometheus.lisp` (cl-prometheus).
* **–≠–∫—Å–ø–æ–∑–∏—Ç–æ—Ä**: –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π HTTP-—Å–µ—Ä–≤–µ—Ä –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ (Hunchentoot).
* **–ü–æ—Ä—Ç**: `50053` (—ç–Ω–¥–ø–æ–∏–Ω—Ç `/metrics`).
* **–§–æ—Ä–º–∞—Ç**: OpenMetrics / Prometheus text format.

## 3. –ü–µ—Ä–µ—á–µ–Ω—å –º–µ—Ç—Ä–∏–∫ (SRE Golden Signals)

### 3.1. –¢—Ä–∞—Ñ–∏–∫ –∏ –û—à–∏–±–∫–∏ (Counters)
| –ù–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ | –¢–∏–ø | –û–ø–∏—Å–∞–Ω–∏–µ | –ú–µ—Ç–∫–∏ (Labels) |
| :--- | :--- | :--- | :--- |
| `dsl_requests_total` | Counter | –û–±—â–µ–µ –∫–æ–ª-–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ | `status` (ok, error) |
| `dsl_errors_total` | Counter | –ö–æ–ª-–≤–æ –æ—à–∏–±–æ–∫ —Ä–∞–∑–±–æ—Ä–∞ | `error_type` (syntax, timeout, internal) |

### 3.2. –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (Histograms)
| –ù–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ | –¢–∏–ø | –û–ø–∏—Å–∞–Ω–∏–µ | Buckets |
| :--- | :--- | :--- | :--- |
| `dsl_parse_duration_seconds` | Histogram | –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ | `.0001, .0005, .001, .002, .005, .01` |

### 3.3. –†–µ—Å—É—Ä—Å—ã (Gauges)
| –ù–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ | –¢–∏–ø | –û–ø–∏—Å–∞–Ω–∏–µ |
| :--- | :--- | :--- |
| `dsl_active_workers` | Gauge | –ö–æ–ª-–≤–æ –ø–æ—Ç–æ–∫–æ–≤, –∑–∞–Ω—è—Ç—ã—Ö –ø–∞—Ä—Å–∏–Ω–≥–æ–º –≤ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç |
| `dsl_memory_usage_bytes` | Gauge | –¢–µ–∫—É—â–∏–π –æ–±—ä–µ–º –ø–∞–º—è—Ç–∏, –∑–∞–Ω—è—Ç—ã–π Lisp-–∫—É—á–µ–π (SBCL heap) |

## 4. –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
1. **Thread Safety**: –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—á–µ—Ç—á–∏–∫–æ–≤ –º–µ—Ç—Ä–∏–∫ –Ω–µ –¥–æ–ª–∂–Ω–æ –ø—Ä–∏–≤–æ–¥–∏—Ç—å –∫ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞–º –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞—Ç–æ–º–∞—Ä–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏).
2. **Isolation**: –°–±–æ–π –≤ –ø–æ–¥—Å–∏—Å—Ç–µ–º–µ –º–µ—Ç—Ä–∏–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∑–∞–≤–∏—Å–∞–Ω–∏–µ HTTP-–ø–æ—Ä—Ç–∞) –Ω–µ –¥–æ–ª–∂–µ–Ω –≤–ª–∏—è—Ç—å –Ω–∞ —Ä–∞–±–æ—Ç—É gRPC.
3. **Efficiency**: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–æ–ª–∂–Ω–æ –∑–∞–Ω–∏–º–∞—Ç—å –º–µ–Ω–µ–µ **1%** –æ—Ç –æ–±—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞.



--- END_FILE: ./doc/DSL_METRICS_REQUIREMENTS.md ---

--- START_FILE: ./doc/architecture-IN.md ---
cat << 'EOF' > ebusta_arch_spec.md
# –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Ebusta (Orchestration Model)

**–î–∞—Ç–∞:** 05.01.2026
**–°—Ç–∞—Ç—É—Å:** –£—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ
**–ú–æ–¥–µ–ª—å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è:** –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è (Orchestration)

## 1. –û–±–∑–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
–°–∏—Å—Ç–µ–º–∞ —Å—Ç—Ä–æ–∏—Ç—Å—è –Ω–∞ –±–∞–∑–µ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ (**Orchestrator**), –∫–æ—Ç–æ—Ä—ã–π –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É ¬´—Ç–æ–Ω–∫–∏—Ö¬ª –∞–¥–∞–ø—Ç–µ—Ä–æ–≤, –ø–∞—Ä—Å–µ—Ä–∞ DSL –∏ —Å–µ—Ä–≤–∏—Å–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É–¥–∞–ª–µ–Ω–Ω–æ–º —Ö–æ—Å—Ç–µ Mercury.

### –ö–ª—é—á–µ–≤—ã–µ —É–∑–ª—ã:
1. **Adapters (The Door)**: SSH/BBS, Telegram, Web. –ü—Ä–∏–Ω–∏–º–∞—é—Ç –≤–≤–æ–¥, –ø–µ—Ä–µ–¥–∞—é—Ç –µ–≥–æ –≤ Core, –ø–æ–ª—É—á–∞—é—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ —Ä–µ–Ω–¥–µ—Ä—è—Ç –µ–≥–æ.
2. **Orchestrator (Core)**: –õ–æ–≥–∏—á–µ—Å–∫–∏–π —Ü–µ–Ω—Ç—Ä. –£–ø—Ä–∞–≤–ª—è–µ—Ç –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –∑–∞–ø—Ä–æ—Å–∞.
3. **Parser**: –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Å—Ç—Ä–æ–∫–∏ –≤ `libraryv1.SearchQuery`.
4. **Data Manager (Mercury Proxy)**: gRPC-—Å–µ—Ä–≤–∏—Å, —Ç—Ä–∞–Ω—Å–ª–∏—Ä—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å—ã –≤ OpenSearch (Docker –Ω–∞ Mercury).

## 2. –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è UnifiedMessage
`UnifiedMessage` —è–≤–ª—è–µ—Ç—Å—è –µ–¥–∏–Ω—ã–º —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–º –≤–Ω—É—Ç—Ä–∏ —Å–∏—Å—Ç–µ–º—ã.

```protobuf
message UnifiedMessage {
    string request_id = 1;
    
    // –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏
    message Context {
        string client_id = 1;
        enum SourceType {
            BBS = 0;
            TELEGRAM = 1;
            WEB = 2;
        }
        SourceType source = 2;
    }
    Context context = 2;

    // –ü–æ–ª–µ–∑–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ (Payload)
    oneof content {
        libraryv1.SearchQuery query = 3;  // –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        SearchResult result = 4;          // –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ OpenSearch
        string error = 5;                 // –û–ø–∏—Å–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
    }
}

--- END_FILE: ./doc/architecture-IN.md ---

--- START_FILE: ./doc/architecture.md ---
# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã "Eboost-Library" (v2.0)

## 1. –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
[cite_start]–í–ª–∞–¥–µ–ª—å—Ü—ã –±–æ–ª—å—à–∏—Ö –ª–∏—á–Ω—ã—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö –∫–Ω–∏–≥ —á–∞—Å—Ç–æ —Å—Ç–∞–ª–∫–∏–≤–∞—é—Ç—Å—è —Å –ø—Ä–æ–±–ª–µ–º–æ–π "–º–µ—Ä—Ç–≤–æ–≥–æ –≥—Ä—É–∑–∞": –∫–Ω–∏–≥–∏ —Ö—Ä–∞–Ω—è—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ, –Ω–æ –¥–æ—Å—Ç—É–ø –∫ –Ω–∏–º –∏–∑–≤–Ω–µ (—Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞, –≤ –¥–æ—Ä–æ–≥–µ, –¥–ª—è –¥—Ä—É–∑–µ–π) –æ–≥—Ä–∞–Ω–∏—á–µ–Ω –∏–ª–∏ –Ω–µ—É–¥–æ–±–µ–Ω[cite: 1, 3]. –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ä–µ—à–µ–Ω–∏—è –ª–∏–±–æ —Å–ª–∏—à–∫–æ–º —Ç—è–∂–µ–ª–æ–≤–µ—Å–Ω—ã, –ª–∏–±–æ –ø—Ä–∏–≤—è–∑–∞–Ω—ã –∫ –æ–¥–Ω–æ–º—É –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É. [cite_start]–ù–µ–æ–±—Ö–æ–¥–∏–º–∞ —Å–∏—Å—Ç–µ–º–∞, –∫–æ—Ç–æ—Ä–∞—è –∞–±—Å—Ç—Ä–∞–≥–∏—Ä—É–µ—Ç —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏ –ø–æ–∏—Å–∫, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—è –µ–¥–∏–Ω—ã–π –¥–æ—Å—Ç—É–ø —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω—ã–µ –∫–∞–Ω–∞–ª—ã –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è[cite: 3, 39].

## 2. –ü—Ä–µ–¥–º–µ—Ç–Ω–∞—è –æ–±–ª–∞—Å—Ç—å (DDD Contexts)
–°–æ–≥–ª–∞—Å–Ω–æ –ø—Ä–∏–Ω—Ü–∏–ø–∞–º Domain-Driven Design, —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–∑–¥–µ–ª–µ–Ω–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã:
* [cite_start]**Interaction (–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ):** –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ (Telegram, IRC, CLI) –≤ –µ–¥–∏–Ω—ã–π –±–∏–∑–Ω–µ—Å-—è–∑—ã–∫ —Å–∏—Å—Ç–µ–º—ã `UnifiedMessage`[cite: 4, 14].
* [cite_start]**Identity & Access (–î–æ—Å—Ç—É–ø):** –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –ø–æ Bot Token –∏–ª–∏ –±–µ–ª—ã–º —Å–ø–∏—Å–∫–∞–º[cite: 6].
* [cite_start]**Library Core (–Ø–¥—Ä–æ):** –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ —Ä–∞–∑–±–æ—Ä–∞ –∫–æ–º–∞–Ω–¥, –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤[cite: 14, 15].
* [cite_start]**Catalog (–ö–∞—Ç–∞–ª–æ–≥):** –ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∫–Ω–∏–≥ –≤ OpenSearch[cite: 19, 21].
* [cite_start]**Delivery (–î–æ—Å—Ç–∞–≤–∫–∞):** –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –∏–ª–∏ –±–∏–Ω–∞—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö[cite: 25, 27].

## 3. –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã

### –°–ª–æ–π –∞–¥–∞–ø—Ç–µ—Ä–æ–≤ (Front-end)
* [cite_start]**TelegramAdapter:** –†–µ–∞–ª–∏–∑—É–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –±–æ—Ç–∞, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç Webhook/Long Polling[cite: 4].
* [cite_start]**IrcAdapter:** –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å-–∫–ª–∏–µ–Ω—Ç –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ IRC-—Å–µ—Ä–≤–µ—Ä–∞–º –∏ –∫–∞–Ω–∞–ª–∞–º[cite: 6, 7].
* [cite_start]**CliAdapter:** –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ (Linux CLI) –¥–ª—è —É–¥–∞–ª–µ–Ω–Ω–æ–≥–æ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ —è–¥—Ä—É[cite: 10, 11].
* [cite_start]**Translator (New):** –ö–æ–º–ø–æ–Ω–µ–Ω—Ç –≤–Ω—É—Ç—Ä–∏ –∞–¥–∞–ø—Ç–µ—Ä–æ–≤ –∏–ª–∏ –ø–µ—Ä–µ–¥ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º, –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—â–∏–π `RawPayload` –≤ `UnifiedMessage`[cite: 30].

### –°–ª–æ–π —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è
* **Auth-Manager (New):** –ü—Ä–æ–≤–µ—Ä—è–µ—Ç UserID –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –≤ Allow-–ª–∏—Å—Ç–∞—Ö –∏–ª–∏ –≤–Ω–µ—à–Ω–∏—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞—Ö (Keycloak).
* **Session-Manager (New):** –ü—Ä–æ–∫—Å–∏ –∫ **Redis** –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–∏—Å–∫–∞ –∏ —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∫–∞—Ç–∞–ª–æ–≥–µ.
* [cite_start]**Config-Manager:** –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤, —à–∞–±–ª–æ–Ω–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤ –∏ –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏[cite: 22, 23].

### –°–ª–æ–π –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∏ (Core)
* [cite_start]**Processor:** –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å, –≤—ã–ø–æ–ª–Ω—è—é—â–∏–π —Ä–∞–∑–±–æ—Ä –∫–æ–º–∞–Ω–¥ (/book, /author) –∏ –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É—é—â–∏–π –¥—Ä—É–≥–∏–µ —Å–ª—É–∂–±—ã[cite: 14, 15, 17].

### –°–ª–æ–π –¥–∞–Ω–Ω—ã—Ö –∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
* [cite_start]**Data-Manager:** –ü—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–∏—Å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ **OpenSearch**[cite: 19, 21].
* [cite_start]**Book-Fetcher:** –°–µ—Ä–≤–∏—Å –≤—ã–¥–∞—á–∏ —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–ª—é—á—É –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∏–ª–∏ –æ–±—ä–µ–∫—Ç–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞[cite: 25, 26, 28].

## 4. –ü–æ—Ç–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö

### –ü–æ–∏—Å–∫ –∫–Ω–∏–≥–∏
1.  [cite_start]**–ê–¥–∞–ø—Ç–µ—Ä** (TG/IRC/CLI) –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –≤–≤–æ–¥ –∏ —á–µ—Ä–µ–∑ **Translator** —Å–æ–∑–¥–∞–µ—Ç `UnifiedMessage`[cite: 30].
2.  **Auth-Manager** –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –ø—Ä–∞–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
3.  [cite_start]**Processor** –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —É **Data-Manager**[cite: 31].
4.  **Processor** —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç ID —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ **Session-Manager** (Redis) –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏.
5.  [cite_start]–§–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –æ—Ç–≤–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —á–µ—Ä–µ–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∞–¥–∞–ø—Ç–µ—Ä[cite: 32, 33].

### –ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
1.  [cite_start]–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±–∏—Ä–∞–µ—Ç –∫–Ω–∏–≥—É –∏ —Ñ–æ—Ä–º–∞—Ç[cite: 34].
2.  [cite_start]**Processor** –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –∏–ª–∏ —Å—Å—ã–ª–∫—É —É **Book-Fetcher**[cite: 35, 36].
3.  [cite_start]**Book-Fetcher** –æ–±—Ä–∞—â–∞–µ—Ç—Å—è –∫ **Book Storage** –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç[cite: 37, 38].

## 5. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ (Go Layout)
```text
.
‚îú‚îÄ‚îÄ cmd/                # –¢–æ—á–∫–∏ –≤—Ö–æ–¥–∞ (main.go) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–¥–∞–ø—Ç–µ—Ä–∞
‚îú‚îÄ‚îÄ internal/           # –ü—Ä–∏–≤–∞—Ç–Ω—ã–π –∫–æ–¥ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ domain/         # –ß–∏—Å—Ç—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (Book, User, UnifiedMessage)
‚îÇ   ‚îú‚îÄ‚îÄ processor/      # –Ø–¥—Ä–æ (–±–∏–∑–Ω–µ—Å-—Å—Ü–µ–Ω–∞—Ä–∏–∏)
‚îÇ   ‚îú‚îÄ‚îÄ auth/           # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –∏ –¥–æ—Å—Ç—É–ø
‚îÇ   ‚îú‚îÄ‚îÄ session/        # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Redis
‚îÇ   ‚îú‚îÄ‚îÄ translator/     # –õ–æ–≥–∏–∫–∞ –º–∞–ø–ø–∏–Ω–≥–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ storage/        # –ö–ª–∏–µ–Ω—Ç—ã OpenSearch (Data-Manager) –∏ FS (Fetcher)
‚îÇ   ‚îî‚îÄ‚îÄ config/         # Config-Manager –∏ –∑–∞–≥—Ä—É–∑–∫–∞ .env/yaml
‚îú‚îÄ‚îÄ pkg/                # –ü—É–±–ª–∏—á–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
‚îú‚îÄ‚îÄ api/                # –ü—Ä–æ—Ç–æ–∫–æ–ª—ã –æ–±–º–µ–Ω–∞ (gRPC/Proto –∏–ª–∏ OpenAPI)
‚îî‚îÄ‚îÄ deployments/        # Docker-compose –∏ –º–∞–Ω–∏—Ñ–µ—Å—Ç—ã

--- END_FILE: ./doc/architecture.md ---

--- START_FILE: ./doc/RUNBOOK_GRPC.md ---
# RUNBOOK: –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ gRPC –∏ DSL –ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞ (Common Lisp)

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —è–≤–ª—è–µ—Ç—Å—è –æ—Å–Ω–æ–≤–Ω—ã–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º –ø–æ —Ä–∞–±–æ—Ç–µ —Å Lisp-—Å–µ—Ä–≤–∏—Å–∞–º–∏ –≤ –ø—Ä–æ–µ–∫—Ç–µ **EBusta**.

---

## 1. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

–°–∏—Å—Ç–µ–º–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞ –Ω–∞ –±–∞–∑–µ `cl-protobufs` –∏ –æ–±–µ—Ä—Ç–∫–∏ –Ω–∞–¥ C++ gRPC core.

### –§–∞–π–ª–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
* `grpc/`: –ü–æ–¥–º–æ–¥—É–ª—å —Å Lisp-–±–∏–Ω–¥–∏–Ω–≥–∞–º–∏ gRPC. –°–æ–¥–µ—Ä–∂–∏—Ç `grpc.so` –∏ –º–∞–∫—Ä–æ—Å—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–µ—Ä–≤–µ—Ä–æ–≤.
* `lisp-converter/search.proto`: –ö–æ–Ω—Ç—Ä–∞–∫—Ç Protobuf. –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è `SearchQuery`, `LogicalNode` (AND/OR) –∏ `FilterNode`.
* `lisp-converter/dsl-service.lisp`: –°–µ—Ä–≤–µ—Ä–Ω–∞—è –ª–æ–≥–∏–∫–∞. –°–æ–¥–µ—Ä–∂–∏—Ç —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–∞—Ä—Å–µ—Ä S-–≤—ã—Ä–∞–∂–µ–Ω–∏–π.
* `lisp-converter/dsl-client.lisp`: –¢–µ—Å—Ç–æ–≤—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.

---

## 2. –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è DSL (S-Expressions)

–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç Lisp-—Å–∏–Ω—Ç–∞–∫—Å–∏—Å –≤ —Å—Ç—Ä–æ–≥–æ —Ç–∏–ø–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ Protobuf-–æ–±—ä–µ–∫—Ç—ã:

| DSL –ü—Ä–∏–º–µ—Ä | –¢–∏–ø Node | Protobuf —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ |
| :--- | :--- | :--- |
| `(:field "title" "Lisp")` | **Filter** | `field: "title", value: "Lisp", op: 1` |
| `(:and ... ...)` | **Logical** | `op: 1 (AND), nodes: [...]` |
| `(:or ... ...)` | **Logical** | `op: 2 (OR), nodes: [...]` |

**–ü—Ä–∏–º–µ—Ä —Å–ª–æ–∂–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞:**
`(:and (:field "title" "Lisp") (:or (:field "author" "Serge") (:field "author" "Reva")))`

---

## 3. –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∑–∞–ø—É—Å–∫—É

### –ê. –£—Ä–æ–≤–µ–Ω—å: Example (SayHello)
–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∑–æ–≤–æ–π —Å–≤—è–∑–Ω–æ—Å—Ç–∏ (–ø–æ—Ä—Ç `50051`).

1.  **–°–µ—Ä–≤–µ—Ä:** `bash ~/projects/ebusta/lisp-converter/run_example_server.sh`
2.  **–ö–ª–∏–µ–Ω—Ç (Lisp):** `bash ~/projects/ebusta/lisp-converter/run_example_client.sh`
3.  **–ö–ª–∏–µ–Ω—Ç (grpcurl):**
    ```bash
    ~/projects/ebusta/lisp-converter/grpcurl -plaintext \
        -import-path ~/projects/ebusta/lisp-converter/ \
        -proto ~/projects/ebusta/lisp-converter/helloworld.proto \
        -d '{"name": "Admin"}' localhost:50051 \
        cl_protobufs.lisp.grpc.integration_testing.Greeter/SayHello
    ```

### –ë. –£—Ä–æ–≤–µ–Ω—å: Production (DSL Converter)
–û—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ä–≤–∏—Å —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏–∏ (–ø–æ—Ä—Ç `50052`).

1.  **–°–µ—Ä–≤–µ—Ä:** `bash ~/projects/ebusta/lisp-converter/run_dsl_server.sh`
2.  **–ö–ª–∏–µ–Ω—Ç (Lisp):** `bash ~/projects/ebusta/lisp-converter/run_dsl_client.sh`
3.  **–ö–ª–∏–µ–Ω—Ç (grpcurl):**
    ```bash
    ~/projects/ebusta/lisp-converter/grpcurl -plaintext \
        -import-path ~/projects/ebusta/lisp-converter/ \
        -proto ~/projects/ebusta/lisp-converter/search.proto \
        -d '{"raw_query": "(:and (:field \"title\" \"Lisp\") (:field \"author\" \"Serge\"))"}' \
        localhost:50052 ebusta.library.v1.MessageConverter/Convert
    ```

---

## 4. SRE: –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–µ–π

### –ü–æ—Ä—Ç—ã –∏ –ø—Ä–æ—Ü–µ—Å—Å—ã
–ï—Å–ª–∏ —Å–µ—Ä–≤–µ—Ä –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è (Address already in use):
* `fuser -k 50051/tcp` (–¥–ª—è Example)
* `fuser -k 50052/tcp` (–¥–ª—è DSL)

### –ü—É—Ç–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (ASDF)
–°–µ—Ä–≤–µ—Ä—ã –ø–æ–ª–∞–≥–∞—é—Ç—Å—è –Ω–∞ `asdf:*central-registry*`. –ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –æ—à–∏–±–∫–∞ `Failed to find TRUENAME`, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤ —Å–∫—Ä–∏–ø—Ç–∞—Ö –∑–∞–ø—É—Å–∫–∞ —É–∫–∞–∑–∞–Ω –≤–µ—Ä–Ω—ã–π –ø—É—Ç—å –∫ –ø–æ–¥–º–æ–¥—É–ª—é `grpc`:
`~/projects/ebusta/grpc/`

### –ü–∞–∫–µ—Ç—ã –∏ —Å–∏–º–≤–æ–ª—ã
–ï—Å–ª–∏ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–µ—Ç–æ–¥–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç `TYPE-ERROR ... is not of type GRPC::METHOD-DETAILS`:
1.  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–ª–Ω–æ–µ –∏–º—è —Å–µ—Ä–≤–∏—Å–∞ –≤ –ª–æ–≥–∞—Ö —Å–µ—Ä–≤–µ—Ä–∞.
2.  –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ `grpcurl` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ—Ä–Ω—ã–π –ø—É—Ç—å: `ebusta.library.v1.MessageConverter/Convert`.

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ grpcurl
–í—Å–µ–≥–¥–∞ —É–∫–∞–∑—ã–≤–∞–π—Ç–µ `-import-path`, –∏–Ω–∞—á–µ `grpcurl` –Ω–µ —Å–º–æ–∂–µ—Ç –Ω–∞–π—Ç–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ `.proto` —Ñ–∞–π–ª–∞—Ö –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö –ø—É—Ç–µ–π.

---

## 5. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤
–ü—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ `.proto` —Ñ–∞–π–ª–æ–≤ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ:
1.  –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–µ—Ä (ASDF –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ—Å–æ–±–µ—Ä–µ—Ç `.lisp` —Ñ–∞–π–ª—ã –∏–∑ `.proto`).
2.  –ï—Å–ª–∏ –¥–æ–±–∞–≤–∏–ª–∏—Å—å –Ω–æ–≤—ã–µ –ø–æ–ª—è, –æ–±–Ω–æ–≤–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é `parse-dsl` –≤ `dsl-service.lisp`.

--- END_FILE: ./doc/RUNBOOK_GRPC.md ---

--- START_FILE: ./doc/DSL_INPUT_OUTPUT_SPEC.md ---
# –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –∏ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö DSL-–ø–∞—Ä—Å–µ—Ä–∞

## 1. –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (Input)
–í—Ö–æ–¥–æ–º —è–≤–ª—è–µ—Ç—Å—è —Ç–µ–∫—Å—Ç–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ DSL. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è:
* **–õ–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã**: `AND`, `OR`, `NOT` (—Ä–µ–≥–∏—Å—Ç—Ä–æ–∑–∞–≤–∏—Å–∏–º—ã–µ).
* **–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞**: –ö—Ä—É–≥–ª—ã–µ —Å–∫–æ–±–∫–∏ `(...)`.
* **–ü–æ–ª—è (Scoped Search)**: `field:value` –∏–ª–∏ `field:"multi word value"`.
* **–†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è**: `/pattern/`.
* **–ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫**: –°–ª–æ–≤–∞ –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –ø–æ–ª—è (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–ª—É—á–∞—é—Ç –ø–æ–ª–µ `any`).

**–ü—Ä–∏–º–µ—Ä —Å–ª–æ–∂–Ω–æ–≥–æ –≤—Ö–æ–¥–∞:**
`author:"–°—Ç–∏–≤–µ–Ω –ö–∏–Ω–≥" AND (title:–ö—É–¥–∂–æ OR tags:/horror/)`

---

## 2. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ (S-Expression)
–í–Ω—É—Ç—Ä–∏ —è–¥—Ä–∞ –Ω–∞ Common Lisp —Å—Ç—Ä–æ–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ –¥–µ—Ä–µ–≤–æ (S-expression). –≠—Ç–æ —Ñ–æ—Ä–º–∞—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –ª–æ–≥–∏–∫–∏ —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏–∏.

**–†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏:**
```lisp
(:AND 
  (:FIELD "author" "–°—Ç–∏–≤–µ–Ω –ö–∏–Ω–≥") 
  (:OR 
    (:FIELD "title" "–ö—É–¥–∂–æ") 
    (:FIELD "tags" "horror" :OP :REGEX)))
3. –í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (gRPC / Protobuf)
–§–∏–Ω–∞–ª—å–Ω—ã–π –≤—ã—Ö–æ–¥ —Å–µ—Ä–≤–∏—Å–∞ ‚Äî —ç—Ç–æ –±–∏–Ω–∞—Ä–Ω—ã–π –æ–±—ä–µ–∫—Ç Protobuf. –ù–∏–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ JSON-–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —ç—Ç–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ–ª—É—á–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç.

–ü—Ä–∏–º–µ—Ä –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—ã—Ö–æ–¥–∞:
Bash

~/projects/ebusta/lisp-converter/grpcurl -plaintext \
    -import-path ~/projects/ebusta/lisp-converter \
    -proto ~/projects/ebusta/lisp-converter/search.proto \
    -d '{"raw_query": "author:\"–°—Ç–∏–≤–µ–Ω –ö–∏–Ω–≥\" AND (title:–ö—É–¥–∂–æ OR tags:/horror/)"}' \
    localhost:50052 ebusta.library.v1.MessageConverter/Convert
–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞ (JSON View):
JSON

{
  "requestId": "req-1737898956",
  "logical": {
    "op": "AND",
    "nodes": [
      {
        "filter": {
          "field": "author",
          "value": "–°—Ç–∏–≤–µ–Ω –ö–∏–Ω–≥",
          "operator": "EQUALS"
        }
      },
      {
        "logical": {
          "op": "OR",
          "nodes": [
            {
              "filter": {
                "field": "title",
                "value": "–ö—É–¥–∂–æ",
                "operator": "EQUALS"
              }
            },
            {
              "filter": {
                "field": "tags",
                "value": "horror",
                "operator": "REGEX"
              }
            }
          ]
        }
      }
    ]
  },
  "canonicalForm": "(:AND (:FIELD \"author\" \"–°—Ç–∏–≤–µ–Ω –ö–∏–Ω–≥\") (:OR (:FIELD \"title\" \"–ö—É–¥–∂–æ\") (:FIELD \"tags\" \"horror\" :OP :REGEX)))"
}
4. –ó–∞–º–µ—Ç–∫–∏ –¥–ª—è SRE
request_id: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è —Å–µ—Ä–≤–µ—Ä–æ–º –¥–ª—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã.

canonical_form: –°—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–µ—Ä–µ–≤–∞. –ò–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∫–ª—é—á–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è (Redis/In-memory).

operator: –ü–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ (Enum), –∫–æ—Ç–æ—Ä–æ–µ –∂–µ—Å—Ç–∫–æ –∑–∞–¥–∞–µ—Ç —Ç–∏–ø –ø–æ–∏—Å–∫–∞ (EQUALS, REGEX –∏ —Ç.–¥.), –∏–∑–±–∞–≤–ª—è—è –Ω–∏–∂–µ–ª–µ–∂–∞—â–∏–µ —Å–µ—Ä–≤–∏—Å—ã –æ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä–æ–∫–∏. EOF

--- END_FILE: ./doc/DSL_INPUT_OUTPUT_SPEC.md ---

--- START_FILE: ./doc/DSL_V19_INTEGRATION_WBS.md ---
# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è EBusta DSL Engine V19

## 1. –ê–∫—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ (Pipeline)

**–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–±–æ—Ä**: Orchestrator –ø–µ—Ä–µ–¥–∞–µ—Ç —Å—ã—Ä—É—é —Å—Ç—Ä–æ–∫—É –≤ **dsl-converter** (EBusta DSL Engine V19). –°–µ—Ä–≤–∏—Å –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É `50052` —Å –ø—É–ª–æ–º –∏–∑ 8 –≤–æ—Ä–∫–µ—Ä–æ–≤ –∏ –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–º Verbose-–ª–æ–≥–æ–º –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –û–Ω –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –≤ –¥–µ—Ä–µ–≤–æ AST (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤—ã–¥–µ–ª—è–µ—Ç –ø–æ–ª—è `author:` –∏–ª–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã `AND`), –≤–æ–∑–≤—Ä–∞—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Protobuf-–æ—Ç–≤–µ—Ç.

---

## 2. Work Breakdown Structure (WBS)

### 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ (Engine V19)
* **1.1. –ö–æ–º–ø–∏–ª—è—Ü–∏—è**: –°–±–æ—Ä–∫–∞ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –±–∏–Ω–∞—Ä–Ω–∏–∫–∞ `dsl-converter` (49MB) —á–µ—Ä–µ–∑ `make build-bin`.
* **1.2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è SRE**: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–ø—É—Å–∫–∞ (Workers: 8, Port: 50052, Verbose: NIL).
* **1.3. CLI Validation**: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–ª–∞–≥–∞ `--verbose` –≤ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ä–µ–¥–µ.

### 2. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Orchestrator
* **2.1. –£–¥–∞–ª–µ–Ω–∏–µ Legacy**: –í—ã–ø–∏–ª–∏–≤–∞–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `internal/parser` –∏–∑ –∫–æ–¥–∞ Orchestrator.
* **2.2. gRPC Client**: –†–µ–∞–ª–∏–∑–∞—Ü–∏—è/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ gRPC –∫–ª–∏–µ–Ω—Ç–∞ –≤ Orchestrator –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å `MessageConverter/Convert`.
* **2.3. Error Handling**: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ—Ç–µ–≤—ã—Ö —Ç–∞–π–º–∞—É—Ç–æ–≤ –∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞ `dsl-converter`.

### 3. –ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ QA
* **3.1. –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ—Ñ–∏–ª—å**: –ó–∞–ø—É—Å–∫ `ghz` —Å –Ω–∞–≥—Ä—É–∑–∫–æ–π 200 RPS (Target Average < 0.8ms).
* **3.2. Stress Test**: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–∫–∏ –æ—Ç–∫–∞–∑–∞ –ø—Ä–∏ 1000+ RPS –Ω–∞ 8 –≤–æ—Ä–∫–µ—Ä–∞—Ö.
* **3.3. Regression**: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è (Compliance) —á–µ—Ä–µ–∑ `test_compliance.sh`.

### 4. –ù–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç—å (Observability)
* **4.1. Logging Strategy**: –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ª–æ–≥–æ–≤ –≤ Silent-—Ä–µ–∂–∏–º–µ –∏ –∏—Ö –Ω–∞–ª–∏—á–∏—è –≤ Verbose.
* **4.2. –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞**: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥–∞—á–∏ `request_id` –æ—Ç Orchestrator —á–µ—Ä–µ–∑ DSL Engine –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π AST.

---

## 3. –ú–∞—Ç—Ä–∏—Ü–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è (Updated)

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –†–æ–ª—å | –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ | –°—Ç–µ–∫ |
| :--- | :--- | :--- | :--- |
| **Orchestrator** | –ö–ª–∏–µ–Ω—Ç | –ü–µ—Ä–µ–¥–∞–µ—Ç `raw_query` | Go / Java / CLI |
| **dsl-converter** | –°–µ—Ä–≤–∏—Å | –í—ã–ø–æ–ª–Ω—è–µ—Ç Shunting-yard (V19) | Common Lisp (SBCL) |
| **gRPC/Proto** | –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç | –ë–∏–Ω–∞—Ä–Ω–∞—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è | Port 50052 |


--- END_FILE: ./doc/DSL_V19_INTEGRATION_WBS.md ---

--- START_FILE: ./doc/ARCHITECTURE.md ---
# Ebusta: –°–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –∏ –¥–æ—Å—Ç–∞–≤–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã (Pipeline)

–°–∏—Å—Ç–µ–º–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞ –Ω–∞ –ø—Ä–∏–Ω—Ü–∏–ø–∞—Ö –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º gRPC –¥–ª—è –º–µ–∂—Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è. –í–µ—Å—å –ø—É—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–æ –¥–∞–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–µ–Ω –Ω–∞ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç—Ç–∞–ø—ã.

### –°—Ö–µ–º–∞ –ø–æ—Ç–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö (Data Flow)
`User Input -> Adapter -> MessageConverter -> Processor -> Data-Manager`

---

## –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã

### 1. Adapters (–í—Ö–æ–¥–Ω—ã–µ —à–ª—é–∑—ã)
**–ü—Ä–∏–º–µ—Ä:** `cmd/web-adapter`
- **–§—É–Ω–∫—Ü–∏—è:** –ü—Ä–∏–µ–º —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤ (HTTP, TG, IRC).
- **–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å:** –¢–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤–Ω–µ—à–Ω–∏–µ –∑–∞–ø—Ä–æ—Å—ã –≤ gRPC-–≤—ã–∑–æ–≤ `MessageConverter.Convert`.

### 2. MessageConverter (–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä)
**–ü—É—Ç—å:** `cmd/message-converter`
- **–§—É–Ω–∫—Ü–∏—è:** –ü–∞—Ä—Å–∏–Ω–≥ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è.
- **–ó–∞–¥–∞—á–∞:** –ò–∑–≤–ª–µ–∫–∞–µ—Ç "–ù–∞–º–µ—Ä–µ–Ω–∏–µ" (Intent) –∏ –æ—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (Payload).
- **UnifiedMessage:** –û–±—ä–µ–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ `Processor` –ø–æ–ª—É—á–∏—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞.

### 3. Processor (–ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞ / –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä)
**–ü—É—Ç—å:** `cmd/processor`
- **–§—É–Ω–∫—Ü–∏—è:** –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∏ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏–π.
- **–õ–æ–≥–∏–∫–∞:**
    - –ï—Å–ª–∏ `Intent == "search"`, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —É `Data-Manager`.
    - –ï—Å–ª–∏ `Intent == "download"`, –∏–Ω–∏—Ü–∏–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–≥—Ä—É–∑–∫–∏.

### 4. Data-Manager (–°–ª–æ–π –¥–∞–Ω–Ω—ã—Ö)
**–ü—É—Ç—å:** `cmd/data-manager`
- **–§—É–Ω–∫—Ü–∏—è:** –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫ –ø–æ–∏—Å–∫–æ–≤–æ–º—É –¥–≤–∏–∂–∫—É (OpenSearch).
- **–ó–∞–¥–∞—á–∞:** –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—Ç —Å–ø–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤ `Book`.

---

## –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫
- **–Ø–∑—ã–∫:** Go (Golang)
- **–°–≤—è–∑—å:** gRPC (Protocol Buffers v3)
- **–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:** Logrus
- **–°–±–æ—Ä–∫–∞:** Makefile

## –ü–æ—Ä—Ç—ã –∏ –∞–¥—Ä–µ—Å–∞ (Service Map)
| –°–µ—Ä–≤–∏—Å            | –ü–æ—Ä—Ç   | –ü—Ä–æ—Ç–æ–∫–æ–ª |
|-------------------|--------|----------|
| Data-Manager      | :50051 | gRPC     |
| MessageConverter  | :50052 | gRPC     |
| Processor         | :50053 | gRPC     |
| Web-Adapter       | :8080  | HTTP     |

## –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–æ–º
- `make run` ‚Äî –ó–∞–ø—É—Å–∫ –≤—Å–µ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –≤ —Ñ–æ–Ω–µ.
- `make stop` ‚Äî –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ (—á–µ—Ä–µ–∑ fuser –∏ pkill).
- `make proto` ‚Äî –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ –∏–∑ .proto —Ñ–∞–π–ª–æ–≤.

--- END_FILE: ./doc/ARCHITECTURE.md ---

--- START_FILE: ./doc/DSL_REQUIREMENTS.md ---
# Specification: Ebusta Search DSL (v1.1)

## 1. Goal
–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–≥–æ —è–∑—ã–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–Ω–∏–≥, –∫–æ—Ç–æ—Ä—ã–π —Ç—Ä–∞–Ω—Å–ª–∏—Ä—É–µ—Ç—Å—è –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –¥–µ—Ä–µ–≤–æ (AST) –¥–ª—è –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –¥–≤–∏–∂–∫–∞ Mercury.

## 2. Lexical Atoms (–õ–µ–∫—Å–∏–∫–∞)
- **Action**: `get`, `find`, `list`, `read` (–∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω—ã)
- **Field Prefixes**: `title:`, `author:`, `author_id:`, `desc:`, `id:`,`containder:`,`filename:`
- **Logic Operators**: `AND`, `OR` (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ)
- **Unary Operators**: `NOT`
- **Pattern**: `/regex/` (—Å—Ç—Ä–æ–∫–∞, –æ–±–µ—Ä–Ω—É—Ç–∞—è –≤ –∫–æ—Å—É—é —á–µ—Ä—Ç—É)
- **Literal**: `"exact phrase"`, `simple_word`, `101`

## 3. –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

### UR 1: –ë–∞–∑–æ–≤—ã–π –ø–æ–∏—Å–∫
- **UR 1.1 (Default Search)**: –õ—é–±–æ–π –≤–≤–æ–¥ –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `Unix`) –¥–æ–ª–∂–µ–Ω –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫–∞–∫ –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –ø–æ–ª—è–º (`field: any`).
- **UR 1.2 (Case Insensitivity)**: –ü–æ–∏—Å–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —Ä–µ–≥–∏—Å—Ç—Ä—É.

### UR 2: –¶–µ–ª–µ–≤–æ–π –ø–æ–∏—Å–∫ (Scoping)
- **UR 2.1 (Field Limiting)**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å–∞ `field:` –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –ø–æ–∏—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –º–µ—Ç–∞-–ø–æ–ª–µ–º.
- **UR 2.2 (Regex)**: –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –æ–±–µ—Ä–Ω—É—Ç–æ –≤ `/ /`, —Å–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è (Operator: `OP_REGEX`).

### UR 3: –°–ª–æ–∂–Ω–∞—è –ª–æ–≥–∏–∫–∞ (Boolean)
- **UR 3.1 (Combination)**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ `AND` –∏ `OR` –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —É—Å–ª–æ–≤–∏–π.
- **UR 3.2 (Negation)**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞ `NOT` –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ –≤—ã–¥–∞—á–∏.
- **UR 3.3 (Precedence)**: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤: `NOT` > `AND` > `OR`.

### UR 4: –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å (Feedback)
- **UR 4.1 (Explanation)**: –ö–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç —Å–∏—Å—Ç–µ–º—ã –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø–æ–ª–µ `meta.canonical_form`, –æ—Ç–æ–±—Ä–∞–∂–∞—é—â–µ–µ –¥–µ—Ä–µ–≤–æ —Ä–∞–∑–±–æ—Ä–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.
- **UR 4.2 (Request Tracing)**: –ö–∞–∂–¥–æ–º—É –∑–∞–ø—Ä–æ—Å—É –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç—Å—è `request_id`, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ –≤—Å—é —Ü–µ–ø–æ—á–∫—É (Adapter -> Converter -> Processor -> Mercury).

## 4. –ü—Ä–∏–º–µ—Ä—ã –≤–∞–ª–∏–¥–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- `author:–ö–∏–Ω–≥ AND NOT title:–ö—É–¥–∂–æ`
- `title:/^Unix.*/ OR desc:linux`
- `101` (—Ç—Ä–∞–∫—Ç—É–µ—Ç—Å—è –∫–∞–∫ –ø–æ–∏—Å–∫ ID –∏–ª–∏ –ª—é–±–æ–π –ø–æ–∏—Å–∫ –ø–æ "101")

--- END_FILE: ./doc/DSL_REQUIREMENTS.md ---

--- START_FILE: ./doc/REQUIREMENTS.md ---
# Software Requirements Specification (SRS) - Ebusta Pipeline

–î–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–∞–∂–¥–æ–º—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—É –∫–æ–Ω–≤–µ–π–µ—Ä–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π —Å–∏—Å—Ç–µ–º—ã Ebusta.

---

## 1. Web-Adapter (The Gateway)
**–†–æ–ª—å:** –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–π —à–ª—é–∑ –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö HTTP-–∑–∞–ø—Ä–æ—Å–æ–≤.

* **SR-1.1 (Interface):** –î–æ–ª–∂–µ–Ω –æ–±–µ—Å–ø–µ—á–∏–≤–∞—Ç—å —ç–Ω–¥–ø–æ–∏–Ω—Ç `GET /input?msg=...` –¥–ª—è –ø—Ä–∏–µ–º–∞ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
* **SR-1.2 (Sanity Check):** –î–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å `HTTP 400 Bad Request`, –µ—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä `msg` –ø—É—Å—Ç –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.
* **SR-1.3 (Source Identification):** –û–±—è–∑–∞–Ω –ø—Ä–∏ –≤—ã–∑–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–≤–µ–Ω–∞ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –º–µ—Ç–∫—É `source: "web"`.
* **SR-1.4 (Logic Isolation):** **–ó–∞–ø—Ä–µ—â–µ–Ω–æ** –≤—ã–ø–æ–ª–Ω—è—Ç—å –ø–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞, –ø–æ–∏—Å–∫ –ø–æ–¥—Å—Ç—Ä–æ–∫ –∏–ª–∏ –ª—é–±—É—é –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É.
* **SR-1.5 (Error Handling):** –î–æ–ª–∂–µ–Ω —Ç—Ä–∞–Ω—Å–ª–∏—Ä–æ–≤–∞—Ç—å gRPC-—Å—Ç–∞—Ç—É—Å—ã –æ—à–∏–±–æ–∫ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ HTTP-–∫–æ–¥—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, `Unavailable` -> `503 Service Unavailable`).

---

## 2. MessageConverter (The Semantic Brain)
**–†–æ–ª—å:** –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–±–æ—Ä –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è.

* **SR-2.1 (Normalization):** –î–æ–ª–∂–µ–Ω –≤—ã–ø–æ–ª–Ω—è—Ç—å –æ—á–∏—Å—Ç–∫—É –≤—Ö–æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ (—É–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ).
* **SR-2.2 (Intent Recognition):** –î–æ–ª–∂–µ–Ω –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —Ç–∏–ø –Ω–∞–º–µ—Ä–µ–Ω–∏—è (`Intent`) –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–º–∞–Ω–¥–Ω—ã—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤:
    * `get ` –∏–ª–∏ `download ` -> `intent: "download"`
    * –û—Å—Ç–∞–ª—å–Ω–æ–µ -> `intent: "search"`
* **SR-2.3 (Payload Extraction):** –î–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –≤ –ø–æ–ª–µ `Payload` —Ç–æ–ª—å–∫–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—É—é —á–∞—Å—Ç—å, –æ—á–∏—â–µ–Ω–Ω—É—é –æ—Ç –∫–æ–º–∞–Ω–¥–Ω—ã—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤.
* **SR-2.4 (Stateless):** –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é "–±–µ–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è" (stateless) ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ –∑–∞–≤–∏—Å–∏—Ç —Ç–æ–ª—å–∫–æ –æ—Ç –≤—Ö–æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏.
* **SR-2.5 (Robustness):** –î–æ–ª–∂–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤, –≤–æ–∑–≤—Ä–∞—â–∞—è –æ—à–∏–±–∫—É –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –∏–Ω—Ç–µ–Ω—Ç.

---

## 3. Processor (The Orchestrator)
**–†–æ–ª—å:** –¶–µ–Ω—Ç—Ä –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π –∏ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏.

* **SR-3.1 (Routing):** –û–±—è–∑–∞–Ω –≤—ã–ø–æ–ª–Ω—è—Ç—å –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é –∑–∞–ø—Ä–æ—Å–∞ —Å—Ç—Ä–æ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—è `Intent` –∏–∑ `UnifiedMessage`.
* **SR-3.2 (Service Coordination):**
    * –ü—Ä–∏ `search`: –í—ã–∑—ã–≤–∞–µ—Ç `Data-Manager.Search()`.
    * –ü—Ä–∏ `download`: (–ë—É–¥—É—â–µ–µ) –í—ã–∑—ã–≤–∞–µ—Ç `Download-Manager`.
* **SR-3.3 (Data Aggregation):** –î–æ–ª–∂–µ–Ω —É–ø–∞–∫–æ–≤—ã–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –æ—Ç –Ω–∏–∂–µ—Å—Ç–æ—è—â–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –≤ –µ–¥–∏–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É `ActionResponse`.
* **SR-3.4 (Resilience):** –î–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ö–∞–Ω–∏–∑–º—ã `Context Timeout` (–Ω–µ –±–æ–ª–µ–µ 5 —Å–µ–∫—É–Ω–¥ –Ω–∞ –∑–∞–ø—Ä–æ—Å) –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –¥—Ä—É–≥–∏–º —Å–µ—Ä–≤–∏—Å–∞–º.
* **SR-3.5 (Enrichment):** –ò–º–µ–µ—Ç –ø—Ä–∞–≤–æ –¥–æ–±–∞–≤–ª—è—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫ –æ—Ç–≤–µ—Ç—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–ª–∏ —Å—Ç–∞—Ç—É—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è).

---

## 4. Data-Manager (The Storage Interface)
**–†–æ–ª—å:** –ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ª–æ–π –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º.

* **SR-4.1 (Contract Compliance):** –î–æ–ª–∂–µ–Ω –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã `SearchRequest`.
* **SR-4.2 (Zero Context):** **–ó–∞–ø—Ä–µ—â–µ–Ω–æ** –∏–º–µ—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö –∑–∞–ø—Ä–æ—Å–∞ (TG/Web) –∏–ª–∏ –∫–æ–º–∞–Ω–¥–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
* **SR-4.3 (Data Consistency):** –î–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ `Book`, –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
* **SR-4.4 (Performance):** –î–æ–ª–∂–µ–Ω –æ–±–µ—Å–ø–µ—á–∏–≤–∞—Ç—å –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ –∏–Ω–¥–µ–∫—Å—É; –≤ —Å–ª—É—á–∞–µ –º–æ–∫–∞ ‚Äî –∏–º–∏—Ç–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–µ—Ä–∂–∫—É —Å–µ—Ç–∏.
* **SR-4.5 (Safety):** –î–æ–ª–∂–µ–Ω –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö –∑–∞–ø–∏—Å–µ–π (–Ω–µ –±–æ–ª–µ–µ 50 –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å) –¥–ª—è –∑–∞—â–∏—Ç—ã –ø–∞–º—è—Ç–∏ —Å–∏—Å—Ç–µ–º—ã.

---

## –û–±—â–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (Cross-Cutting)
1. **Communication:** –í—Å–µ –º–µ–∂—Å–µ—Ä–≤–∏—Å–Ω–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ gRPC.
2. **Observability:** –ö–∞–∂–¥—ã–π —Å–µ—Ä–≤–∏—Å –æ–±—è–∑–∞–Ω –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–∫—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ—Ä–µ–∑ `logrus`.
3. **Graceful Shutdown:** –í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≤–µ—Ä—à–∞—Ç—å —Ä–∞–±–æ—Ç—É –ø–æ —Å–∏–≥–Ω–∞–ª—É `SIGTERM`, –∑–∞–∫—Ä—ã–≤–∞—è –∞–∫—Ç–∏–≤–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è.

## 5. UnifiedMessage (The Internal Protocol)
**–†–æ–ª—å:** –ï–¥–∏–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –≤–Ω—É—Ç—Ä–∏ —Å–∏—Å—Ç–µ–º—ã.

* **SR-5.1 (Neutrality):** –û–±—ä–µ–∫—Ç –Ω–µ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –¥–ª—è –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–æ–≤ –ø–æ–ª–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, `chat_id` –∏–ª–∏ `irc_channel`). –í—Å—è –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–∞.
* **SR-5.2 (Intent Categorization):** –ü–æ–ª–µ `Intent` –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å—Ç—Ä–æ–≥–æ —Ç–∏–ø–∏–∑–∏—Ä–æ–≤–∞–Ω–æ (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ enum), –æ–ø—Ä–µ–¥–µ–ª—è—é—â–µ–µ –¥–∞–ª—å–Ω–µ–π—à–∏–π –ø—É—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è:
    * `search` ‚Äî –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.
    * `download` ‚Äî –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∞–π–ª–∞.
    * `help` ‚Äî –∑–∞–ø—Ä–æ—Å —Å–∏—Å—Ç–µ–º–Ω–æ–π —Å–ø—Ä–∞–≤–∫–∏.
    * `meta` ‚Äî –∑–∞–ø—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–µ—Ä–≤–∏—Å–µ.
* **SR-5.3 (Payload Integrity):** –ü–æ–ª–µ `Payload` –æ–±—è–∑–∞–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –≥–æ—Ç–æ–≤—ã–µ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ –ø–æ–∏—Å–∫–æ–≤–æ–π –¥–≤–∏–∂–æ–∫ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏.
* **SR-5.4 (Traceability):** (–ë—É–¥—É—â–µ–µ) –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å `CorrelationID` –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—É—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ –ª–æ–≥–∏ –≤—Å–µ—Ö –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤.
* **SR-5.5 (Context Enrichment):** –î–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å –ø–æ–ª–µ `Source` (–æ—Ç–∫—É–¥–∞ –ø—Ä–∏—à–µ–ª –∑–∞–ø—Ä–æ—Å), —á—Ç–æ–±—ã `Processor` –º–æ–≥ –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ –æ –ª–∏–º–∏—Ç–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è Web-–∫–ª–∏–µ–Ω—Ç–æ–≤ –ª–∏–º–∏—Ç—ã –∂–µ—Å—Ç—á–µ, —á–µ–º –¥–ª—è CLI).

--- END_FILE: ./doc/REQUIREMENTS.md ---

--- START_FILE: ./doc/components.md ---
–ö–æ–º–ø–æ–Ω–µ–Ω—Ç,–†–æ–ª—å,–û–ø–∏—Å–∞–Ω–∏–µ,–í—Ö–æ–¥—è—â–∏–µ (In),–ò—Å—Ö–æ–¥—è—â–∏–µ (Out)
Web-Adapter,API Gateway,"–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞. –ü—Ä–∏–Ω–∏–º–∞–µ—Ç HTTP-–∑–∞–ø—Ä–æ—Å—ã, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Trace-ID –∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç —Ü–µ–ø–æ—á–∫–æ–π –≤—ã–∑–æ–≤–æ–≤.",HTTP :8080 (/input?msg=...),"gRPC -> Message-Converter, gRPC -> Processor"
Message-Converter,DSL Parser,–ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –¥–µ—Ä–µ–≤–æ (AST). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç internal/parser.,gRPC :50052 (Convert),–ù–µ—Ç
Processor,Orchestrator,"–Ø–¥—Ä–æ —Å–∏—Å—Ç–µ–º—ã. –†–µ–∞–ª–∏–∑—É–µ—Ç –ª–æ–≥–∏–∫—É AST Walker: –ø–æ–ª—É—á–∞–µ—Ç –¥–µ—Ä–µ–≤–æ, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –∏—Ö.",gRPC :50053 (HandleCommand),gRPC -> Data-Manager (GetData)
Data-Manager,Data Provider,–•—Ä–∞–Ω–∏–ª–∏—â–µ. –ó–∞–≥—Ä—É–∂–∞–µ—Ç books.json –∏ –æ—Ç–¥–∞–µ—Ç —Å—ã—Ä–æ–π —Å–ø–∏—Å–æ–∫ –∫–Ω–∏–≥ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.,gRPC :50051 (GetData),–§–∞–π–ª–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ (books.json)
CLI,UI Client,–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –∫–æ–Ω—Å–æ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏—Å—Ç–æ—Ä–∏–∏ –∫–æ–º–∞–Ω–¥ (readline).,User Input,HTTP -> Web-Adapter
Client,Debug Tool,–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –ø—Ä—è–º–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Data-Manager –≤ –æ–±—Ö–æ–¥ —à–ª—é–∑–æ–≤.,Manual Run,gRPC -> Data-Manager

--- END_FILE: ./doc/components.md ---
